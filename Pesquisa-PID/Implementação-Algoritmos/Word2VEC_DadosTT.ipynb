{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2VEC-DadosTT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NH89Hg6E2N-G",
        "Z76x8Ogm3PTP",
        "qp-5B4aj30LL",
        "leuuGBZCSVMk",
        "I5FfBf044igm"
      ],
      "authorship_tag": "ABX9TyMc8yDfRPjzPDG6kVVjEUDJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/italolima04/monitoria-probabilidade-estatistica/blob/master/Pesquisa-PID/Implementa%C3%A7%C3%A3o-Algoritmos/Word2VEC_DadosTT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH89Hg6E2N-G",
        "colab_type": "text"
      },
      "source": [
        "# Importando Bibliotecas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv8CT8V72VS9",
        "colab_type": "text"
      },
      "source": [
        "**Notebook produzido com base no Artigo: Unsupervised Sentiment Analysis de Rafa≈Ç W√≥jcik e no tutorial: Gensim Word2Vec Tutorial de Pierre Megret**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88WN5wL2dq68",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "296a32b8-be40-47ad-f774-0d20725df8fb"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy  \n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import re  \n",
        "from collections import defaultdict \n",
        "import logging \n",
        "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z76x8Ogm3PTP",
        "colab_type": "text"
      },
      "source": [
        "# Dados do Artigo Referenciado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYrOvI2c3BJS",
        "colab_type": "text"
      },
      "source": [
        "**Verificando estrutura do Dataset utilizado no Estudo referenciado.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT-umxBPdrz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Criando DataFrame a partir dos dados em formato CSV.\n",
        "data = pd.read_csv('polish_sentiment_dataset.csv')"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgvm09nqgMGa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "89cd3225-ee92-4c75-cda0-86d242a777bb"
      },
      "source": [
        "#Visualizando as 5 primeiras linhas do DataFrame.\n",
        "data.head()"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>length</th>\n",
              "      <th>rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Polecam nie pierwszy i nie ostatni raz!</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bardzo dobra komunikacja sms i telefoniczna. Z...</td>\n",
              "      <td>121.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Polecam zakupy w tym sklepie. SƒÖ dostƒôpne czƒô≈õ...</td>\n",
              "      <td>87.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jestem w pe≈Çni zadowolona z przebiegu transakcji</td>\n",
              "      <td>48.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         description  length  rate\n",
              "0            Polecam nie pierwszy i nie ostatni raz!    39.0   1.0\n",
              "1  Bardzo dobra komunikacja sms i telefoniczna. Z...   121.0   1.0\n",
              "2  Polecam zakupy w tym sklepie. SƒÖ dostƒôpne czƒô≈õ...    87.0   1.0\n",
              "3                                                  0     0.0   0.0\n",
              "4   Jestem w pe≈Çni zadowolona z przebiegu transakcji    48.0   1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdvtgbyDgNEr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "80aad4a6-350a-41ff-d22e-5b2bb31b1df2"
      },
      "source": [
        "#Verificando as 5 √∫ltimas linhas do DataFrame.\n",
        "data.tail()"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>length</th>\n",
              "      <th>rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>936878</th>\n",
              "      <td>Coraz lepiej wyglƒÖda</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>936879</th>\n",
              "      <td>JA SRAM NA TEN PIERSCIONEK I NA CIEBIE CHWILE ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>936880</th>\n",
              "      <td>Rafatus do Marleny  Ty kurwo bez honoru       ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>936881</th>\n",
              "      <td>matka Marleny   prosi o pomoc</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>936882</th>\n",
              "      <td>wiesz cz≈Çowieku ≈ºe on jƒÖ nawet nie uderzy≈Ç i m...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              description  length  rate\n",
              "936878                              Coraz lepiej wyglƒÖda      NaN  -1.0\n",
              "936879  JA SRAM NA TEN PIERSCIONEK I NA CIEBIE CHWILE ...     NaN  -1.0\n",
              "936880  Rafatus do Marleny  Ty kurwo bez honoru       ...     NaN  -1.0\n",
              "936881                      matka Marleny   prosi o pomoc     NaN  -1.0\n",
              "936882  wiesz cz≈Çowieku ≈ºe on jƒÖ nawet nie uderzy≈Ç i m...     NaN  -1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeyncvUB3X_z",
        "colab_type": "text"
      },
      "source": [
        "**Pode-se observar que apesar de n√£o serem dados rotulados, para cada frase h√° uma taxa relacionada.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8bbqQ4tgS_S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ecba8826-779e-4931-d5d1-822a51781767"
      },
      "source": [
        "#Descrevendo os dados a partir de medidas estat√≠sticas.\n",
        "data.describe()"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "      <th>rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>762836.000000</td>\n",
              "      <td>936817.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>88.486888</td>\n",
              "      <td>0.587340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>97.483536</td>\n",
              "      <td>0.797016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>44.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>63.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>101.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7970.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              length           rate\n",
              "count  762836.000000  936817.000000\n",
              "mean       88.486888       0.587340\n",
              "std        97.483536       0.797016\n",
              "min         0.000000      -1.000000\n",
              "25%        44.000000       1.000000\n",
              "50%        63.000000       1.000000\n",
              "75%       101.000000       1.000000\n",
              "max      7970.000000       1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6haw-oigUmP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6798ce61-a03d-40ba-9cc7-9ad48f724177"
      },
      "source": [
        "#Verificando a aus√™ncia dos dados para as colunas do DataFrame.\n",
        "data.isna().sum()"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "description       629\n",
              "length         174047\n",
              "rate               66\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tsvLO-XgX9Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bc6b1fc6-520e-4149-eba5-56e459af448d"
      },
      "source": [
        "#Verificando a distribui√ß√£o da taxa atribu√≠da a cada frase, dentre a cole√ß√£o de frases.\n",
        "data['rate'].value_counts()"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1.0    734250\n",
              "-1.0    184020\n",
              " 0.0     18547\n",
              "Name: rate, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qp-5B4aj30LL",
        "colab_type": "text"
      },
      "source": [
        "# Estudo com a Base de Dados do Twitter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Pd6n1sLgeRQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "outputId": "16b4aa3a-9b6d-4183-9b2b-4eb5e6145159"
      },
      "source": [
        "#Criando DataFrame a partir dos dados coletados do Twitter, que se encontram dispostos em formato CSV.\n",
        "df = pd.read_csv('dados-pesquisa.csv')\n",
        "#Verificando as 10 √∫ltimas linhas do DataFrame.\n",
        "df.tail(10)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>created_at</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>user</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>109954</th>\n",
              "      <td>109954</td>\n",
              "      <td>Mon Jul 20 15:08:32 +0000 2020</td>\n",
              "      <td>1.285230e+18</td>\n",
              "      <td>@oatila Ent√£o bastam distanciamento social e m...</td>\n",
              "      <td>{'id': 1057053859774902273, 'id_str': '1057053...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109955</th>\n",
              "      <td>109955</td>\n",
              "      <td>Mon Jul 20 15:07:52 +0000 2020</td>\n",
              "      <td>1.285230e+18</td>\n",
              "      <td>sim isso mesmo pe√ßam lockdown pro meu pai que ...</td>\n",
              "      <td>{'id': 2939855297, 'id_str': '2939855297', 'na...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109956</th>\n",
              "      <td>109956</td>\n",
              "      <td>Mon Jul 20 15:07:52 +0000 2020</td>\n",
              "      <td>1.285230e+18</td>\n",
              "      <td>@SissyRibs @MichaelAncap @_XURIQUEM_ @izaqueba...</td>\n",
              "      <td>{'id': 1143970643207184384, 'id_str': '1143970...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109957</th>\n",
              "      <td>109957</td>\n",
              "      <td>Mon Jul 20 15:05:08 +0000 2020</td>\n",
              "      <td>1.285229e+18</td>\n",
              "      <td>Sem frear aumento de casos da Covid, cidades d...</td>\n",
              "      <td>{'id': 60722362, 'id_str': '60722362', 'name':...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109958</th>\n",
              "      <td>109958</td>\n",
              "      <td>Mon Jul 20 15:04:28 +0000 2020</td>\n",
              "      <td>1.285229e+18</td>\n",
              "      <td>Serasse eu fiz esse post sobre quarentena por ...</td>\n",
              "      <td>{'id': 3019776221, 'id_str': '3019776221', 'na...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109959</th>\n",
              "      <td>109959</td>\n",
              "      <td>Mon Jul 20 15:04:14 +0000 2020</td>\n",
              "      <td>1.285229e+18</td>\n",
              "      <td>porto alegre perigando a entrar em lockdown e ...</td>\n",
              "      <td>{'id': 1245313171, 'id_str': '1245313171', 'na...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109960</th>\n",
              "      <td>109960</td>\n",
              "      <td>Mon Jul 20 15:03:35 +0000 2020</td>\n",
              "      <td>1.285229e+18</td>\n",
              "      <td>Nunca que a M√≠dia vai falar isso!\\nAMB, CFM e ...</td>\n",
              "      <td>{'id': 40697641, 'id_str': '40697641', 'name':...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109961</th>\n",
              "      <td>109961</td>\n",
              "      <td>Mon Jul 20 15:03:33 +0000 2020</td>\n",
              "      <td>1.285229e+18</td>\n",
              "      <td>@joaopiresrj Eu n√£o sou cientista mas esse LOC...</td>\n",
              "      <td>{'id': 942176977, 'id_str': '942176977', 'name...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109962</th>\n",
              "      <td>109962</td>\n",
              "      <td>Mon Jul 20 15:01:54 +0000 2020</td>\n",
              "      <td>1.285228e+18</td>\n",
              "      <td>Q&amp;amp;A - Recess√£o ou Lockdown. O que √© pior? ...</td>\n",
              "      <td>{'id': 1136982345137958912, 'id_str': '1136982...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109963</th>\n",
              "      <td>109963</td>\n",
              "      <td>Mon Jul 20 15:01:38 +0000 2020</td>\n",
              "      <td>1.285228e+18</td>\n",
              "      <td>O prefeito de Los Angeles est√° preste a decret...</td>\n",
              "      <td>{'id': 494366716, 'id_str': '494366716', 'name...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0  ... lang\n",
              "109954      109954  ...   pt\n",
              "109955      109955  ...   pt\n",
              "109956      109956  ...   pt\n",
              "109957      109957  ...   pt\n",
              "109958      109958  ...   pt\n",
              "109959      109959  ...   pt\n",
              "109960      109960  ...   pt\n",
              "109961      109961  ...   pt\n",
              "109962      109962  ...   pt\n",
              "109963      109963  ...   pt\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is47htDqjhz0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f0a81510-0c2d-45e6-ce03-c849b7ada1b5"
      },
      "source": [
        "#Filtrando os dados e selecionando somente as colunas de interesse inicial para o estudo.\n",
        "df = df[['created_at', 'text']]\n",
        "#Visualizando as 5 √∫ltimas linhas dos dados.\n",
        "df.tail()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>109959</th>\n",
              "      <td>Mon Jul 20 15:04:14 +0000 2020</td>\n",
              "      <td>porto alegre perigando a entrar em lockdown e ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109960</th>\n",
              "      <td>Mon Jul 20 15:03:35 +0000 2020</td>\n",
              "      <td>Nunca que a M√≠dia vai falar isso!\\nAMB, CFM e ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109961</th>\n",
              "      <td>Mon Jul 20 15:03:33 +0000 2020</td>\n",
              "      <td>@joaopiresrj Eu n√£o sou cientista mas esse LOC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109962</th>\n",
              "      <td>Mon Jul 20 15:01:54 +0000 2020</td>\n",
              "      <td>Q&amp;amp;A - Recess√£o ou Lockdown. O que √© pior? ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109963</th>\n",
              "      <td>Mon Jul 20 15:01:38 +0000 2020</td>\n",
              "      <td>O prefeito de Los Angeles est√° preste a decret...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            created_at                                               text\n",
              "109959  Mon Jul 20 15:04:14 +0000 2020  porto alegre perigando a entrar em lockdown e ...\n",
              "109960  Mon Jul 20 15:03:35 +0000 2020  Nunca que a M√≠dia vai falar isso!\\nAMB, CFM e ...\n",
              "109961  Mon Jul 20 15:03:33 +0000 2020  @joaopiresrj Eu n√£o sou cientista mas esse LOC...\n",
              "109962  Mon Jul 20 15:01:54 +0000 2020  Q&amp;A - Recess√£o ou Lockdown. O que √© pior? ...\n",
              "109963  Mon Jul 20 15:01:38 +0000 2020  O prefeito de Los Angeles est√° preste a decret..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgdztZpNjp0Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2024d510-69bd-4597-8189-f4dcb6772467"
      },
      "source": [
        "#Verificando a estrutura do DataFrame.\n",
        "df.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(109964, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syXp_hZw4PMU",
        "colab_type": "text"
      },
      "source": [
        "Observa-se a presen√ßa de aproximadamente 110k de linhas, cujas representam os tweets filtrados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRo6J7crjxhL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "dbdf3029-a16f-414d-e84f-a814b8bc0573"
      },
      "source": [
        "#Verificando a exist√™ncia de dados nulos.\n",
        "df.isnull().sum()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "created_at    0\n",
              "text          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntMjmA1hj_pB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Removendo dados duplicados na coluna de Texto e substituindo dentro do pr√≥prio Data Frame.\n",
        "df.drop_duplicates(['text'], inplace=True)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyhrarbekOUJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc42f84f-5908-42b3-e198-077da67d6664"
      },
      "source": [
        "#Verificando novamente a estrutura dos dados para observar a quantidade de dados √∫nicos.\n",
        "df.shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(103364, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZJMvJ0i4aKN",
        "colab_type": "text"
      },
      "source": [
        "Cerca de 6.6k de Tweets foram removidos, devido ao fato de que o conte√∫do se encontrava duplicado na base de dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leuuGBZCSVMk",
        "colab_type": "text"
      },
      "source": [
        "# Pr√©-Processando os Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0mXGAG5isR0",
        "colab_type": "text"
      },
      "source": [
        "**Fun√ß√£o que remove links, urls, sinais de pontua√ß√£o, padroniza os caracteres como min√∫sculos e remove as stopwords atrav√©s de um dos m√≥dulos da biblioteca NLTK.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDt6G21ntIhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Preprocessing_data(instance):\n",
        "      instance = re.sub(r\"http\\S+\", \"\", instance).lower().replace('.', '').replace(';','').replace('-','').replace(':', '').replace(')', '')\n",
        "      stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
        "      words = [i for i in instance.split() if not i in stopwords]\n",
        "      return (\" \".join(words))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNqfqGAITh6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Utilizando nota√ß√£o comum em estudos de Aprendizado de M√°quina.\n",
        "X = df['text']"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fd_6tRgScLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Aplicando Fun√ß√£o aos dados de Texto.\n",
        "X = [Preprocessing_data(i) for i in X]"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygSWwDXHS3jL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "3d6fcbfd-c0b1-4c2e-9a39-885855ca9113"
      },
      "source": [
        "#Visualizando os dados ap√≥s a aplica√ß√£o da fun√ß√£o de Pr√©-Processamento.\n",
        "X[:15]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tudo mudou forma trabalhar, nada mudou objetivo informar #jornalismo #imprensa‚Ä¶',\n",
              " 'mcdonald‚Äôs reabriu lojas p√∫blico #comida #covid19 #mcdonalds',\n",
              " 'sindicato, atento tudo envolve sa√∫de condi√ß√µes trabalho nessa pandemia #covid @spbancarios',\n",
              " 'problemas sa√∫de definitivamente acabaram #saude #forabolsonaro #covid',\n",
              " 'f√°bricas todo mundo viram obrigadas dispensarem funcion√°rios decorr√™ncia #covid19 antes m‚Ä¶',\n",
              " '@g1 @redeglobo @jornalhoje governo @jairbolsonaro vai socorrer ningu√©m vai enrolar! pois minto quer r‚Ä¶',\n",
              " 'lei n¬∞ 6666, #eua, pretende tra√ßar investigar percurso pessoas tivestes contatos, usand‚Ä¶',\n",
              " 'governo precisa ser responsabilizado #covid #covid19',\n",
              " 'blockchain tecnologia popularizou #bitcoin sendo testada combate #covid19 sistema capaz de‚Ä¶',\n",
              " 'conhecem algum pa√≠s al√©m brasil torcida organizada coronavirus???? #covid #covid19',\n",
              " 'itaju√≠pe recebe centro municipal isolamento covid19 #covid19 #isolamentosocial #covid @rctitajuipe',\n",
              " 'üì£ not√≠cia / news / nouvelles üáµüáπ manual boas pr√°ticas ‚Äì algarve clean &amp safe üá¨üáß good practice guide algarve c‚Ä¶',\n",
              " 'enquanto governo bolsonaro permanecer irrespons√°vel, povo paga vida #calabocabolsonaro #covid‚Ä¶',\n",
              " 'fa√ßa diferen√ßa! doador fronteiras sou! #covid #covid19 @msf_brasil',\n",
              " 'manaus, maio 2020 reportagem sobre colapso sus @veja dessa semana, mostra situa√ß√£o pacientes em‚Ä¶']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaWheGjoTu0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Criando DataFrame com os dados pr√©-processados.\n",
        "data_text = pd.DataFrame(data=X, columns=['text'])"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qpCXQu4T4ej",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "2d31e8e7-3bb7-4070-9fc1-a0fd6a1dce56"
      },
      "source": [
        "#Visualizando DataFrame.\n",
        "data_text"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tudo mudou forma trabalhar, nada mudou objetiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mcdonald‚Äôs reabriu lojas p√∫blico #comida #covi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sindicato, atento tudo envolve sa√∫de condi√ß√µes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>problemas sa√∫de definitivamente acabaram #saud...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>f√°bricas todo mundo viram obrigadas dispensare...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103359</th>\n",
              "      <td>porto alegre perigando entrar lockdown √¥nibus ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103360</th>\n",
              "      <td>nunca m√≠dia vai falar isso! amb, cfm crms, tod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103361</th>\n",
              "      <td>@joaopiresrj cientista lockdown acho q duas se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103362</th>\n",
              "      <td>q&amp;ampa recess√£o lockdown pior? | fiique tranqu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103363</th>\n",
              "      <td>prefeito los angeles preste decretar lockdown ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>103364 rows √ó 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text\n",
              "0       tudo mudou forma trabalhar, nada mudou objetiv...\n",
              "1       mcdonald‚Äôs reabriu lojas p√∫blico #comida #covi...\n",
              "2       sindicato, atento tudo envolve sa√∫de condi√ß√µes...\n",
              "3       problemas sa√∫de definitivamente acabaram #saud...\n",
              "4       f√°bricas todo mundo viram obrigadas dispensare...\n",
              "...                                                   ...\n",
              "103359  porto alegre perigando entrar lockdown √¥nibus ...\n",
              "103360  nunca m√≠dia vai falar isso! amb, cfm crms, tod...\n",
              "103361  @joaopiresrj cientista lockdown acho q duas se...\n",
              "103362  q&ampa recess√£o lockdown pior? | fiique tranqu...\n",
              "103363  prefeito los angeles preste decretar lockdown ...\n",
              "\n",
              "[103364 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5FfBf044igm",
        "colab_type": "text"
      },
      "source": [
        "# Transformando os Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3vFCKCKkoCp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "829fdb4a-49b4-4ce1-f295-3fd6da543203"
      },
      "source": [
        "#Importando m√≥dulos do Gensim, biblioteca que auxilia na implementa√ß√£o do Modelo Word2VEC.\n",
        "from gensim.models.phrases import Phrases, Phraser"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 14:01:10: 'pattern' package not found; tag filters are not available for English\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-REPzwemo9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Quebrando as frases por palavra.\n",
        "sent = [row.split() for row in data_text['text']]"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiKuzgSOm-6u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ef55922f-67f3-4eeb-99d9-41785cd09ad7"
      },
      "source": [
        "#Visualizando a representa√ß√£o criada acima.\n",
        "sent"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['tudo',\n",
              "  'mudou',\n",
              "  'forma',\n",
              "  'trabalhar,',\n",
              "  'nada',\n",
              "  'mudou',\n",
              "  'objetivo',\n",
              "  'informar',\n",
              "  '#jornalismo',\n",
              "  '#imprensa‚Ä¶'],\n",
              " ['mcdonald‚Äôs',\n",
              "  'reabriu',\n",
              "  'lojas',\n",
              "  'p√∫blico',\n",
              "  '#comida',\n",
              "  '#covid19',\n",
              "  '#mcdonalds'],\n",
              " ['sindicato,',\n",
              "  'atento',\n",
              "  'tudo',\n",
              "  'envolve',\n",
              "  'sa√∫de',\n",
              "  'condi√ß√µes',\n",
              "  'trabalho',\n",
              "  'nessa',\n",
              "  'pandemia',\n",
              "  '#covid',\n",
              "  '@spbancarios'],\n",
              " ['problemas',\n",
              "  'sa√∫de',\n",
              "  'definitivamente',\n",
              "  'acabaram',\n",
              "  '#saude',\n",
              "  '#forabolsonaro',\n",
              "  '#covid'],\n",
              " ['f√°bricas',\n",
              "  'todo',\n",
              "  'mundo',\n",
              "  'viram',\n",
              "  'obrigadas',\n",
              "  'dispensarem',\n",
              "  'funcion√°rios',\n",
              "  'decorr√™ncia',\n",
              "  '#covid19',\n",
              "  'antes',\n",
              "  'm‚Ä¶'],\n",
              " ['@g1',\n",
              "  '@redeglobo',\n",
              "  '@jornalhoje',\n",
              "  'governo',\n",
              "  '@jairbolsonaro',\n",
              "  'vai',\n",
              "  'socorrer',\n",
              "  'ningu√©m',\n",
              "  'vai',\n",
              "  'enrolar!',\n",
              "  'pois',\n",
              "  'minto',\n",
              "  'quer',\n",
              "  'r‚Ä¶'],\n",
              " ['lei',\n",
              "  'n¬∞',\n",
              "  '6666,',\n",
              "  '#eua,',\n",
              "  'pretende',\n",
              "  'tra√ßar',\n",
              "  'investigar',\n",
              "  'percurso',\n",
              "  'pessoas',\n",
              "  'tivestes',\n",
              "  'contatos,',\n",
              "  'usand‚Ä¶'],\n",
              " ['governo', 'precisa', 'ser', 'responsabilizado', '#covid', '#covid19'],\n",
              " ['blockchain',\n",
              "  'tecnologia',\n",
              "  'popularizou',\n",
              "  '#bitcoin',\n",
              "  'sendo',\n",
              "  'testada',\n",
              "  'combate',\n",
              "  '#covid19',\n",
              "  'sistema',\n",
              "  'capaz',\n",
              "  'de‚Ä¶'],\n",
              " ['conhecem',\n",
              "  'algum',\n",
              "  'pa√≠s',\n",
              "  'al√©m',\n",
              "  'brasil',\n",
              "  'torcida',\n",
              "  'organizada',\n",
              "  'coronavirus????',\n",
              "  '#covid',\n",
              "  '#covid19'],\n",
              " ['itaju√≠pe',\n",
              "  'recebe',\n",
              "  'centro',\n",
              "  'municipal',\n",
              "  'isolamento',\n",
              "  'covid19',\n",
              "  '#covid19',\n",
              "  '#isolamentosocial',\n",
              "  '#covid',\n",
              "  '@rctitajuipe'],\n",
              " ['üì£',\n",
              "  'not√≠cia',\n",
              "  '/',\n",
              "  'news',\n",
              "  '/',\n",
              "  'nouvelles',\n",
              "  'üáµüáπ',\n",
              "  'manual',\n",
              "  'boas',\n",
              "  'pr√°ticas',\n",
              "  '‚Äì',\n",
              "  'algarve',\n",
              "  'clean',\n",
              "  '&amp',\n",
              "  'safe',\n",
              "  'üá¨üáß',\n",
              "  'good',\n",
              "  'practice',\n",
              "  'guide',\n",
              "  'algarve',\n",
              "  'c‚Ä¶'],\n",
              " ['enquanto',\n",
              "  'governo',\n",
              "  'bolsonaro',\n",
              "  'permanecer',\n",
              "  'irrespons√°vel,',\n",
              "  'povo',\n",
              "  'paga',\n",
              "  'vida',\n",
              "  '#calabocabolsonaro',\n",
              "  '#covid‚Ä¶'],\n",
              " ['fa√ßa',\n",
              "  'diferen√ßa!',\n",
              "  'doador',\n",
              "  'fronteiras',\n",
              "  'sou!',\n",
              "  '#covid',\n",
              "  '#covid19',\n",
              "  '@msf_brasil'],\n",
              " ['manaus,',\n",
              "  'maio',\n",
              "  '2020',\n",
              "  'reportagem',\n",
              "  'sobre',\n",
              "  'colapso',\n",
              "  'sus',\n",
              "  '@veja',\n",
              "  'dessa',\n",
              "  'semana,',\n",
              "  'mostra',\n",
              "  'situa√ß√£o',\n",
              "  'pacientes',\n",
              "  'em‚Ä¶'],\n",
              " ['am√©m',\n",
              "  '#maythe4thbewithyou',\n",
              "  '#matarife',\n",
              "  '#staysafe',\n",
              "  '#Ï†ÑÏ†ïÍµ≠ÏÇ¨ÎûëÌï¥',\n",
              "  '#covid',\n",
              "  '#zurena',\n",
              "  '#covid19',\n",
              "  '#Ïû¨ÌòÑÏïÑÏÇ¨ÎûëÌï¥',\n",
              "  '#coloresperanza2020',\n",
              "  '#„Éè„É≥„Çø„Éº„Éè„É≥„Çø„Éº‚Ä¶'],\n",
              " ['#covid',\n",
              "  '#coronav√≠rus',\n",
              "  'agravase',\n",
              "  'problema',\n",
              "  '#inclus√£odigital',\n",
              "  'advogado',\n",
              "  'det√©m',\n",
              "  'condi√ß√£o',\n",
              "  'econ√¥mica',\n",
              "  '@tjbahia‚Ä¶'],\n",
              " ['boa',\n",
              "  'not√≠cia!',\n",
              "  'vacina',\n",
              "  'sendo',\n",
              "  'testada',\n",
              "  'eua',\n",
              "  'come√ßa',\n",
              "  'ter',\n",
              "  'resultados',\n",
              "  'promissores',\n",
              "  '#corona',\n",
              "  '#vacina‚Ä¶'],\n",
              " ['m√©dico',\n",
              "  'alerta',\n",
              "  'riscos',\n",
              "  'hipertens√£o',\n",
              "  'arterial',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid'],\n",
              " ['novo',\n",
              "  'coronav√≠rus',\n",
              "  'andar',\n",
              "  '#carro',\n",
              "  'pode',\n",
              "  'ser',\n",
              "  'perigoso?',\n",
              "  '#covid19',\n",
              "  '#covid'],\n",
              " ['melhor',\n",
              "  'lembran√ßa',\n",
              "  '@flamengo',\n",
              "  '#libertadores2019,',\n",
              "  'd√∫vidas,',\n",
              "  'imagem',\n",
              "  '@gabigol',\n",
              "  'fazendo',\n",
              "  'lixo',\n",
              "  'do‚Ä¶'],\n",
              " ['v√≠deo',\n",
              "  'dessa',\n",
              "  'vez',\n",
              "  'tema',\n",
              "  'popula√ß√£o',\n",
              "  'situa√ß√£o',\n",
              "  'rua',\n",
              "  'covid19#racismo',\n",
              "  '#covid'],\n",
              " ['hotelaria',\n",
              "  'galiza',\n",
              "  'quer',\n",
              "  'portugueses',\n",
              "  'fa√ßam',\n",
              "  'teste',\n",
              "  'r√°pido',\n",
              "  '#covid19',\n",
              "  '#economia',\n",
              "  '#galiza'],\n",
              " ['tamanho',\n",
              "  'grupo',\n",
              "  'risco',\n",
              "  '#covid19',\n",
              "  'brasil?',\n",
              "  'pesquisadores',\n",
              "  '@unifesp',\n",
              "  'tentam',\n",
              "  'esclarecer',\n",
              "  'quest‚Ä¶'],\n",
              " ['articula√ß√£o',\n",
              "  'povos',\n",
              "  'ind√≠genas',\n",
              "  'brasil',\n",
              "  'apib',\n",
              "  '|',\n",
              "  '18/05/2020',\n",
              "  'resumo',\n",
              "  'casos',\n",
              "  'registrados',\n",
              "  'comit√™',\n",
              "  'nacional',\n",
              "  'pela‚Ä¶'],\n",
              " ['governo',\n",
              "  'estado',\n",
              "  'garantiu',\n",
              "  'entrega',\n",
              "  '29',\n",
              "  'respiradores',\n",
              "  'abertura',\n",
              "  'novos',\n",
              "  'leitos',\n",
              "  'uti',\n",
              "  'pacientes‚Ä¶'],\n",
              " ['partilho',\n",
              "  'opini√£o',\n",
              "  'dei',\n",
              "  'algumas',\n",
              "  'semanas',\n",
              "  '@andrebiernath,',\n",
              "  'revista',\n",
              "  '@vejasaude',\n",
              "  'üáßüá∑,',\n",
              "  'sobre',\n",
              "  'acreditava‚Ä¶'],\n",
              " ['rapaziada',\n",
              "  'fiquem',\n",
              "  'espertos!',\n",
              "  'existem',\n",
              "  'umas',\n",
              "  'minas',\n",
              "  'tipo',\n",
              "  '#covid,',\n",
              "  'al√©m',\n",
              "  'voc√™,',\n",
              "  '5',\n",
              "  'casos',\n",
              "  'confirmados',\n",
              "  '2',\n",
              "  'amigos',\n",
              "  'suspeitos'],\n",
              " ['cara',\n",
              "  'deseja',\n",
              "  'ter',\n",
              "  'estabilidade',\n",
              "  'financeira',\n",
              "  'liberdade',\n",
              "  'geogr√°fica',\n",
              "  'poder',\n",
              "  'trabalhar',\n",
              "  'conforto',\n",
              "  'casa',\n",
              "  'voc‚Ä¶'],\n",
              " ['esque√ßa',\n",
              "  'passado,',\n",
              "  'perdoe',\n",
              "  'recomece',\n",
              "  '#meditation',\n",
              "  '#meditopia',\n",
              "  '#nostress',\n",
              "  '#focus',\n",
              "  '#covid'],\n",
              " ['#12emponto98',\n",
              "  'saiba',\n",
              "  'tudo',\n",
              "  'sobre',\n",
              "  'pagamento',\n",
              "  'segunda',\n",
              "  'parcela',\n",
              "  'aux√≠lio',\n",
              "  'emergencial',\n",
              "  'assistindo',\n",
              "  'programa',\n",
              "  'complet‚Ä¶'],\n",
              " ['contato',\n",
              "  'compliance',\n",
              "  'control',\n",
              "  'saiba',\n",
              "  '#somosoquefazemos',\n",
              "  '#compliancecontrol',\n",
              "  '#transparencia‚Ä¶'],\n",
              " ['conhe√ßa',\n",
              "  'melhores',\n",
              "  'pr√°ticas',\n",
              "  'preven√ß√£o',\n",
              "  '#covid19',\n",
              "  'colaboradores',\n",
              "  'empresa',\n",
              "  'garanta',\n",
              "  'sa√∫de‚Ä¶'],\n",
              " ['falta',\n",
              "  'pr√≥ximas',\n",
              "  'elei√ß√µes',\n",
              "  'presidenciais?',\n",
              "  'vejo',\n",
              "  'hora!',\n",
              "  '\\U0001f9d8\\u200d‚ôÄÔ∏è',\n",
              "  '#covid19',\n",
              "  '#eleicoes',\n",
              "  '#presidente',\n",
              "  '#covid',\n",
              "  '#vacinabrasil',\n",
              "  '#socorro'],\n",
              " ['preocupa',\n",
              "  'pode',\n",
              "  'acontecer',\n",
              "  'poderia',\n",
              "  'ter',\n",
              "  'acontecido,',\n",
              "  'perde',\n",
              "  'acontecendo',\n",
              "  'agora‚Ä¶'],\n",
              " ['tentativas',\n",
              "  'desastradas',\n",
              "  'prefeitura',\n",
              "  'paulo',\n",
              "  'pra',\n",
              "  'aumentar',\n",
              "  'isolamento',\n",
              "  'conseguiram',\n",
              "  'oposto',\n",
              "  'preciso',\n",
              "  'planej‚Ä¶'],\n",
              " ['enquanto',\n",
              "  'esperan√ßa',\n",
              "  'determina√ß√£o,',\n",
              "  'haver√°',\n",
              "  'possibilidades!',\n",
              "  'üî•',\n",
              "  '#quarentena',\n",
              "  '#vamosvencerjuntos',\n",
              "  '#vamosaluta‚Ä¶'],\n",
              " ['maioria',\n",
              "  'popula√ß√£o',\n",
              "  'anticorpos',\n",
              "  'contra',\n",
              "  '#covid19',\n",
              "  'declara√ß√£o',\n",
              "  'diretorgeral',\n",
              "  '#oms,',\n",
              "  'tedros',\n",
              "  'adhanom‚Ä¶'],\n",
              " ['q',\n",
              "  'absurdo',\n",
              "  'pa√≠s,passaremos',\n",
              "  'pandemia',\n",
              "  'nunca',\n",
              "  'ter',\n",
              "  'tido',\n",
              "  'quarentena',\n",
              "  'd',\n",
              "  'verdade',\n",
              "  'governo',\n",
              "  'pedindo',\n",
              "  'pr‚Ä¶'],\n",
              " ['devasta', '#covid19', 'comunidades', 'ind√≠genas', '#onu', '#internacional'],\n",
              " ['#covid',\n",
              "  'estragando',\n",
              "  'tudo!',\n",
              "  'espero',\n",
              "  'todo',\n",
              "  'mundo',\n",
              "  'use',\n",
              "  'quarentena',\n",
              "  'pra',\n",
              "  'repensar',\n",
              "  'atitudes,',\n",
              "  'valores,',\n",
              "  'se‚Ä¶'],\n",
              " ['riqueza',\n",
              "  'maior',\n",
              "  'neste',\n",
              "  'mundo',\n",
              "  'paz',\n",
              "  'esp√≠rito',\n",
              "  '#meditation',\n",
              "  '#relax',\n",
              "  '#covid',\n",
              "  '#nostress',\n",
              "  '#peace'],\n",
              " ['idosa',\n",
              "  'cadeirante',\n",
              "  'ganha',\n",
              "  'festa',\n",
              "  '82',\n",
              "  'dentro',\n",
              "  'carro',\n",
              "  'pra√ßa',\n",
              "  'covid',\n",
              "  '#sonoticiaboa',\n",
              "  '#goodnews‚Ä¶'],\n",
              " ['#fiqueemcasa',\n",
              "  'rio',\n",
              "  'janeiro',\n",
              "  '85%',\n",
              "  'leitos',\n",
              "  'uti',\n",
              "  'ocupados',\n",
              "  'sus',\n",
              "  '1720',\n",
              "  'pacientes',\n",
              "  'internados',\n",
              "  'suspeita‚Ä¶'],\n",
              " ['km',\n",
              "  'cargo',\n",
              "  'v√™m',\n",
              "  'trabalhando',\n",
              "  'transporte',\n",
              "  'medicamentos',\n",
              "  'relacionado',\n",
              "  'covid19',\n",
              "  'frota',\n",
              "  'caminh√µes',\n",
              "  'e‚Ä¶'],\n",
              " ['preocupe',\n",
              "  'pensamentos',\n",
              "  'durante',\n",
              "  'medita√ß√£o',\n",
              "  'apenas',\n",
              "  'observe',\n",
              "  'entenda',\n",
              "  'si',\n",
              "  '#meditation',\n",
              "  '#relax‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'diminui',\n",
              "  'estoque',\n",
              "  'leite',\n",
              "  'materno',\n",
              "  'df',\n",
              "  'm√™s',\n",
              "  'abril',\n",
              "  'fechou',\n",
              "  'd√©ficit',\n",
              "  '11%',\n",
              "  '@secsaudedf',\n",
              "  '‚û°Ô∏è‚Ä¶'],\n",
              " ['#sp1',\n",
              "  'btarde!',\n",
              "  '@cesartralli',\n",
              "  '#rogeriolins',\n",
              "  '#prefeito',\n",
              "  '#osasco,',\n",
              "  'fazendo',\n",
              "  'vista',\n",
              "  'grossa',\n",
              "  '#covid',\n",
              "  'todo',\n",
              "  'com‚Ä¶'],\n",
              " ['coral',\n",
              "  'rob√¥',\n",
              "  '#magon',\n",
              "  '#marcelomagon',\n",
              "  '#charges',\n",
              "  '#charge',\n",
              "  '#politica',\n",
              "  '#corona',\n",
              "  '#covid',\n",
              "  '#corona',\n",
              "  '#coronavirus',\n",
              "  '#cloroquina‚Ä¶'],\n",
              " ['porque',\n",
              "  'depender',\n",
              "  'desses',\n",
              "  'ignorantes',\n",
              "  'presidente,',\n",
              "  'naturalidade',\n",
              "  'brasileiro(a',\n",
              "  'vai',\n",
              "  'ser',\n",
              "  'extinta!',\n",
              "  '#coronavirus‚Ä¶'],\n",
              " ['#covid',\n",
              "  '#coronav√≠rus',\n",
              "  'lado,',\n",
              "  'nazistas',\n",
              "  'diziam',\n",
              "  '\"es',\n",
              "  'ist',\n",
              "  'zu',\n",
              "  'ihrer',\n",
              "  'sicherheit\"',\n",
              "  '(isso',\n",
              "  'seguran√ßa‚Ä¶'],\n",
              " ['sair',\n",
              "  'rua',\n",
              "  'desrespeitando',\n",
              "  'regras',\n",
              "  'cont√°gio',\n",
              "  '#covid19,',\n",
              "  'justificativa',\n",
              "  'pessoa',\n",
              "  'prerrogativ‚Ä¶'],\n",
              " ['culpa',\n",
              "  'bolsonaro,',\n",
              "  'ficaremos',\n",
              "  'receber',\n",
              "  'vacina',\n",
              "  'contra',\n",
              "  'coronavirus',\n",
              "  '#culpadobozo',\n",
              "  '#culpadobozo‚Ä¶'],\n",
              " ['culpa',\n",
              "  'bolsonaro,',\n",
              "  'ficaremos',\n",
              "  'receber',\n",
              "  'vacina',\n",
              "  'contra',\n",
              "  'coronavirus',\n",
              "  '#culpadobozo',\n",
              "  '#culpadobozo‚Ä¶'],\n",
              " ['conte',\n",
              "  'arco√≠ris',\n",
              "  'tempestades',\n",
              "  '#meditation',\n",
              "  '#meditopia',\n",
              "  '#nostress',\n",
              "  '#covid'],\n",
              " ['atualiza√ß√£o',\n",
              "  '#covid19',\n",
              "  'mundo',\n",
              "  'atualiza√ß√£o',\n",
              "  '18/05/2020',\n",
              "  '154314',\n",
              "  'utc',\n",
              "  'casos',\n",
              "  '4841007',\n",
              "  'casos',\n",
              "  'hoje',\n",
              "  '41741',\n",
              "  'mortes',\n",
              "  '31736‚Ä¶'],\n",
              " ['farmac√™utica',\n",
              "  'diz',\n",
              "  'ter',\n",
              "  'encontrado',\n",
              "  'anti',\n",
              "  'corpo',\n",
              "  'protege',\n",
              "  '100%',\n",
              "  'contra',\n",
              "  '#covid',\n",
              "  '19',\n",
              "  '#fe',\n",
              "  '#vida'],\n",
              " ['v√≠deos',\n",
              "  'novos!',\n",
              "  'lembrando',\n",
              "  'hoje',\n",
              "  'ocorrer√°',\n",
              "  'pagamento',\n",
              "  'segunda',\n",
              "  'parcela',\n",
              "  'benef√≠cio',\n",
              "  '#covid19',\n",
              "  '#covid‚Ä¶'],\n",
              " ['antes',\n",
              "  'responsabilidade',\n",
              "  'rela√ß√µes',\n",
              "  '√≠ntimas,',\n",
              "  'preven√ß√£o',\n",
              "  'dst‚Äôs',\n",
              "  'uso',\n",
              "  'camisinha',\n",
              "  'agora',\n",
              "  'tem‚Ä¶'],\n",
              " ['#covid19', 'fiqueemcasa', '#comigo'],\n",
              " ['m√©dica',\n",
              "  'licen√ßa',\n",
              "  'maternidade',\n",
              "  'negada',\n",
              "  'morre',\n",
              "  'coronav√≠rus',\n",
              "  'arg√©lia',\n",
              "  '#covid19',\n",
              "  '#covid‚Ä¶'],\n",
              " ['agora', 'vai!', '@minsaude', '@jairbolsonaro', '#covid', '#fy'],\n",
              " ['agora', 'acerta,', 'confia', '#covid', '#nisenasaude'],\n",
              " ['@nataliabteles',\n",
              "  '@mmipexrenata',\n",
              "  '@dfdanielfreitas',\n",
              "  '@lalbert95519675',\n",
              "  'aceita',\n",
              "  'vacina',\n",
              "  'china?',\n",
              "  'china',\n",
              "  'completar√°',\n",
              "  'testes‚Ä¶'],\n",
              " ['ninguem',\n",
              "  'faz',\n",
              "  'aniversario',\n",
              "  'ano!',\n",
              "  'marca',\n",
              "  'amigo',\n",
              "  'perdeu',\n",
              "  'festa',\n",
              "  'aniversario',\n",
              "  'acham',\n",
              "  'nao',\n",
              "  'vai',\n",
              "  'perde‚Ä¶'],\n",
              " ['semana',\n",
              "  'assembleia',\n",
              "  'geral',\n",
              "  '@who',\n",
              "  'isso,',\n",
              "  'v√°rios',\n",
              "  'eventos',\n",
              "  'sendo',\n",
              "  'transmitidos',\n",
              "  'online',\n",
              "  'hoje,',\n",
              "  'aco‚Ä¶'],\n",
              " ['vida',\n",
              "  'supro',\n",
              "  'valor',\n",
              "  'pequenas',\n",
              "  'coisas',\n",
              "  'vida',\n",
              "  'principalmente',\n",
              "  'pessoas',\n",
              "  'ama,at√©',\n",
              "  'por‚Ä¶'],\n",
              " ['sociedade',\n",
              "  'brasileira',\n",
              "  'imunologia',\n",
              "  'conclui',\n",
              "  'precoce',\n",
              "  'recomenda√ß√£o',\n",
              "  'uso',\n",
              "  'deste',\n",
              "  'medicamento',\n",
              "  'covid19‚Ä¶'],\n",
              " ['luta',\n",
              "  'contra',\n",
              "  'inimigo',\n",
              "  'invis√≠vel',\n",
              "  'sentimento',\n",
              "  '#enfermeiros',\n",
              "  'trabalham',\n",
              "  'diretamente',\n",
              "  'pacientes',\n",
              "  'de‚Ä¶'],\n",
              " ['forma',\n",
              "  'eficaz',\n",
              "  'proteger',\n",
              "  'contra',\n",
              "  'coronav√≠rus!',\n",
              "  '#ficaemcasa',\n",
              "  '#cuidadocoletivo',\n",
              "  '#quarentena',\n",
              "  '#covid‚Ä¶'],\n",
              " ['escolas',\n",
              "  '80%',\n",
              "  'alunos',\n",
              "  'falta',\n",
              "  'alguns',\n",
              "  'professores',\n",
              "  '#covid19',\n",
              "  '#escolas'],\n",
              " ['fenprof',\n",
              "  'acusa',\n",
              "  'minist√©rio',\n",
              "  '‚Äúalguma',\n",
              "  'imprud√™ncia‚Äù',\n",
              "  'reabertura',\n",
              "  'escolas',\n",
              "  '#covid19',\n",
              "  '#fenprof',\n",
              "  '#professores'],\n",
              " ['cliente',\n",
              "  'feliz,',\n",
              "  'lugalma',\n",
              "  'feliz',\n",
              "  '\\U0001f970\\U0001f970‚ù§üôèüò∑',\n",
              "  '#m√°scaraprote√ß√£o',\n",
              "  '#m√°scarapersonalizada',\n",
              "  '#covid19',\n",
              "  '#protejase',\n",
              "  '#prote√ß√£ocomestilo‚Ä¶'],\n",
              " ['reorganizadas',\n",
              "  '√°reas',\n",
              "  'destinadas',\n",
              "  'doentes',\n",
              "  'covid',\n",
              "  'alto',\n",
              "  'minho',\n",
              "  '#covid19',\n",
              "  '#emdestaque',\n",
              "  '#hospitais'],\n",
              " ['concello',\n",
              "  '#op√°ramo',\n",
              "  '#bases',\n",
              "  'axudas,',\n",
              "  'dirixidas',\n",
              "  '√°',\n",
              "  '#compra',\n",
              "  '#alimentos',\n",
              "  'produtos',\n",
              "  '1¬™',\n",
              "  'necesidade',\n",
              "  'para‚Ä¶'],\n",
              " ['vai', 'pa', 'onde?', '#covid', '#fiqueemcasa'],\n",
              " ['guimar√£es',\n",
              "  'define',\n",
              "  'plano',\n",
              "  'a√ß√£o',\n",
              "  'apoiar',\n",
              "  'artistas',\n",
              "  'locais',\n",
              "  '#artes',\n",
              "  '#covid19',\n",
              "  '#cultura'],\n",
              " ['l√°',\n",
              "  'facebook',\n",
              "  'ainda',\n",
              "  'acredito',\n",
              "  'mundo',\n",
              "  'jeito!',\n",
              "  'puder',\n",
              "  'precisar,',\n",
              "  'entra',\n",
              "  'l√°',\n",
              "  'vamos',\n",
              "  'ajudar!',\n",
              "  'hora',\n",
              "  'de‚Ä¶'],\n",
              " ['ainda',\n",
              "  'bem',\n",
              "  'animais',\n",
              "  'dom√©sticos',\n",
              "  'transmitem',\n",
              "  '#covid',\n",
              "  'precisam',\n",
              "  'tomar',\n",
              "  'rem√©dio',\n",
              "  'pra',\n",
              "  'tratar',\n",
              "  'pensou',\n",
              "  'esse‚Ä¶'],\n",
              " ['sad',\n",
              "  'op√µese',\n",
              "  'presidente',\n",
              "  'desportivo',\n",
              "  'aves',\n",
              "  'impugna√ß√£o',\n",
              "  'i',\n",
              "  'liga',\n",
              "  '#covid19',\n",
              "  '#futebol',\n",
              "  '#iliga'],\n",
              " ['fundo',\n",
              "  'solid√°rio',\n",
              "  'angaria',\n",
              "  '291',\n",
              "  'mil',\n",
              "  'euros',\n",
              "  'equipar',\n",
              "  'hospital',\n",
              "  'braga',\n",
              "  '#braga',\n",
              "  '#covid19',\n",
              "  '#emdestaque'],\n",
              " ['carga',\n",
              "  'composta',\n",
              "  'm√°scaras',\n",
              "  'respirat√≥rias',\n",
              "  'vestu√°rios',\n",
              "  'prote√ß√£o',\n",
              "  'saiba'],\n",
              " ['vamos',\n",
              "  'participar?',\n",
              "  'üìå',\n",
              "  '19/05,',\n",
              "  '16h',\n",
              "  'üìù',\n",
              "  'inscri√ß√µes',\n",
              "  'gratuitas'],\n",
              " ['#calamidade',\n",
              "  '#estadodecalamidade',\n",
              "  '#covid',\n",
              "  '#covid19',\n",
              "  '#coronavirus',\n",
              "  '#streetphotography',\n",
              "  '#lisboa',\n",
              "  '#portugal',\n",
              "  '#paulocaladophoto‚Ä¶'],\n",
              " ['informamos',\n",
              "  'amanh√£,',\n",
              "  'dia',\n",
              "  '19',\n",
              "  'maio,',\n",
              "  'refeit√≥rio',\n",
              "  'estar√°',\n",
              "  'portas',\n",
              "  'abertas',\n",
              "  'receber',\n",
              "  'todas',\n",
              "  'me‚Ä¶'],\n",
              " ['dinheiro',\n",
              "  'provavelmente',\n",
              "  'maior',\n",
              "  'vetor',\n",
              "  'contamina√ß√£o',\n",
              "  'ningu√©m',\n",
              "  'fala',\n",
              "  'nisso?',\n",
              "  'china',\n",
              "  'desinfetaram',\n",
              "  'usaram',\n",
              "  'u‚Ä¶'],\n",
              " ['#balancogeralrj',\n",
              "  'desejo',\n",
              "  'mal',\n",
              "  'pra',\n",
              "  'ningu√©m',\n",
              "  'por√©m',\n",
              "  '#covid',\n",
              "  '19',\n",
              "  'pegar',\n",
              "  'ladr√µes'],\n",
              " ['drivethru',\n",
              "  '#testagem',\n",
              "  '#covid19',\n",
              "  'retornou',\n",
              "  'nesta',\n",
              "  'segunda',\n",
              "  '(18',\n",
              "  'segue',\n",
              "  'pr√≥xima',\n",
              "  'sexta',\n",
              "  '(se',\n",
              "  'disponibi‚Ä¶'],\n",
              " ['ap√≥s',\n",
              "  '78',\n",
              "  'dias,',\n",
              "  'it√°lia',\n",
              "  'come√ßou',\n",
              "  'semana',\n",
              "  'retornando',\n",
              "  'algumas',\n",
              "  'atividades',\n",
              "  'paralisadas',\n",
              "  '#covid',\n",
              "  '@arthurvneto'],\n",
              " ['maioria',\n",
              "  'estudos',\n",
              "  'mostra',\n",
              "  'cloroquina',\n",
              "  'ineficaz',\n",
              "  'contra',\n",
              "  '#covid19',\n",
              "  'simples',\n",
              "  'assim',\n",
              "  'cabe',\n",
              "  'opini√£o',\n",
              "  'uso‚Ä¶'],\n",
              " ['hospitais',\n",
              "  'braga',\n",
              "  'guimar√£es',\n",
              "  'negam',\n",
              "  'falta',\n",
              "  'material',\n",
              "  'combate',\n",
              "  'covid19',\n",
              "  '#braga',\n",
              "  '#covid19',\n",
              "  '#emdestaque'],\n",
              " ['tatuadores',\n",
              "  'minho',\n",
              "  'vendem',\n",
              "  'bens',\n",
              "  'pagar',\n",
              "  'renda',\n",
              "  '‚Äúdeixemnos',\n",
              "  'trabalhar,',\n",
              "  'd',\n",
              "  '#com√©rcio',\n",
              "  '#covid19',\n",
              "  '#economia'],\n",
              " ['al√¥',\n",
              "  '@cnnbrasil',\n",
              "  'prefeito',\n",
              "  'teres√≥polis',\n",
              "  'diz',\n",
              "  'servi√ßos',\n",
              "  'essenciais',\n",
              "  'liberados',\n",
              "  'documento,',\n",
              "  'assim‚Ä¶'],\n",
              " ['causa',\n",
              "  'alecrim',\n",
              "  'dourado',\n",
              "  'brasil',\n",
              "  '√∫ltimos',\n",
              "  'fila',\n",
              "  'vacina',\n",
              "  '#covid',\n",
              "  'no√ß√£o',\n",
              "  'disso',\n",
              "  '?',\n",
              "  'um‚Ä¶'],\n",
              " ['espet√°culo!',\n",
              "  '#fortaleza',\n",
              "  '#cear√°',\n",
              "  '#praia',\n",
              "  '#shot',\n",
              "  '#photography',\n",
              "  '#natgeoyourshot',\n",
              "  '#clouds',\n",
              "  '#sunrise‚Ä¶'],\n",
              " ['pro',\n",
              "  'dia',\n",
              "  'nascer',\n",
              "  'feliz',\n",
              "  'vem',\n",
              "  'logo',\n",
              "  'vacina!',\n",
              "  '#fortaleza',\n",
              "  '#cear√°',\n",
              "  '#praia',\n",
              "  '#shot',\n",
              "  '#photography‚Ä¶'],\n",
              " ['novidades', 'sobre', 'vacina', 'coronav√≠rus!!üôèüôèüôè', '#covid', '#covid„Éº19'],\n",
              " ['passa',\n",
              "  '1,5',\n",
              "  'milh√£o',\n",
              "  'n√∫mero',\n",
              "  'recuperados',\n",
              "  'covid19',\n",
              "  'mundo',\n",
              "  'marca',\n",
              "  '1502468',\n",
              "  'batida',\n",
              "  'sextafeira‚Ä¶'],\n",
              " ['fazendo', 'parte', 'estat√≠stica', '#covid'],\n",
              " ['contato',\n",
              "  'solicite',\n",
              "  'visita',\n",
              "  'avalia√ß√£o',\n",
              "  'or√ßamento',\n",
              "  '#higiene',\n",
              "  '#solucao',\n",
              "  '#limpezaprofissional‚Ä¶'],\n",
              " ['ibc', '2020', 'cancelado', '#ibcshow', '#covid', '#cancel'],\n",
              " ['receita',\n",
              "  'diminuiu?',\n",
              "  'aumentar',\n",
              "  'busca',\n",
              "  'empresa?',\n",
              "  'outras',\n",
              "  'd√∫vidas',\n",
              "  'respondidas',\n",
              "  'blog!',\n",
              "  'con‚Ä¶'],\n",
              " ['@concelloribeira',\n",
              "  'celebrar√°',\n",
              "  'un',\n",
              "  '#pleno',\n",
              "  'telem√°tico',\n",
              "  'encaixar',\n",
              "  'axudas',\n",
              "  'polo',\n",
              "  '#covid',\n",
              "  '#orzamentos'],\n",
              " ['#covid19,',\n",
              "  'menina',\n",
              "  'cinco',\n",
              "  'anos',\n",
              "  'luta',\n",
              "  'contra',\n",
              "  'doen√ßa',\n",
              "  'kawasaki'],\n",
              " ['desabafo!',\n",
              "  'ass',\n",
              "  'eli√©verson',\n",
              "  'louren√ßo',\n",
              "  'silva',\n",
              "  '#pandemia',\n",
              "  '#pandemia2020',\n",
              "  '#covid19',\n",
              "  '#covid_19',\n",
              "  '#covid',\n",
              "  '#cacoal',\n",
              "  '#rond√¥nia‚Ä¶'],\n",
              " ['@jornaloglobo',\n",
              "  'imagina',\n",
              "  'todo',\n",
              "  'dinheiro',\n",
              "  'licita√ß√£o',\n",
              "  'usando',\n",
              "  'combate',\n",
              "  '#covid'],\n",
              " ['observando',\n",
              "  'aumento',\n",
              "  'contaminados',\n",
              "  '#covid,',\n",
              "  'devido',\n",
              "  'grande',\n",
              "  'ideia',\n",
              "  '√∫ltima',\n",
              "  'semana',\n",
              "  'rod√≠zio',\n",
              "  '#par',\n",
              "  '#impar',\n",
              "  'do‚Ä¶'],\n",
              " ['arthur',\n",
              "  'virg√≠lio,',\n",
              "  'fez',\n",
              "  'apelo',\n",
              "  'popula√ß√£o,',\n",
              "  'mantidos',\n",
              "  'cuidados',\n",
              "  'preventivos',\n",
              "  'respeito',\n",
              "  'isolamen‚Ä¶'],\n",
              " ['cloroquina', 'cura', '#covid', 'tanto', 'quanto', 'copa√≠baarrisca', 'quer'],\n",
              " ['@statedeptpm',\n",
              "  '@asstsecpm',\n",
              "  'r',\n",
              "  'clarke',\n",
              "  'cooper',\n",
              "  'sb',\n",
              "  'investimentos',\n",
              "  'longo',\n",
              "  'prazo',\n",
              "  '@statedeptpm',\n",
              "  '@usforeignassist',\n",
              "  'e‚Ä¶'],\n",
              " ['@amastharompre', 'parab√©ns', 'posicionamento', 'l√∫cido', 'üëèüëèüëè', '#covid'],\n",
              " ['rio',\n",
              "  'janeiro',\n",
              "  '2,7',\n",
              "  'mil',\n",
              "  'mortes',\n",
              "  'covid19',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid'],\n",
              " ['china',\n",
              "  'completar√°',\n",
              "  'testes',\n",
              "  'cl√≠nicos',\n",
              "  'segunda',\n",
              "  'fase',\n",
              "  'vacinas',\n",
              "  '#covid19',\n",
              "  'julho,',\n",
              "  'diz',\n",
              "  'funcion√°rio‚Ä¶'],\n",
              " ['covid19',\n",
              "  'concelho',\n",
              "  'maia',\n",
              "  'volta',\n",
              "  'ter',\n",
              "  'casos',\n",
              "  'infe√ß√£o',\n",
              "  '#atualiza√ß√£o',\n",
              "  '#boletim',\n",
              "  '#covid',\n",
              "  '#dgs',\n",
              "  '#infe√ß√µes'],\n",
              " ['\"se',\n",
              "  '25',\n",
              "  'anos,',\n",
              "  'saud√°vel',\n",
              "  '#covid,',\n",
              "  '99%',\n",
              "  'probabilidade',\n",
              "  'ter',\n",
              "  'forma',\n",
              "  'leve',\n",
              "  'sair',\n",
              "  'bem',\n",
              "  'se‚Ä¶'],\n",
              " ['tocantins',\n",
              "  'decreta',\n",
              "  'lockdown',\n",
              "  'ap√≥s',\n",
              "  'reabrir',\n",
              "  'com√©rcio',\n",
              "  'abril',\n",
              "  '#tocantins',\n",
              "  '#covid19',\n",
              "  '#covid',\n",
              "  '#to‚Ä¶'],\n",
              " ['confira',\n",
              "  'artigo',\n",
              "  '@arquivossbc',\n",
              "  'destaque',\n",
              "  '@redescielo',\n",
              "  'exerc√≠cio',\n",
              "  'f√≠sico',\n",
              "  'pacientes',\n",
              "  'cardiopatas',\n",
              "  'popula√ß‚Ä¶'],\n",
              " ['dist√¢ncia',\n",
              "  's√©rie',\n",
              "  'quarenteners',\n",
              "  '#bnw',\n",
              "  '#quarantine',\n",
              "  '#quarentena',\n",
              "  '#quarentenou',\n",
              "  '#caution',\n",
              "  '#isolation',\n",
              "  '#warning‚Ä¶'],\n",
              " ['dilemas',\n",
              "  'alternativas',\n",
              "  'tempos',\n",
              "  'covid19',\n",
              "  'via',\n",
              "  '@diariope',\n",
              "  '#covid',\n",
              "  '#covid19',\n",
              "  '#lockdown',\n",
              "  '#pernambuco'],\n",
              " ['todos', 'dias', 'mudam', 'opini√£o?', '#covid', 'via', '@tvi24pt'],\n",
              " ['#covid',\n",
              "  '@agenciabrasil',\n",
              "  'aonde',\n",
              "  'politico',\n",
              "  '@dataprev',\n",
              "  '@caixa',\n",
              "  '@saude',\n",
              "  '@onyz',\n",
              "  'reginaldo',\n",
              "  'romanini',\n",
              "  'oliveira',\n",
              "  'aguas',\n",
              "  'de‚Ä¶'],\n",
              " ['proje√ß√µes',\n",
              "  'pib',\n",
              "  'brasileiro',\n",
              "  '2020',\n",
              "  'perturbadoras',\n",
              "  'tudo',\n",
              "  'indica,',\n",
              "  'maior',\n",
              "  'queda',\n",
              "  'pib',\n",
              "  'desde',\n",
              "  '1‚Ä¶'],\n",
              " ['\"#covid19',\n",
              "  'cooperamos',\n",
              "  'futuro',\n",
              "  'nenhum\"',\n",
              "  'leonardo',\n",
              "  'boff',\n",
              "  '#fiqueemcasa'],\n",
              " ['associa√ß√£o',\n",
              "  'europeia',\n",
              "  'fornecedores',\n",
              "  'sector',\n",
              "  'autom√≥vel',\n",
              "  '(clepa',\n",
              "  'fez',\n",
              "  'estudo',\n",
              "  'avaliar',\n",
              "  'impacto',\n",
              "  'pandemia‚Ä¶'],\n",
              " ['coisa',\n",
              "  'podem',\n",
              "  'negar',\n",
              "  'carnaval',\n",
              "  '2020',\n",
              "  'contagiante!',\n",
              "  '#covid',\n",
              "  '#quarentena'],\n",
              " ['#saopaulo',\n",
              "  '#covid19',\n",
              "  '#covid„Éº19',\n",
              "  '#lockdown',\n",
              "  '#rushhour',\n",
              "  '#rush',\n",
              "  '#usemascaranoonibus',\n",
              "  '#saude',\n",
              "  '#oms',\n",
              "  '#jairbolsonaro‚Ä¶'],\n",
              " ['seguidores',\n",
              "  'bolsonaro',\n",
              "  'radicais',\n",
              "  'alma,',\n",
              "  'respeitam',\n",
              "  'dor',\n",
              "  'outro',\n",
              "  '#impeachmentbolsonaro‚Ä¶'],\n",
              " ['escroto',\n",
              "  'privada,',\n",
              "  'vamos',\n",
              "  'dar',\n",
              "  'descarga',\n",
              "  'esperamos',\n",
              "  'bosta',\n",
              "  'descer',\n",
              "  'dois',\n",
              "  'juntos?',\n",
              "  '#lavajato‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'uso',\n",
              "  '#cloroquina',\n",
              "  '#nutriz',\n",
              "  '#lactante',\n",
              "  'impede',\n",
              "  '#amamenta√ß√£o,',\n",
              "  'contudo',\n",
              "  'droga',\n",
              "  'recomendada‚Ä¶'],\n",
              " ['rede',\n",
              "  'upas',\n",
              "  'agora',\n",
              "  'dedicada',\n",
              "  'totalmente',\n",
              "  'casos',\n",
              "  '#covid19',\n",
              "  'hospitais',\n",
              "  'credenciados',\n",
              "  'vicente,',\n",
              "  'nova',\n",
              "  'es‚Ä¶'],\n",
              " ['comunidade',\n",
              "  'intermunicipal',\n",
              "  '(cim',\n",
              "  'regi√£o',\n",
              "  'coimbra',\n",
              "  'registou',\n",
              "  'segundafeira',\n",
              "  'dois',\n",
              "  'novos',\n",
              "  'casos',\n",
              "  'infe√ß√£o',\n",
              "  'cov‚Ä¶'],\n",
              " ['empresa',\n",
              "  'oportunidade',\n",
              "  'treinar',\n",
              "  'funcion√°rios',\n",
              "  'sobre',\n",
              "  'fundamentos',\n",
              "  'b√°sicos',\n",
              "  'seguran√ßa',\n",
              "  'informa√ß√£o‚Ä¶'],\n",
              " ['atualiza√ß√£o',\n",
              "  '#covid19',\n",
              "  'mundo',\n",
              "  'atualiza√ß√£o',\n",
              "  '18/05/2020',\n",
              "  '115310',\n",
              "  'utc',\n",
              "  'casos',\n",
              "  '4820543',\n",
              "  'casos',\n",
              "  'hoje',\n",
              "  '21277',\n",
              "  'mortes',\n",
              "  '31698‚Ä¶'],\n",
              " ['impacto',\n",
              "  '#covid19',\n",
              "  'traz',\n",
              "  'convic√ß√£o',\n",
              "  'buscar',\n",
              "  'nova',\n",
              "  'forma',\n",
              "  'fazer',\n",
              "  '#neg√≥cios',\n",
              "  'crescer',\n",
              "  'quest√£o',\n",
              "  'de‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'v√≠rus',\n",
              "  'pode',\n",
              "  'transmitir',\n",
              "  'atrav√©s',\n",
              "  'superf√≠cies',\n",
              "  'objetos'],\n",
              " ['terapia',\n",
              "  'anticorpos',\n",
              "  'contra',\n",
              "  'covid19',\n",
              "  'inicia',\n",
              "  'testes',\n",
              "  'junho',\n",
              "  'setembro',\n",
              "  'leia',\n",
              "  '+',\n",
              "  'portal',\n",
              "  'enfermagem‚Ä¶'],\n",
              " ['saiba',\n",
              "  'algu√©m',\n",
              "  'pode',\n",
              "  'ser',\n",
              "  'considerado',\n",
              "  'curado',\n",
              "  '#covid19',\n",
              "  'conhe√ßa',\n",
              "  'crit√©rios',\n",
              "  'avalia√ß√µes',\n",
              "  'envolvidos',\n",
              "  'recup‚Ä¶'],\n",
              " ['escolha',\n",
              "  'vantagem',\n",
              "  'enviar',\n",
              "  'rapidez!',\n",
              "  '#mercadofinanceiro',\n",
              "  '#economizar',\n",
              "  '#savemoney',\n",
              "  '#enviorapido',\n",
              "  '#facilidade‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'projeto',\n",
              "  'mapeia',\n",
              "  'iniciativas',\n",
              "  'economia',\n",
              "  'solid√°ria',\n",
              "  'pandemia',\n",
              "  'iniciativa,',\n",
              "  're√∫ne',\n",
              "  'pesquisadores',\n",
              "  'da‚Ä¶'],\n",
              " ['vez',\n",
              "  'c√£o',\n",
              "  'chameilhe',\n",
              "  '\"fica\"',\n",
              "  'qd',\n",
              "  'ia',\n",
              "  'passear',\n",
              "  'dizialhe',\n",
              "  'fica,',\n",
              "  'anda',\n",
              "  'c√°!',\n",
              "  'fica,',\n",
              "  'anda',\n",
              "  'c√°!',\n",
              "  'coitado‚Ä¶'],\n",
              " ['volume',\n",
              "  'clientes',\n",
              "  'zonas',\n",
              "  'raianas',\n",
              "  'alto',\n",
              "  'minho',\n",
              "  'chega',\n",
              "  '20%',\n",
              "  '#ceval',\n",
              "  '#com√©rcio',\n",
              "  '#covid19'],\n",
              " ['comunidade',\n",
              "  'cigana',\n",
              "  'barcelos',\n",
              "  'novos',\n",
              "  'casos',\n",
              "  'positivos',\n",
              "  '#barcelos',\n",
              "  '#covid19'],\n",
              " ['cl√≠nica',\n",
              "  'm√©dica,',\n",
              "  'elevador!',\n",
              "  'todos',\n",
              "  'falam',\n",
              "  'evitem',\n",
              "  'elevadores!',\n",
              "  'a√≠',\n",
              "  'm√©dicos',\n",
              "  'enfermeiras',\n",
              "  'usam',\n",
              "  'escada‚Ä¶'],\n",
              " ['menino',\n",
              "  '12',\n",
              "  'cria',\n",
              "  'ferramenta',\n",
              "  'protege',\n",
              "  'contra',\n",
              "  'coronav√≠rus',\n",
              "  '#sonoticiaboa',\n",
              "  '#goodnews',\n",
              "  '#digita‚Ä¶'],\n",
              " ['oficial',\n",
              "  '1794',\n",
              "  'pessoas',\n",
              "  'recuperaram',\n",
              "  '√∫ltimas',\n",
              "  '24',\n",
              "  'horas',\n",
              "  'pa√≠s',\n",
              "  '#covid19',\n",
              "  '#dgs',\n",
              "  '#emdestaque'],\n",
              " ['bbc',\n",
              "  'news',\n",
              "  'coronavirus',\n",
              "  'hospitals',\n",
              "  'in',\n",
              "  \"brazil's\",\n",
              "  'paulo',\n",
              "  \"'near\",\n",
              "  \"collapse'\",\n",
              "  '#covid'],\n",
              " ['#covid19',\n",
              "  'calor',\n",
              "  'europa',\n",
              "  'primavera',\n",
              "  'eua',\n",
              "  'testam',\n",
              "  'novas',\n",
              "  'regras',\n",
              "  'pa√≠ses',\n",
              "  'flexibilizam',\n",
              "  'gradualmente',\n",
              "  'restri√ß√µes‚Ä¶'],\n",
              " ['caso',\n",
              "  'positivo',\n",
              "  'adia',\n",
              "  'reabertura',\n",
              "  'creche',\n",
              "  'cruz',\n",
              "  'vermelha',\n",
              "  'braga',\n",
              "  '#braga',\n",
              "  '#covid19',\n",
              "  '#creches'],\n",
              " ['brasil',\n",
              "  'hoje',\n",
              "  '(18/05/2020',\n",
              "  '130836',\n",
              "  'doentes',\n",
              "  'conta',\n",
              "  '#coronav√≠rus,',\n",
              "  'al√©m',\n",
              "  '94122',\n",
              "  'pessoas',\n",
              "  'curad‚Ä¶'],\n",
              " ['vemos',\n",
              "  'agora',\n",
              "  'nessa',\n",
              "  'altura',\n",
              "  '#covid19',\n",
              "  '#covid__19',\n",
              "  '#covid',\n",
              "  '#stayathome'],\n",
              " ['#cloroquina',\n",
              "  'volta',\n",
              "  'holofotes,',\n",
              "  'estudos',\n",
              "  'recentes',\n",
              "  'indicam',\n",
              "  'droga',\n",
              "  'ineficaz',\n",
              "  'contra',\n",
              "  '#covid19',\n",
              "  '#coronavirus'],\n",
              " ['#ci√™ncia',\n",
              "  '&amp',\n",
              "  '#covid19',\n",
              "  'belo',\n",
              "  'recado',\n",
              "  'entende',\n",
              "  'biodiversidade',\n",
              "  'thomas',\n",
              "  'lovejoy',\n",
              "  'vale',\n",
              "  'pena',\n",
              "  'conferir‚Ä¶'],\n",
              " ['caixa',\n",
              "  'inicia,',\n",
              "  'partir',\n",
              "  'desta',\n",
              "  'segundafeira',\n",
              "  '(18,',\n",
              "  'disponibiliza√ß√£o',\n",
              "  'parcela',\n",
              "  '2',\n",
              "  'aux√≠lio',\n",
              "  'emergencial',\n",
              "  'govern‚Ä¶'],\n",
              " ['resum√£o',\n",
              "  'fim',\n",
              "  'semana',\n",
              "  'heran√ßa',\n",
              "  'gugu,',\n",
              "  'gente',\n",
              "  'alienada',\n",
              "  'acha',\n",
              "  'covid',\n",
              "  'golpe,',\n",
              "  'presidente',\n",
              "  'filtro,',\n",
              "  'paulo',\n",
              "  'g‚Ä¶'],\n",
              " ['passo',\n",
              "  'tempo',\n",
              "  'umbral',\n",
              "  'vou',\n",
              "  'torcer',\n",
              "  'pro',\n",
              "  '#covid19',\n",
              "  'levar',\n",
              "  'monte',\n",
              "  'bolsominiom'],\n",
              " ['it√°lia',\n",
              "  'irlanda',\n",
              "  'retomam',\n",
              "  'atividades',\n",
              "  'ap√≥s',\n",
              "  'isolamento',\n",
              "  '#sonoticiaboa',\n",
              "  '#goodnews',\n",
              "  '#italia‚Ä¶'],\n",
              " ['futurosüìä',\n",
              "  '18/05/2020',\n",
              "  'ewz',\n",
              "  '+1,08%',\n",
              "  '(adr',\n",
              "  'brasil',\n",
              "  'dji',\n",
              "  '+1,55%',\n",
              "  'sp500',\n",
              "  '+1,49%',\n",
              "  'vix',\n",
              "  '4,90%',\n",
              "  '(aos',\n",
              "  '2055',\n",
              "  'min√©rio',\n",
              "  'ferro',\n",
              "  '5,41‚Ä¶'],\n",
              " ['mandetta',\n",
              "  'hoje,',\n",
              "  'qua',\n",
              "  'fala',\n",
              "  '200',\n",
              "  'mil',\n",
              "  '√≥bitos',\n",
              "  'passamos',\n",
              "  'apenas',\n",
              "  '1/3',\n",
              "  'pandemia',\n",
              "  'janeiro',\n",
              "  'd‚Ä¶'],\n",
              " ['feirantes',\n",
              "  'exigem',\n",
              "  'reabertura',\n",
              "  'total',\n",
              "  'feira',\n",
              "  'barcelos',\n",
              "  '#barcelos',\n",
              "  '#covid19',\n",
              "  '#economia'],\n",
              " ['exaltar',\n",
              "  'perseguir',\n",
              "  'medicamento',\n",
              "  'raz√£o',\n",
              "  'pol√≠tica',\n",
              "  'atitude',\n",
              "  'deprimente',\n",
              "  'contradi√ß√µes',\n",
              "  'patentes',\n",
              "  'nesse',\n",
              "  'artigo‚Ä¶'],\n",
              " ['papa',\n",
              "  'reza',\n",
              "  'cuidam',\n",
              "  'limpeza',\n",
              "  'ruas',\n",
              "  '#hospitais',\n",
              "  '#covid',\n",
              "  '#not√≠cias'],\n",
              " ['vale',\n",
              "  'refor√ßar',\n",
              "  'sair',\n",
              "  'casa,',\n",
              "  'saia',\n",
              "  'sempre',\n",
              "  'm√°scara',\n",
              "  '√°lcool',\n",
              "  'gel',\n",
              "  'm√£os',\n",
              "  'voltar',\n",
              "  'casa',\n",
              "  'ev‚Ä¶'],\n",
              " ['visitas',\n",
              "  'lares',\n",
              "  'permitidas',\n",
              "  'partir',\n",
              "  'hoje',\n",
              "  '#covid19',\n",
              "  '#emdestaque',\n",
              "  '#leresdeidosos'],\n",
              " ['#fiqueemcasa',\n",
              "  'limpe',\n",
              "  'quintal!',\n",
              "  '#covid19',\n",
              "  '#dengue',\n",
              "  'castigam',\n",
              "  'brasileiros',\n",
              "  'norte',\n",
              "  'sul',\n",
              "  'saiba',\n",
              "  'na‚Ä¶'],\n",
              " ['@tocantins79',\n",
              "  '@chico_dangelo',\n",
              "  '@zehdeabreu',\n",
              "  'sei',\n",
              "  '(posso',\n",
              "  'estar',\n",
              "  'enganada',\n",
              "  'deu',\n",
              "  'origem',\n",
              "  'descoberta,',\n",
              "  'foi‚Ä¶'],\n",
              " ['#brasil',\n",
              "  'atinge',\n",
              "  '16118',\n",
              "  'mortes',\n",
              "  '#coronav√≠rus',\n",
              "  '#oms',\n",
              "  '#epidemia',\n",
              "  '#covid19',\n",
              "  '#jairbolsonaro',\n",
              "  '#saludmundial'],\n",
              " ['l√∫cio',\n",
              "  'crespo,',\n",
              "  'diretor',\n",
              "  't√©cnico',\n",
              "  'gold',\n",
              "  'partner',\n",
              "  '@incentea',\n",
              "  'participantes',\n",
              "  'entrevista',\n",
              "  'virtual',\n",
              "  'conduz‚Ä¶'],\n",
              " ['exdiretor',\n",
              "  '#oms',\n",
              "  '\"√©',\n",
              "  'realmente',\n",
              "  'poss√≠vel',\n",
              "  'v√≠rus',\n",
              "  'queime',\n",
              "  'naturalmente',\n",
              "  'antes',\n",
              "  'haver',\n",
              "  'vacina\"‚Ä¶'],\n",
              " ['photos',\n",
              "  'from',\n",
              "  'vgma',\n",
              "  'covid',\n",
              "  '19',\n",
              "  'heroes',\n",
              "  'concert',\n",
              "  '@efya_nokturnal',\n",
              "  '@kinaatagh',\n",
              "  '@akwaboahmusic',\n",
              "  '@amandziba',\n",
              "  '#vgma',\n",
              "  '#ghanamusic‚Ä¶'],\n",
              " ['conhe√ßa',\n",
              "  'roomoffice,',\n",
              "  'sa√≠da',\n",
              "  'setor',\n",
              "  'hoteleiro',\n",
              "  '#pandemia',\n",
              "  '#covid'],\n",
              " ['us',\n",
              "  'to',\n",
              "  'deport',\n",
              "  '161',\n",
              "  'indians',\n",
              "  '#unitedstates',\n",
              "  '#indians',\n",
              "  '#deport',\n",
              "  '#corona',\n",
              "  '#coronacrisis',\n",
              "  '#coronavirus',\n",
              "  '#coronavirusoutbreak‚Ä¶'],\n",
              " ['mundo',\n",
              "  'reinventou',\n",
              "  'agora',\n",
              "  'reuni√µes',\n",
              "  'virtuais',\n",
              "  'ferramentas',\n",
              "  'sendo',\n",
              "  'utilizadas,',\n",
              "  'seguras?',\n",
              "  'iss‚Ä¶'],\n",
              " ['rusia',\n",
              "  'xa',\n",
              "  'superou',\n",
              "  'guaiomin√≠',\n",
              "  'segundo',\n",
              "  'pa√≠s',\n",
              "  'mundo',\n",
              "  'con',\n",
              "  'm√°is',\n",
              "  '#covid,',\n",
              "  'detr√°s',\n",
              "  'eua,',\n",
              "  'claro',\n",
              "  '#guerrafr√≠a'],\n",
              " ['tomem',\n",
              "  'cuidado',\n",
              "  'pois',\n",
              "  'pior',\n",
              "  'ra√ßa',\n",
              "  'vi',\n",
              "  '√∫ltimos',\n",
              "  'tempos',\n",
              "  '#bolsonarorainhalouca',\n",
              "  '#bolsonaroassassino‚Ä¶'],\n",
              " ['√≥tima',\n",
              "  'semana',\n",
              "  'todos',\n",
              "  'üôèüåûüåûüò∑',\n",
              "  '#semana',\n",
              "  '#desejo',\n",
              "  '#boasemana',\n",
              "  '#otimasemana',\n",
              "  '#fiqueemcasa',\n",
              "  '#stayhome',\n",
              "  '#covid',\n",
              "  '#brasil',\n",
              "  '#saopaulo‚Ä¶'],\n",
              " ['libertar√°',\n",
              "  '#bolsonarorainhalouca',\n",
              "  '#bolsonaroassassino',\n",
              "  '#bolsonaroficaquieto',\n",
              "  '#bolsonaro',\n",
              "  '#brasil‚Ä¶'],\n",
              " ['provinha', 'pra', 'vcs', '#covid', '#divulgaai'],\n",
              " ['@vitoriamailla',\n",
              "  'dias',\n",
              "  'fim',\n",
              "  '?',\n",
              "  'kkk',\n",
              "  'nome',\n",
              "  'desse',\n",
              "  'filme',\n",
              "  '#covid',\n",
              "  '19',\n",
              "  'kkkk',\n",
              "  '40tena',\n",
              "  '?kkk'],\n",
              " ['l√°vate',\n",
              "  'constantemente',\n",
              "  'las',\n",
              "  'manos!',\n",
              "  '#covid',\n",
              "  '#quedateencasa',\n",
              "  '#lavatelasmanos'],\n",
              " ['casualmente',\n",
              "  'intern√™',\n",
              "  '#chicoc√©sar',\n",
              "  'd√°',\n",
              "  'soco',\n",
              "  'meio',\n",
              "  'cara',\n",
              "  'achei',\n",
              "  'hoje',\n",
              "  'ia',\n",
              "  'chorar',\n",
              "  'antes',\n",
              "  'dormir‚Ä¶'],\n",
              " ['sobrevivermos',\n",
              "  'torna',\n",
              "  'leve',\n",
              "  'fardo',\n",
              "  'morte',\n",
              "  'sobre',\n",
              "  'consci√™ncia',\n",
              "  'coletiva,',\n",
              "  'nunca',\n",
              "  'esquecer',\n",
              "  'so‚Ä¶'],\n",
              " ['bbc',\n",
              "  'news',\n",
              "  'coronavirus',\n",
              "  'hospitals',\n",
              "  'in',\n",
              "  \"brazil's\",\n",
              "  'paulo',\n",
              "  \"'near\",\n",
              "  \"collapse'\",\n",
              "  '#covid19',\n",
              "  '#brazil',\n",
              "  '#coronavirus',\n",
              "  '#bbcnews‚Ä¶'],\n",
              " ['@luciano_hang',\n",
              "  'faz',\n",
              "  'seguinte',\n",
              "  'trabalha',\n",
              "  'meio',\n",
              "  'pov√£o',\n",
              "  'ruas',\n",
              "  'lojas',\n",
              "  'm√™s',\n",
              "  'tipo,',\n",
              "  'mistura',\n",
              "  'messsmoooo‚Ä¶'],\n",
              " ['promovendo',\n",
              "  'pr√°ticas',\n",
              "  'saud√°veis',\n",
              "  'cuidados',\n",
              "  'contra',\n",
              "  'covid19',\n",
              "  'acesse',\n",
              "  'v√≠deo',\n",
              "  'üëâ'],\n",
              " ['vou',\n",
              "  'ajudar',\n",
              "  'sa√≠rem',\n",
              "  't√©dio',\n",
              "  'nessa',\n",
              "  'pandemia',\n",
              "  'criei',\n",
              "  'perfil',\n",
              "  'onde',\n",
              "  'farei',\n",
              "  'lives',\n",
              "  'sexo,',\n",
              "  'masturba√ß√£o',\n",
              "  'corr‚Ä¶'],\n",
              " ['fa√ßa', 'eu,', 'use', 'mascara', '#covidse'],\n",
              " ['pa√≠s',\n",
              "  '√≥bitos',\n",
              "  'casos',\n",
              "  '1',\n",
              "  'üá∫üá∏',\n",
              "  '89932',\n",
              "  '1516343',\n",
              "  '2',\n",
              "  'üá¨üáß',\n",
              "  '34716',\n",
              "  '244995',\n",
              "  '3',\n",
              "  'üáÆüáπ',\n",
              "  '31908‚Ä¶'],\n",
              " ['hora',\n",
              "  'retirar',\n",
              "  'm√°scara,',\n",
              "  'fa√ßa',\n",
              "  'partir',\n",
              "  'el√°stico',\n",
              "  'tiras',\n",
              "  'parte',\n",
              "  'tr√°s',\n",
              "  'imagem',\n",
              "  'frida',\n",
              "  'kahlo,',\n",
              "  'reimag‚Ä¶'],\n",
              " ['precisa',\n",
              "  'sair',\n",
              "  'rua',\n",
              "  'ir',\n",
              "  'trabalhar',\n",
              "  'ir',\n",
              "  'mercado?',\n",
              "  'use',\n",
              "  'm√°scara!',\n",
              "  'pode',\n",
              "  'ser',\n",
              "  'pano',\n",
              "  'deve',\n",
              "  'cobrir',\n",
              "  'nariz',\n",
              "  'boca‚Ä¶'],\n",
              " ['ver',\n",
              "  'imagens',\n",
              "  '#praias',\n",
              "  'parques',\n",
              "  '#portugal',\n",
              "  'so',\n",
              "  'vem',\n",
              "  'cabe√ßa,',\n",
              "  '‚Äùmas',\n",
              "  'gente',\n",
              "  'bem',\n",
              "  'cornos,',\n",
              "  'qu‚Ä¶'],\n",
              " ['desaparecido!',\n",
              "  'enfim,',\n",
              "  'caos',\n",
              "  'a√≠',\n",
              "  'outro',\n",
              "  'maior',\n",
              "  'chegando!',\n",
              "  'a√≠',\n",
              "  'lembro',\n",
              "  'ensinamentos',\n",
              "  'pai',\n",
              "  'p‚Ä¶'],\n",
              " ['verdadeiro',\n",
              "  'estado',\n",
              "  'terror,',\n",
              "  'inocentes',\n",
              "  'sendo',\n",
              "  'presos',\n",
              "  'andarem',\n",
              "  's√≥s',\n",
              "  'lugares',\n",
              "  'desertos,',\n",
              "  'cidad√£os',\n",
              "  'obrigados',\n",
              "  'f‚Ä¶'],\n",
              " ['economia',\n",
              "  'prefeitura',\n",
              "  'santa',\n",
              "  'b√°rbara',\n",
              "  'publica',\n",
              "  'novo',\n",
              "  'decreto',\n",
              "  'flexibilizando',\n",
              "  'abertura',\n",
              "  'com√©rcio',\n",
              "  'partir',\n",
              "  'quartaf‚Ä¶'],\n",
              " ['pib',\n",
              "  'brasil',\n",
              "  'deve',\n",
              "  'cair',\n",
              "  '4,11%',\n",
              "  '2020,',\n",
              "  'prev√™',\n",
              "  'mercado',\n",
              "  '#covid'],\n",
              " ['#coronav√≠rus',\n",
              "  '#hidroxicloroquina',\n",
              "  '#covid',\n",
              "  'hidroxicloroquina',\n",
              "  'c/',\n",
              "  'drs',\n",
              "  'paolo',\n",
              "  'zanotto',\n",
              "  'usp',\n",
              "  'pedro',\n",
              "  'batista',\n",
              "  'jr',\n",
              "  'prevent',\n",
              "  'sen‚Ä¶'],\n",
              " ['inclusive',\n",
              "  'dia',\n",
              "  '21/04',\n",
              "  'fiz',\n",
              "  'publica√ß√£o',\n",
              "  'instagram',\n",
              "  'correlacionando',\n",
              "  'pa√≠ses',\n",
              "  'mortes',\n",
              "  'covid19‚Ä¶'],\n",
              " ['presidente?',\n",
              "  'vc',\n",
              "  'formador',\n",
              "  'opini√£o',\n",
              "  'perdeu',\n",
              "  'consci√™ncia?',\n",
              "  'ganhando',\n",
              "  'isso?',\n",
              "  'qto',\n",
              "  'ganhava',\n",
              "  'antes‚Ä¶'],\n",
              " ['texto',\n",
              "  'anterior',\n",
              "  'sa√≠da',\n",
              "  'teich',\n",
              "  '\"o',\n",
              "  'tratamento',\n",
              "  'covid',\n",
              "  'pede',\n",
              "  'ci√™ncia,',\n",
              "  'voluntarismo\"'],\n",
              " ['orgulho',\n",
              "  'maninha',\n",
              "  'linha',\n",
              "  'frente',\n",
              "  'combate',\n",
              "  'co',\n",
              "  '#covid',\n",
              "  'mana',\n",
              "  'deus',\n",
              "  'proteja',\n",
              "  'todos',\n",
              "  'pacientes‚Ä¶'],\n",
              " ['importante',\n",
              "  'perdermos',\n",
              "  'controle,',\n",
              "  'sen√£o',\n",
              "  'manteremos',\n",
              "  'calma',\n",
              "  '#brasil',\n",
              "  '#covid'],\n",
              " ['excelente',\n",
              "  'not√≠cia',\n",
              "  'apenas',\n",
              "  '13',\n",
              "  'pa√≠ses',\n",
              "  'todo',\n",
              "  'planeta',\n",
              "  'terra',\n",
              "  '50',\n",
              "  'mortes',\n",
              "  'covid19',\n",
              "  'dia',\n",
              "  '17/05/202‚Ä¶'],\n",
              " ['agenda',\n",
              "  'aberta',\n",
              "  'devidos',\n",
              "  'cuidados',\n",
              "  'gente',\n",
              "  'consegue',\n",
              "  'fuder',\n",
              "  'gostoso',\n",
              "  't√°',\n",
              "  'esperando',\n",
              "  'que?',\n",
              "  'quer',\n",
              "  'namorado',\n",
              "  'para‚Ä¶'],\n",
              " ['vc',\n",
              "  'compra',\n",
              "  '#tv',\n",
              "  '@samsungbrasil',\n",
              "  'sai',\n",
              "  'defeito',\n",
              "  'loja,',\n",
              "  'compra',\n",
              "  '@tcl_oficialbr',\n",
              "  '1',\n",
              "  'ano',\n",
              "  'co‚Ä¶'],\n",
              " ['boletim', 'cabo', 'santo', 'agostinho', '#covid19'],\n",
              " ['\"n√≥s',\n",
              "  'aprendemos',\n",
              "  'hist√≥ria,',\n",
              "  'brasil,',\n",
              "  'coronav√≠rus',\n",
              "  'compromete',\n",
              "  'crian√ßas,',\n",
              "  'essa‚Ä¶'],\n",
              " ['stf',\n",
              "  'diplomatas',\n",
              "  'venezuelanos',\n",
              "  'podem',\n",
              "  'ficar',\n",
              "  'brasil',\n",
              "  'fim',\n",
              "  '#pandemia',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid'],\n",
              " ['parte',\n",
              "  '#inumer√°veis',\n",
              "  'faz',\n",
              "  'ficar',\n",
              "  'garganta',\n",
              "  'fechada',\n",
              "  'querendo',\n",
              "  'chorar',\n",
              "  '#fantastico',\n",
              "  '#covid',\n",
              "  '#17demaio',\n",
              "  '#forabolsonaro'],\n",
              " ['#bostonaroüí©',\n",
              "  'virou',\n",
              "  'v√≠deo',\n",
              "  'ridicularizando',\n",
              "  'decis√µes',\n",
              "  '#bostonaroüí©',\n",
              "  'diante',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['saiu',\n",
              "  'segundo',\n",
              "  'epis√≥dio',\n",
              "  'humanos',\n",
              "  'quarentena,',\n",
              "  'dessa',\n",
              "  'vez',\n",
              "  '@fehavila',\n",
              "  'batemos',\n",
              "  'papo',\n",
              "  'sobre',\n",
              "  'roti‚Ä¶'],\n",
              " ['#maranh√£o,',\n",
              "  'estado',\n",
              "  'ningu√©m',\n",
              "  'morre',\n",
              "  'outra',\n",
              "  'coisa,',\n",
              "  '#covid,',\n",
              "  'melhor,',\n",
              "  'mortes',\n",
              "  'outras',\n",
              "  'raz√µes',\n",
              "  'e‚Ä¶'],\n",
              " ['17/5',\n",
              "  '#covid',\n",
              "  '#paran√°',\n",
              "  '(3/3',\n",
              "  '#fiqueemcasa',\n",
              "  '884(+193',\n",
              "  'investig',\n",
              "  '1477',\n",
              "  'recup',\n",
              "  '21006(+193',\n",
              "  'exames',\n",
              "  '18538(+1265',\n",
              "  'result',\n",
              "  'n‚Ä¶'],\n",
              " ['busca',\n",
              "  'rem√©dio',\n",
              "  'auxilie',\n",
              "  'tratamento',\n",
              "  'casos',\n",
              "  '#covid19',\n",
              "  'pauta',\n",
              "  'brasil',\n",
              "  'mundo',\n",
              "  'discuss√£o',\n",
              "  'ini‚Ä¶'],\n",
              " ['#covid',\n",
              "  '#dadosn√£omentem,',\n",
              "  'informa√ß√£o',\n",
              "  'maior',\n",
              "  'arma,',\n",
              "  'perfil',\n",
              "  '#brasil',\n",
              "  'mortes',\n",
              "  'covid,',\n",
              "  '#pneumonia,',\n",
              "  '#srag,',\n",
              "  's√≠ndrome',\n",
              "  're‚Ä¶'],\n",
              " ['@bleierfilho',\n",
              "  '@jmarciopenha',\n",
              "  '@jdoriajr',\n",
              "  'n√£o!',\n",
              "  'perdi',\n",
              "  'conhecido',\n",
              "  'covid',\n",
              "  'confirmado,',\n",
              "  'tomou',\n",
              "  'medicamento',\n",
              "  'ho‚Ä¶'],\n",
              " ['causas',\n",
              "  'mortes',\n",
              "  'devidamente',\n",
              "  'informadas,',\n",
              "  'sugest√£o',\n",
              "  'vi√©s',\n",
              "  'dados',\n",
              "  'clara#covid‚Ä¶'],\n",
              " ['#covid',\n",
              "  '#dadosn√£omentem,',\n",
              "  'figura',\n",
              "  'anexo',\n",
              "  'conseguem',\n",
              "  'entender',\n",
              "  'pouco',\n",
              "  'dados,',\n",
              "  'indicadores',\n",
              "  'mortes',\n",
              "  'por‚Ä¶'],\n",
              " ['2020', 'aprendi', 'lavar', 'm√£os!', '#covid', '#alcoolgel'],\n",
              " ['deve',\n",
              "  'ser',\n",
              "  'extremamente',\n",
              "  'desgastante',\n",
              "  'ser',\n",
              "  'pessoa',\n",
              "  'grande',\n",
              "  'visibilidade',\n",
              "  'minimamente',\n",
              "  'coerente,',\n",
              "  'brasil',\n",
              "  'hoje!‚Ä¶'],\n",
              " ['0bora',\n",
              "  'participar',\n",
              "  'pessoal!?',\n",
              "  'responde',\n",
              "  'a√≠',\n",
              "  'compartilhem',\n",
              "  'vai',\n",
              "  'ser',\n",
              "  'primeira',\n",
              "  'atitude',\n",
              "  'sair',\n",
              "  'quarenten‚Ä¶'],\n",
              " ['saiba',\n",
              "  'tudo',\n",
              "  'sobre',\n",
              "  'projeto',\n",
              "  'lei',\n",
              "  'pode',\n",
              "  'ajudar',\n",
              "  'milhares',\n",
              "  'pessoas',\n",
              "  'empresas',\n",
              "  'enfrentamento',\n",
              "  'crise',\n",
              "  'provocad‚Ä¶'],\n",
              " ['@correio24horas',\n",
              "  'usa',\n",
              "  'bandeira,',\n",
              "  'maior',\n",
              "  's√≠mbolo',\n",
              "  'agredir',\n",
              "  'professional',\n",
              "  'trabalhando?',\n",
              "  'isso‚Ä¶'],\n",
              " ['#covid',\n",
              "  'avan√ßa',\n",
              "  'rio',\n",
              "  'negro',\n",
              "  'perde',\n",
              "  'feliz',\n",
              "  'i',\n",
              "  'copi√¥,',\n",
              "  'parente',\n",
              "  'epis√≥dio',\n",
              "  '146',\n",
              "  'via',\n",
              "  '@youtube'],\n",
              " ['@apenasfehh',\n",
              "  '@minsaude',\n",
              "  '@gabbardojoao',\n",
              "  '@jairbolsonaro',\n",
              "  'exemplo,',\n",
              "  'acredita',\n",
              "  'todos',\n",
              "  '√≥bitos',\n",
              "  'anotados',\n",
              "  'como‚Ä¶'],\n",
              " ['16',\n",
              "  'mil',\n",
              "  'mortes',\n",
              "  'dois',\n",
              "  'meses',\n",
              "  'domingo',\n",
              "  'completa',\n",
              "  'dois',\n",
              "  'meses',\n",
              "  'primeira',\n",
              "  'morte',\n",
              "  'oficial,',\n",
              "  'registrada',\n",
              "  '17‚Ä¶'],\n",
              " ['@barbaragancia',\n",
              "  '@riqfreire',\n",
              "  'imaginem',\n",
              "  'quanto',\n",
              "  '#covid',\n",
              "  'galerinha',\n",
              "  'levar√°',\n",
              "  'volta',\n",
              "  'pras',\n",
              "  'cidades',\n",
              "  'podemos',\n",
              "  'dizer‚Ä¶'],\n",
              " ['entenderam',\n",
              "  'desespero',\n",
              "  'm√≠dia',\n",
              "  'governadores',\n",
              "  'quest√£o',\n",
              "  'hcq,',\n",
              "  'querendo',\n",
              "  'dizer',\n",
              "  'funciona',\n",
              "  '(e',\n",
              "  'bat‚Ä¶'],\n",
              " ['#fantastico',\n",
              "  'pq',\n",
              "  'vcs',\n",
              "  'mostram',\n",
              "  'empresas',\n",
              "  'q',\n",
              "  'fechando',\n",
              "  'portas',\n",
              "  '?',\n",
              "  'f√°cil',\n",
              "  'postar',\n",
              "  '#ficaemcasa',\n",
              "  'qndo',\n",
              "  't√°‚Ä¶'],\n",
              " ['rio',\n",
              "  'janeiro',\n",
              "  'vez',\n",
              "  'p√°ginas',\n",
              "  'pol√≠cias,',\n",
              "  'furto',\n",
              "  'dinheiro',\n",
              "  'combate',\n",
              "  '#covid19,',\n",
              "  'cadeia',\n",
              "  'resp‚Ä¶'],\n",
              " ['deus',\n",
              "  'bom',\n",
              "  'dms',\n",
              "  '!',\n",
              "  'üôè‚ù§Ô∏è',\n",
              "  '#blessed',\n",
              "  '#gratid√£o',\n",
              "  '#agradecer',\n",
              "  '#covid'],\n",
              " ['#brasil,üáßüá∑',\n",
              "  '#covid19',\n",
              "  '#brasil,',\n",
              "  'relacionados',\n",
              "  '485',\n",
              "  'obitos',\n",
              "  '24',\n",
              "  'horas',\n",
              "  '16,118',\n",
              "  'mortes'],\n",
              " ['pesquisadores',\n",
              "  'autoriza√ß√£o',\n",
              "  'pra',\n",
              "  'fazer',\n",
              "  'pesquisa',\n",
              "  'conseguem',\n",
              "  'fazer',\n",
              "  'trabalho',\n",
              "  'impressionante',\n",
              "  'brasil',\n",
              "  'm‚Ä¶'],\n",
              " ['brasil',\n",
              "  'registra',\n",
              "  '485',\n",
              "  'novas',\n",
              "  'mortes',\n",
              "  '#covid19',\n",
              "  '√∫ltimas',\n",
              "  '24',\n",
              "  'horas,',\n",
              "  'totalizando',\n",
              "  '16118',\n",
              "  'n√∫mero',\n",
              "  'recuperados,',\n",
              "  'd‚Ä¶'],\n",
              " ['#cloroquina', 'rem√©dio', 'corrup√ß√£o', '#covid'],\n",
              " ['terror',\n",
              "  'lockdown',\n",
              "  'estrat√©gias',\n",
              "  'governadores!',\n",
              "  '15',\n",
              "  'dias',\n",
              "  'lockdown',\n",
              "  'recife,',\n",
              "  'luiz,',\n",
              "  'diver‚Ä¶'],\n",
              " ['telesus',\n",
              "  'criado',\n",
              "  'aproximar',\n",
              "  'minist√©rio',\n",
              "  'sa√∫de',\n",
              "  'modo',\n",
              "  'combate',\n",
              "  'coronav√≠rus',\n",
              "  'faci‚Ä¶'],\n",
              " ['d√∫vida',\n",
              "  'proteger',\n",
              "  '√≥culos',\n",
              "  'contra',\n",
              "  'coronav√≠rus?',\n",
              "  'dicas',\n",
              "  'v√£o',\n",
              "  'ajudar',\n",
              "  'hora',\n",
              "  'higienizar',\n",
              "  's‚Ä¶'],\n",
              " ['rio',\n",
              "  'janeiro',\n",
              "  '2,7',\n",
              "  'mil',\n",
              "  'mortes',\n",
              "  '#covid19',\n",
              "  'casos',\n",
              "  'confirmados,',\n",
              "  '17557',\n",
              "  'pacientes',\n",
              "  'recuperaram‚Ä¶'],\n",
              " ['curva', '#covid', '#argentina', 'an√°lisis', '@totinfraire', 'üëá'],\n",
              " ['queria',\n",
              "  'passar',\n",
              "  'pros',\n",
              "  'navegantes',\n",
              "  'quanto',\n",
              "  'extremamente',\n",
              "  'importante',\n",
              "  'lixos',\n",
              "  'recolhidos',\n",
              "  'garis',\n",
              "  'com‚Ä¶'],\n",
              " ['nunca',\n",
              "  'acreditei',\n",
              "  'mundo,',\n",
              "  'pessoas,',\n",
              "  'iria',\n",
              "  'voltar',\n",
              "  'outro',\n",
              "  '#covid',\n",
              "  'vai!'],\n",
              " ['#projetopoemanaquarentenams',\n",
              "  '1¬∫',\n",
              "  'teaser',\n",
              "  '2¬™',\n",
              "  'temporada',\n",
              "  'projeto',\n",
              "  'poema',\n",
              "  'quarentena',\n",
              "  'ms,',\n",
              "  're√∫ne',\n",
              "  '28',\n",
              "  'poetas',\n",
              "  'ma‚Ä¶'],\n",
              " ['‚Äúcrise',\n",
              "  'prolongada',\n",
              "  'dolorosa‚Äù',\n",
              "  'prevista',\n",
              "  'turismo',\n",
              "  'minho',\n",
              "  '#braga',\n",
              "  '#covid19',\n",
              "  '#emdestaque'],\n",
              " ['casos',\n",
              "  '#covid',\n",
              "  '#guarulhos',\n",
              "  'chegam',\n",
              "  '1528,',\n",
              "  '165',\n",
              "  'mortes',\n",
              "  'fonte',\n",
              "  'seade,',\n",
              "  '17/05',\n",
              "  '1710'],\n",
              " ['basta',\n",
              "  '#covid',\n",
              "  'trazer',\n",
              "  'v√°rios',\n",
              "  'sintomas',\n",
              "  'aleat√≥rios',\n",
              "  'rem√©dio',\n",
              "  'd√°',\n",
              "  'dor',\n",
              "  'est√¥mago',\n",
              "  'a√≠',\n",
              "  'tomar',\n",
              "  'rem‚Ä¶'],\n",
              " ['n√∫meros',\n",
              "  'podem',\n",
              "  'aumentar',\n",
              "  'pr√≥ximas',\n",
              "  'semanas',\n",
              "  'autoriza√ß√£o',\n",
              "  '@prefeiturabh',\n",
              "  '@alexandrekalil',\n",
              "  'reabertura',\n",
              "  'do‚Ä¶'],\n",
              " ['vantagens',\n",
              "  'usar',\n",
              "  'm√°scara',\n",
              "  'pano',\n",
              "  '#corona',\n",
              "  '#covid',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid19'],\n",
              " ['#gripe',\n",
              "  'espanhola',\n",
              "  '(1918',\n",
              "  '#covid19',\n",
              "  '(2020',\n",
              "  'pouco',\n",
              "  'tempo',\n",
              "  '(historicamente',\n",
              "  'falando',\n",
              "  'mundo',\n",
              "  'muda‚Ä¶'],\n",
              " ['ibope',\n",
              "  'impedido',\n",
              "  'fazer',\n",
              "  'pesquisa',\n",
              "  'sobre',\n",
              "  'covid',\n",
              "  'cobrou',\n",
              "  'r$',\n",
              "  '10',\n",
              "  'milh√µes',\n",
              "  '#coronavirus‚Ä¶'],\n",
              " ['aterrador!', 'cremat√≥rio', 'funciona', 'escala', 'industrial', '#covid'],\n",
              " ['live',\n",
              "  'evolu√ß√£o',\n",
              "  'dimensional',\n",
              "  '#dakilapesquisas',\n",
              "  '#17demaio',\n",
              "  '#livedobem',\n",
              "  '#covid',\n",
              "  '#evolu√ß√£o',\n",
              "  '#etbilu'],\n",
              " ['pessoas',\n",
              "  'obedecendo',\n",
              "  'quarentena?',\n",
              "  'entenda',\n",
              "  'partir',\n",
              "  'deste',\n",
              "  'v√≠deo!',\n",
              "  '#politica',\n",
              "  '#economia‚Ä¶'],\n",
              " ['sair',\n",
              "  'rapidamente',\n",
              "  'carro',\n",
              "  'pouco,',\n",
              "  'alguns',\n",
              "  'lugares',\n",
              "  'gente',\n",
              "  'domingos',\n",
              "  '‚Äúnormais‚Äù',\n",
              "  '(sem',\n",
              "  'pan‚Ä¶'],\n",
              " ['covid19',\n",
              "  'brasil',\n",
              "  '15,3',\n",
              "  'mil',\n",
              "  'novos',\n",
              "  'casos',\n",
              "  'total',\n",
              "  'chega',\n",
              "  '218,2',\n",
              "  'mil',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid'],\n",
              " ['eua',\n",
              "  'aliados',\n",
              "  'ocidente',\n",
              "  '(',\n",
              "  'incluindo',\n",
              "  'brasil',\n",
              "  'temer,',\n",
              "  'bozo,',\n",
              "  'a√©cio,',\n",
              "  'fhc,',\n",
              "  'm√≠dia,',\n",
              "  'igrejas,',\n",
              "  'judici√°ri‚Ä¶'],\n",
              " ['üóíÔ∏è',\n",
              "  '#coronav√≠rus',\n",
              "  'boletim',\n",
              "  '17/05/20',\n",
              "  'neste',\n",
              "  'domingo,',\n",
              "  'seviep',\n",
              "  '#santos',\n",
              "  'recebeu',\n",
              "  'notifica√ß√£o',\n",
              "  '50',\n",
              "  'novos',\n",
              "  'casos',\n",
              "  'c‚Ä¶'],\n",
              " ['acesse',\n",
              "  'dados',\n",
              "  'p√°gina',\n",
              "  'instagram',\n",
              "  'üëâ',\n",
              "  '#renovarobrasil',\n",
              "  '#renovabrcovid19',\n",
              "  '#renovabr‚Ä¶'],\n",
              " ['ivermectina',\n",
              "  'medicamento',\n",
              "  'parasitas',\n",
              "  'exemplo',\n",
              "  'piolho!!',\n",
              "  '#covid',\n",
              "  '#governo',\n",
              "  'inventa',\n",
              "  'cada',\n",
              "  'marmota',\n",
              "  'jesus'],\n",
              " ['gente',\n",
              "  'porque',\n",
              "  'galera',\n",
              "  't√°',\n",
              "  'tomando',\n",
              "  'ivermectina',\n",
              "  'pro',\n",
              "  'covid?',\n",
              "  '#covid',\n",
              "  '#caos',\n",
              "  '#voltajesus'],\n",
              " ['verdade',\n",
              "  'gripe',\n",
              "  'chinesa',\n",
              "  'contratada',\n",
              "  '#flamengo',\n",
              "  'absoluto',\n",
              "  'ano',\n",
              "  'novo',\n",
              "  '#mengao',\n",
              "  '#covid'],\n",
              " ['#stf',\n",
              "  'destina',\n",
              "  'r$',\n",
              "  '153',\n",
              "  'milh√µes',\n",
              "  'lava',\n",
              "  'jato',\n",
              "  'combater',\n",
              "  '#pandemia',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid'],\n",
              " ['acb',\n",
              "  '|',\n",
              "  '√≠ndice',\n",
              "  'isolamento',\n",
              "  'x',\n",
              "  'novo',\n",
              "  'rod√≠zio',\n",
              "  'suspens√£o',\n",
              "  '#covid',\n",
              "  '#covid19',\n",
              "  '#governoestadual',\n",
              "  '#governofederal‚Ä¶'],\n",
              " ['enquanto',\n",
              "  'coloca',\n",
              "  'm√°scara',\n",
              "  'pra',\n",
              "  'trabalhar,',\n",
              "  'sinh√°',\n",
              "  'coloca',\n",
              "  'm√°scara',\n",
              "  'pra',\n",
              "  'correr',\n",
              "  'cal√ßad√£o',\n",
              "  'fique',\n",
              "  'casa',\n",
              "  'p‚Ä¶'],\n",
              " ['boletim',\n",
              "  'coronav√≠rus',\n",
              "  '#covid19',\n",
              "  '|',\n",
              "  'confira',\n",
              "  'atualiza√ß√£o',\n",
              "  'boletim',\n",
              "  'municipal',\n",
              "  'deste',\n",
              "  'domingo',\n",
              "  '(17/05',\n",
              "  'informa√ß‚Ä¶'],\n",
              " ['\\U0001f9a0\\U0001f9a0',\n",
              "  'boletim',\n",
              "  'coronav√≠rus',\n",
              "  '#covid19',\n",
              "  '|',\n",
              "  'confira',\n",
              "  'atualiza√ß√£o',\n",
              "  'boletim',\n",
              "  'municipal',\n",
              "  'deste',\n",
              "  'domingo',\n",
              "  '(17/05',\n",
              "  'observa√ß√£o',\n",
              "  'fora‚Ä¶'],\n",
              " ['q', 'vale', 'q', 'praia', '#matosinhos', '#covid', 'virgem', 'extra'],\n",
              " ['prioridade',\n",
              "  'profissionais',\n",
              "  'sa√∫de',\n",
              "  'testes',\n",
              "  'covid19',\n",
              "  '#covid',\n",
              "  '#pandemia',\n",
              "  '#sa√∫de‚Ä¶'],\n",
              " ['ac', '/', 'dc', 'antes', 'corona', '/', 'corona', '#quarentena', '#covid'],\n",
              " ['covid19',\n",
              "  '3¬∫',\n",
              "  'caso',\n",
              "  'br√°s',\n",
              "  'alportel',\n",
              "  'aponta',\n",
              "  'nova',\n",
              "  'cadeia',\n",
              "  'cont√°gio',\n",
              "  'ativa',\n",
              "  '#covid19',\n",
              "  '#coronavirus‚Ä¶'],\n",
              " ['liga!',\n",
              "  '#live',\n",
              "  'rel√¢mpago',\n",
              "  'sobre',\n",
              "  '#covid',\n",
              "  'pode',\n",
              "  'ser',\n",
              "  'combatida',\n",
              "  '#radiestesia',\n",
              "  'j√°,',\n",
              "  'j√°!',\n",
              "  'logo',\n",
              "  '17h,‚Ä¶'],\n",
              " ['festa,',\n",
              "  'festa',\n",
              "  'todo',\n",
              "  'mundo',\n",
              "  'diverte,',\n",
              "  'rindo',\n",
              "  'n√≥s!',\n",
              "  '#tbt',\n",
              "  'nada,',\n",
              "  'vou',\n",
              "  'lan√ßar',\n",
              "  'hastag‚Ä¶'],\n",
              " ['üò∑',\n",
              "  'seguran√ßa',\n",
              "  'todos',\n",
              "  'primeiro',\n",
              "  'lugar!',\n",
              "  'isso,',\n",
              "  'precisou',\n",
              "  'sair',\n",
              "  'casa?',\n",
              "  'v√°',\n",
              "  '#m√°scara!',\n",
              "  'üëâ',\n",
              "  'usada',\n",
              "  'corretament‚Ä¶'],\n",
              " ['‚ö†',\n",
              "  'fazemos',\n",
              "  'teste',\n",
              "  'pcr',\n",
              "  'covid19!',\n",
              "  '#corona',\n",
              "  '#virus',\n",
              "  '#coronavirus',\n",
              "  '#saude',\n",
              "  '#covid19',\n",
              "  '#covid19',\n",
              "  '#covid_19',\n",
              "  '#prevencao',\n",
              "  '#sus‚Ä¶'],\n",
              " ['primeira',\n",
              "  'vez,',\n",
              "  'mon√ß√£o',\n",
              "  'casos',\n",
              "  'covid',\n",
              "  'recuperados',\n",
              "  'ativos',\n",
              "  '#covid19',\n",
              "  '#emdestaque',\n",
              "  '#mon√ß√£o'],\n",
              " ['passada',\n",
              "  'ressaca,',\n",
              "  'alguns',\n",
              "  '\"exinfectados\"',\n",
              "  'reclamam',\n",
              "  'extrema',\n",
              "  'fadiga',\n",
              "  'parece',\n",
              "  'ser',\n",
              "  'pr√≥xima',\n",
              "  'fronteira',\n",
              "  'holand‚Ä¶'],\n",
              " ['covid19',\n",
              "  'fran√ßa',\n",
              "  'ultrapassa',\n",
              "  '28',\n",
              "  'mil',\n",
              "  'mortos',\n",
              "  '483',\n",
              "  'novos',\n",
              "  '√≥bitos',\n",
              "  '#covid19',\n",
              "  '#fran√ßa',\n",
              "  '#√≥bitos'],\n",
              " ['lembrando',\n",
              "  'teich',\n",
              "  'ministro',\n",
              "  'indicado',\n",
              "  'amb',\n",
              "  'segundo',\n",
              "  'informa√ß√µes',\n",
              "  'pr√≥pria',\n",
              "  'associa√ß√£o',\n",
              "  'bolsonaro',\n",
              "  'cita‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['covid19',\n",
              "  'it√°lia',\n",
              "  'acentua',\n",
              "  'descida',\n",
              "  '145',\n",
              "  'mortes',\n",
              "  '675',\n",
              "  'casos',\n",
              "  '24',\n",
              "  'horas',\n",
              "  '#covid19',\n",
              "  '#it√°lia',\n",
              "  '#√≥bitos'],\n",
              " ['covid19',\n",
              "  'reino',\n",
              "  'unido',\n",
              "  '170',\n",
              "  'novas',\n",
              "  'mortes,',\n",
              "  'n√∫mero',\n",
              "  'baixo',\n",
              "  'desde',\n",
              "  'mar√ßo',\n",
              "  '#covid19',\n",
              "  '#√≥bitos',\n",
              "  '#reinounido'],\n",
              " ['espanha',\n",
              "  'vai',\n",
              "  'impor',\n",
              "  'uso',\n",
              "  'obrigat√≥rio',\n",
              "  'm√°scara',\n",
              "  'locais',\n",
              "  'p√∫blicos',\n",
              "  '#covid19',\n",
              "  '#espanha',\n",
              "  '#sa√∫de'],\n",
              " ['fc',\n",
              "  'famalicao',\n",
              "  'casos',\n",
              "  'positivos',\n",
              "  'covid',\n",
              "  '#covid19',\n",
              "  '#famalic√£o',\n",
              "  '#fcfamalic√£o'],\n",
              " ['#cloroquina',\n",
              "  'eficaz',\n",
              "  'contra',\n",
              "  'covid',\n",
              "  'perigosa,',\n",
              "  'pode',\n",
              "  'matar',\n",
              "  'pacientes!',\n",
              "  '#hidroxicloroquina',\n",
              "  'efi‚Ä¶'],\n",
              " ['aces',\n",
              "  'nega',\n",
              "  'falta',\n",
              "  'material',\n",
              "  'centro',\n",
              "  'sa√∫de',\n",
              "  'esposende',\n",
              "  '#acesc√°vado',\n",
              "  '#covid19',\n",
              "  '#esposende'],\n",
              " ['sweet',\n",
              "  'dreams',\n",
              "  'assista',\n",
              "  '#albertooliveira',\n",
              "  '#ao',\n",
              "  '#musica',\n",
              "  '#sweetdreams',\n",
              "  '#coronavirus‚Ä¶'],\n",
              " ['#advogado',\n",
              "  'londrina,',\n",
              "  '#igreja,',\n",
              "  '#covid19',\n",
              "  'mpf',\n",
              "  'pede',\n",
              "  'retirada',\n",
              "  'ar',\n",
              "  'v√≠deos',\n",
              "  'pastor',\n",
              "  'anuncia',\n",
              "  'cura',\n",
              "  \"'m√°gica'\",\n",
              "  'cov‚Ä¶'],\n",
              " ['urgente',\n",
              "  'mega',\n",
              "  'carreata',\n",
              "  'bolsonarista',\n",
              "  'rio',\n",
              "  'janeiro',\n",
              "  'manifestantes',\n",
              "  'pedem',\n",
              "  'witzel',\n",
              "  'volta',\n",
              "  'trabalho‚Ä¶'],\n",
              " ['agora',\n",
              "  'avenida',\n",
              "  'paulista,',\n",
              "  'grupo',\n",
              "  'manifestantes',\n",
              "  're√∫nem',\n",
              "  'prox',\n",
              "  'fiesp',\n",
              "  'grupo',\n",
              "  'pede',\n",
              "  'impeachment',\n",
              "  'governador‚Ä¶'],\n",
              " ['live',\n",
              "  'on',\n",
              "  '#periscope',\n",
              "  'explorerinf',\n",
              "  'paranormal',\n",
              "  'pete!',\n",
              "  '#creepy',\n",
              "  '#thesewoodsarrhaunted',\n",
              "  '#covid',\n",
              "  '#ghosts',\n",
              "  '#snakes'],\n",
              " ['üôÑ',\n",
              "  '#covid19',\n",
              "  'causando',\n",
              "  'n',\n",
              "  'planeta',\n",
              "  'n√∫mero',\n",
              "  'd',\n",
              "  'mortandade',\n",
              "  'absurdamente',\n",
              "  'preocupante',\n",
              "  'tempo',\n",
              "  'rev‚Ä¶'],\n",
              " ['neste',\n",
              "  'programa,',\n",
              "  'ivan',\n",
              "  'mizanzuk',\n",
              "  'conversa',\n",
              "  'sonia',\n",
              "  'guajajara',\n",
              "  'sobre',\n",
              "  'impacto',\n",
              "  'novo',\n",
              "  '#coronav√≠rus',\n",
              "  'povos‚Ä¶'],\n",
              " ['funcion√°rios',\n",
              "  'creches',\n",
              "  'barcelos',\n",
              "  'esposende',\n",
              "  'casos',\n",
              "  'positivos',\n",
              "  'covid',\n",
              "  '#acesc√°vado',\n",
              "  '#barcelos',\n",
              "  '#covid19'],\n",
              " ['#ufba',\n",
              "  '#ifba',\n",
              "  '#oceanografia',\n",
              "  '#ufrj',\n",
              "  '#laurodefreitas',\n",
              "  '#brasil',\n",
              "  '#bolsonaro',\n",
              "  '#bahia',\n",
              "  '#salvador',\n",
              "  '#mario',\n",
              "  '#jo√£o',\n",
              "  '#jose',\n",
              "  '#covid',\n",
              "  '#pai‚Ä¶'],\n",
              " ['#pessoal',\n",
              "  'acham',\n",
              "  'dr',\n",
              "  'anthony',\n",
              "  'wong',\n",
              "  'par',\n",
              "  'minist√©rio',\n",
              "  'sa√∫de?',\n",
              "  '#bolsonaro',\n",
              "  '#ministeriodasaude',\n",
              "  '#covid'],\n",
              " ['policial',\n",
              "  'penal',\n",
              "  'problemas',\n",
              "  'sa√∫de',\n",
              "  '(comorbidades',\n",
              "  'infectado',\n",
              "  'dentro',\n",
              "  'papuda',\n",
              "  'enfrenta',\n",
              "  'surto‚Ä¶'],\n",
              " ['üåç',\n",
              "  '#covid',\n",
              "  '#boasnot√≠cias',\n",
              "  'üá´üá∑',\n",
              "  '#fran√ßa',\n",
              "  'registra',\n",
              "  'menos',\n",
              "  'cem',\n",
              "  'mortes',\n",
              "  'covid19',\n",
              "  '24h',\n",
              "  'üáØüáµ',\n",
              "  'com√©rcio',\n",
              "  'reabre',\n",
              "  '#jap√£o‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['pandemia',\n",
              "  'covid19',\n",
              "  'afetou',\n",
              "  'h√°bitos',\n",
              "  'vida?',\n",
              "  'responda',\n",
              "  '#fiqueemcasa',\n",
              "  '#sa√∫de‚Ä¶'],\n",
              " ['triste',\n",
              "  'realidade',\n",
              "  'espalhando',\n",
              "  'todos',\n",
              "  'setores',\n",
              "  'goi√¢nia,',\n",
              "  'goi√°s,',\n",
              "  'ocorrendo',\n",
              "  'todos',\n",
              "  'setores‚Ä¶'],\n",
              " ['covas',\n",
              "  'diz',\n",
              "  'sa√∫de',\n",
              "  'sp',\n",
              "  'perto',\n",
              "  'colapso',\n",
              "  'depende',\n",
              "  'doria',\n",
              "  'implantar',\n",
              "  \"'lockdown'‚Ä¶\"],\n",
              " ['#fifa',\n",
              "  'definir√°',\n",
              "  'pa√≠ssede',\n",
              "  '#mundial',\n",
              "  'futebol',\n",
              "  'feminino',\n",
              "  '25',\n",
              "  'junho',\n",
              "  '#copadomundo',\n",
              "  '#covid'],\n",
              " ['acho',\n",
              "  'dever√≠amos',\n",
              "  'aderir',\n",
              "  'urgente',\n",
              "  'gesto',\n",
              "  'aqui',\n",
              "  '!',\n",
              "  'mostrar',\n",
              "  'n√∫meros',\n",
              "  '!!',\n",
              "  '#vaitomarnocucorona‚Ä¶'],\n",
              " ['direito!!!',\n",
              "  'empresas',\n",
              "  'podem',\n",
              "  'requerer',\n",
              "  'suspens√£o',\n",
              "  'tributos',\n",
              "  'distritais',\n",
              "  'fun√ß√£o',\n",
              "  'pandemia',\n",
              "  'covid19',\n",
              "  '‚Ä¶'],\n",
              " ['enquanto',\n",
              "  'isso,',\n",
              "  'cart√£o',\n",
              "  'corporativo',\n",
              "  'compras',\n",
              "  'emergenciais',\n",
              "  'estados',\n",
              "  'munic√≠pios!!!',\n",
              "  'üò°üò°',\n",
              "  '#vergonha‚Ä¶'],\n",
              " ['covid',\n",
              "  '19',\n",
              "  'ms',\n",
              "  '#covid_19',\n",
              "  '#covid19',\n",
              "  '#covid',\n",
              "  '#covid19cg',\n",
              "  '#campograndems',\n",
              "  '#matogrossodosul',\n",
              "  '#portaljeffersondealmeida‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['#covid19', 'mata', 'segunda', 'crian√ßa', '48', 'horas', 'sp'],\n",
              " ['emocionante',\n",
              "  'texto',\n",
              "  'salvem',\n",
              "  'idosos',\n",
              "  'lutaram',\n",
              "  'tanto,',\n",
              "  'agora',\n",
              "  'sob',\n",
              "  'cuidados',\n",
              "  '#eugenia',\n",
              "  'n‚Ä¶'],\n",
              " ['alerta', 'sobre', 'responsabilidade', 'mortes', 'evit√°veis', '#covid19'],\n",
              " ['empresa',\n",
              "  'alentejana',\n",
              "  'oferece',\n",
              "  '500',\n",
              "  'quilos',\n",
              "  'legumes',\n",
              "  'carenciados',\n",
              "  'famalic√£o',\n",
              "  '#alentejo',\n",
              "  '#covid19',\n",
              "  '#famalic√£o'],\n",
              " ['querem',\n",
              "  'despachar',\n",
              "  'estoque',\n",
              "  'ex√©rcito',\n",
              "  'fabricou',\n",
              "  'larga',\n",
              "  'escala,',\n",
              "  'mando',\n",
              "  'bolsonaro',\n",
              "  'pra',\n",
              "  'livrar',\n",
              "  'crime',\n",
              "  'de‚Ä¶'],\n",
              " ['algu√©m',\n",
              "  'ainda',\n",
              "  'duvida',\n",
              "  'brasil',\n",
              "  'vai',\n",
              "  'protagonizar',\n",
              "  'maiores',\n",
              "  'trag√©dias',\n",
              "  'humanit√°rias',\n",
              "  'hist√≥ria',\n",
              "  'recente?',\n",
              "  've‚Ä¶'],\n",
              " ['overthinking',\n",
              "  'nesses',\n",
              "  'tempos',\n",
              "  'quarentena',\n",
              "  'normal',\n",
              "  'deixemos',\n",
              "  'levar',\n",
              "  'bombas',\n",
              "  'informa√ß√£o',\n",
              "  'constante,',\n",
              "  'pel‚Ä¶'],\n",
              " ['munic√≠pio',\n",
              "  'ind√≠genas',\n",
              "  'pa√≠s',\n",
              "  '219',\n",
              "  'casos',\n",
              "  'covid19',\n",
              "  '#amazonas',\n",
              "  '#covid'],\n",
              " ['ontem',\n",
              "  'convidei',\n",
              "  '@supercaruso',\n",
              "  'participar',\n",
              "  'desse',\n",
              "  'projeto',\n",
              "  'hoje',\n",
              "  '#live',\n",
              "  '1600!',\n",
              "  'no‚Ä¶'],\n",
              " ['partida',\n",
              "  'semifinal',\n",
              "  'jogo',\n",
              "  'bem',\n",
              "  '@evertonri',\n",
              "  'filho',\n",
              "  '@_felipemelo_,',\n",
              "  'davi',\n",
              "  'melo,',\n",
              "  'sensacional!!‚öΩüéÆüî•üíØ‚Ä¶'],\n",
              " ['#china',\n",
              "  '#covid',\n",
              "  'embaixador',\n",
              "  'china',\n",
              "  'israel',\n",
              "  'encontrado',\n",
              "  'morto',\n",
              "  'casa',\n",
              "  '|',\n",
              "  'mundo',\n",
              "  '|',\n",
              "  'g1'],\n",
              " ['exemplo', 'deveria', 'ser', 'seguido', 'muitas', 'pessoas', '#covid'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['lajeado',\n",
              "  'mp',\n",
              "  'conclui',\n",
              "  'acordos',\n",
              "  'brf',\n",
              "  'minuano',\n",
              "  'prote√ß√£o',\n",
              "  'sa√∫de',\n",
              "  'popula√ß√£o',\n",
              "  'local'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho'],\n",
              " ['elogio',\n",
              "  'passando',\n",
              "  'feed',\n",
              "  'üòç',\n",
              "  'dessa',\n",
              "  'vez',\n",
              "  'aluno',\n",
              "  'luiz',\n",
              "  'carlos,',\n",
              "  'super',\n",
              "  'feliz',\n",
              "  'cursosüíö‚Ä¶'],\n",
              " ['@diegomachados01',\n",
              "  '@spsobretrilhos',\n",
              "  '@jdoriajr',\n",
              "  '@brunocovas',\n",
              "  '@metrosp_oficial',\n",
              "  '@jairbolsonaro',\n",
              "  'triste',\n",
              "  'al√¥',\n",
              "  '@prefsp‚Ä¶'],\n",
              " ['principio',\n",
              "  'isonomia',\n",
              "  '\"tratar',\n",
              "  'iguais',\n",
              "  'medida',\n",
              "  'igualdade',\n",
              "  'desiguais',\n",
              "  'medida',\n",
              "  'desigualdade\"‚Ä¶'],\n",
              " ['#governo',\n",
              "  '#federal',\n",
              "  '#diminuir',\n",
              "  '#sal√°rios',\n",
              "  '#deputados,',\n",
              "  '#senadores',\n",
              "  'assessores',\n",
              "  'metade',\n",
              "  '#combater',\n",
              "  '#covid1‚Ä¶'],\n",
              " ['passa',\n",
              "  'vergonha,',\n",
              "  'bolsominios',\n",
              "  't√™m',\n",
              "  'limites',\n",
              "  '#vergonha',\n",
              "  '#impeachmentbolsonaro',\n",
              "  '#jairbolsonaro‚Ä¶'],\n",
              " ['diverg√™ncia,',\n",
              "  'nelson',\n",
              "  'teich',\n",
              "  'deixa',\n",
              "  'cargo',\n",
              "  'ministro',\n",
              "  'sa√∫de',\n",
              "  'brasil',\n",
              "  'di√°rio',\n",
              "  'pandemia,',\n",
              "  '17',\n",
              "  'maio',\n",
              "  '2020',\n",
              "  'ver',\n",
              "  'ma‚Ä¶'],\n",
              " ['\"vai',\n",
              "  'tomar',\n",
              "  'cu',\n",
              "  'corona\"?',\n",
              "  'gado',\n",
              "  'direcione',\n",
              "  'raiva',\n",
              "  'v√≠rus',\n",
              "  'mito!',\n",
              "  '#bolsonaro',\n",
              "  '#brasilien‚Ä¶'],\n",
              " ['#covid19', 'dados', 'oficais', '#mo√ßambique'],\n",
              " ['valeime', 'rafael!!', '#dornacabe√ßa', '#covid', '#cansei'],\n",
              " ['problema',\n",
              "  'meme',\n",
              "  'peti√ß√£o',\n",
              "  '#covas',\n",
              "  '#rod√≠zio',\n",
              "  '#covid',\n",
              "  '#pandemia',\n",
              "  '#advocacia',\n",
              "  '#oab'],\n",
              " ['hipertensos',\n",
              "  'fazem',\n",
              "  'parte',\n",
              "  'grupo',\n",
              "  'vulner√°vel',\n",
              "  'cont√°gio',\n",
              "  'covid19,',\n",
              "  'importante',\n",
              "  'evitem',\n",
              "  'agl‚Ä¶'],\n",
              " ['alimentos,',\n",
              "  'm√°scaras',\n",
              "  'prote√ß√£o',\n",
              "  '√°lcool',\n",
              "  'gel',\n",
              "  'entregues',\n",
              "  'duas',\n",
              "  'mil',\n",
              "  'fam√≠lias',\n",
              "  'ind√≠genas',\n",
              "  'gabriel',\n",
              "  'd‚Ä¶'],\n",
              " ['4',\n",
              "  'planos',\n",
              "  'aula',\n",
              "  'combater',\n",
              "  'desinforma√ß√£o',\n",
              "  'tempos',\n",
              "  'coronav√≠rus',\n",
              "  'via',\n",
              "  '@porvir‚Ä¶'],\n",
              " ['brasil',\n",
              "  'registra',\n",
              "  '14,9',\n",
              "  'mil',\n",
              "  'novos',\n",
              "  '#casos',\n",
              "  '816',\n",
              "  'novas',\n",
              "  '#mortes',\n",
              "  'covid19',\n",
              "  '#balan√ßo',\n",
              "  '#covid'],\n",
              " ['cumprimento',\n",
              "  'decreto',\n",
              "  'gdf,',\n",
              "  'alteramos',\n",
              "  'hor√°rio',\n",
              "  'funcionamento',\n",
              "  'continuamos',\n",
              "  '‚Äúon',\n",
              "  'line‚Äù',\n",
              "  '24',\n",
              "  'horas',\n",
              "  'por‚Ä¶'],\n",
              " ['deputados',\n",
              "  'estaduais',\n",
              "  'impeachment',\n",
              "  'governador',\n",
              "  'camilo',\n",
              "  'santana',\n",
              "  '(',\n",
              "  'pt',\n",
              "  '#foracamilo',\n",
              "  'assine',\n",
              "  'peti√ß√£o!‚Ä¶'],\n",
              " ['empresa?',\n",
              "  'pensou',\n",
              "  'medidas',\n",
              "  'precisa',\n",
              "  'adotar',\n",
              "  'enquanto',\n",
              "  'covid19',\n",
              "  'passa?',\n",
              "  'confira',\n",
              "  'mat√©ria',\n",
              "  'blog',\n",
              "  'para‚Ä¶'],\n",
              " ['#rondon√≥polis', 'registra', 'morte', '#covid19'],\n",
              " ['sobre',\n",
              "  '#covid',\n",
              "  'brasil',\n",
              "  'üò∑',\n",
              "  '\\U0001f9a0',\n",
              "  'üìå',\n",
              "  '#sp',\n",
              "  'continua',\n",
              "  'liderando',\n",
              "  'ranking',\n",
              "  'seguido',\n",
              "  'rj',\n",
              "  'üö´',\n",
              "  '#par√°',\n",
              "  'estende',\n",
              "  '#lockdown',\n",
              "  'p‚Ä¶'],\n",
              " ['2080',\n",
              "  'povo',\n",
              "  'entendeu',\n",
              "  'ainda',\n",
              "  'isolamento',\n",
              "  'social',\n",
              "  '#covid',\n",
              "  '#domingodetremurasdv‚Ä¶'],\n",
              " ['dgs',\n",
              "  'avisado',\n",
              "  'limpar',\n",
              "  'grandes',\n",
              "  'superf√≠cies',\n",
              "  'desinfetante',\n",
              "  'eficaz',\n",
              "  '#covid19',\n",
              "  '#dgs',\n",
              "  '#gra√ßafreitas'],\n",
              " ['@vaseldaniel',\n",
              "  'inimigo',\n",
              "  'inimigo',\n",
              "  'amigo,',\n",
              "  'moro',\n",
              "  'pasta',\n",
              "  'justi√ßa,',\n",
              "  'suspender',\n",
              "  'lavajato,',\n",
              "  'sendo',\n",
              "  'sincero‚Ä¶'],\n",
              " ['@gduvivier',\n",
              "  'fantastico',\n",
              "  'greg',\n",
              "  'news',\n",
              "  'leveza,',\n",
              "  'cultura,',\n",
              "  'arte,',\n",
              "  'vida',\n",
              "  'morte',\n",
              "  '#brasil,',\n",
              "  'tempos',\n",
              "  '#covid,',\n",
              "  'lideranc‚Ä¶'],\n",
              " ['regras',\n",
              "  'festas',\n",
              "  'partid√°rias',\n",
              "  'populares',\n",
              "  't√™m',\n",
              "  '‚Äúvaler',\n",
              "  'todos‚Äù',\n",
              "  '#covid19',\n",
              "  '#pol√≠tica',\n",
              "  '#sa√∫de'],\n",
              " ['vc,',\n",
              "  'cearense,',\n",
              "  '√±',\n",
              "  'ficar',\n",
              "  'casa,',\n",
              "  'todo',\n",
              "  'esfor√ßo',\n",
              "  'v√£o',\n",
              "  '#fiqueemcasa',\n",
              "  '#covid19'],\n",
              " ['vai',\n",
              "  'tomar',\n",
              "  'cu',\n",
              "  'corona',\n",
              "  'deveria',\n",
              "  'ser',\n",
              "  'presidente',\n",
              "  'rep√∫blica',\n",
              "  'financiou',\n",
              "  'pesquisas',\n",
              "  'encontra‚Ä¶'],\n",
              " ['ir√£o',\n",
              "  'regista',\n",
              "  'quase',\n",
              "  '7000',\n",
              "  'mortos',\n",
              "  'devido',\n",
              "  'v√≠rus',\n",
              "  '#covid19',\n",
              "  '#ir√£o',\n",
              "  '#√≥bitos'],\n",
              " ['m√°scaras',\n",
              "  'certificado',\n",
              "  'inv√°lido',\n",
              "  'distribu√≠das',\n",
              "  'pagas',\n",
              "  '#covid19',\n",
              "  '#dgs'],\n",
              " ['medo', 'deve', 'paralisar', 'portugueses', '#covid19', '#dgs', '#sa√∫de'],\n",
              " ['covid19',\n",
              "  'trump',\n",
              "  'parou',\n",
              "  'insistir',\n",
              "  'uso',\n",
              "  'hidroxicloroquina?',\n",
              "  'acredito',\n",
              "  'resposta',\n",
              "  'quest‚Ä¶'],\n",
              " ['reposted',\n",
              "  'from',\n",
              "  '@pcriminalanimal',\n",
              "  'causa',\n",
              "  'pandemia',\n",
              "  '#covid19,',\n",
              "  'n√∫mero',\n",
              "  'casos',\n",
              "  'viol√™ncia',\n",
              "  'dom√©stica',\n",
              "  'fami‚Ä¶'],\n",
              " ['c√£es',\n",
              "  'farejadores',\n",
              "  'come√ßam',\n",
              "  'ser',\n",
              "  'testados',\n",
              "  'detectar',\n",
              "  'pessoas',\n",
              "  'coronav√≠rus',\n",
              "  'cheiro',\n",
              "  '#blogdosilvalima',\n",
              "  '#saude‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'cuidado',\n",
              "  'almo√ßo!',\n",
              "  'pessoas',\n",
              "  'peso',\n",
              "  'acima',\n",
              "  'recomend√°vel',\n",
              "  'devem',\n",
              "  'redobrar',\n",
              "  'cuidados',\n",
              "  'nesse',\n",
              "  'cen√°rio',\n",
              "  'qu‚Ä¶'],\n",
              " ['primo',\n",
              "  'porteiro',\n",
              "  'condom√≠nio',\n",
              "  '04',\n",
              "  'pegou',\n",
              "  'metade,',\n",
              "  'morrido',\n",
              "  'estouro',\n",
              "  'pneu',\n",
              "  'colocaram',\n",
              "  'foi‚Ä¶'],\n",
              " ['lembra,', 'tug√£o', 'vai', 'assim', 'culpa', '#covid', '√≥', '#varandasout?'],\n",
              " ['oficial',\n",
              "  'braga',\n",
              "  'vai',\n",
              "  'seis',\n",
              "  'dias',\n",
              "  'novos',\n",
              "  'casos',\n",
              "  'covid',\n",
              "  '#braga',\n",
              "  '#covid19',\n",
              "  '#dgs'],\n",
              " ['sabe',\n",
              "  'maior',\n",
              "  'medo',\n",
              "  'momento',\n",
              "  '?',\n",
              "  'mortos',\n",
              "  'covid19',\n",
              "  'acordem',\n",
              "  'apocalipse',\n",
              "  'zumbi',\n",
              "  '!',\n",
              "  'vou',\n",
              "  'parar',\n",
              "  'se‚Ä¶'],\n",
              " ['#brasil',\n",
              "  'conseguiu',\n",
              "  'ter',\n",
              "  'hospital',\n",
              "  'superfaturado,',\n",
              "  'dentro',\n",
              "  'est√°dio',\n",
              "  'superfaturado',\n",
              "  'respiradores',\n",
              "  'superfaturados!',\n",
              "  'üëèüèº‚Ä¶'],\n",
              " ['escapa',\n",
              "  'contagiado',\n",
              "  'eagle',\n",
              "  'pass',\n",
              "  'nava',\n",
              "  '#cincomanantiales',\n",
              "  '#covid19'],\n",
              " ['escapa',\n",
              "  'contagiado',\n",
              "  'eagle',\n",
              "  'pass',\n",
              "  'nava',\n",
              "  '#cincomanantiales',\n",
              "  '#covid19'],\n",
              " ['#covid',\n",
              "  '#abrolhosbrasil',\n",
              "  'carlos',\n",
              "  'drumond',\n",
              "  'havia',\n",
              "  'pedra',\n",
              "  'meio',\n",
              "  'caminho',\n",
              "  '@direitonoponto',\n",
              "  'meio',\n",
              "  'caminh‚Ä¶'],\n",
              " ['ofical',\n",
              "  '814',\n",
              "  'pessoas',\n",
              "  'recuperaram',\n",
              "  'covid',\n",
              "  'pa√≠s',\n",
              "  '√∫ltimas',\n",
              "  '24',\n",
              "  'horas',\n",
              "  '#covid19',\n",
              "  '#dgs',\n",
              "  '#emdestaque'],\n",
              " ['bom',\n",
              "  'dia!',\n",
              "  'hoje',\n",
              "  'dia',\n",
              "  'marcado',\n",
              "  'conquistas',\n",
              "  'vit√≥rias',\n",
              "  'gl√≥ria',\n",
              "  'deus',\n",
              "  '#fiqueemcasa',\n",
              "  '#covid19',\n",
              "  '#vamosvencer'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['atualiza√ß√£o',\n",
              "  '#covid19',\n",
              "  '#brasil',\n",
              "  'atualiza√ß√£o',\n",
              "  '17/05/2020',\n",
              "  '114316',\n",
              "  'utc',\n",
              "  'casos',\n",
              "  '233511',\n",
              "  'casos',\n",
              "  'hoje',\n",
              "  '369',\n",
              "  'mortes',\n",
              "  '15662',\n",
              "  'mo‚Ä¶'],\n",
              " ['üáßüá∑',\n",
              "  'total',\n",
              "  'casos',\n",
              "  'brasil',\n",
              "  'casos',\n",
              "  'confirmadoss',\n",
              "  '233,511',\n",
              "  '√≥bitos',\n",
              "  '15,662',\n",
              "  'recupera√ß√µes',\n",
              "  '89,672',\n",
              "  '#covid,#corona,‚Ä¶'],\n",
              " ['pessoas',\n",
              "  'tipo',\n",
              "  'sangu√≠neo',\n",
              "  'podem',\n",
              "  'ter',\n",
              "  'maiores',\n",
              "  '#chances',\n",
              "  'pegar',\n",
              "  'coronav√≠rus,',\n",
              "  'segundo',\n",
              "  '#pesquisa',\n",
              "  '#covid'],\n",
              " ['pandemia',\n",
              "  '‚Äúroubou‚Äù',\n",
              "  'sustento',\n",
              "  'vendedores',\n",
              "  'farturas',\n",
              "  'feiras',\n",
              "  'romarias',\n",
              "  '#covid19',\n",
              "  '#economia'],\n",
              " ['m√°scaras',\n",
              "  'luvas',\n",
              "  'descart√°veis',\n",
              "  'materiais',\n",
              "  'preven√ß√£o',\n",
              "  'bastante',\n",
              "  'comuns',\n",
              "  'durante',\n",
              "  'pandemia',\n",
              "  'fizermos',\n",
              "  'u‚Ä¶'],\n",
              " ['sa√∫de!',\n",
              "  'paz',\n",
              "  'prosperidade!',\n",
              "  'hoje',\n",
              "  '#orando',\n",
              "  'vez,',\n",
              "  '#infectados/doentes',\n",
              "  '#covid19',\n",
              "  'clamando‚Ä¶'],\n",
              " ['hoje',\n",
              "  '#orando',\n",
              "  'vez,',\n",
              "  '#infectados/doentes',\n",
              "  '#covid19',\n",
              "  'clamando',\n",
              "  'deus',\n",
              "  '#cura!‚Ä¶'],\n",
              " ['tempos',\n",
              "  'pandemia,',\n",
              "  'centro',\n",
              "  'triagem',\n",
              "  'lipor',\n",
              "  'continua',\n",
              "  'laborar!',\n",
              "  'conhe√ßa',\n",
              "  'resultados',\n",
              "  'mar√ßo',\n",
              "  'veja',\n",
              "  'que‚Ä¶'],\n",
              " ['situa√ß√£o',\n",
              "  'clara',\n",
              "  '1',\n",
              "  'sp,',\n",
              "  'rj,',\n",
              "  'pa,',\n",
              "  'ce,',\n",
              "  'radicalmente',\n",
              "  'contra',\n",
              "  '@jairbolsonaro',\n",
              "  ',',\n",
              "  'n√∫meros',\n",
              "  '#covid',\n",
              "  'distorcido‚Ä¶'],\n",
              " ['novas',\n",
              "  'elei√ß√µes',\n",
              "  'vota?',\n",
              "  '(se',\n",
              "  'chapa',\n",
              "  'bolsonaro',\n",
              "  'cassada',\n",
              "  '#globohack',\n",
              "  '#furacao2000',\n",
              "  '#lgbt',\n",
              "  '#covid'],\n",
              " ['fim', 'cloroquina', 'eua', '#covid19'],\n",
              " ['#hospitalodilonbehrens,',\n",
              "  '#bh,',\n",
              "  'vai',\n",
              "  'receber',\n",
              "  'r$',\n",
              "  '339900,77',\n",
              "  'viabilizados',\n",
              "  '@mptmg,',\n",
              "  'recursos',\n",
              "  'utilizados',\n",
              "  'n‚Ä¶'],\n",
              " ['üéÆ‚öΩ√©',\n",
              "  'dia',\n",
              "  'decis√£o‚öΩüéÆ',\n",
              "  'jogo',\n",
              "  'bem',\n",
              "  'chega',\n",
              "  '√∫ltimo',\n",
              "  'dia',\n",
              "  'disputa',\n",
              "  'semifinais',\n",
              "  'final!',\n",
              "  'venha',\n",
              "  'particip‚Ä¶'],\n",
              " ['07h45',\n",
              "  'bom',\n",
              "  'dia',\n",
              "  '#ficaemcasa',\n",
              "  'caraleo',\n",
              "  'preparado',\n",
              "  'gripe',\n",
              "  's√≠nica',\n",
              "  'aparecer',\n",
              "  'bora',\n",
              "  'correr,',\n",
              "  'sedentarismo‚Ä¶'],\n",
              " ['üëâ√±',\n",
              "  'mentir,',\n",
              "  'sabem,',\n",
              "  'fa√ßa',\n",
              "  'pergunta',\n",
              "  'certa',\n",
              "  'escute',\n",
              "  'voz',\n",
              "  'alta',\n",
              "  'resposta,',\n",
              "  '√±',\n",
              "  'tente',\n",
              "  'adivinhar',\n",
              "  '√±',\n",
              "  'vai',\n",
              "  's‚Ä¶'],\n",
              " ['enviou',\n",
              "  'mensagem',\n",
              "  '(email',\n",
              "  'pol√≠tico',\n",
              "  'ajudou',\n",
              "  'eleger',\n",
              "  'pedindo',\n",
              "  'informa√ß√µes',\n",
              "  'cobrando',\n",
              "  'trabalho',\n",
              "  'co‚Ä¶'],\n",
              " ['15000',\n",
              "  'fam√≠lias',\n",
              "  'recorreram',\n",
              "  'pagamento',\n",
              "  'faseado',\n",
              "  'luz',\n",
              "  '#covid19',\n",
              "  '#edp',\n",
              "  '#eletricidade'],\n",
              " ['agricultores',\n",
              "  'pedem',\n",
              "  'apoio',\n",
              "  'forma',\n",
              "  'urgente',\n",
              "  '#agricultura',\n",
              "  '#covid19'],\n",
              " ['15000',\n",
              "  'mortos',\n",
              "  '#covid',\n",
              "  'testes',\n",
              "  'p√≠fios',\n",
              "  '4¬∞',\n",
              "  'lugar',\n",
              "  'mundo',\n",
              "  'n√∫mero',\n",
              "  'casos',\n",
              "  '#forabolsonaro'],\n",
              " ['@jairbolsonaro',\n",
              "  't√°',\n",
              "  'direcionando',\n",
              "  'gado',\n",
              "  'qe',\n",
              "  'fala',\n",
              "  'qe',\n",
              "  '#covid19',\n",
              "  'gripezinha',\n",
              "  'pro',\n",
              "  'curral',\n",
              "  'deveria',\n",
              "  'chegar',\n",
              "  'l√°',\n",
              "  'pra‚Ä¶'],\n",
              " ['d√™',\n",
              "  'prioridade!',\n",
              "  '#valorizesuavida',\n",
              "  '#luteeven√ßa',\n",
              "  '#marksmidia',\n",
              "  '#somostodosiguais',\n",
              "  '#fiqueemcasa',\n",
              "  '#quarentena',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['@minsaude', 'somente', '#covid', '?'],\n",
              " ['brasil',\n",
              "  'galgando',\n",
              "  'posi√ß√µes',\n",
              "  'ranking',\n",
              "  'quer√≠amos',\n",
              "  'estar!!!',\n",
              "  '#forabolsonaro',\n",
              "  '#forabolsonarourgente‚Ä¶'],\n",
              " ['ent√£o,',\n",
              "  'vamos',\n",
              "  'reduzir',\n",
              "  '@assalariado,',\n",
              "  'tirar',\n",
              "  '#direitos',\n",
              "  '#benef√≠cios',\n",
              "  '#trabalhistas,',\n",
              "  'enquanto',\n",
              "  'governo‚Ä¶'],\n",
              " ['governos',\n",
              "  'municipais',\n",
              "  'frente',\n",
              "  'coronav√≠rus',\n",
              "  '#coronavirusbrasil',\n",
              "  '#covid',\n",
              "  '#bolsonarogenocida'],\n",
              " ['crit√©rio',\n",
              "  'uniforme',\n",
              "  'calcular',\n",
              "  '(identificar',\n",
              "  'mortes',\n",
              "  'covid19',\n",
              "  '(varia',\n",
              "  'conforme',\n",
              "  'pa√≠s',\n",
              "  'inte‚Ä¶'],\n",
              " ['üëèüèºüëèüèºüëèüèºüëèüèºüëèüèº',\n",
              "  'bravo',\n",
              "  '#pflege',\n",
              "  '#covid2019',\n",
              "  '#covid',\n",
              "  '#coronapandemie',\n",
              "  '#'],\n",
              " ['vacina',\n",
              "  'anticorpo',\n",
              "  'aprovado',\n",
              "  'sera',\n",
              "  'distribu√≠do',\n",
              "  'alto',\n",
              "  'escala',\n",
              "  'eua',\n",
              "  'daqui',\n",
              "  '5',\n",
              "  'meses',\n",
              "  'eua',\n",
              "  'bras‚Ä¶'],\n",
              " ['domingo,', 'acordo', 'casa,', 'to', 'ressaca,', 'acordei', 'lado', 'u‚Ä¶'],\n",
              " ['@carlos_jb_paz',\n",
              "  'concordar',\n",
              "  'liberais',\n",
              "  'twitter',\n",
              "  'coisa',\n",
              "  'rara',\n",
              "  'aconteceu',\n",
              "  'burocracia',\n",
              "  '#covid',\n",
              "  'o‚Ä¶'],\n",
              " ['\"assembleia',\n",
              "  'mundial',\n",
              "  'sa√∫de',\n",
              "  'oms',\n",
              "  'ocorre',\n",
              "  'meio',\n",
              "  'crise',\n",
              "  '#covid19\"',\n",
              "  '#wha73'],\n",
              " ['quarantine',\n",
              "  'fatigue',\n",
              "  'is',\n",
              "  'real',\n",
              "  '#pandemia',\n",
              "  '#coronavirus',\n",
              "  '#covid'],\n",
              " ['\"#covid19', 'brasil', 'supera', 'espanha', 'it√°lia', 'n√∫mero', 'casos\"'],\n",
              " ['@g1',\n",
              "  'estampa',\n",
              "  'üìå',\n",
              "  '21',\n",
              "  'estados',\n",
              "  '#df',\n",
              "  'prop√µem',\n",
              "  'multar',\n",
              "  'divulga',\n",
              "  '#fakenews',\n",
              "  '#pandemia',\n",
              "  '#covid',\n",
              "  'üò∑',\n",
              "  'regras',\n",
              "  'par‚Ä¶'],\n",
              " ['luz', 'fim', 't√∫nel!?', '#covid', '#covid19brasil', '#covid„Éº19'],\n",
              " ['nada',\n",
              "  'novo',\n",
              "  'terra',\n",
              "  'kimchi',\n",
              "  'üò†',\n",
              "  '#vidanacoreia',\n",
              "  '#coronavirus',\n",
              "  '#covid',\n",
              "  '#coreiadosul'],\n",
              " ['tudo',\n",
              "  'respiradores',\n",
              "  'virem',\n",
              "  'super',\n",
              "  'faturados',\n",
              "  'vergonha!',\n",
              "  '#quarentena',\n",
              "  '#covid',\n",
              "  'debate,',\n",
              "  'governadores',\n",
              "  'p‚Ä¶'],\n",
              " ['#pandemia',\n",
              "  'leva',\n",
              "  '#startups',\n",
              "  'desenvolverem',\n",
              "  'produtos',\n",
              "  'contra',\n",
              "  'covid19',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid'],\n",
              " ['assento',\n",
              "  'preferencial',\n",
              "  'destinado',\n",
              "  'pessoas',\n",
              "  'idosas,',\n",
              "  'gestantes,',\n",
              "  'deficientes',\n",
              "  'pessoas',\n",
              "  'cabe√ßa',\n",
              "  'cachorro‚Ä¶'],\n",
              " ['3',\n",
              "  'di√°rio',\n",
              "  'quarentena',\n",
              "  'vantagem',\n",
              "  'ficar',\n",
              "  'tarde',\n",
              "  'saber',\n",
              "  'tretas',\n",
              "  'pol√≠ticas',\n",
              "  'madruga',\n",
              "  'desvantagem',\n",
              "  'n√£o‚Ä¶'],\n",
              " ['2',\n",
              "  'di√°rio',\n",
              "  'quarentena',\n",
              "  'uso',\n",
              "  'madrugadas',\n",
              "  'estudar,',\n",
              "  'rotina',\n",
              "  'torna',\n",
              "  'rotina',\n",
              "  'pra',\n",
              "  'muitos',\n",
              "  'n√£o‚Ä¶'],\n",
              " ['#covid19', 'india'],\n",
              " ['ai',\n",
              "  '@jairbolsonaro,',\n",
              "  'agr',\n",
              "  'falta',\n",
              "  'vc',\n",
              "  'recusa',\n",
              "  'hist√≥rico',\n",
              "  'atleta',\n",
              "  'cria',\n",
              "  'cura',\n",
              "  'casa',\n",
              "  'hist√≥rico',\n",
              "  'repr‚Ä¶'],\n",
              " ['ny',\n",
              "  'times',\n",
              "  'rememora',\n",
              "  'feitos',\n",
              "  'medicina',\n",
              "  'ci√™ncia,',\n",
              "  'hiv',\n",
              "  'zika',\n",
              "  'v√≠rus,',\n",
              "  'salienta',\n",
              "  'quanto',\n",
              "  'incompat‚Ä¶'],\n",
              " ['mour√£o',\n",
              "  'entra',\n",
              "  'isolamento',\n",
              "  'ap√≥s',\n",
              "  'contato',\n",
              "  'servidor',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid',\n",
              "  '#not√≠cias'],\n",
              " ['pandemia', 'desinforma√ß√£o', '#qanon', '#qanonbr', '#covid'],\n",
              " ['flex√£o',\n",
              "  'madrugada',\n",
              "  'quis',\n",
              "  'fiz',\n",
              "  'decidi',\n",
              "  'realizei',\n",
              "  'desejei',\n",
              "  'nunca',\n",
              "  'desisti',\n",
              "  'conquistei',\n",
              "  'agradeci‚Ä¶'],\n",
              " ['#angola',\n",
              "  'comunidade',\n",
              "  'cient√≠fica',\n",
              "  'consegue',\n",
              "  '#explicar',\n",
              "  'porqu√™',\n",
              "  'agora',\n",
              "  'ainda',\n",
              "  'nenhum',\n",
              "  'paciente',\n",
              "  'de‚Ä¶'],\n",
              " ['not√≠cias',\n",
              "  'corona',\n",
              "  'manaus',\n",
              "  'enchem',\n",
              "  'esperan√ßa',\n",
              "  'leitos',\n",
              "  'vazios',\n",
              "  'v√°rios',\n",
              "  'hospitais,',\n",
              "  'n√∫mero',\n",
              "  'enterro‚Ä¶'],\n",
              " ['precious!',\n",
              "  'üò¢',\n",
              "  '@potus',\n",
              "  '@vp',\n",
              "  '@whitehouse',\n",
              "  '@tuckercarlson',\n",
              "  '@seanhannity',\n",
              "  '@judgejeanine',\n",
              "  '@dbongino',\n",
              "  '@jessebwatters‚Ä¶'],\n",
              " ['üöÄ',\n",
              "  'facilite',\n",
              "  'vendas!',\n",
              "  '#fiqueemcasa',\n",
              "  'receba',\n",
              "  'pedidos',\n",
              "  'web!',\n",
              "  'üì±',\n",
              "  'conhe√ßa',\n",
              "  'agora',\n",
              "  'feira',\n",
              "  'hippie',\n",
              "  'online!!!',\n",
              "  '‚Ä¶'],\n",
              " ['üöÄ',\n",
              "  'facilite',\n",
              "  'vendas!',\n",
              "  '#fiqueemcasa',\n",
              "  'receba',\n",
              "  'pedidos',\n",
              "  'web!',\n",
              "  'üì±',\n",
              "  'conhe√ßa',\n",
              "  'agora',\n",
              "  'feira',\n",
              "  'hippie',\n",
              "  'online!!!',\n",
              "  '‚Ä¶'],\n",
              " ['üöÄ',\n",
              "  'facilite',\n",
              "  'vendas!',\n",
              "  '#fiqueemcasa',\n",
              "  'receba',\n",
              "  'pedidos',\n",
              "  'web!',\n",
              "  'üì±',\n",
              "  'conhe√ßa',\n",
              "  'agora',\n",
              "  'feira',\n",
              "  'hippie',\n",
              "  'online!!!',\n",
              "  '‚Ä¶'],\n",
              " ['üöÄ',\n",
              "  'facilite',\n",
              "  'vendas!',\n",
              "  '#fiqueemcasa',\n",
              "  'receba',\n",
              "  'pedidos',\n",
              "  'web!',\n",
              "  'üì±',\n",
              "  'conhe√ßa',\n",
              "  'agora',\n",
              "  'feira',\n",
              "  'hippie',\n",
              "  'online!!!',\n",
              "  '‚Ä¶'],\n",
              " ['üöÄ',\n",
              "  'facilite',\n",
              "  'vendas!',\n",
              "  '#fiqueemcasa',\n",
              "  'receba',\n",
              "  'pedidos',\n",
              "  'web!',\n",
              "  'üì±',\n",
              "  'conhe√ßa',\n",
              "  'agora',\n",
              "  'feira',\n",
              "  'hippie',\n",
              "  'online!!!',\n",
              "  '‚Ä¶'],\n",
              " ['@gabznscmnt',\n",
              "  'dormir',\n",
              "  'direito',\n",
              "  'hora',\n",
              "  'certa',\n",
              "  'mant√©m',\n",
              "  'imunidade',\n",
              "  'alta',\n",
              "  '#covid'],\n",
              " ['vicepresidente',\n",
              "  'brasil',\n",
              "  'entra',\n",
              "  'isolamento',\n",
              "  'ap√≥s',\n",
              "  'contato',\n",
              "  'servidor',\n",
              "  'coronav√≠rus',\n",
              "  '#brasil',\n",
              "  '#mour√£o‚Ä¶'],\n",
              " ['laborat√≥rio',\n",
              "  'americano',\n",
              "  '#sorrento',\n",
              "  'afirma',\n",
              "  'ter',\n",
              "  'rem√©dio',\n",
              "  '100%',\n",
              "  'eficaz',\n",
              "  'contra',\n",
              "  '#covid19',\n",
              "  'clique',\n",
              "  'ver‚òõ'],\n",
              " ['federa√ß√£o',\n",
              "  'nata√ß√£o',\n",
              "  'solid√°ria',\n",
              "  'movimento',\n",
              "  '‚Äòn√£o',\n",
              "  'deixes',\n",
              "  'portugal',\n",
              "  'afogar‚Äô',\n",
              "  '#covid19',\n",
              "  '#dianadur√£es',\n",
              "  '#jos√©lopes'],\n",
              " ['ortopedista',\n",
              "  'conhecido',\n",
              "  'tubo',\n",
              "  'devido',\n",
              "  '#covid',\n",
              "  'vamos',\n",
              "  'torcer',\n",
              "  'recupere',\n",
              "  'assim',\n",
              "  'outros',\n",
              "  'recuperaram'],\n",
              " ['lives', 'tamo', 'como?!', '#ocorvojubileu', '#covid', '#quarentena'],\n",
              " ['segundo',\n",
              "  '#beneditodaniel',\n",
              "  '#covid19',\n",
              "  'trouxe',\n",
              "  'grandes',\n",
              "  'preju√≠zos',\n",
              "  'li√ß√µes',\n",
              "  'cada',\n",
              "  'pa√≠s',\n",
              "  'crie',\n",
              "  'solu√ß√µes‚Ä¶'],\n",
              " ['\"nenhun',\n",
              "  'pres',\n",
              "  'maior',\n",
              "  'minist√©rio(',\n",
              "  '\"nomea√ß√µes',\n",
              "  't√©cnicas\"',\n",
              "  '#jornalismo',\n",
              "  '#marketing',\n",
              "  'sa√∫de',\n",
              "  'triste',\n",
              "  'al‚Ä¶'],\n",
              " ['üöÄ',\n",
              "  'facilite',\n",
              "  'vendas!',\n",
              "  '#fiqueemcasa',\n",
              "  'receba',\n",
              "  'pedidos',\n",
              "  'web!',\n",
              "  'üì±',\n",
              "  'conhe√ßa',\n",
              "  'agora',\n",
              "  'feira',\n",
              "  'hippie',\n",
              "  'online!!!',\n",
              "  '‚Ä¶'],\n",
              " ['acredito',\n",
              "  'pessoas',\n",
              "  'escutassem',\n",
              "  'poetas',\n",
              "  'topo',\n",
              "  '33',\n",
              "  '(pt',\n",
              "  'mv',\n",
              "  'bill',\n",
              "  'iam',\n",
              "  'parar',\n",
              "  'matar',\n",
              "  'iriam',\n",
              "  'ver',\n",
              "  'n‚Ä¶'],\n",
              " ['sair',\n",
              "  'vacina',\n",
              "  'dezembro',\n",
              "  '(7',\n",
              "  'meses,',\n",
              "  'toma?',\n",
              "  '#coronavirus',\n",
              "  '#covid„Éº19',\n",
              "  '#covid'],\n",
              " ['covarde,',\n",
              "  'assassino,',\n",
              "  'criminoso',\n",
              "  '#impeachmentbolsonaro',\n",
              "  '#covid_19',\n",
              "  '#quarentena',\n",
              "  '#lockdown',\n",
              "  '#conversaafiada',\n",
              "  '#covid‚Ä¶'],\n",
              " ['ainda',\n",
              "  'bem',\n",
              "  '@uolnoticias',\n",
              "  'cometeu',\n",
              "  'erro',\n",
              "  'digita√ß√£o',\n",
              "  'referente',\n",
              "  'mortes',\n",
              "  '#covid',\n",
              "  '#coronavirus'],\n",
              " ['fa√ßa',\n",
              "  'exerc√≠cio',\n",
              "  '‚Äúvergonha',\n",
              "  'alheia‚Äù',\n",
              "  'comigo',\n",
              "  'neste',\n",
              "  'momento',\n",
              "  'c√≠rculo',\n",
              "  'd',\n",
              "  'conviv√™ncia',\n",
              "  'estaria',\n",
              "  'neste',\n",
              "  'ce‚Ä¶'],\n",
              " ['esperando',\n",
              "  'filhinhos',\n",
              "  'vai',\n",
              "  'pegar',\n",
              "  'covid',\n",
              "  'logo,',\n",
              "  'pra',\n",
              "  'imunizar',\n",
              "  'dar',\n",
              "  'historia',\n",
              "  'supera√ß√£o',\n",
              "  'papai‚Ä¶'],\n",
              " ['16/5',\n",
              "  '#covid',\n",
              "  '#paran√°',\n",
              "  '(3/3',\n",
              "  '#fiqueemcasa',\n",
              "  '691(356',\n",
              "  'investig',\n",
              "  '1477',\n",
              "  'recuperados',\n",
              "  '20813(+1017',\n",
              "  'exames',\n",
              "  '18539(+1266‚Ä¶'],\n",
              " ['andrea',\n",
              "  'entra',\n",
              "  'brincar',\n",
              "  'comigo',\n",
              "  'diz',\n",
              "  'respeitando',\n",
              "  'm√°ximo',\n",
              "  'isolamento',\n",
              "  '#covid,',\n",
              "  'est√°‚Ä¶'],\n",
              " ['#bolsonaro',\n",
              "  '#quarentena',\n",
              "  '#brasil',\n",
              "  '#coronavirus',\n",
              "  '#coronavirusbrasil',\n",
              "  '#covid_19',\n",
              "  '#covid',\n",
              "  'bolsonaro‚Ä¶'],\n",
              " ['#covid',\n",
              "  '#brasil',\n",
              "  '\\U0001f9a0',\n",
              "  's√°bado,',\n",
              "  '16',\n",
              "  'maio',\n",
              "  '‚ñ∂Ô∏è',\n",
              "  '233142',\n",
              "  '#casos',\n",
              "  '‚ñ∂Ô∏è',\n",
              "  '15633',\n",
              "  '√≥bitos',\n",
              "  '#rn',\n",
              "  '‚è∫',\n",
              "  '3004',\n",
              "  'cas‚Ä¶'],\n",
              " ['sentimentos',\n",
              "  'familiares',\n",
              "  'mortossem',\n",
              "  'respeito',\n",
              "  'dorsem',\n",
              "  'medir',\n",
              "  'consequencias',\n",
              "  'atos',\n",
              "  'tudo',\n",
              "  'pe‚Ä¶'],\n",
              " ['\"o',\n",
              "  'modelo',\n",
              "  'simula√ß√£o',\n",
              "  'neil',\n",
              "  'ferguson',\n",
              "  '(imperial',\n",
              "  'college',\n",
              "  'pode',\n",
              "  'ser',\n",
              "  'considerado',\n",
              "  'devastante',\n",
              "  \"'erro'\",\n",
              "  'softwar‚Ä¶'],\n",
              " ['pastor',\n",
              "  'clovis',\n",
              "  'entra',\n",
              "  'live,',\n",
              "  'diz',\n",
              "  'favor',\n",
              "  'isolamento',\n",
              "  'total',\n",
              "  'contra',\n",
              "  '#covid',\n",
              "  '\"temos',\n",
              "  'muita',\n",
              "  'vid‚Ä¶'],\n",
              " ['\"se',\n",
              "  'n√∫meros',\n",
              "  'frios',\n",
              "  'tocam',\n",
              "  'gente,',\n",
              "  'espero',\n",
              "  'nomes',\n",
              "  'consigam',\n",
              "  'tocar\"',\n",
              "  'homenagem',\n",
              "  'dr',\n",
              "  '@chicocesarof',\n",
              "  'v√≠timas',\n",
              "  'do‚Ä¶'],\n",
              " ['passamos',\n",
              "  'marca',\n",
              "  '15',\n",
              "  'mil',\n",
              "  '√≥bitos,',\n",
              "  'ocasionados',\n",
              "  'gripezinha',\n",
              "  'ent√£o,',\n",
              "  '10',\n",
              "  'mil',\n",
              "  '#bolsonaro',\n",
              "  'andar',\n",
              "  'j‚Ä¶'],\n",
              " ['geral', 'fazendo', 'agora', '#covid'],\n",
              " ['hoje', 'sufocando', 'mercado', 'pois', 'm√°scara', '#covid', 'saia'],\n",
              " ['partido',\n",
              "  'comunista',\n",
              "  'china',\n",
              "  'iniciou',\n",
              "  'guerra',\n",
              "  'biol√≥gica,',\n",
              "  'devastando',\n",
              "  'todo',\n",
              "  'ocidente',\n",
              "  'choramos',\n",
              "  'mortos,',\n",
              "  'mas‚Ä¶'],\n",
              " ['triste', 'tomar', '#heineken', 'sentir', 'sabor', 'üòï', '#dia27', '#covid'],\n",
              " ['#tbt',\n",
              "  'nada,',\n",
              "  'vou',\n",
              "  'lan√ßar',\n",
              "  'hastag',\n",
              "  '#tudoantesdacovid',\n",
              "  'casamento',\n",
              "  'maravilhoso',\n",
              "  'amigos',\n",
              "  'inf√¢ncia',\n",
              "  '#casamento‚Ä¶'],\n",
              " ['$600',\n",
              "  '20',\n",
              "  'passos',\n",
              "  '#sobreviver',\n",
              "  '#auxilioemerg√™ncia',\n",
              "  'via',\n",
              "  '@youtube',\n",
              "  '#pandemia',\n",
              "  '#covid‚Ä¶'],\n",
              " ['supermercados',\n",
              "  'wuhan',\n",
              "  '2¬™',\n",
              "  'quinzena',\n",
              "  'janeiro,',\n",
              "  'antes',\n",
              "  '#lockdown',\n",
              "  '#covid',\n",
              "  '#covid19',\n",
              "  '#virus'],\n",
              " ['hospital',\n",
              "  'leonardo',\n",
              "  'vinci',\n",
              "  'emocionante!',\n",
              "  '17',\n",
              "  'altas',\n",
              "  '√∫nica',\n",
              "  'enfermaria',\n",
              "  '32',\n",
              "  'leitos',\n",
              "  'dia',\n",
              "  's√≥!',\n",
              "  'atende',\n",
              "  'covid1‚Ä¶'],\n",
              " ['m√°scara',\n",
              "  'esconde',\n",
              "  'boa',\n",
              "  'parte',\n",
              "  'rosto',\n",
              "  'e,',\n",
              "  'todo',\n",
              "  'contato',\n",
              "  'express√µes,',\n",
              "  'agora',\n",
              "  'buscam',\n",
              "  'olhos',\n",
              "  'deveria',\n",
              "  'ser',\n",
              "  'sempre',\n",
              "  'assim,‚Ä¶'],\n",
              " ['@correio',\n",
              "  'amanh√£',\n",
              "  'bras√≠lia',\n",
              "  ',',\n",
              "  'cegueira',\n",
              "  'providencial',\n",
              "  'gov',\n",
              "  'df',\n",
              "  ',',\n",
              "  'mundo',\n",
              "  'vai',\n",
              "  'presenciar',\n",
              "  'ataque',\n",
              "  's‚Ä¶'],\n",
              " ['supondo',\n",
              "  '#benzetacil',\n",
              "  'eficaz',\n",
              "  'contra',\n",
              "  '#covid19,',\n",
              "  'vc',\n",
              "  'al√©rgico,',\n",
              "  'vc',\n",
              "  'faria?',\n",
              "  'iria',\n",
              "  'preferir',\n",
              "  'ficar',\n",
              "  'cas‚Ä¶'],\n",
              " ['artigo',\n",
              "  '|',\n",
              "  'ex√©rcito',\n",
              "  'eua',\n",
              "  'pode',\n",
              "  'ter',\n",
              "  'levado',\n",
              "  'v√≠rus',\n",
              "  'china,',\n",
              "  'pepe',\n",
              "  'escobar'],\n",
              " ['aguento', 'tal', 'covid', '#covid', 'odeio', 'abomino'],\n",
              " ['@blogdonoblat', 'desempenho,', 'p√¥?!!', 't√°', 'tchum', 'pro', '#covid'],\n",
              " ['desculpa',\n",
              "  '@cinthiacribeiro,',\n",
              "  '2',\n",
              "  'meses',\n",
              "  'sair',\n",
              "  'casa',\n",
              "  'vou',\n",
              "  'beber',\n",
              "  'sim!',\n",
              "  '#covid',\n",
              "  '#voubeber',\n",
              "  '#lei‚Ä¶'],\n",
              " ['algu√©m',\n",
              "  'sabe',\n",
              "  'dizer',\n",
              "  'informa√ß√£o',\n",
              "  'ver√≠dica?',\n",
              "  'diz',\n",
              "  'sim',\n",
              "  '#covid'],\n",
              " ['dif√≠cil',\n",
              "  'entender',\n",
              "  'proibi√ß√£o',\n",
              "  'caminhar',\n",
              "  'praias,',\n",
              "  'apesar',\n",
              "  'ser',\n",
              "  'permitido',\n",
              "  'ruas',\n",
              "  'falo',\n",
              "  'simplesmente',\n",
              "  'ca‚Ä¶'],\n",
              " ['v√£o',\n",
              "  'morrer',\n",
              "  '10',\n",
              "  'mil',\n",
              "  'pessoas',\n",
              "  'pr√≥ximos',\n",
              "  '710',\n",
              "  'dias?',\n",
              "  'poss√≠vel',\n",
              "  '233142',\n",
              "  'total',\n",
              "  'infectados',\n",
              "  '89672',\n",
              "  'cu‚Ä¶'],\n",
              " ['tempos', 'negros', 'l√°', 'brasil', '#covid', '#coronavirus'],\n",
              " ['@alexandrebrss',\n",
              "  '@jrguzzofatos',\n",
              "  'ilustra√ß√£o',\n",
              "  'demonstra',\n",
              "  'bem',\n",
              "  'confinamento',\n",
              "  'for√ßado',\n",
              "  'fazendo',\n",
              "  'ca‚Ä¶'],\n",
              " ['premier',\n",
              "  'belga',\n",
              "  'sophie',\n",
              "  'wilm√®s',\n",
              "  'visitou',\n",
              "  'hoje,',\n",
              "  '1¬™',\n",
              "  'vez,',\n",
              "  'desde',\n",
              "  'in√≠cio',\n",
              "  'pandemia,',\n",
              "  'v√°rios',\n",
              "  'hospitais',\n",
              "  'bruxelas‚Ä¶'],\n",
              " ['com√©rcio',\n",
              "  'pior',\n",
              "  'queda',\n",
              "  'mar√ßo',\n",
              "  '17',\n",
              "  'anos',\n",
              "  'veja',\n",
              "  'setores',\n",
              "  'afetados',\n",
              "  '#covid'],\n",
              " ['#covid19',\n",
              "  'governo',\n",
              "  'pretende',\n",
              "  'usar',\n",
              "  'experi√™ncia',\n",
              "  'pi',\n",
              "  'mudar',\n",
              "  'protocolo',\n",
              "  'sobre',\n",
              "  'cloroquina',\n",
              "  'via',\n",
              "  '@revistaoeste'],\n",
              " ['queria',\n",
              "  'compartilhar',\n",
              "  'iniciativa',\n",
              "  '@avischiffmann,',\n",
              "  'adolescente',\n",
              "  'recusa',\n",
              "  'ofertas',\n",
              "  'milion√°rias',\n",
              "  'pra',\n",
              "  'pod‚Ä¶'],\n",
              " ['arbitr√°rio',\n",
              "  'inconstitucional',\n",
              "  'ataque',\n",
              "  'liberdades',\n",
              "  'direitos',\n",
              "  'individuais',\n",
              "  'fundamentais',\n",
              "  'lei',\n",
              "  'seca',\n",
              "  'tocanti‚Ä¶'],\n",
              " ['acabamos',\n",
              "  'atualizar',\n",
              "  'dados',\n",
              "  '#siglitoral',\n",
              "  'ufrgs',\n",
              "  'conta',\n",
              "  'atualiza√ß√£o',\n",
              "  '@sesrs',\n",
              "  'hor√°rio',\n",
              "  'previst‚Ä¶'],\n",
              " ['#elheraldotv', '|', '#covid19almomento'],\n",
              " ['@gerlingeri',\n",
              "  '@brunafcruz',\n",
              "  '@acioli_s',\n",
              "  '@moura_101',\n",
              "  'entretanto',\n",
              "  'negacionistas',\n",
              "  'cidades',\n",
              "  'brasil',\n",
              "  '#covid‚Ä¶'],\n",
              " ['respeito',\n",
              "  'respeita!',\n",
              "  '#bolsonarorainhalouca',\n",
              "  '#bolsonaroassassino',\n",
              "  '#bolsonaroficaquieto',\n",
              "  '#bolsonaro‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'prefeitura',\n",
              "  'alc√¢ntara',\n",
              "  'compra',\n",
              "  'testes',\n",
              "  'r√°pidos',\n",
              "  'rem√©dios',\n",
              "  'combate',\n",
              "  'covid19'],\n",
              " ['justi√ßa',\n",
              "  'federal',\n",
              "  'autoriza',\n",
              "  '#reabertura',\n",
              "  'gradual',\n",
              "  '#lojas',\n",
              "  'bras√≠lia',\n",
              "  '#com√©rcio',\n",
              "  '#covid'],\n",
              " ['desse',\n",
              "  'modelo',\n",
              "  'marque',\n",
              "  'vizinho',\n",
              "  'curioso',\n",
              "  'üòÇüòÇüòÇ',\n",
              "  'vizinhos',\n",
              "  'curiosos',\n",
              "  'üòÇüòÇüòÇüòÇ',\n",
              "  '@bitapaulin',\n",
              "  '#covid‚Ä¶'],\n",
              " ['entretanto', 'negacionistas', 'brasil', '#covid', '#coronavirus'],\n",
              " ['matos',\n",
              "  'collado',\n",
              "  'acabam',\n",
              "  'publicar',\n",
              "  'espanha',\n",
              "  'livro',\n",
              "  'el',\n",
              "  'virus',\n",
              "  'filosof√≠a',\n",
              "  'la',\n",
              "  'filosof√≠a',\n",
              "  'virus',\n",
              "  '‚Äì',\n",
              "  'reflexione‚Ä¶'],\n",
              " ['aplausos',\n",
              "  'pros',\n",
              "  'profissionais',\n",
              "  'sa√∫de',\n",
              "  'üëèüèºüëèüèºüëèüèº',\n",
              "  '12h',\n",
              "  'luva',\n",
              "  'm√°scara',\n",
              "  'engata',\n",
              "  'ziper,',\n",
              "  'd√≥i',\n",
              "  'cabe√ßa,',\n",
              "  'or‚Ä¶'],\n",
              " ['militares',\n",
              "  'gnr',\n",
              "  'guimar√£es',\n",
              "  'doaram',\n",
              "  'alimentos',\n",
              "  'carenciados',\n",
              "  '#covid19',\n",
              "  '#gnr',\n",
              "  '#guimar√£es'],\n",
              " ['204', 'casos', 'confirmados', '#covid19', '#paragominas', 'clique', 'ver‚òõ'],\n",
              " ['virtude',\n",
              "  '#pandemia,',\n",
              "  '#ufba',\n",
              "  'realizar√°',\n",
              "  'congresso',\n",
              "  'modo',\n",
              "  'virtual',\n",
              "  'aqui,',\n",
              "  'programa√ß√£o',\n",
              "  'participa√ß√£o',\n",
              "  'do‚Ä¶'],\n",
              " ['secretaria',\n",
              "  '@saudegovba',\n",
              "  'colocou',\n",
              "  'opera√ß√£o',\n",
              "  'neste',\n",
              "  's√°bado,',\n",
              "  'sistema',\n",
              "  'integra',\n",
              "  'base',\n",
              "  'dados',\n",
              "  'epidemiol√≥gicos',\n",
              "  'e‚Ä¶'],\n",
              " ['dr',\n",
              "  '@nelioaguiar',\n",
              "  'senhor',\n",
              "  'tomou',\n",
              "  'decis√£o',\n",
              "  'correta',\n",
              "  'jesus',\n",
              "  'tomaria',\n",
              "  'exatamente',\n",
              "  'decis√£o',\n",
              "  'lembra',\n",
              "  'expulsou',\n",
              "  'os‚Ä¶'],\n",
              " ['vamos',\n",
              "  'boicotar',\n",
              "  'respeita',\n",
              "  'vida!!!',\n",
              "  '@luciano_hang',\n",
              "  '@maderobrasil',\n",
              "  '@riachuelo',\n",
              "  '#bolsonarorainhalouca‚Ä¶'],\n",
              " ['#covid',\n",
              "  '#edicao18',\n",
              "  'alertei',\n",
              "  'constantemente',\n",
              "  'achatamento',\n",
              "  'curva,',\n",
              "  'isolamento',\n",
              "  'in√≥cuo,',\n",
              "  'ineficaz‚Ä¶'],\n",
              " ['jornal',\n",
              "  'alem√£o',\n",
              "  'den√∫ncia',\n",
              "  'governo',\n",
              "  'chln√™s',\n",
              "  'via',\n",
              "  '@youtube',\n",
              "  '#coronavirus',\n",
              "  '#viruschines',\n",
              "  '#covid19'],\n",
              " ['metade',\n",
              "  'pessoas',\n",
              "  'atendimento',\n",
              "  'fazendo',\n",
              "  'exames',\n",
              "  'profissionais',\n",
              "  'sa√∫de',\n",
              "  'possivelmente',\n",
              "  'infectados',\n",
              "  '#covid‚Ä¶'],\n",
              " ['quero',\n",
              "  'ver',\n",
              "  'corona',\n",
              "  'pegar',\n",
              "  'povo',\n",
              "  'manifesta√ß√£o',\n",
              "  'vou',\n",
              "  'rir',\n",
              "  'pq',\n",
              "  'to',\n",
              "  'aqui',\n",
              "  '#covid',\n",
              "  't√£o',\n",
              "  'com‚Ä¶'],\n",
              " ['ricos',\n",
              "  'direita',\n",
              "  'radical',\n",
              "  'come√ßaram,',\n",
              "  'repente,',\n",
              "  'interessar',\n",
              "  'pobres',\n",
              "  'antes',\n",
              "  'tudo',\n",
              "  'quest√£o',\n",
              "  'meritocracia',\n",
              "  '#covid'],\n",
              " ['‚ö†Ô∏èalerta‚ö†Ô∏è',\n",
              "  '#medicos',\n",
              "  'sendo',\n",
              "  '#pressionados',\n",
              "  'atestar',\n",
              "  'mortes',\n",
              "  'suspeitas',\n",
              "  '#covid',\n",
              "  'exames',\n",
              "  'üáßüá∑#averdadesemp‚Ä¶'],\n",
              " ['senador',\n",
              "  '@josemaranhaopb',\n",
              "  '(mdbpb,',\n",
              "  'refor√ßa',\n",
              "  'necessidade',\n",
              "  'uni√£o',\n",
              "  'todos',\n",
              "  'sa√∫de',\n",
              "  'p√∫blica',\n",
              "  'possa',\n",
              "  'responde‚Ä¶'],\n",
              " ['academia', 'essencial', 'sa√∫de?', '#academias', '#coronavirus', '#covid19'],\n",
              " ['conhce√ßa',\n",
              "  'sistema',\n",
              "  'simula√ß√£o',\n",
              "  'computacional',\n",
              "  'sobre',\n",
              "  'din√¢mica',\n",
              "  'propaga√ß√£o',\n",
              "  '#covid19'],\n",
              " ['casos',\n",
              "  '#covid',\n",
              "  '#guarulhos',\n",
              "  'chegam',\n",
              "  'a1507,',\n",
              "  '165',\n",
              "  'mortes',\n",
              "  'apesar',\n",
              "  'aumento',\n",
              "  'expressivo',\n",
              "  'casos',\n",
              "  '√∫ltima',\n",
              "  'semana‚Ä¶'],\n",
              " ['pa√≠s',\n",
              "  'ingovern√°vel,',\n",
              "  'corrup√ß√£o!',\n",
              "  'pena',\n",
              "  'popula√ß√£o',\n",
              "  'honesta(vide',\n",
              "  '1contra',\n",
              "  'todos',\n",
              "  '#brasil‚Ä¶'],\n",
              " ['agora',\n",
              "  'ganhou',\n",
              "  'for√ßa',\n",
              "  'protestos,',\n",
              "  'pode',\n",
              "  'comer',\n",
              "  'pilha',\n",
              "  'isqueiro',\n",
              "  '@rafaelilha',\n",
              "  '#bolsonarorainhalouca‚Ä¶'],\n",
              " ['cad√™',\n",
              "  'sal√°rios',\n",
              "  'm√©dicos',\n",
              "  'enfermeiros?',\n",
              "  'cad√™',\n",
              "  'dinheiro',\n",
              "  'respiradores',\n",
              "  'comprados',\n",
              "  'empresas',\n",
              "  'fantasmas?‚Ä¶'],\n",
              " ['santista',\n",
              "  '@brunocovas,',\n",
              "  'aborte',\n",
              "  'rodizio',\n",
              "  'desenvolva',\n",
              "  'outra',\n",
              "  'estrat√©gia',\n",
              "  'muita',\n",
              "  'gente',\n",
              "  'precisa',\n",
              "  'ir',\n",
              "  'trabalhar',\n",
              "  'vai',\n",
              "  'u‚Ä¶'],\n",
              " ['#covid',\n",
              "  'mundo',\n",
              "  'dividido',\n",
              "  'tres',\n",
              "  'partes',\n",
              "  'respeita',\n",
              "  'regras',\n",
              "  'quarentena,',\n",
              "  'usa',\n",
              "  'm√°scara',\n",
              "  'coopera',\n",
              "  'outra',\n",
              "  'n‚Ä¶'],\n",
              " ['#calamidade',\n",
              "  '#estadodecalamidade',\n",
              "  '#lisboa',\n",
              "  '#covid',\n",
              "  '#covid19',\n",
              "  '#coronavirus',\n",
              "  '#streetphotography',\n",
              "  '#portugal',\n",
              "  '#paulocaladophoto‚Ä¶'],\n",
              " ['par√°',\n",
              "  'i',\n",
              "  'sesai',\n",
              "  'cumpre',\n",
              "  'recomenda√ß√£o',\n",
              "  'mpf',\n",
              "  'inclui',\n",
              "  'estat√≠stica',\n",
              "  'casos',\n",
              "  '#covid19',\n",
              "  'ind√≠genas',\n",
              "  'alter',\n",
              "  'c‚Ä¶'],\n",
              " ['üéÆ‚öΩagora',\n",
              "  'fase',\n",
              "  'final‚öΩüéÆ',\n",
              "  'jogo',\n",
              "  'bem',\n",
              "  'chegar√°',\n",
              "  'neste',\n",
              "  'domingo',\n",
              "  'partir',\n",
              "  '11h',\n",
              "  'reta',\n",
              "  'final!',\n",
              "  'jogos',\n",
              "  'se‚Ä¶'],\n",
              " ['(multim√≠dia',\n",
              "  '#china',\n",
              "  'completar√°',\n",
              "  'testes',\n",
              "  'cl√≠nicos',\n",
              "  'segunda',\n",
              "  'fase',\n",
              "  'vacinas',\n",
              "  '#covid19',\n",
              "  'julho,',\n",
              "  'diz',\n",
              "  'funcion√°rio‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'estudo',\n",
              "  'indica',\n",
              "  'n√∫mero',\n",
              "  'casos',\n",
              "  'eua',\n",
              "  'poderia',\n",
              "  'ser',\n",
              "  '35',\n",
              "  'vezes',\n",
              "  'maior',\n",
              "  'isolamento'],\n",
              " ['m√°scara',\n",
              "  'simples',\n",
              "  'fazer',\n",
              "  'qualquer',\n",
              "  'd√∫vida',\n",
              "  'chama',\n",
              "  'direct',\n",
              "  '#mascaradetecido',\n",
              "  '#mascara',\n",
              "  '#tecidodealgodao‚Ä¶'],\n",
              " ['g√°s',\n",
              "  'clandestino',\n",
              "  'vendido',\n",
              "  'acima',\n",
              "  'pre√ßo',\n",
              "  'apreendido',\n",
              "  'opera√ß√£o',\n",
              "  '@proconspoficial',\n",
              "  'dope',\n",
              "  '(departamento',\n",
              "  'ope‚Ä¶'],\n",
              " ['‚òùÔ∏è\"eu',\n",
              "  'quero',\n",
              "  'sair',\n",
              "  'governo',\n",
              "  '#bolsonaro\"',\n",
              "  '#comofaz',\n",
              "  '#bolsonarogenocida',\n",
              "  '#covid„Éº19',\n",
              "  '#covidiots',\n",
              "  '#covid„Éº19',\n",
              "  '#covid‚Ä¶'],\n",
              " ['basta',\n",
              "  'palavra',\n",
              "  'deus',\n",
              "  'tudo',\n",
              "  'volta',\n",
              "  'lugar',\n",
              "  'üéºüôåüèæüéºüôåüèæ',\n",
              "  '#covid',\n",
              "  '#sesaia'],\n",
              " ['#fiquememcasa', '#covid', 'acha', 'morte', 'alheia', 'importa', 'quanto?'],\n",
              " ['√©,', '\"quando', '#covid', 'mata,', 'mata', 'dispara\"'],\n",
              " ['gua√≠ra',\n",
              "  'registra',\n",
              "  'quarto',\n",
              "  'caso',\n",
              "  'covid19',\n",
              "  '|',\n",
              "  '#guairasp',\n",
              "  '#coronavirus',\n",
              "  '#covid',\n",
              "  '#saude'],\n",
              " ['sugest√£o',\n",
              "  'acabarmos',\n",
              "  '#covid',\n",
              "  'todos',\n",
              "  'curados,',\n",
              "  'seja,',\n",
              "  'imunizados,',\n",
              "  'assumir',\n",
              "  'servi√ßos',\n",
              "  'essencia‚Ä¶'],\n",
              " ['dia',\n",
              "  'frio',\n",
              "  'd√°',\n",
              "  'pregui√ßa',\n",
              "  'abrir',\n",
              "  'olho!',\n",
              "  'pra',\n",
              "  'dar',\n",
              "  'animada',\n",
              "  'sugest√£o',\n",
              "  'hj',\n",
              "  \"'\",\n",
              "  \"cara'\",\n",
              "  '2005',\n",
              "  'samuel',\n",
              "  'l‚Ä¶'],\n",
              " ['s√°bado',\n",
              "  'vinho',\n",
              "  'chocolate',\n",
              "  'chuva',\n",
              "  'netflix',\n",
              "  'queria',\n",
              "  'chocolate',\n",
              "  'anda,',\n",
              "  'sorri',\n",
              "  'apertar',\n",
              "  'barr‚Ä¶'],\n",
              " ['n√∫mero',\n",
              "  'casos',\n",
              "  'novos',\n",
              "  'covid19',\n",
              "  'registrados',\n",
              "  'amazonas',\n",
              "  '1285,',\n",
              "  'neste',\n",
              "  's√°bado',\n",
              "  '(16,',\n",
              "  'totalizando',\n",
              "  '19677',\n",
              "  'casos‚Ä¶'],\n",
              " ['crime', '???????', '#covid', '#livedodiney', '#bundesliga', '#coronavirus'],\n",
              " ['bora',\n",
              "  'toma',\n",
              "  '@zenetoecristiano',\n",
              "  'after',\n",
              "  '@ludmilla',\n",
              "  '!',\n",
              "  '#ocorvojubileu',\n",
              "  '#live',\n",
              "  '#covid'],\n",
              " ['parab√©ns',\n",
              "  'comunica√ß√£o',\n",
              "  '@policiacivilrn',\n",
              "  'deixar',\n",
              "  'esquecer',\n",
              "  'tema',\n",
              "  'caro',\n",
              "  'sem‚Ä¶'],\n",
              " ['aqui',\n",
              "  'mogi',\n",
              "  'cruzes',\n",
              "  'igreja',\n",
              "  'funcionando',\n",
              "  'mas,',\n",
              "  'vc',\n",
              "  'quer',\n",
              "  'trabalhar',\n",
              "  'gcm',\n",
              "  'fiscaliza√ß√£o',\n",
              "  'vai',\n",
              "  'multar',\n",
              "  'seu‚Ä¶'],\n",
              " ['esperan√ßoso',\n",
              "  '@drtedros,',\n",
              "  'diretorgeral',\n",
              "  '@who,',\n",
              "  'falou',\n",
              "  'sobre',\n",
              "  'realiza√ß√£o',\n",
              "  'jogos',\n",
              "  'ol√≠mpicos',\n",
              "  '@tokyo2020',\n",
              "  'durante',\n",
              "  'r‚Ä¶'],\n",
              " ['distanciamento',\n",
              "  'social',\n",
              "  'indiscriminado',\n",
              "  'ruim',\n",
              "  'sistema',\n",
              "  'imunol√≥gico!',\n",
              "  'quer',\n",
              "  'entender',\n",
              "  'mais?',\n",
              "  'acesse',\n",
              "  'link',\n",
              "  'abaix‚Ä¶'],\n",
              " ['algu√©m',\n",
              "  'covid',\n",
              "  'pra',\n",
              "  'sair',\n",
              "  '(',\n",
              "  'sigilo',\n",
              "  's/aglomera√ß√£o!',\n",
              "  '#orgulholgbtq',\n",
              "  '#covid',\n",
              "  '#sindicatodosdovulgadores'],\n",
              " ['\\U0001f9a0\\U0001f9a0',\n",
              "  'boletim',\n",
              "  'coronav√≠rus',\n",
              "  '#covid19',\n",
              "  '|',\n",
              "  'confira',\n",
              "  'atualiza√ß√£o',\n",
              "  'boletim',\n",
              "  'municipal',\n",
              "  'deste',\n",
              "  's√°bado',\n",
              "  '(16/05'],\n",
              " ['boletim',\n",
              "  'coronav√≠rus',\n",
              "  '#covid19',\n",
              "  '|',\n",
              "  'confira',\n",
              "  'atualiza√ß√£o',\n",
              "  'boletim',\n",
              "  'municipal',\n",
              "  'deste',\n",
              "  's√°bado',\n",
              "  '(16/05',\n",
              "  'informa√ß√µ‚Ä¶'],\n",
              " ['sa√∫de',\n",
              "  'bem',\n",
              "  'essencial',\n",
              "  'liberdade',\n",
              "  'ando',\n",
              "  'aterrado',\n",
              "  'burocratas',\n",
              "  '#covid',\n",
              "  'haver√°',\n",
              "  'no√ß√£o',\n",
              "  'magnitu‚Ä¶'],\n",
              " ['n√∫mero',\n",
              "  'casos',\n",
              "  'coronav√≠rus',\n",
              "  'eua',\n",
              "  'poderia',\n",
              "  'ser',\n",
              "  '35',\n",
              "  'vezes',\n",
              "  'maior',\n",
              "  'medidas',\n",
              "  'isolamento',\n",
              "  'social',\n",
              "  'governo,',\n",
              "  'diz‚Ä¶'],\n",
              " ['#brasil',\n",
              "  'aproxima',\n",
              "  '15',\n",
              "  'mil',\n",
              "  'mortes',\n",
              "  '#covid19',\n",
              "  'acordo',\n",
              "  'dados,',\n",
              "  '√∫ltimas',\n",
              "  '24‚Ä¶'],\n",
              " ['pegar',\n",
              "  '#covid',\n",
              "  'vai',\n",
              "  'querer',\n",
              "  'tratamento',\n",
              "  '#cloroquina?',\n",
              "  'fico',\n",
              "  'pensando',\n",
              "  'sobremeu',\n",
              "  'pai',\n",
              "  'faz',\n",
              "  'tratamento',\n",
              "  'l√∫‚Ä¶'],\n",
              " ['espantem',\n",
              "  'governo',\n",
              "  'americano',\n",
              "  'descobrir',\n",
              "  'comprar',\n",
              "  'patente',\n",
              "  'vacina',\n",
              "  'contra',\n",
              "  'covid19',\n",
              "  'priorizar',\n",
              "  'a‚Ä¶'],\n",
              " ['ap√≥s',\n",
              "  '9',\n",
              "  'dias',\n",
              "  'uti,',\n",
              "  'enfermeiro',\n",
              "  'volta',\n",
              "  'servi√ßo',\n",
              "  'ajudar',\n",
              "  '#covid',\n",
              "  '#sonoticiaboa‚Ä¶'],\n",
              " ['agora',\n",
              "  'd√°',\n",
              "  'pra',\n",
              "  'recusar',\n",
              "  'lanches',\n",
              "  'desculpa',\n",
              "  'corona',\n",
              "  'algu√©m',\n",
              "  'pedir',\n",
              "  '\"me',\n",
              "  'd√°',\n",
              "  'pedacinho\"?‚Ä¶'],\n",
              " ['olga',\n",
              "  'savary,',\n",
              "  'grande,',\n",
              "  'gigante,',\n",
              "  'partiu',\n",
              "  'ontem',\n",
              "  'v√≠tima',\n",
              "  'desse',\n",
              "  'v√≠rus',\n",
              "  'agressivo',\n",
              "  'sorrateiro',\n",
              "  'obrigada',\n",
              "  'tudo,',\n",
              "  'poeta',\n",
              "  '#fiqueemcasa',\n",
              "  '#covid'],\n",
              " ['#assembrati',\n",
              "  'porta',\n",
              "  \"sant'angelo\",\n",
              "  '#scattano',\n",
              "  '#controlli',\n",
              "  '#sanzioni',\n",
              "  '#umbria',\n",
              "  '#terni',\n",
              "  '#covid‚Ä¶'],\n",
              " ['tal',\n",
              "  'cuidar',\n",
              "  'sa√∫de',\n",
              "  'mental?',\n",
              "  'quartafeira,',\n",
              "  'dia',\n",
              "  '20',\n",
              "  'maio,',\n",
              "  '1900',\n",
              "  'hs',\n",
              "  'inscrevase',\n",
              "  'gratuitamente‚Ä¶'],\n",
              " ['inatividade',\n",
              "  'fun√ß√£o',\n",
              "  'covid19',\n",
              "  'riscos',\n",
              "  'sa√∫de',\n",
              "  '#covid19',\n",
              "  '#covid_19',\n",
              "  '#covid',\n",
              "  '#exercicios',\n",
              "  '#saude',\n",
              "  '#inatividade‚Ä¶'],\n",
              " ['üîät√°',\n",
              "  'sabendo?',\n",
              "  'neste',\n",
              "  'domingo,',\n",
              "  '17/05,',\n",
              "  'live',\n",
              "  '@mateusolano',\n",
              "  'falar',\n",
              "  'sobre',\n",
              "  'a√ß√µes',\n",
              "  'enfrentamento',\n",
              "  'coronav‚Ä¶'],\n",
              " ['pulverizar',\n",
              "  'ruas',\n",
              "  'desinfetante',\n",
              "  'perigoso',\n",
              "  'ineficaz,',\n",
              "  'alerta',\n",
              "  'oms',\n",
              "  '#covid19',\n",
              "  '#oms'],\n",
              " ['podcast',\n",
              "  '\"apokalipson',\n",
              "  '06',\n",
              "  'fim',\n",
              "  'mundo',\n",
              "  'todo',\n",
              "  'dia',\n",
              "  'semana\"',\n",
              "  'by',\n",
              "  'apokalipson',\n",
              "  '‚öì',\n",
              "  '#podcast‚Ä¶'],\n",
              " ['poderia',\n",
              "  'acrescentar',\n",
              "  '250',\n",
              "  'inicativas',\n",
              "  'nessa',\n",
              "  '#thread',\n",
              "  'monitor',\n",
              "  'doa√ß√µes',\n",
              "  '@captacaoabcr',\n",
              "  '(associa√ß√£o',\n",
              "  'brasile‚Ä¶'],\n",
              " ['vez',\n",
              "  'falo',\n",
              "  'pq',\n",
              "  '√±',\n",
              "  'vejo',\n",
              "  'alguns',\n",
              "  'notici√°rios',\n",
              "  '√±',\n",
              "  'dou',\n",
              "  'cr√©dito',\n",
              "  '@redeglobo',\n",
              "  '@folha',\n",
              "  'posto',\n",
              "  'im‚Ä¶'],\n",
              " ['(multim√≠dia',\n",
              "  'igual',\n",
              "  'aten√ß√£o',\n",
              "  'prestada',\n",
              "  'casos',\n",
              "  'assintom√°ticos',\n",
              "  '#covid19,',\n",
              "  'diz',\n",
              "  'funcion√°rio',\n",
              "  'chin√™s‚Ä¶'],\n",
              " ['estar',\n",
              "  'insens√≠vel',\n",
              "  'realidade',\n",
              "  'brasil?',\n",
              "  'calamidade',\n",
              "  'sa√∫de,',\n",
              "  '#covid,',\n",
              "  '#governo',\n",
              "  'irrespons√°vel,',\n",
              "  '15',\n",
              "  'mil',\n",
              "  'am‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'breves',\n",
              "  '(na',\n",
              "  'ilha',\n",
              "  'maraj√≥',\n",
              "  'maior',\n",
              "  'taxa',\n",
              "  'letalidade',\n",
              "  'munic√≠pios',\n",
              "  '+',\n",
              "  '100',\n",
              "  'mil',\n",
              "  'habitantes',\n",
              "  'no‚Ä¶'],\n",
              " ['departamento',\n",
              "  'vigil√¢ncia',\n",
              "  'sanit√°ria',\n",
              "  '(devisa',\n",
              "  'campinas',\n",
              "  'apresentou',\n",
              "  'relat√≥rio',\n",
              "  'mostra',\n",
              "  'popula√ß√£o',\n",
              "  'entr‚Ä¶'],\n",
              " ['estrat√©gias',\n",
              "  'dados',\n",
              "  'an√°lise',\n",
              "  'empresas',\n",
              "  'desmoronaram',\n",
              "  '#covid19',\n",
              "  '#vmware',\n",
              "  '#vmw_carbonblack‚Ä¶'],\n",
              " ['espanha',\n",
              "  'vai',\n",
              "  'prolongar',\n",
              "  'estado',\n",
              "  'emerg√™ncia',\n",
              "  'm√™s',\n",
              "  '#covid19',\n",
              "  '#espanha'],\n",
              " ['v√≠deo',\n",
              "  'novo',\n",
              "  'daniel',\n",
              "  'chamado',\n",
              "  'nova',\n",
              "  'reencarna√ß√£o,',\n",
              "  'fica',\n",
              "  'apreensivo',\n",
              "  'retornar',\n",
              "  'l‚Ä¶'],\n",
              " ['trump',\n",
              "  'diz',\n",
              "  'estar',\n",
              "  'avaliar',\n",
              "  'retomar',\n",
              "  'parcialmente',\n",
              "  'contribui√ß√£o',\n",
              "  'oms',\n",
              "  '#covid19',\n",
              "  '#donaldtrump',\n",
              "  '#oms'],\n",
              " ['covid19',\n",
              "  'it√°lia',\n",
              "  '153',\n",
              "  'novas',\n",
              "  'mortes',\n",
              "  '24',\n",
              "  'horas,',\n",
              "  '31763',\n",
              "  'total',\n",
              "  '#covid19',\n",
              "  '#it√°lia'],\n",
              " ['pandemia',\n",
              "  'oportunidade',\n",
              "  'repensar',\n",
              "  'atletismo',\n",
              "  '#atletismo',\n",
              "  '#covid19'],\n",
              " ['tornar',\n",
              "  't√≥quio2020',\n",
              "  'evento',\n",
              "  'global',\n",
              "  'seguro',\n",
              "  '‚Äún√£o',\n",
              "  'f√°cil‚Äù',\n",
              "  '#covid19',\n",
              "  '#t√≥quio'],\n",
              " ['uefa',\n",
              "  'diz',\n",
              "  'entrada',\n",
              "  'competi√ß√µes',\n",
              "  'continua',\n",
              "  'ser',\n",
              "  '‚Äòranking‚Äô',\n",
              "  '#covid19',\n",
              "  '#futebol',\n",
              "  '#uefa'],\n",
              " ['fc',\n",
              "  'porto',\n",
              "  'volta',\n",
              "  'pisar',\n",
              "  'relvado',\n",
              "  'drag√£o,',\n",
              "  'dois',\n",
              "  'meses',\n",
              "  '#covid19',\n",
              "  '#fcporto',\n",
              "  '#futebol'],\n",
              " ['liga',\n",
              "  'vai',\n",
              "  'limitar',\n",
              "  'acesso',\n",
              "  'est√°dio',\n",
              "  '185',\n",
              "  'pessoas',\n",
              "  'dias',\n",
              "  'jogo',\n",
              "  '#covid19',\n",
              "  '#futebol',\n",
              "  '#iliga'],\n",
              " ['covid19',\n",
              "  'jogadores',\n",
              "  '‚Äòstaff‚Äô',\n",
              "  'devem',\n",
              "  'manter',\n",
              "  'isolamento',\n",
              "  'social',\n",
              "  'retoma',\n",
              "  'competi√ß√µes',\n",
              "  '#covid19',\n",
              "  '#futebol'],\n",
              " ['futebolistas,',\n",
              "  'treinadores',\n",
              "  'staff',\n",
              "  'sporting',\n",
              "  'testes',\n",
              "  '‚Äúnegativos‚Äù',\n",
              "  '#covid19',\n",
              "  '#futebol',\n",
              "  '#iliga'],\n",
              " ['grupos',\n",
              "  'ajuda',\n",
              "  'alimentar',\n",
              "  'profissionais',\n",
              "  'cultura',\n",
              "  '#covid19',\n",
              "  '#cultura'],\n",
              " ['supreso?',\n",
              "  'talvez',\n",
              "  'boa',\n",
              "  'ler',\n",
              "  'not√≠cias',\n",
              "  '#covid',\n",
              "  '#madero',\n",
              "  'dono',\n",
              "  'madero',\n",
              "  'diz',\n",
              "  'estar',\n",
              "  'surpreso',\n",
              "  '‚Äúsumi√ßo‚Äù',\n",
              "  'cl‚Ä¶'],\n",
              " ['diminui√ß√£o',\n",
              "  'voos,',\n",
              "  'causa',\n",
              "  '#covid19,',\n",
              "  'local',\n",
              "  'enfrenta',\n",
              "  'problemas',\n",
              "  'receber',\n",
              "  'quantidade',\n",
              "  'bambu',\n",
              "  'ne‚Ä¶'],\n",
              " ['melhor',\n",
              "  'unboxing',\n",
              "  '√∫ltimos',\n",
              "  'tempos!',\n",
              "  '#coronavirus',\n",
              "  '#covid19',\n",
              "  '#covidiots',\n",
              "  '#covid‚Ä¶'],\n",
              " ['#solidariedade',\n",
              "  'fundamental',\n",
              "  'tempos',\n",
              "  'pandemia',\n",
              "  '#hoje,',\n",
              "  '@ordem_publica',\n",
              "  'recebeu,',\n",
              "  'riocentro,',\n",
              "  'doa√ß√µes',\n",
              "  'grupo‚Ä¶'],\n",
              " ['@carlosmoises',\n",
              "  'caminhoneiro',\n",
              "  'veio',\n",
              "  'sp',\n",
              "  '#covid',\n",
              "  'nova',\n",
              "  'trento,',\n",
              "  'hoje',\n",
              "  'detectado',\n",
              "  'cad√™',\n",
              "  'controle',\n",
              "  'e‚Ä¶'],\n",
              " ['dgs',\n",
              "  'garante',\n",
              "  'pa√≠s',\n",
              "  '‚Äúmuito',\n",
              "  'atento‚Äù',\n",
              "  'doen√ßa',\n",
              "  'kawasaki',\n",
              "  '#covid19',\n",
              "  '#dgs',\n",
              "  '#gra√ßafreitas'],\n",
              " ['#espanha',\n",
              "  'registra',\n",
              "  'menor',\n",
              "  'n√∫mero',\n",
              "  'mortes',\n",
              "  '#covid19',\n",
              "  'desde',\n",
              "  'mar√ßo',\n",
              "  'via',\n",
              "  '@portalr7'],\n",
              " ['governo',\n",
              "  'prepara',\n",
              "  'financiamento',\n",
              "  'regi√µes',\n",
              "  'alterar',\n",
              "  'lei',\n",
              "  '#covid19',\n",
              "  '#pol√≠tica',\n",
              "  '#ps'],\n",
              " ['trabalhadores',\n",
              "  'lares',\n",
              "  'creches',\n",
              "  'testados',\n",
              "  'pr√≥ximo',\n",
              "  'dias',\n",
              "  '#covid19',\n",
              "  '#creches',\n",
              "  '#dgs'],\n",
              " ['ministra',\n",
              "  'sa√∫de',\n",
              "  'diz',\n",
              "  'indicadores',\n",
              "  '‚Äúmant√™mse',\n",
              "  'encorajadores‚Äù',\n",
              "  '#covid19',\n",
              "  '#martatemido',\n",
              "  '#sa√∫de'],\n",
              " ['retoma',\n",
              "  'social',\n",
              "  'depende',\n",
              "  'pessoas',\n",
              "  '‚Äúsociedade',\n",
              "  'policial‚Äù',\n",
              "  '#covid19',\n",
              "  '#martatemido'],\n",
              " ['costa',\n",
              "  'antev√™',\n",
              "  'campanha',\n",
              "  'presidencial',\n",
              "  'diferente,',\n",
              "  'distanciamento',\n",
              "  'f√≠sico',\n",
              "  '#ant√≥niocosta',\n",
              "  '#covid19',\n",
              "  '#pol√≠tica'],\n",
              " ['quousque',\n",
              "  'tandem',\n",
              "  'abutere,',\n",
              "  'azzolina,',\n",
              "  'patientia',\n",
              "  'nostra?',\n",
              "  '#covid',\n",
              "  '#scuola',\n",
              "  '#azzolina'],\n",
              " ['editorial',\n",
              "  'lancet',\n",
              "  '\"administra√ß√£o',\n",
              "  'obcecada',\n",
              "  'balas',\n",
              "  'prata',\n",
              "  'vacinas,',\n",
              "  'novas',\n",
              "  'drogas,',\n",
              "  'esperan√ßa',\n",
              "  'v‚Ä¶'],\n",
              " ['algu√©m',\n",
              "  'parou',\n",
              "  'pensar',\n",
              "  'todos',\n",
              "  'morremos',\n",
              "  'pagando',\n",
              "  'pecados',\n",
              "  'inferno,',\n",
              "  '#covid',\n",
              "  '+‚Ä¶'],\n",
              " ['@cirogomes',\n",
              "  'pensou',\n",
              "  'vc',\n",
              "  'cai',\n",
              "  'm√£o',\n",
              "  'm√©dico',\n",
              "  'segue',\n",
              "  'risca',\n",
              "  'cegamente',\n",
              "  'bozo',\n",
              "  'fala????????',\n",
              "  't√™m',\n",
              "  'muit‚Ä¶'],\n",
              " ['@lucianohuck',\n",
              "  '#calaabocalucianohuck',\n",
              "  '@lucianohuck',\n",
              "  'comparsas',\n",
              "  'ajudaram',\n",
              "  'desgoverno',\n",
              "  'agora',\n",
              "  'vem',\n",
              "  'essa‚Ä¶'],\n",
              " ['autoridade',\n",
              "  'mar√≠tima',\n",
              "  'vai',\n",
              "  'estar',\n",
              "  'praias',\n",
              "  '‚Äúcom',\n",
              "  'robusto',\n",
              "  'dispositivo‚Äù',\n",
              "  '#covid19',\n",
              "  '#pol√≠ciamar√≠tima',\n",
              "  '#praias'],\n",
              " ['costa',\n",
              "  'pede',\n",
              "  'portugueses',\n",
              "  'regressem',\n",
              "  'rua',\n",
              "  'cautelas',\n",
              "  '#ant√≥niocosta',\n",
              "  '#covid19',\n",
              "  '#emdestaque'],\n",
              " ['concession√°rios',\n",
              "  'praia',\n",
              "  'avisam',\n",
              "  'muitos',\n",
              "  't√™m',\n",
              "  'condi√ß√µes',\n",
              "  'abrir',\n",
              "  '#covid19',\n",
              "  '#emdestaque',\n",
              "  '#praias'],\n",
              " ['regresso',\n",
              "  'creche',\n",
              "  'bom',\n",
              "  'crian√ßas',\n",
              "  'pais,',\n",
              "  'concordam',\n",
              "  'especialistas',\n",
              "  '#covid19',\n",
              "  '#creches',\n",
              "  '#educa√ß√£o'],\n",
              " ['(multim√≠dia',\n",
              "  'hospitais',\n",
              "  'tempor√°rios',\n",
              "  '#wuhan',\n",
              "  'cr√≠ticos',\n",
              "  'indispens√°veis',\n",
              "  'controle',\n",
              "  '#covid19,',\n",
              "  'dizem',\n",
              "  'especial‚Ä¶'],\n",
              " ['restaurantes',\n",
              "  'reabrem',\n",
              "  'segunda',\n",
              "  '‚Äútodas',\n",
              "  'condi√ß√µes‚Äù',\n",
              "  'seguran√ßa',\n",
              "  '#covid19',\n",
              "  '#emdestaque',\n",
              "  '#restaura√ß√£o'],\n",
              " ['faleceu',\n",
              "  'hoje',\n",
              "  'marido',\n",
              "  'amiga',\n",
              "  'üíî',\n",
              "  'gente,',\n",
              "  'conhecia,',\n",
              "  'imposs√≠vel',\n",
              "  'sentir',\n",
              "  'dor',\n",
              "  'dela!',\n",
              "  'deus',\n",
              "  'cuide',\n",
              "  'do‚Ä¶'],\n",
              " ['dia',\n",
              "  'gari',\n",
              "  'comemorado',\n",
              "  '16',\n",
              "  'maio',\n",
              "  'todo',\n",
              "  'brasil',\n",
              "  'parab√©ns',\n",
              "  'profissionais',\n",
              "  'exercem',\n",
              "  'trabalho',\n",
              "  'e‚Ä¶'],\n",
              " ['perdi',\n",
              "  'toda',\n",
              "  'fama',\n",
              "  'mal',\n",
              "  'm√°scara',\n",
              "  '#covid',\n",
              "  '#coronga',\n",
              "  '#profissionaldetiüíª',\n",
              "  '#lordrenf',\n",
              "  'carapicu√≠ba,',\n",
              "  'brazil'],\n",
              " ['efeitos',\n",
              "  'quarentena',\n",
              "  'chu',\n",
              "  'üëèüëèüëèüëèüëèüëè',\n",
              "  '#puzzle',\n",
              "  '#puzzles',\n",
              "  '#quebracabe√ßa',\n",
              "  '#quarentena',\n",
              "  '#quarentine',\n",
              "  '#covid_19',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['deixe',\n",
              "  'procurar',\n",
              "  'cuidado',\n",
              "  '#m√©dico',\n",
              "  'necess√°rio!',\n",
              "  'where',\n",
              "  'are',\n",
              "  'all',\n",
              "  'the',\n",
              "  'patients?',\n",
              "  'addressing‚Ä¶'],\n",
              " ['precisa',\n",
              "  'explicar?',\n",
              "  '#obrasilnaopodeparar',\n",
              "  '#bolsonarotemrazao',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid',\n",
              "  '#quarentena',\n",
              "  '#brasilnomapadafome‚Ä¶'],\n",
              " ['orgulho',\n",
              "  'pequeno',\n",
              "  'povo',\n",
              "  'medo',\n",
              "  'mostrar!',\n",
              "  'orgulho',\n",
              "  'pernambuco',\n",
              "  'rezam',\n",
              "  'carrilha',\n",
              "  'd‚Ä¶'],\n",
              " ['meio',\n",
              "  'passando',\n",
              "  'resta',\n",
              "  'orar',\n",
              "  'cidade',\n",
              "  '#compartilhem',\n",
              "  '#covid19',\n",
              "  '#ora√ß√£o',\n",
              "  '#chave‚Ä¶'],\n",
              " ['verdade',\n",
              "  'precisa',\n",
              "  'ser',\n",
              "  'complicada',\n",
              "  '#fakenewsmedia',\n",
              "  '#bolsonarogenocida',\n",
              "  '#bolsonaro',\n",
              "  '#impeachmentdebolsonarourgente‚Ä¶'],\n",
              " ['bem',\n",
              "  'vindo',\n",
              "  'brazuela!!!',\n",
              "  '#ficaemcasa',\n",
              "  '#elenao',\n",
              "  '#euavisei',\n",
              "  '#bosonada',\n",
              "  '#governo',\n",
              "  '#brasil‚Ä¶'],\n",
              " ['pasara,',\n",
              "  'en',\n",
              "  'guitiriz,',\n",
              "  'pobo,',\n",
              "  'mertes',\n",
              "  'mercores',\n",
              "  'despois',\n",
              "  'eleccions',\n",
              "  'aparece',\n",
              "  'un',\n",
              "  'votante',\n",
              "  'con',\n",
              "  '#covid19?'],\n",
              " ['marca',\n",
              "  'amiga',\n",
              "  'ta',\n",
              "  'doida',\n",
              "  'pra',\n",
              "  'voltar',\n",
              "  'ex!',\n",
              "  '#ocorvojubileu',\n",
              "  '#covid',\n",
              "  '#quarentena'],\n",
              " ['t√£o',\n",
              "  'dif√≠cil',\n",
              "  'entender',\n",
              "  'limita√ß√£o',\n",
              "  'estudo',\n",
              "  'usa',\n",
              "  '6',\n",
              "  'pacientes',\n",
              "  'grupo',\n",
              "  'tratado',\n",
              "  'hidroxicloroquina‚Ä¶'],\n",
              " ['fiz',\n",
              "  'desenho',\n",
              "  'paisagem',\n",
              "  'janela',\n",
              "  'esperan√ßa',\n",
              "  'queria',\n",
              "  'ver',\n",
              "  'janela',\n",
              "  'pandemia',\n",
              "  'n',\n",
              "  'posso',\n",
              "  'ir',\n",
              "  'p‚Ä¶'],\n",
              " ['amplia√ß√£o',\n",
              "  'dr√°stica',\n",
              "  'uso',\n",
              "  'cloroquina',\n",
              "  'flexibiliza√ß√£o',\n",
              "  'imediata',\n",
              "  'quarentena',\n",
              "  'apenas',\n",
              "  'duas',\n",
              "  'posi√ß√µes',\n",
              "  'presid‚Ä¶'],\n",
              " ['algu√©m',\n",
              "  'explica!!!!',\n",
              "  '#bolsonarorainhalouca',\n",
              "  '#bolsonaroassassino',\n",
              "  '#bolsonaroficaquieto',\n",
              "  '#bolsonaro',\n",
              "  '#brasil‚Ä¶'],\n",
              " ['leveza',\n",
              "  'tempos',\n",
              "  '#pandemia!',\n",
              "  'üôèüçÉ',\n",
              "  'epis√≥dio',\n",
              "  'fort√≠ssimo',\n",
              "  '@gduvivier',\n",
              "  '@hbo_brasil‚Ä¶'],\n",
              " ['hackers',\n",
              "  'invadem',\n",
              "  '#hospital',\n",
              "  'encontram',\n",
              "  '#exame',\n",
              "  '#covid19',\n",
              "  '#bolsonaro',\n",
              "  'ser√°,',\n",
              "  'n√©?!',\n",
              "  'via',\n",
              "  '@tec_mundo'],\n",
              " ['falo', 'qu√™???üòÇüòÇüòÇüòÇ', '#covid', '#humor', '#quarentena'],\n",
              " ['@jim_edwards', '@hblodget', 'india', '#covid'],\n",
              " ['cloroquina',\n",
              "  'derruba',\n",
              "  '#covid19,',\n",
              "  'derrubou',\n",
              "  '2',\n",
              "  'ministros',\n",
              "  'tal',\n",
              "  'agora',\n",
              "  'derrubar',\n",
              "  'presidente?'],\n",
              " ['boa',\n",
              "  'tarde',\n",
              "  'aliados!!!',\n",
              "  'daqui',\n",
              "  'pouco',\n",
              "  'live',\n",
              "  'canal',\n",
              "  'youtube',\n",
              "  'vamos',\n",
              "  'falar',\n",
              "  'sobre',\n",
              "  'guerra',\n",
              "  'narrativas,',\n",
              "  'informa‚Ä¶'],\n",
              " ['casos',\n",
              "  '#covid',\n",
              "  '#guarulhos',\n",
              "  'chegam',\n",
              "  '1426,',\n",
              "  '163',\n",
              "  'mortes',\n",
              "  'fontes',\n",
              "  'seade',\n",
              "  'pmg,',\n",
              "  'dados',\n",
              "  'combinados'],\n",
              " ['@drguiga1',\n",
              "  '@alessandrojferreira',\n",
              "  '@mfrancomed',\n",
              "  '@franciscoguedess',\n",
              "  '@danielcmrocha',\n",
              "  '#novidade',\n",
              "  '#agentefazbemparavoc√™‚Ä¶'],\n",
              " ['#hackathon',\n",
              "  'online',\n",
              "  'gratuito,',\n",
              "  'criado',\n",
              "  'desenvolver',\n",
              "  'reunir',\n",
              "  'solu√ß√µes',\n",
              "  'pro‚Ä¶'],\n",
              " ['saiu',\n",
              "  'hoje',\n",
              "  'estudo',\n",
              "  'randomizado',\n",
              "  'controlado,',\n",
              "  'hidroxicloroquina',\n",
              "  'versus',\n",
              "  'n√£ohidroxicloroquina',\n",
              "  'pacientes',\n",
              "  '#covid‚Ä¶'],\n",
              " ['v√≠deo',\n",
              "  'novo',\n",
              "  'canal',\n",
              "  'vem',\n",
              "  'gente',\n",
              "  '#lockdownpe',\n",
              "  '#covid',\n",
              "  '#forabolsonaro'],\n",
              " ['@benozzatiarthur',\n",
              "  'desatualizado,',\n",
              "  'descobri',\n",
              "  'q',\n",
              "  'vc',\n",
              "  'bolsonarista',\n",
              "  '#forabolsonaro',\n",
              "  '#covid'],\n",
              " ['#coronav√≠rus',\n",
              "  '#covid19',\n",
              "  'tratamento',\n",
              "  'r√°pido',\n",
              "  'barato',\n",
              "  'porque',\n",
              "  'proibido',\n",
              "  'falar',\n",
              "  'nele',\n",
              "  'todas',\n",
              "  'm√≠dias?',\n",
              "  'tratamento‚Ä¶'],\n",
              " ['sendo',\n",
              "  'chamados',\n",
              "  '2',\n",
              "  'enfermeiros',\n",
              "  '44',\n",
              "  't√©cnicos',\n",
              "  'enfermagem,',\n",
              "  'atuar,',\n",
              "  'combate',\n",
              "  'novo',\n",
              "  'coronav√≠rus,',\n",
              "  'causado‚Ä¶'],\n",
              " ['precisamos',\n",
              "  'falar',\n",
              "  'sobre',\n",
              "  'equidade',\n",
              "  'carreira',\n",
              "  'acad√™mica',\n",
              "  '√≥timo',\n",
              "  'levantamento',\n",
              "  '@dadosrevista!',\n",
              "  '#sciencejournal',\n",
              "  '#women‚Ä¶'],\n",
              " ['judici√°rio',\n",
              "  'batendo',\n",
              "  'cabe√ßa',\n",
              "  'pandemia',\n",
              "  '#judici√°rio',\n",
              "  '#justi√ßa',\n",
              "  '#advocacia',\n",
              "  '#covid',\n",
              "  '#pandemia‚Ä¶'],\n",
              " ['sabe',\n",
              "  'n√∫mero',\n",
              "  'mortes',\n",
              "  'di√°ria',\n",
              "  'it√°lia',\n",
              "  'chocou?',\n",
              "  'pois',\n",
              "  'alcan√ßamos',\n",
              "  'virou',\n",
              "  'rotina!',\n",
              "  'sabe',\n",
              "  'q‚Ä¶'],\n",
              " ['#cloroquina',\n",
              "  '#covid',\n",
              "  '#covid_19',\n",
              "  '#coronavirusbrazil',\n",
              "  'prefeiturademacae',\n",
              "  'informemacae',\n",
              "  'portalmacaerj',\n",
              "  'maca√©'],\n",
              " ['mundo',\n",
              "  'pos',\n",
              "  '#covid',\n",
              "  'vai',\n",
              "  'ter',\n",
              "  'viabilizar',\n",
              "  'projeto',\n",
              "  'renda',\n",
              "  'basica',\n",
              "  'universal',\n",
              "  'toda',\n",
              "  'sociedade',\n",
              "  'renda',\n",
              "  'trabalho‚Ä¶'],\n",
              " ['live',\n",
              "  'melhor',\n",
              "  'prote√ß√£o',\n",
              "  '#prematuro',\n",
              "  'tempos',\n",
              "  '#covid19?',\n",
              "  '#prematuridade'],\n",
              " ['üáßüá∑',\n",
              "  'total',\n",
              "  'casos',\n",
              "  'brasil',\n",
              "  'casos',\n",
              "  'confirmadoss',\n",
              "  '220,291',\n",
              "  '√≥bitos',\n",
              "  '14,962',\n",
              "  'recupera√ß√µes',\n",
              "  '84,970',\n",
              "  '#covid,#corona,‚Ä¶'],\n",
              " ['crian√ßa',\n",
              "  'fica',\n",
              "  'apavorada',\n",
              "  '#jn',\n",
              "  '#jornalista',\n",
              "  '#jornal',\n",
              "  '#globo',\n",
              "  '#bebe',\n",
              "  '#medo',\n",
              "  '#covid',\n",
              "  '#nenem',\n",
              "  '#globolixo',\n",
              "  '#bolsonaro‚Ä¶'],\n",
              " ['bundesliga',\n",
              "  'serve',\n",
              "  'term√¥metro',\n",
              "  'volta',\n",
              "  'futebol',\n",
              "  'mundo',\n",
              "  'der',\n",
              "  'certo,',\n",
              "  'veremos',\n",
              "  'cada',\n",
              "  'vez',\n",
              "  'campeonatos‚Ä¶'],\n",
              " ['descobriu',\n",
              "  'trai√ß√£o',\n",
              "  'abandonou',\n",
              "  'relacionamento',\n",
              "  'corno',\n",
              "  'sempre',\n",
              "  '√∫ltimo',\n",
              "  'saber',\n",
              "  '#coronavirus‚Ä¶'],\n",
              " ['#covid', 'quase', 'todos', 'bairros', 'goi√¢nia'],\n",
              " ['nova',\n",
              "  'pesquisa',\n",
              "  'toda',\n",
              "  'cidade',\n",
              "  'paulo',\n",
              "  'dar√°',\n",
              "  'quadro',\n",
              "  'ainda',\n",
              "  '+',\n",
              "  'fidedigno',\n",
              "  'situa√ß√£o',\n",
              "  'pesquisas',\n",
              "  'assim',\n",
              "  'fundame‚Ä¶'],\n",
              " ['conhecimento',\n",
              "  'tudo!!!',\n",
              "  '#universidadepublica',\n",
              "  '#universidade',\n",
              "  '#ciencia',\n",
              "  '#covid',\n",
              "  '#covidbrasil'],\n",
              " ['rede',\n",
              "  'supermercados',\n",
              "  'eua',\n",
              "  'abre',\n",
              "  'hor√°rio',\n",
              "  'especial',\n",
              "  'p/',\n",
              "  'profissionais',\n",
              "  'sa√∫de',\n",
              "  'seguran√ßa',\n",
              "  'e,',\n",
              "  'hora',\n",
              "  'pagarem',\n",
              "  'por‚Ä¶'],\n",
              " ['tempo',\n",
              "  'pandemia,',\n",
              "  'prefeitura',\n",
              "  'manaus',\n",
              "  'oferece',\n",
              "  'vagas',\n",
              "  'cursos',\n",
              "  'profissionalizantes',\n",
              "  'online',\n",
              "  '#covid‚Ä¶'],\n",
              " ['todas',\n",
              "  'limitacoes',\n",
              "  'economicas',\n",
              "  'enfrentando',\n",
              "  'bloqueio',\n",
              "  'genocida',\n",
              "  'eua,',\n",
              "  '#cuba',\n",
              "  'continua',\n",
              "  'dando',\n",
              "  'exemplo',\n",
              "  'posi‚Ä¶'],\n",
              " ['novo',\n",
              "  'coronav√≠rus',\n",
              "  'infetou',\n",
              "  '4549100',\n",
              "  'pessoas',\n",
              "  'todo',\n",
              "  'mundo,',\n",
              "  'menos',\n",
              "  '307321',\n",
              "  'quais',\n",
              "  'morreram,',\n",
              "  'segundo',\n",
              "  'um‚Ä¶'],\n",
              " ['sentes',\n",
              "  'falta?!',\n",
              "  '#coronavirus',\n",
              "  '#covid',\n",
              "  '#covid19',\n",
              "  '#covid„Éº19',\n",
              "  '#thoughtoftheday'],\n",
              " ['favor,',\n",
              "  'algu√©m',\n",
              "  'fala',\n",
              "  'onde',\n",
              "  'desliga',\n",
              "  'bolsonaro?',\n",
              "  '#covid',\n",
              "  '#coronavirus'],\n",
              " ['@caixa',\n",
              "  'amor',\n",
              "  'jesus!',\n",
              "  'jeito',\n",
              "  'vez',\n",
              "  'todas',\n",
              "  'desse',\n",
              "  'aplicativo',\n",
              "  'caixa',\n",
              "  'funcionar',\n",
              "  'quase',\n",
              "  'm‚Ä¶'],\n",
              " ['resumo',\n",
              "  'porqu√™',\n",
              "  'tocado',\n",
              "  'certos',\n",
              "  'assuntos',\n",
              "  '#pol√™mica',\n",
              "  '#pandemia',\n",
              "  '#politica',\n",
              "  '#brasil',\n",
              "  '#covid',\n",
              "  '#etc'],\n",
              " ['aproveite',\n",
              "  'distanciamento',\n",
              "  'social,',\n",
              "  'retomar',\n",
              "  'proximidades',\n",
              "  't√≥xicas',\n",
              "  'elimina',\n",
              "  'logo',\n",
              "  'agora',\n",
              "  'desprende',\n",
              "  '#quarentena',\n",
              "  '#covid'],\n",
              " ['cada',\n",
              "  'dia',\n",
              "  'passa',\n",
              "  'percept√≠vel',\n",
              "  'todos',\n",
              "  'palmenses',\n",
              "  'merc√™',\n",
              "  'desorienta√ß√£o',\n",
              "  'falta',\n",
              "  'di√°logo‚Ä¶'],\n",
              " ['astros',\n",
              "  '#covid',\n",
              "  'saturno',\n",
              "  'dando',\n",
              "  'li√ß√£o',\n",
              "  'nunca',\n",
              "  'esquecermos,',\n",
              "  'pobres',\n",
              "  'arrogantes,‚Ä¶'],\n",
              " ['avi√£o',\n",
              "  'cai',\n",
              "  'cear√°',\n",
              "  'deixa',\n",
              "  '4',\n",
              "  'mortos',\n",
              "  'aeronave',\n",
              "  'transportava',\n",
              "  'piau√≠',\n",
              "  'm√©dico',\n",
              "  'covid',\n",
              "  'avi√£o',\n",
              "  'pequeno',\n",
              "  'po‚Ä¶'],\n",
              " ['@teichnelson,',\n",
              "  'conv√≠vio',\n",
              "  'secretarias',\n",
              "  'estado',\n",
              "  'munic√≠pios',\n",
              "  'devia',\n",
              "  'estar',\n",
              "  'insustent√°vel',\n",
              "  'seguissem',\n",
              "  'a√ß√µ‚Ä¶'],\n",
              " ['telesus',\n",
              "  'criado',\n",
              "  'aproximarmos',\n",
              "  'modo',\n",
              "  'combate',\n",
              "  'coronav√≠rus',\n",
              "  'facilita',\n",
              "  'acesso',\n",
              "  'cons‚Ä¶'],\n",
              " ['*para',\n",
              "  'pensarmos',\n",
              "  'seriamente',\n",
              "  'respeito!!!!!*',\n",
              "  '#covid',\n",
              "  '#coronavirus',\n",
              "  '@jairbolsonaro‚Ä¶'],\n",
              " ['brasil',\n",
              "  '@exercitooficial',\n",
              "  'mata',\n",
              "  'pr√≥prio',\n",
              "  'povo',\n",
              "  'governo',\n",
              "  'miliciano',\n",
              "  'apoiado',\n",
              "  '@exercitooficial',\n",
              "  'des‚Ä¶'],\n",
              " ['cabines',\n",
              "  'desinfec√ß√£o,',\n",
              "  'objetivo',\n",
              "  'evitar',\n",
              "  'dissemina√ß√£o',\n",
              "  'novo',\n",
              "  'coronav√≠rus,',\n",
              "  'autorizada',\n",
              "  'pela‚Ä¶'],\n",
              " ['pedro',\n",
              "  's√°nchez',\n",
              "  '\"temos',\n",
              "  'coidar',\n",
              "  'medidas',\n",
              "  'seguridade,',\n",
              "  'follamos',\n",
              "  'dous',\n",
              "  'metros\"',\n",
              "  '#covid'],\n",
              " ['aqui',\n",
              "  'pensar',\n",
              "  'naquele',\n",
              "  'tempo',\n",
              "  'pessoas',\n",
              "  'sopravam',\n",
              "  'velas',\n",
              "  'cima',\n",
              "  'bolo,',\n",
              "  'cantar',\n",
              "  'parab√©ns',\n",
              "  '#covid'],\n",
              " ['gr√°fico',\n",
              "  'mostra',\n",
              "  'tend√™ncia',\n",
              "  'crescente',\n",
              "  'novos',\n",
              "  'casos',\n",
              "  'brasil',\n",
              "  'decrescente',\n",
              "  'demais',\n",
              "  'pa√≠ses',\n",
              "  'europa‚Ä¶'],\n",
              " ['pa√≠s',\n",
              "  '|',\n",
              "  'regulamentar',\n",
              "  'desporto',\n",
              "  'nacional',\n",
              "  'nada,',\n",
              "  'mil√≠metro',\n",
              "  'quadrado,',\n",
              "  'escapa',\n",
              "  'regras',\n",
              "  'para‚Ä¶'],\n",
              " ['@brumelianebrum',\n",
              "  '@jeanwyllys_real',\n",
              "  'prioridade',\n",
              "  'vida',\n",
              "  'morte',\n",
              "  '#covid'],\n",
              " ['teich,',\n",
              "  'reuni√£o',\n",
              "  'ministerial',\n",
              "  'exames',\n",
              "  'bolsonaro',\n",
              "  'assista',\n",
              "  'fatos',\n",
              "  'semana',\n",
              "  '#brasil‚Ä¶'],\n",
              " ['q',\n",
              "  'acontecer',\n",
              "  'pandemia',\n",
              "  'v√≠rus',\n",
              "  'mundial,',\n",
              "  'pra',\n",
              "  'baixar',\n",
              "  'pre√ßo',\n",
              "  'gasolina',\n",
              "  '#quarentena',\n",
              "  '#pandemia',\n",
              "  '#coronavirus‚Ä¶'],\n",
              " ['pedido',\n",
              "  '@mptmg,',\n",
              "  'vt',\n",
              "  'congonhas',\n",
              "  'determina',\n",
              "  'csn',\n",
              "  'minera√ß√£o',\n",
              "  'adote',\n",
              "  'medidas',\n",
              "  'reduzir',\n",
              "  'risco',\n",
              "  'cont√°gio',\n",
              "  'da‚Ä¶'],\n",
              " ['muita',\n",
              "  'gente',\n",
              "  'internet',\n",
              "  'virou',\n",
              "  'especialista',\n",
              "  '√°rea',\n",
              "  'sa√∫de,',\n",
              "  'nunca',\n",
              "  'ter',\n",
              "  'lido',\n",
              "  'artigo,',\n",
              "  'nunca',\n",
              "  'ter',\n",
              "  'freque‚Ä¶'],\n",
              " ['estudo,',\n",
              "  'pacientes',\n",
              "  'tomavam',\n",
              "  'cloroquina,',\n",
              "  'protegeram',\n",
              "  '#covid_19',\n",
              "  'cloroquina',\n",
              "  'sequer',\n",
              "  'capaz',\n",
              "  'ev‚Ä¶'],\n",
              " ['boa',\n",
              "  'not√≠cia',\n",
              "  'üòÉ!',\n",
              "  'brasil,',\n",
              "  '79479',\n",
              "  'pessoas',\n",
              "  '#curaram',\n",
              "  '#covid19',\n",
              "  'dados',\n",
              "  '14',\n",
              "  'maio',\n",
              "  'minist√©rio',\n",
              "  's‚Ä¶'],\n",
              " ['dia',\n",
              "  'aben√ßoado',\n",
              "  '#jesus',\n",
              "  'dessa',\n",
              "  'pandemia',\n",
              "  'respeito',\n",
              "  'crentes',\n",
              "  'crentes,',\n",
              "  'pra',\n",
              "  'v‚Ä¶'],\n",
              " ['@thammymiranda',\n",
              "  'pronunciou',\n",
              "  'sobre',\n",
              "  'caos',\n",
              "  'passando',\n",
              "  'sa√∫de',\n",
              "  'p√∫blica',\n",
              "  'pa√≠s‚Ä¶'],\n",
              " ['segundo',\n",
              "  'boletim',\n",
              "  'epidemiol√≥gico',\n",
              "  'dire√ß√£ogeral',\n",
              "  'sa√∫de',\n",
              "  '(dgs,',\n",
              "  'comunidade',\n",
              "  'intermunicipal',\n",
              "  'regi√£o',\n",
              "  'coimbra',\n",
              "  'h√°‚Ä¶'],\n",
              " ['#edecasa',\n",
              "  'muit√≠ssimo',\n",
              "  'importante',\n",
              "  'falar',\n",
              "  'sobre',\n",
              "  'profissionais',\n",
              "  'sa√∫de',\n",
              "  'falem',\n",
              "  'tbm',\n",
              "  'seguran√ßas,',\n",
              "  'pessoal',\n",
              "  'li‚Ä¶'],\n",
              " ['avan√ßos',\n",
              "  'ci√™ncia',\n",
              "  'combate',\n",
              "  '#covid',\n",
              "  '\\U0001f9a0üî¨',\n",
              "  'üá∫üá∏',\n",
              "  'calif√≥rnia',\n",
              "  'afirma',\n",
              "  'ter',\n",
              "  'descoberto',\n",
              "  '#anticorpo',\n",
              "  'eficaz',\n",
              "  'contra',\n",
              "  'a‚Ä¶'],\n",
              " ['dia',\n",
              "  '16',\n",
              "  'maio',\n",
              "  '2020,',\n",
              "  '57',\n",
              "  'novos',\n",
              "  'infectados',\n",
              "  'novo',\n",
              "  'coronav√≠rus',\n",
              "  'jap√£o',\n",
              "  '#coronavirus',\n",
              "  '#covid19',\n",
              "  '#pandemia',\n",
              "  '#covid_19japao'],\n",
              " ['enquanto',\n",
              "  'gente',\n",
              "  'furando',\n",
              "  '#quarentena,',\n",
              "  'n√∫mero',\n",
              "  'infectados',\n",
              "  'aumentar√°,',\n",
              "  'n√∫mero',\n",
              "  'interna√ß√µes',\n",
              "  'aumentar√°,',\n",
              "  'o‚Ä¶'],\n",
              " ['@brunnosarttori',\n",
              "  'vai',\n",
              "  'autodeclarar',\n",
              "  'm√©dico',\n",
              "  'receitar',\n",
              "  'cloroquina',\n",
              "  'pra',\n",
              "  '#covid'],\n",
              " ['covid19',\n",
              "  'cinco',\n",
              "  'dias',\n",
              "  'novas',\n",
              "  'infe√ß√µes',\n",
              "  'maia',\n",
              "  '#atualiza√ß√£o',\n",
              "  '#covid',\n",
              "  '#dgs',\n",
              "  '#infe√ß√µes',\n",
              "  '#n√∫meros'],\n",
              " ['üî¥',\n",
              "  'vivo',\n",
              "  '√∫ltimas',\n",
              "  'informa√ß√µes',\n",
              "  'sobre',\n",
              "  'coronav√≠rus',\n",
              "  'chapec√≥',\n",
              "  'neste',\n",
              "  's√°bado',\n",
              "  '(16',\n",
              "  'acesse',\n",
              "  'acompanhe‚Ä¶'],\n",
              " ['bate',\n",
              "  'papo',\n",
              "  'dra',\n",
              "  'tais',\n",
              "  'hon√≥rio',\n",
              "  'sobre',\n",
              "  'gest√£o',\n",
              "  'resolu√ß√£o',\n",
              "  'conflitos',\n",
              "  'durante',\n",
              "  'pandemia',\n",
              "  '#covid',\n",
              "  '#coronavirus'],\n",
              " ['oficial',\n",
              "  'braga',\n",
              "  'infetados',\n",
              "  '120',\n",
              "  'horas',\n",
              "  '#braga',\n",
              "  '#covid19',\n",
              "  '#dgs'],\n",
              " ['bolsonaro',\n",
              "  'defende',\n",
              "  'protocolo',\n",
              "  'diferente',\n",
              "  'covid19,',\n",
              "  'diz',\n",
              "  'braga',\n",
              "  'netto',\n",
              "  '#braganetto',\n",
              "  '#covid'],\n",
              " ['praias',\n",
              "  'p√≥voa',\n",
              "  'varzim',\n",
              "  'abrem',\n",
              "  '01',\n",
              "  'julho',\n",
              "  '#covid19',\n",
              "  '#p√≥voadevarzim',\n",
              "  '#praias'],\n",
              " ['ana',\n",
              "  'carolina',\n",
              "  'precisou',\n",
              "  '1',\n",
              "  'hora',\n",
              "  'live',\n",
              "  'pra',\n",
              "  'dar',\n",
              "  'tap√£o',\n",
              "  '@jairbolsonaro',\n",
              "  '#covid',\n",
              "  '#corona',\n",
              "  '#coronavirus‚Ä¶'],\n",
              " ['quiser',\n",
              "  'outros',\n",
              "  'detalhes',\n",
              "  'sobre',\n",
              "  'diz',\n",
              "  'projeto',\n",
              "  '#ldo2021,',\n",
              "  'clique',\n",
              "  'aqui'],\n",
              " ['#r√∫ssia',\n",
              "  'alerta',\n",
              "  'desinforma√ß√£o',\n",
              "  'durante',\n",
              "  '#pandemia',\n",
              "  '#covid19',\n",
              "  '#epidemia',\n",
              "  '#oms',\n",
              "  '#saludmundial'],\n",
              " ['#midiasocial',\n",
              "  '#quarentena',\n",
              "  '#pandemia',\n",
              "  '#covid',\n",
              "  '#gera√ß√µes',\n",
              "  'baby',\n",
              "  'boomers',\n",
              "  'gera√ß√£o',\n",
              "  'z',\n",
              "  'con‚Ä¶'],\n",
              " ['sobre',\n",
              "  'rem√©dio,',\n",
              "  'todos',\n",
              "  'contra',\n",
              "  'usam',\n",
              "  'contra',\n",
              "  'favor',\n",
              "  '#cloroquina',\n",
              "  '#covid',\n",
              "  '#fiqueemcasa',\n",
              "  '#emcasa'],\n",
              " ['vou',\n",
              "  'fazer',\n",
              "  'parte',\n",
              "  'üí°',\n",
              "  '________',\n",
              "  '________',\n",
              "  '#life',\n",
              "  '#words',\n",
              "  '#today',\n",
              "  '#quotes',\n",
              "  '#mood',\n",
              "  '#covid',\n",
              "  '#quarantine‚Ä¶'],\n",
              " ['trump',\n",
              "  '\"est√°',\n",
              "  'considerando\"',\n",
              "  'vacina',\n",
              "  'contra',\n",
              "  '#coronav√≠rus',\n",
              "  'dispon√≠vel',\n",
              "  'gratuitamente',\n",
              "  '#oms',\n",
              "  '#epidemia',\n",
              "  '#covid‚Ä¶'],\n",
              " ['üÜï',\n",
              "  '‚òÖfumigadora',\n",
              "  'astarsa',\n",
              "  'aa33‚òÖ',\n",
              "  '‚òé',\n",
              "  '+54',\n",
              "  '11',\n",
              "  '52635610',\n",
              "  'int',\n",
              "  '206',\n",
              "  'üì≤+54',\n",
              "  '9',\n",
              "  '3512023508',\n",
              "  'consultas@corvialcomar',\n",
              "  '#corvial‚Ä¶'],\n",
              " ['pa√≠s',\n",
              "  '√≥bitos',\n",
              "  'casos',\n",
              "  '1',\n",
              "  'üá∫üá∏',\n",
              "  '88237',\n",
              "  '1473415',\n",
              "  '2üá¨üáß',\n",
              "  '34078',\n",
              "  '238004',\n",
              "  '3',\n",
              "  'üáÆüáπ',\n",
              "  '31610‚Ä¶'],\n",
              " ['ningu√©m',\n",
              "  'desconfia',\n",
              "  'pegou',\n",
              "  '#covid19,',\n",
              "  'trataram',\n",
              "  '#cloroquina,',\n",
              "  'recuperou,',\n",
              "  'falsificou',\n",
              "  'exames',\n",
              "  'quer‚Ä¶'],\n",
              " ['@xicograziano',\n",
              "  'coisa',\n",
              "  'proibi√ß√£o',\n",
              "  'cloroquina',\n",
              "  'narrativa',\n",
              "  'criada',\n",
              "  'governo',\n",
              "  'proibi√ß√£o',\n",
              "  'uso',\n",
              "  'o‚Ä¶'],\n",
              " ['#health',\n",
              "  '#professionals',\n",
              "  '#covid',\n",
              "  '#pandemic',\n",
              "  '#pandemia',\n",
              "  'her√≥is',\n",
              "  'precisam',\n",
              "  'ajuda‚Ä¶'],\n",
              " ['#espanha,',\n",
              "  'falecido',\n",
              "  'caiu',\n",
              "  '102',\n",
              "  '√∫ltimas',\n",
              "  '24',\n",
              "  'horas',\n",
              "  'total',\n",
              "  '27563',\n",
              "  '#salud',\n",
              "  '#profecionalesdelasalud‚Ä¶'],\n",
              " ['famalic√£o',\n",
              "  'empresas',\n",
              "  'doam',\n",
              "  '3500',\n",
              "  'euros',\n",
              "  'tal√µes',\n",
              "  'alimentares',\n",
              "  'solid√°rios',\n",
              "  'minimercados',\n",
              "  '#com√©rcio',\n",
              "  '#covid19',\n",
              "  '#economia'],\n",
              " ['#ignorebolsonaro',\n",
              "  'presidente',\n",
              "  'no√ß√£o',\n",
              "  'confira',\n",
              "  'n√∫meros',\n",
              "  'pesquise',\n",
              "  'sobre',\n",
              "  'fala',\n",
              "  'parem',\n",
              "  'fazer',\n",
              "  'politicag‚Ä¶'],\n",
              " ['dois',\n",
              "  'meses',\n",
              "  'ap√≥s',\n",
              "  '1¬™',\n",
              "  'morte',\n",
              "  '#covid19,',\n",
              "  '#brasil',\n",
              "  'cen√°rio',\n",
              "  'pesadelos',\n",
              "  'via',\n",
              "  '@folha'],\n",
              " ['existe',\n",
              "  'podrid√£o',\n",
              "  'tr√°s',\n",
              "  'disso',\n",
              "  'tudo',\n",
              "  'povo',\n",
              "  'acordasse',\n",
              "  'veria#covƒ±d'],\n",
              " ['farmac√™utica',\n",
              "  'sobe',\n",
              "  '240%',\n",
              "  'ap√≥s',\n",
              "  'dizer',\n",
              "  'ter',\n",
              "  'poss√≠vel',\n",
              "  '‚Äúcura‚Äù',\n",
              "  'covid19',\n",
              "  '|',\n",
              "  'exame',\n",
              "  '#covid__19',\n",
              "  '#covid',\n",
              "  '#cura'],\n",
              " ['cader',\n",
              "  'rem√©dios',\n",
              "  'prefeitos',\n",
              "  'governadores',\n",
              "  'receberam',\n",
              "  'governo',\n",
              "  'federal',\n",
              "  '#foramaia',\n",
              "  '#foraalcolumbre',\n",
              "  '#forastf‚Ä¶'],\n",
              " ['morcegos',\n",
              "  'brasil',\n",
              "  't√™m',\n",
              "  'coronav√≠rus',\n",
              "  'diferente',\n",
              "  'surgiu',\n",
              "  'china',\n",
              "  'via',\n",
              "  '@uolnoticias',\n",
              "  '@uol',\n",
              "  '#covid19'],\n",
              " ['caixa',\n",
              "  'disponibilizar√°',\n",
              "  'r$',\n",
              "  '246',\n",
              "  'milh√µes',\n",
              "  'aux√≠lio',\n",
              "  'emergencial',\n",
              "  '405163',\n",
              "  'pessoas',\n",
              "  'neste',\n",
              "  's√°bado',\n",
              "  '#covid‚Ä¶'],\n",
              " ['‚öΩüéÆjogo',\n",
              "  'bemüéÆ‚öΩ',\n",
              "  '‚†Ä',\n",
              "  'seguimos',\n",
              "  'quartas',\n",
              "  'finais',\n",
              "  'jogo',\n",
              "  'bem!',\n",
              "  'fique',\n",
              "  'ligado',\n",
              "  'partir',\n",
              "  '11h',\n",
              "  'participe',\n",
              "  'fa√ßa‚Ä¶'],\n",
              " ['ficarmos',\n",
              "  'atentos',\n",
              "  'n√∫meros',\n",
              "  'medonhos',\n",
              "  'utilizados',\n",
              "  'm√≠dia',\n",
              "  'politicagem',\n",
              "  'continuar',\n",
              "  'medidas',\n",
              "  'preventivas',\n",
              "  'de‚Ä¶'],\n",
              " ['ap√≥s',\n",
              "  'afrouxamento',\n",
              "  'geral',\n",
              "  'pandemia,',\n",
              "  'devemos',\n",
              "  'continuar',\n",
              "  'pensando',\n",
              "  'pr√≥ximo',\n",
              "  'lutar',\n",
              "  'contra',\n",
              "  'roubalheiras,',\n",
              "  'su‚Ä¶'],\n",
              " ['finalmente',\n",
              "  'florian√≥polis',\n",
              "  'sob',\n",
              "  'controle',\n",
              "  'infec√ß√£o',\n",
              "  '#covid19',\n",
              "  'gra√ßas',\n",
              "  'confinamento',\n",
              "  'imposto',\n",
              "  'prefeit‚Ä¶'],\n",
              " ['nesse',\n",
              "  'momento',\n",
              "  'deveria',\n",
              "  'existir',\n",
              "  'esquerda,',\n",
              "  'direita',\n",
              "  'sim',\n",
              "  'todos',\n",
              "  'juntos',\n",
              "  'vida!',\n",
              "  '14‚Ä¶'],\n",
              " ['ministro',\n",
              "  'sa√∫de',\n",
              "  'ideal,',\n",
              "  'cabe√ßa',\n",
              "  'bolsonaro,',\n",
              "  'deve',\n",
              "  'ser',\n",
              "  'felizmente',\n",
              "  'morreu',\n",
              "  'bertioga,',\n",
              "  '1979',\n",
              "  'josef',\n",
              "  'me‚Ä¶'],\n",
              " ['viva',\n",
              "  'transplante',\n",
              "  'combatendo',\n",
              "  'not√≠cias',\n",
              "  'falsas',\n",
              "  'sobre',\n",
              "  'covid',\n",
              "  '#covid19',\n",
              "  '#covid'],\n",
              " ['@govsc',\n",
              "  'quantos',\n",
              "  'casos',\n",
              "  'novos',\n",
              "  '#covid',\n",
              "  'registrados',\n",
              "  'sc',\n",
              "  'dia',\n",
              "  '14',\n",
              "  'dia',\n",
              "  '15/05',\n",
              "  'encontrei',\n",
              "  'lugar',\n",
              "  'nenhum‚Ä¶'],\n",
              " ['milhares',\n",
              "  'creches',\n",
              "  'preparadas',\n",
              "  'reabrir',\n",
              "  'sob',\n",
              "  'condi√ß√µes',\n",
              "  'at√≠picas,',\n",
              "  'especialistas',\n",
              "  'educadores',\n",
              "  'inf√¢nci‚Ä¶'],\n",
              " ['liberar',\n",
              "  '#hidroxicloroquina',\n",
              "  '#sus',\n",
              "  'estados=',\n",
              "  'acabar√°',\n",
              "  'mamata',\n",
              "  'cm',\n",
              "  'grana',\n",
              "  'gov',\n",
              "  'federal',\n",
              "  'medicamento',\n",
              "  'ba‚Ä¶'],\n",
              " ['directora',\n",
              "  'nacional',\n",
              "  'sa√∫de',\n",
              "  'p√∫blica',\n",
              "  'indicou',\n",
              "  'doente,',\n",
              "  '33',\n",
              "  'anos',\n",
              "  'idade,',\n",
              "  'diagnosticada',\n",
              "  '#covid19',\n",
              "  'cid‚Ä¶'],\n",
              " ['directora',\n",
              "  'nacional',\n",
              "  'sa√∫de',\n",
              "  'p√∫blica',\n",
              "  'indicou',\n",
              "  'doente,',\n",
              "  '33',\n",
              "  'anos',\n",
              "  'idade,',\n",
              "  'diagnosticada',\n",
              "  '#covid19',\n",
              "  'cid‚Ä¶'],\n",
              " ['assembleia',\n",
              "  'mundial',\n",
              "  'sa√∫de',\n",
              "  'oms',\n",
              "  'ocorre',\n",
              "  'meio',\n",
              "  'crise',\n",
              "  '#covid19',\n",
              "  '#wha73'],\n",
              " ['it√°lia',\n",
              "  'vai',\n",
              "  'abrir',\n",
              "  'fronteiras',\n",
              "  'uni√£o',\n",
              "  'europeia,',\n",
              "  'necessidade',\n",
              "  'quarentena,',\n",
              "  'partir',\n",
              "  '3',\n",
              "  'junho,',\n",
              "  'segundo‚Ä¶'],\n",
              " ['quantos',\n",
              "  'funcion√°rios',\n",
              "  'supermercado,',\n",
              "  'farm√°cia,',\n",
              "  'restaurante,',\n",
              "  'motoboys',\n",
              "  'afins',\n",
              "  'morreram',\n",
              "  '#covid?'],\n",
              " ['@lucianohuck',\n",
              "  'imaginou',\n",
              "  'salvando',\n",
              "  'todo',\n",
              "  'mundo',\n",
              "  'seria,',\n",
              "  'super',\n",
              "  'her√≥i,',\n",
              "  'imperador',\n",
              "  'mundo,',\n",
              "  'basta',\n",
              "  'voc√™‚Ä¶'],\n",
              " ['@teichnelson',\n",
              "  'saia!',\n",
              "  '#fiqueemcasacomaciencia',\n",
              "  '#fiquememcasa',\n",
              "  '#covid'],\n",
              " ['piritiba',\n",
              "  '√¥nibus',\n",
              "  '40',\n",
              "  'pessoas',\n",
              "  'vindas',\n",
              "  'outra',\n",
              "  'cidade',\n",
              "  'barrado',\n",
              "  'blitz',\n",
              "  'sa√∫de',\n",
              "  'porto',\n",
              "  'feliz',\n",
              "  'confira!‚Ä¶'],\n",
              " ['@wilsonwitzel',\n",
              "  'her√≥i',\n",
              "  'q',\n",
              "  'vai',\n",
              "  'cadeia',\n",
              "  'mario',\n",
              "  'peixoto',\n",
              "  'olha,',\n",
              "  '@policiafederal',\n",
              "  'iniciou',\n",
              "  'a√ß√µes',\n",
              "  'rj',\n",
              "  'et‚Ä¶'],\n",
              " ['quase',\n",
              "  '6h',\n",
              "  'manh√£',\n",
              "  'nada',\n",
              "  'sono',\n",
              "  'troco',\n",
              "  'dia',\n",
              "  'noite',\n",
              "  'entrevistas',\n",
              "  'notici√°rios',\n",
              "  'descubro',\n",
              "  'q',\n",
              "  '√∫nica‚Ä¶'],\n",
              " ['not√≠cia', 'senhores', 'üòç', '#coronavitus', '#covid19', '#covid'],\n",
              " ['#covid19',\n",
              "  't√¥',\n",
              "  'fora!',\n",
              "  '#m√°scaradetecido,',\n",
              "  '#robertsjeans',\n",
              "  'tem!',\n",
              "  'pe√ßa',\n",
              "  'imagem',\n",
              "  'original',\n",
              "  'via',\n",
              "  '#whatsappüì≤',\n",
              "  '11',\n",
              "  '22924461',\n",
              "  'rob‚Ä¶'],\n",
              " ['#tipoftheday',\n",
              "  'in',\n",
              "  '#covid19',\n",
              "  'caros',\n",
              "  'amigos',\n",
              "  '#profissionaisdesa√∫de',\n",
              "  'bem',\n",
              "  'vindos',\n",
              "  '#webmeeting',\n",
              "  'refer√™ncia',\n",
              "  'sobre',\n",
              "  'a‚Ä¶'],\n",
              " ['diagnosticados',\n",
              "  'nesta',\n",
              "  'sextafeira',\n",
              "  '(15',\n",
              "  'novos',\n",
              "  'infectados',\n",
              "  '#covid19',\n",
              "  '#mo√ßambique,',\n",
              "  '\"temos',\n",
              "  'quatro',\n",
              "  'indiv√≠duo‚Ä¶'],\n",
              " ['jap√£o',\n",
              "  'autoriza',\n",
              "  'antiviral',\n",
              "  '#tratamento',\n",
              "  '#covid19',\n",
              "  'promete',\n",
              "  '#vacina',\n",
              "  'via',\n",
              "  '@yahoobr'],\n",
              " ['gente',\n",
              "  'achando',\n",
              "  'grande',\n",
              "  'mancha',\n",
              "  'oleo',\n",
              "  'litoral',\n",
              "  'ne',\n",
              "  'grande',\n",
              "  'dor',\n",
              "  'cabe√ßa',\n",
              "  '2020',\n",
              "  '#tolinhos',\n",
              "  '#covid'],\n",
              " ['#covid19',\n",
              "  '#s√£ovicente',\n",
              "  'confira',\n",
              "  '#casos',\n",
              "  '#bairro',\n",
              "  'nesta',\n",
              "  '#sexta,',\n",
              "  '15',\n",
              "  'via',\n",
              "  '@costanortemais'],\n",
              " ['bom',\n",
              "  'dia',\n",
              "  'fa√ßam',\n",
              "  'teste',\n",
              "  'hahahahahahahahahahahahahahaha',\n",
              "  '#quarentena',\n",
              "  '#covid',\n",
              "  '#radio',\n",
              "  '#agentenaodesiste',\n",
              "  '#sucupirasat'],\n",
              " ['impress√£o', 'fotos', 'volante', 'heteros', 'top', 'diminuiram', '#covid'],\n",
              " ['@folha',\n",
              "  'pena',\n",
              "  'melhores',\n",
              "  'programas',\n",
              "  'informa√ß√£o,',\n",
              "  'dedicados',\n",
              "  '#covid19'],\n",
              " ['@mamuteobeso',\n",
              "  '@brehenrique_',\n",
              "  '@william_castro',\n",
              "  'censura',\n",
              "  'cnn',\n",
              "  'cortar',\n",
              "  'microfone',\n",
              "  'ministro',\n",
              "  'cnn',\n",
              "  'prestando',\n",
              "  'um‚Ä¶'],\n",
              " ['#portadaprocesodigital',\n",
              "  's√°bado',\n",
              "  '16052020',\n",
              "  '#tapasdeld√≠a',\n",
              "  '#honduras',\n",
              "  '#covid19',\n",
              "  '#tusaludestaentusmanos'],\n",
              " ['rindo,',\n",
              "  'desespero',\n",
              "  'm√°scara',\n",
              "  '#ministrodasa√∫de',\n",
              "  '#bolsonarogenocida',\n",
              "  '#bolsonaroenlouqueceu',\n",
              "  '#rindodedesespero‚Ä¶'],\n",
              " ['@melimoficial',\n",
              "  '#livemelim',\n",
              "  '#euquero',\n",
              "  '#ifeatvoce',\n",
              "  '#letsdance',\n",
              "  '#musicismagic',\n",
              "  '#vegpress',\n",
              "  '#confins',\n",
              "  '#angradosreis‚Ä¶'],\n",
              " ['quatro',\n",
              "  'pessoas',\n",
              "  'morreram',\n",
              "  'ap√≥s',\n",
              "  'avi√£o',\n",
              "  'pequeno',\n",
              "  'porte,',\n",
              "  'levava',\n",
              "  'paciente',\n",
              "  'coronav√≠rus',\n",
              "  'teresina,',\n",
              "  'pi‚Ä¶'],\n",
              " ['#m√°scarapersonalizada#m√°scaraprote√ß√£o',\n",
              "  '#bts',\n",
              "  '#covid19',\n",
              "  'lugalma',\n",
              "  'acess√≥rios'],\n",
              " ['enquanto',\n",
              "  'quarentena',\n",
              "  'devido',\n",
              "  '#pandemia',\n",
              "  'causado',\n",
              "  '#covid19,',\n",
              "  'pal√°cio',\n",
              "  'planalto',\n",
              "  'segue',\n",
              "  '#pandemonio',\n",
              "  'ca‚Ä¶'],\n",
              " ['#m√°scaraprote√ß√£o',\n",
              "  '#m√°scarapersonalizada',\n",
              "  '#nowunited',\n",
              "  '#covid19',\n",
              "  'lugalma',\n",
              "  'acess√≥rios'],\n",
              " ['#m√°scarapersonalizada',\n",
              "  '#m√°scaradeprote√ß√£o',\n",
              "  '#covid19',\n",
              "  'lugalma',\n",
              "  'acess√≥rios'],\n",
              " ['#mascaradeprote√ßao',\n",
              "  '#m√°scarapersonalizada',\n",
              "  '#covid19',\n",
              "  'lugalma',\n",
              "  'acess√≥rios'],\n",
              " ['@ninafreitas',\n",
              "  'mandar',\n",
              "  'equipe',\n",
              "  'surpresa',\n",
              "  'todos',\n",
              "  'dias',\n",
              "  'pro',\n",
              "  'augusto',\n",
              "  'franco,',\n",
              "  'bater√°',\n",
              "  'recorde',\n",
              "  'mundial',\n",
              "  'infectado‚Ä¶'],\n",
              " ['al√©m',\n",
              "  'importar',\n",
              "  'popula√ß√£o',\n",
              "  'pobre,',\n",
              "  '@pauloguedesmf',\n",
              "  'mostra',\n",
              "  'nesta',\n",
              "  'entrevista',\n",
              "  'nunca',\n",
              "  'encheu',\n",
              "  'laj‚Ä¶'],\n",
              " ['@afpespanol',\n",
              "  '@lulaoficial',\n",
              "  '@paulacramon',\n",
              "  'mito',\n",
              "  'bolsonaro',\n",
              "  'vem',\n",
              "  'demonstrando',\n",
              "  'ser',\n",
              "  'exemplo',\n",
              "  'tr√°gico',\n",
              "  'brasil,',\n",
              "  'assim‚Ä¶'],\n",
              " ['deve',\n",
              "  'ser',\n",
              "  'novo',\n",
              "  'ministro?',\n",
              "  '#auxilioemergencial',\n",
              "  '#auxilioemergecial',\n",
              "  '#covid',\n",
              "  '#covid1948',\n",
              "  '#covid19',\n",
              "  '#covid„Éº19',\n",
              "  '#coronavirus'],\n",
              " ['tuuuuudo',\n",
              "  'f',\n",
              "  'k',\n",
              "  'numeros',\n",
              "  'fakes',\n",
              "  'morte',\n",
              "  '#coronahoax',\n",
              "  '#covid19',\n",
              "  'sigla',\n",
              "  'certificate',\n",
              "  'of',\n",
              "  'vaccine',\n",
              "  'identity‚Ä¶'],\n",
              " ['sobre',\n",
              "  'd√≥lar',\n",
              "  'subindo,',\n",
              "  'bolsa',\n",
              "  'caindo,',\n",
              "  'fuga',\n",
              "  'capital',\n",
              "  'estrangeiro',\n",
              "  'falta',\n",
              "  'perspectiva',\n",
              "  'recupera√ß√£o',\n",
              "  'eco‚Ä¶'],\n",
              " ['@lulaoficial',\n",
              "  'governo',\n",
              "  'matou',\n",
              "  'covid',\n",
              "  'poder√°',\n",
              "  'matar',\n",
              "  'aqui',\n",
              "  'brasil',\n",
              "  'governo',\n",
              "  'v√≠rus',\n",
              "  'mortal',\n",
              "  'pt',\n",
              "  'nun‚Ä¶'],\n",
              " ['üí∞',\n",
              "  'pagamento',\n",
              "  '2¬™',\n",
              "  'parcela',\n",
              "  'aux√≠lio',\n",
              "  'emergencial',\n",
              "  'veja!',\n",
              "  'confira',\n",
              "  'detalhes',\n",
              "  'arrastando',\n",
              "  'cima',\n",
              "  'stories',\n",
              "  'di‚Ä¶'],\n",
              " ['pr√≥xima', 'semana', 'inicia', 'descenso', 'casos', '#covid19', '#amlo'],\n",
              " ['jeito,',\n",
              "  '@wilsonwitzel',\n",
              "  'curado',\n",
              "  '#covid',\n",
              "  'falou',\n",
              "  'pra',\n",
              "  'ningu√©m',\n",
              "  'menos',\n",
              "  'cheio',\n",
              "  'disposi√ß√£o,',\n",
              "  'po‚Ä¶'],\n",
              " ['vamos',\n",
              "  'ter',\n",
              "  'outro',\n",
              "  'governador',\n",
              "  'preso',\n",
              "  '@riodejaneiro?',\n",
              "  'aguardando',\n",
              "  'cenas',\n",
              "  'pr√≥ximos',\n",
              "  'cap√≠tulos',\n",
              "  'carioca‚Ä¶'],\n",
              " ['membros',\n",
              "  'stf',\n",
              "  'tempo',\n",
              "  'tendo',\n",
              "  'posi√ß√£o',\n",
              "  'contr√°rio',\n",
              "  'desejos',\n",
              "  'povo',\n",
              "  'povo',\n",
              "  'queremos',\n",
              "  'moti‚Ä¶'],\n",
              " ['tributa√ß√£o',\n",
              "  'ricos',\n",
              "  'equilibrar',\n",
              "  'contas',\n",
              "  'p√≥spandemia',\n",
              "  '#tributo',\n",
              "  '#imposto',\n",
              "  '#economia‚Ä¶'],\n",
              " ['sabe',\n",
              "  'diz',\n",
              "  'manh√™',\n",
              "  'to',\n",
              "  'achando',\n",
              "  'coiso',\n",
              "  'diz',\n",
              "  'menino,',\n",
              "  'a√≠',\n",
              "  'achar',\n",
              "  'pqp,',\n",
              "  'mainha,',\n",
              "  't‚Ä¶'],\n",
              " ['mortes',\n",
              "  's√≠ndromes',\n",
              "  'respirat√≥rias',\n",
              "  '2020',\n",
              "  'superam',\n",
              "  'm√©dia',\n",
              "  '√∫ltimos',\n",
              "  '10',\n",
              "  'anos,',\n",
              "  'apontam',\n",
              "  'dados',\n",
              "  'fiocruz',\n",
              "  '|',\n",
              "  'coronav√≠ru‚Ä¶'],\n",
              " ['petrobras', 'preju√≠zo', 'r$', '48,5', 'bi', '1¬∞', 'trimestre', '#covid'],\n",
              " ['prefeito',\n",
              "  'bel√©m,',\n",
              "  'zenaldo',\n",
              "  'coutinho,',\n",
              "  'anunciou',\n",
              "  'in√≠cio',\n",
              "  'tarde',\n",
              "  'desta',\n",
              "  'sextafeira,',\n",
              "  '15,',\n",
              "  'bel√©m',\n",
              "  'ir√°',\n",
              "  'prorrogar',\n",
              "  'a‚Ä¶'],\n",
              " ['gl√≥ria',\n",
              "  'deus!!!',\n",
              "  'nenhuma',\n",
              "  'morte',\n",
              "  '#covid„Éº19,',\n",
              "  '√∫ltimas',\n",
              "  '24',\n",
              "  'horas',\n",
              "  'maranh√£o!!!',\n",
              "  'compartilhe',\n",
              "  'verdade!!!',\n",
              "  '#covid‚Ä¶'],\n",
              " ['sindicato',\n",
              "  'aciona',\n",
              "  'mp',\n",
              "  'investigar',\n",
              "  'suposta',\n",
              "  'press√£o',\n",
              "  'm√©dicos',\n",
              "  'atestarem',\n",
              "  '√≥bitos',\n",
              "  '#covid19'],\n",
              " ['parece',\n",
              "  'bolsominios',\n",
              "  'continuam',\n",
              "  'defendendo',\n",
              "  'vagabundo',\n",
              "  'jair',\n",
              "  'bolsonaro',\n",
              "  '#impeachmentbolsonaro',\n",
              "  '#covid_19',\n",
              "  '#covid‚Ä¶'],\n",
              " ['mulher',\n",
              "  'fan√°tica',\n",
              "  'religiosa,',\n",
              "  'irrespons√°vel',\n",
              "  'ponto',\n",
              "  'defender',\n",
              "  'indefens√°vel',\n",
              "  '#impeachmentbolsonaro‚Ä¶'],\n",
              " ['tr√™s',\n",
              "  'coisas',\n",
              "  'aprendi',\n",
              "  'hoje',\n",
              "  '1',\n",
              "  'segundo',\n",
              "  'ministro',\n",
              "  'educa√ß√£o',\n",
              "  '#cnn',\n",
              "  'pode',\n",
              "  'perguntar',\n",
              "  '‚Äúcombinado‚Äù',\n",
              "  '2‚Ä¶'],\n",
              " ['marta',\n",
              "  'pergunta',\n",
              "  'ser',\n",
              "  'assistente',\n",
              "  'social',\n",
              "  'durante',\n",
              "  'pandemia',\n",
              "  '#covid',\n",
              "  'geane',\n",
              "  'diz',\n",
              "  'ser',\n",
              "  '\"persistente',\n",
              "  'soc‚Ä¶'],\n",
              " ['imagine',\n",
              "  '\"isto\"',\n",
              "  'presidente!',\n",
              "  'üíÄüëé‚ö∞Ô∏èüï≥Ô∏è#china',\n",
              "  '#chinavirus',\n",
              "  '#chinawuhan',\n",
              "  '#wuhanvirus',\n",
              "  '#covid',\n",
              "  '#covid19',\n",
              "  '#corona',\n",
              "  '#coronavirus‚Ä¶'],\n",
              " ['arte',\n",
              "  'disse',\n",
              "  'fazendo',\n",
              "  'maus',\n",
              "  'demora',\n",
              "  'v',\n",
              "  'compartilhem',\n",
              "  'favor!',\n",
              "  '#politica',\n",
              "  '#bolsonaro‚Ä¶'],\n",
              " ['camila',\n",
              "  'pergunta',\n",
              "  'maior',\n",
              "  'dificuldade',\n",
              "  'orienta√ß√£o',\n",
              "  'idosos',\n",
              "  'sobre',\n",
              "  '#covid',\n",
              "  'geane',\n",
              "  'diz',\n",
              "  'que,',\n",
              "  'onde',\n",
              "  'atua,',\n",
              "  'os‚Ä¶'],\n",
              " ['mulherada',\n",
              "  'fiquem',\n",
              "  'esperta,',\n",
              "  'homem',\n",
              "  'tipo',\n",
              "  '#covid',\n",
              "  ',',\n",
              "  'al√©m',\n",
              "  'ti',\n",
              "  't√™m',\n",
              "  '+',\n",
              "  '5',\n",
              "  'casos',\n",
              "  'confirmados',\n",
              "  '+',\n",
              "  '2',\n",
              "  '\"amigas',\n",
              "  'suspeitas\"',\n",
              "  'üôÑüò¨\\U0001f92büòÇ'],\n",
              " ['palabras',\n",
              "  'clave',\n",
              "  'manejar',\n",
              "  'la',\n",
              "  'pandemia',\n",
              "  'testtraceisolate',\n",
              "  '#covid19',\n",
              "  '#sarscov2'],\n",
              " ['anadelma',\n",
              "  'pergunta',\n",
              "  'sobre',\n",
              "  '#covid',\n",
              "  'geane',\n",
              "  'diz',\n",
              "  'todos',\n",
              "  'servi√ßos',\n",
              "  'assist√™ncia',\n",
              "  'social',\n",
              "  'funcionando,',\n",
              "  'com‚Ä¶'],\n",
              " ['defesa',\n",
              "  'civil',\n",
              "  'sg',\n",
              "  'informa',\n",
              "  'atualiza√ß√£o',\n",
              "  'dados',\n",
              "  'nacionais',\n",
              "  'üáßüá∑',\n",
              "  '15/05/20',\n",
              "  '19h',\n",
              "  '#covid',\n",
              "  '#coronavirus'],\n",
              " ['braga',\n",
              "  'neto,',\n",
              "  'mando',\n",
              "  '@jairbolsonaro,',\n",
              "  'dourando',\n",
              "  'n√∫mero',\n",
              "  'mortes',\n",
              "  'gr√°fico',\n",
              "  'log',\n",
              "  'comparado',\n",
              "  'brasil',\n",
              "  'b√©lgica‚Ä¶'],\n",
              " ['momento',\n",
              "  'bra',\n",
              "  '0',\n",
              "  'x',\n",
              "  'cor',\n",
              "  '14817',\n",
              "  'presidente',\n",
              "  'esfor√ßando',\n",
              "  '#bolsonaro',\n",
              "  '#brasil',\n",
              "  '#covid'],\n",
              " ['dias',\n",
              "  'fazer',\n",
              "  'compras',\n",
              "  'dias',\n",
              "  'luta,',\n",
              "  'dias',\n",
              "  'beber',\n",
              "  'dias',\n",
              "  'gl√≥ria!',\n",
              "  '#quarentena',\n",
              "  '#covid19',\n",
              "  '#covid'],\n",
              " ['cara',\n",
              "  'inclui',\n",
              "  'academias',\n",
              "  'gin√°stica,',\n",
              "  'sal√µes',\n",
              "  'beleza',\n",
              "  'barbearias',\n",
              "  'servi√ßos',\n",
              "  'essenciais',\n",
              "  'durante',\n",
              "  'pandemia',\n",
              "  'do‚Ä¶'],\n",
              " ['michele',\n",
              "  'pergunta',\n",
              "  'sobre',\n",
              "  'trabalho',\n",
              "  'idosos',\n",
              "  'durante',\n",
              "  'pandemia',\n",
              "  '#covid',\n",
              "  'geane',\n",
              "  'responde',\n",
              "  'acompanhamento‚Ä¶'],\n",
              " ['distantes,',\n",
              "  'sido',\n",
              "  'incr√≠vel!!',\n",
              "  'digitalizar',\n",
              "  'aproximar',\n",
              "  '#orgulhoempertencer',\n",
              "  '#timegrande',\n",
              "  '#jur√≠dico‚Ä¶'],\n",
              " ['rindo',\n",
              "  'pra',\n",
              "  'chorar',\n",
              "  'üòÇüò≠',\n",
              "  'moro',\n",
              "  'aconselhando',\n",
              "  '#teich',\n",
              "  '#cloroquina',\n",
              "  '#coronavirus',\n",
              "  '#covidiotas‚Ä¶'],\n",
              " ['geane',\n",
              "  'diz',\n",
              "  'que,',\n",
              "  'idoso',\n",
              "  'mora',\n",
              "  'sozinho,',\n",
              "  'antes',\n",
              "  '#covid,',\n",
              "  'orienta√ß√£o',\n",
              "  'ter',\n",
              "  'rede',\n",
              "  'prote√ß√£o',\n",
              "  'conta‚Ä¶'],\n",
              " ['enquanto',\n",
              "  'gente',\n",
              "  'assiste',\n",
              "  'dan√ßa',\n",
              "  'cadeiras',\n",
              "  'governo,',\n",
              "  'pov√£o',\n",
              "  'continua',\n",
              "  'pagando',\n",
              "  'conta',\n",
              "  '#covid',\n",
              "  'aumentando‚Ä¶'],\n",
              " ['presidente',\n",
              "  'conselho',\n",
              "  'sa√∫de',\n",
              "  'roraima',\n",
              "  'afirmou',\n",
              "  'hospital',\n",
              "  'ventiladores',\n",
              "  'renovar',\n",
              "  'ar',\n",
              "  'hospi‚Ä¶'],\n",
              " ['pergunto',\n",
              "  'geane',\n",
              "  'sobre',\n",
              "  'orienta√ß√µes',\n",
              "  'idosos',\n",
              "  'durante',\n",
              "  'pandemia',\n",
              "  '#covid',\n",
              "  'diz',\n",
              "  'comunidades',\n",
              "  'id‚Ä¶'],\n",
              " ['@fasalles',\n",
              "  '@edgaarcia',\n",
              "  'esquerdistas',\n",
              "  'podem',\n",
              "  'usar',\n",
              "  'maconha',\n",
              "  'globo',\n",
              "  'disse',\n",
              "  'eficiente',\n",
              "  'combate',\n",
              "  '#covid',\n",
              "  'po‚Ä¶'],\n",
              " ['reuni√£o',\n",
              "  'semanal',\n",
              "  'projeto',\n",
              "  'gradua√ß√£o',\n",
              "  'engenharia',\n",
              "  'qu√≠mica',\n",
              "  '!',\n",
              "  '#jitsi',\n",
              "  '#reuniao',\n",
              "  '#fiqueemcasa',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['coisa',\n",
              "  'surreal',\n",
              "  'tentar',\n",
              "  'argumentar',\n",
              "  'contra',\n",
              "  'isolamento',\n",
              "  'cuidados',\n",
              "  're',\n",
              "  '#covid',\n",
              "  'comparando',\n",
              "  'mortes',\n",
              "  'de‚Ä¶'],\n",
              " ['colocar',\n",
              "  'militar',\n",
              "  'justificar',\n",
              "  'mortes',\n",
              "  '#covid19',\n",
              "  'comparandoas',\n",
              "  'n√∫mero',\n",
              "  'mortes',\n",
              "  'conta',\n",
              "  'outra‚Ä¶'],\n",
              " ['vai',\n",
              "  'gerar',\n",
              "  'fome,',\n",
              "  'pobreza',\n",
              "  'tudo',\n",
              "  '@govbr',\n",
              "  '#forabolsonarourgente',\n",
              "  'economia',\n",
              "  't√°',\n",
              "  'afundada',\n",
              "  'pa√≠s‚Ä¶'],\n",
              " ['skate',\n",
              "  'park',\n",
              "  'tempos',\n",
              "  'pandemia',\n",
              "  'licita√ß√£o?',\n",
              "  'modalidade?',\n",
              "  '@tcuoficial',\n",
              "  'entendimento',\n",
              "  'consolidado‚Ä¶'],\n",
              " ['üÜï',\n",
              "  '‚òÖfumigadora',\n",
              "  'astarsa',\n",
              "  'aa33‚òÖ',\n",
              "  '‚òé',\n",
              "  '+54',\n",
              "  '11',\n",
              "  '52635610',\n",
              "  'int',\n",
              "  '206',\n",
              "  'üì≤+54',\n",
              "  '9',\n",
              "  '3512023508',\n",
              "  'consultas@corvialcomar',\n",
              "  '#corvial‚Ä¶'],\n",
              " ['uso',\n",
              "  '#hidroxicloroquina',\n",
              "  'tratamento',\n",
              "  '#covid_19',\n",
              "  'estudo',\n",
              "  'washington',\n",
              "  'university',\n",
              "  'mostra',\n",
              "  'brasil',\n",
              "  'podem',\n",
              "  'mor‚Ä¶'],\n",
              " ['vamos',\n",
              "  'desesperardeus',\n",
              "  'controle',\n",
              "  'tudotenhamos',\n",
              "  'f√©',\n",
              "  '#coronavirus',\n",
              "  '#covid19',\n",
              "  '#esperanca‚Ä¶'],\n",
              " ['covid19',\n",
              "  'm√°rcio',\n",
              "  'ara√∫jo',\n",
              "  'recebe',\n",
              "  'alta',\n",
              "  'ap√≥s',\n",
              "  'quatro',\n",
              "  'dias',\n",
              "  'uti',\n",
              "  '#covid',\n",
              "  '#esportes'],\n",
              " ['parab√©ns',\n",
              "  'exministro',\n",
              "  '@teichnelson',\n",
              "  'ter',\n",
              "  'escolhido',\n",
              "  'princ√≠pios',\n",
              "  'detrimento',\n",
              "  'corja',\n",
              "  'quer',\n",
              "  'comprometer',\n",
              "  'todos‚Ä¶'],\n",
              " ['hoje',\n",
              "  'vivemos',\n",
              "  'caos',\n",
              "  'estrutura',\n",
              "  'sa√∫de?',\n",
              "  'hoje?',\n",
              "  'hoje',\n",
              "  'n√£o!',\n",
              "  'faz',\n",
              "  'algum',\n",
              "  'tempo',\n",
              "  'sa√∫de',\n",
              "  'renegada',\n",
              "  'a‚Ä¶'],\n",
              " ['amanh√£',\n",
              "  'hein',\n",
              "  'vai',\n",
              "  'perder',\n",
              "  '#covid',\n",
              "  '#dianacionaldecombateahomofobia',\n",
              "  '#coronavirus',\n",
              "  '#amor',\n",
              "  '#webserielgbt‚Ä¶'],\n",
              " ['vivo',\n",
              "  '#conectadocomramalha',\n",
              "  'hoje,',\n",
              "  'convidada',\n",
              "  'geane',\n",
              "  'souza,',\n",
              "  '√©‚Ä¶'],\n",
              " ['nesta',\n",
              "  'sextafeira',\n",
              "  '(15,',\n",
              "  'boletim',\n",
              "  'epidemiol√≥gico',\n",
              "  'registra',\n",
              "  '√≥bito',\n",
              "  'homem,',\n",
              "  'v√≠tima',\n",
              "  'covid19',\n",
              "  '26',\n",
              "  'an‚Ä¶'],\n",
              " ['acabou',\n",
              "  'acontecer',\n",
              "  'natal',\n",
              "  'homem',\n",
              "  'quer',\n",
              "  'bruno',\n",
              "  'nogueira',\n",
              "  'passou',\n",
              "  'duas',\n",
              "  'vezes',\n",
              "  'rua',\n",
              "  '#lisboa‚Ä¶'],\n",
              " ['assist√™ncia',\n",
              "  '#enfermagem',\n",
              "  'uti',\n",
              "  'pacientes',\n",
              "  '#covid19',\n",
              "  'tema',\n",
              "  'palestra',\n",
              "  'ministrada',\n",
              "  'noite',\n",
              "  'hoje',\n",
              "  'pel‚Ä¶'],\n",
              " ['mostrem',\n",
              "  'pa√≠s',\n",
              "  'descente,',\n",
              "  '2',\n",
              "  'meses',\n",
              "  'estado',\n",
              "  'emergencia,',\n",
              "  'devido',\n",
              "  'pandemia',\n",
              "  '#covid,',\n",
              "  'perde',\n",
              "  'minist‚Ä¶'],\n",
              " ['n√∫meros',\n",
              "  'casos',\n",
              "  'confirmados',\n",
              "  'covid19',\n",
              "  'cana√£',\n",
              "  'caraj√°s',\n",
              "  'aumentando',\n",
              "  'cada',\n",
              "  'dia',\n",
              "  '#voceinformado‚Ä¶'],\n",
              " ['hospital',\n",
              "  'campanha',\n",
              "  'pronto',\n",
              "  'aqui',\n",
              "  'boa',\n",
              "  'vista',\n",
              "  'por√©m',\n",
              "  'm√£o',\n",
              "  'obra!',\n",
              "  'm√©dicos',\n",
              "  'um‚Ä¶'],\n",
              " ['contagem', 'confirma', 'duas', 'mortes', '#covid19', '#coronav√≠rusmg'],\n",
              " ['contagem', 'confirma', 'duas', 'mortes', '#covid19', '#coronav√≠rusmg'],\n",
              " ['2',\n",
              "  'mil',\n",
              "  'sergipanos',\n",
              "  'contaminados',\n",
              "  'coronav√≠rus,',\n",
              "  'empres√°rios',\n",
              "  'mostram',\n",
              "  'desd√©m',\n",
              "  'vida',\n",
              "  'trabalhadore‚Ä¶'],\n",
              " ['filho',\n",
              "  'ambuzando',\n",
              "  'pai',\n",
              "  'enquanto',\n",
              "  'espera',\n",
              "  'ventilador',\n",
              "  'todo',\n",
              "  'dia',\n",
              "  'choro',\n",
              "  'pouquinho',\n",
              "  '#covid'],\n",
              " ['acabamos',\n",
              "  'atualizar',\n",
              "  'dados',\n",
              "  '#siglitoral',\n",
              "  'ufrgs',\n",
              "  'hoje',\n",
              "  'maior',\n",
              "  'alta',\n",
              "  'novos',\n",
              "  'casos',\n",
              "  'registrados',\n",
              "  'rs',\n",
              "  '60‚Ä¶'],\n",
              " ['preocupados',\n",
              "  '#covid',\n",
              "  'manos',\n",
              "  'fazer',\n",
              "  'penteados',\n",
              "  'pra',\n",
              "  'estrear',\n",
              "  'casa',\n",
              "  'üò£üò£üò£',\n",
              "  't√°',\n",
              "  'bom',\n",
              "  'tamb√©m,',\n",
              "  't‚Ä¶'],\n",
              " ['sobre',\n",
              "  'pol√≠tica,',\n",
              "  'falando',\n",
              "  'vidas',\n",
              "  'antes',\n",
              "  'tudo',\n",
              "  'pense',\n",
              "  '14',\n",
              "  'mil',\n",
              "  'pessoas',\n",
              "  'vieram',\n",
              "  '√≥bito',\n",
              "  's‚Ä¶'],\n",
              " ['@srlm',\n",
              "  'silvio,',\n",
              "  'viu',\n",
              "  'uk',\n",
              "  '#fakenews',\n",
              "  'relaciona',\n",
              "  '5g',\n",
              "  '#covid',\n",
              "  '(!!!!',\n",
              "  'levando',\n",
              "  'pessoas',\n",
              "  'atacar',\n",
              "  'equipamen‚Ä¶'],\n",
              " ['@lucianohuck',\n",
              "  '#ditadoria',\n",
              "  'sobre',\n",
              "  '#covid',\n",
              "  'carnaval',\n",
              "  'cr√°pula,',\n",
              "  'sr',\n",
              "  '@lucianohuck‚Ä¶'],\n",
              " ['objetivo',\n",
              "  'salvar',\n",
              "  'vidas!',\n",
              "  'chega',\n",
              "  'politizar',\n",
              "  'v√≠rus',\n",
              "  '‚Ä¢',\n",
              "  '@biakicis',\n",
              "  '‚Ä¢',\n",
              "  '#cloroquina',\n",
              "  '#hospitaisprivados‚Ä¶'],\n",
              " ['ministro',\n",
              "  'sa√∫de',\n",
              "  'pediu',\n",
              "  'demiss√£o',\n",
              "  '#covid',\n",
              "  '@miltonneves',\n",
              "  '@leojaime',\n",
              "  '@danilogentili'],\n",
              " ['braga',\n",
              "  'dst',\n",
              "  'contratou',\n",
              "  '158',\n",
              "  'trabalhdores',\n",
              "  'durante',\n",
              "  'pandemia',\n",
              "  '#braga',\n",
              "  '#covid19',\n",
              "  '#dst'],\n",
              " ['marcos',\n",
              "  'pontes',\n",
              "  'visita',\n",
              "  'linha',\n",
              "  'montagem',\n",
              "  'ventiladores',\n",
              "  'pulmonares',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid'],\n",
              " ['sensa√ß√µes',\n",
              "  'paga',\n",
              "  'pode',\n",
              "  'sentir',\n",
              "  't√°',\n",
              "  'afim',\n",
              "  'pagar',\n",
              "  'pra',\n",
              "  'v√™?',\n",
              "  'ent√£o',\n",
              "  'agende',\n",
              "  'hor√°rio!',\n",
              "  'sinta',\n",
              "  'prazer',\n",
              "  'nessa',\n",
              "  'qua‚Ä¶'],\n",
              " ['plano',\n",
              "  'fuga?',\n",
              "  'melhor',\n",
              "  't√°',\n",
              "  'tendo',\n",
              "  'pra',\n",
              "  'entra',\n",
              "  'ali',\n",
              "  '#coronavirusplantao',\n",
              "  '#coronavirus',\n",
              "  '#coronaviruspandemic‚Ä¶'],\n",
              " ['\"quando',\n",
              "  'cabe√ßa',\n",
              "  'pensa,',\n",
              "  'corpo',\n",
              "  'padece\"',\n",
              "  '(ditado',\n",
              "  'av√≥',\n",
              "  '#coronavirusplantao',\n",
              "  '#covidiots',\n",
              "  '#coronavirus‚Ä¶'],\n",
              " ['brasil‚è¨',\n",
              "  '#fiqueemcasa',\n",
              "  '#ficaemcasa',\n",
              "  '#covid„Éº19',\n",
              "  '#coronavirusnobrasil',\n",
              "  '#coronavirus',\n",
              "  '#covid__19',\n",
              "  '#covid',\n",
              "  '#covid19',\n",
              "  '#brasil',\n",
              "  'b‚Ä¶'],\n",
              " ['relat√≥rio',\n",
              "  'semestral',\n",
              "  'sobre',\n",
              "  'regi√£o',\n",
              "  'am√©rica',\n",
              "  'latina',\n",
              "  'caribe',\n",
              "  'economia',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  '#economia‚Ä¶'],\n",
              " ['ter√ßafeira,',\n",
              "  '12/05,',\n",
              "  'riogale√£o',\n",
              "  'cargo',\n",
              "  'recebeu',\n",
              "  '1¬∫',\n",
              "  '6',\n",
              "  'voos',\n",
              "  'transportando',\n",
              "  'respiradores',\n",
              "  'equipamentos',\n",
              "  'm√©dicos',\n",
              "  'q‚Ä¶'],\n",
              " ['hj',\n",
              "  'not√≠cia',\n",
              "  'amigo',\n",
              "  '@edvaldonogueira',\n",
              "  'testou',\n",
              "  'positivo',\n",
              "  'p/',\n",
              "  '#covid',\n",
              "  'conhecer',\n",
              "  'garra',\n",
              "  'comprometimen‚Ä¶'],\n",
              " ['solidariedade',\n",
              "  'familiares,',\n",
              "  'amigas',\n",
              "  'amigos',\n",
              "  'rodolfo,',\n",
              "  'adufes',\n",
              "  'reitera',\n",
              "  'posi√ß√£o',\n",
              "  'afirmativa',\n",
              "  'prote√ß√£o',\n",
              "  'i‚Ä¶'],\n",
              " ['munic√≠pio',\n",
              "  'confirmou',\n",
              "  '√≥bito',\n",
              "  'paciente',\n",
              "  '68',\n",
              "  'anos,',\n",
              "  'moradora',\n",
              "  'bairro',\n",
              "  'retiro,',\n",
              "  'internada',\n",
              "  'hac',\n",
              "  'de‚Ä¶'],\n",
              " ['#covid',\n",
              "  '\\U0001f9a0',\n",
              "  '#brasil',\n",
              "  'sexta,',\n",
              "  '15',\n",
              "  'maio',\n",
              "  '2020',\n",
              "  '‚§µÔ∏è',\n",
              "  '‚ñ∂Ô∏è218223',\n",
              "  'casos',\n",
              "  '‚ñ∂Ô∏è14817',\n",
              "  '√≥bitos',\n",
              "  '#rn',\n",
              "  'üò∑',\n",
              "  '‚è∫',\n",
              "  '2786',\n",
              "  '#casos',\n",
              "  '‚è∫‚Ä¶'],\n",
              " ['aulas',\n",
              "  'online',\n",
              "  'seguem',\n",
              "  'firme',\n",
              "  'duas',\n",
              "  'novas',\n",
              "  'alunas',\n",
              "  'encararam',\n",
              "  'desafio',\n",
              "  'plena',\n",
              "  'pandemia!',\n",
              "  'assim',\n",
              "  'seguimos',\n",
              "  'vencendo',\n",
              "  'nossa‚Ä¶'],\n",
              " ['infelizmente',\n",
              "  'carro√ßa',\n",
              "  'brasil',\n",
              "  'burro',\n",
              "  'dianteira!!!',\n",
              "  '#bolsonarorainhalouca',\n",
              "  '#bolsonaroassassino‚Ä¶'],\n",
              " ['t√©nis', 'prolonga', 'suspens√£o', '31', 'julho', '#covid19', '#t√©nis'],\n",
              " ['sporting',\n",
              "  'prolonga',\n",
              "  '‚Äòlayoff‚Äô',\n",
              "  '30',\n",
              "  'dias',\n",
              "  '#covid19',\n",
              "  '#futebol',\n",
              "  '#iliga'],\n",
              " ['pandemia',\n",
              "  'vai',\n",
              "  '‚Äúrecentrar',\n",
              "  'posi√ß√£o',\n",
              "  'adepto‚Äù',\n",
              "  'futebol',\n",
              "  '#covid19',\n",
              "  '#futebol'],\n",
              " ['@cesargomes23',\n",
              "  '@gugachacra',\n",
              "  'vai',\n",
              "  'pra',\n",
              "  'rua!',\n",
              "  'sabe',\n",
              "  'vc',\n",
              "  'pega',\n",
              "  '#covid',\n",
              "  'a√≠',\n",
              "  'ficar',\n",
              "  '100%',\n",
              "  'morto',\n",
              "  'calado,',\n",
              "  'ningu√©m',\n",
              "  'a‚Ä¶'],\n",
              " ['83',\n",
              "  'mortes',\n",
              "  'dia',\n",
              "  'hoje',\n",
              "  '(15/05/2020',\n",
              "  'estado',\n",
              "  'pernambuco',\n",
              "  'üò≠',\n",
              "  'ainda',\n",
              "  'dizem',\n",
              "  'lockdow',\n",
              "  'necess√°ri‚Ä¶'],\n",
              " ['dia',\n",
              "  '30/03/2020',\n",
              "  'it√°lia',\n",
              "  '100000',\n",
              "  'casos',\n",
              "  'covid',\n",
              "  'br',\n",
              "  'debochava',\n",
              "  'apenas',\n",
              "  '4,500',\n",
              "  'casos',\n",
              "  'amanh√£',\n",
              "  'dia',\n",
              "  '16/05/2020',\n",
              "  'o‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'brasil',\n",
              "  'bate',\n",
              "  'recorde',\n",
              "  'registra',\n",
              "  '15,3',\n",
              "  'mil',\n",
              "  'casos',\n",
              "  'dia',\n",
              "  'outras',\n",
              "  '824',\n",
              "  'mortes',\n",
              "  'inclu√≠das‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'brasil',\n",
              "  'bate',\n",
              "  'recorde',\n",
              "  'registra',\n",
              "  '15,3',\n",
              "  'mil',\n",
              "  'casos',\n",
              "  'dia',\n",
              "  'outras',\n",
              "  '824',\n",
              "  'mortes',\n",
              "  'inclu√≠das‚Ä¶'],\n",
              " ['governo',\n",
              "  'prop√µe',\n",
              "  'prolongamento',\n",
              "  '01',\n",
              "  'setembro',\n",
              "  'empr√©stimos',\n",
              "  'rendas',\n",
              "  '#covid19',\n",
              "  '#economia',\n",
              "  '#habita√ß√£o'],\n",
              " ['feiras',\n",
              "  'mercados',\n",
              "  'reabrem',\n",
              "  'segundafeira',\n",
              "  'plano',\n",
              "  'conting√™ncia',\n",
              "  '#covid19',\n",
              "  '#economia',\n",
              "  '#feiras'],\n",
              " ['dr',\n",
              "  'rey',\n",
              "  'minist√©rio',\n",
              "  'sa√∫de?',\n",
              "  'menos',\n",
              "  'engra√ßado',\n",
              "  'certamente',\n",
              "  'iria',\n",
              "  'usar',\n",
              "  'terno',\n",
              "  'aberto,',\n",
              "  'camisa',\n",
              "  'co‚Ä¶'],\n",
              " ['caminha',\n",
              "  'vai',\n",
              "  'ter',\n",
              "  'equipas',\n",
              "  'aconselhamento',\n",
              "  'cada',\n",
              "  'praia',\n",
              "  '#caminha',\n",
              "  '#covid19',\n",
              "  '#praia'],\n",
              " ['telesus',\n",
              "  'criado',\n",
              "  'aproximar',\n",
              "  'minist√©rio',\n",
              "  'sa√∫de',\n",
              "  'modo',\n",
              "  'combate',\n",
              "  'coronav√≠rus',\n",
              "  'faci‚Ä¶'],\n",
              " ['gente',\n",
              "  'moro',\n",
              "  'perdeu',\n",
              "  'tempo!',\n",
              "  '#nelsonteich',\n",
              "  '#covid',\n",
              "  '#moro',\n",
              "  '#estoufechadocombolsonaro'],\n",
              " ['pois',\n",
              "  'china',\n",
              "  'criou',\n",
              "  'doen√ßa',\n",
              "  'poder',\n",
              "  'vender',\n",
              "  'vacinas',\n",
              "  'podemos',\n",
              "  'deixar',\n",
              "  'guerreiro',\n",
              "  'brasileiro,',\n",
              "  'negr‚Ä¶'],\n",
              " ['aten√ß√£o,',\n",
              "  'veja',\n",
              "  'pagamento',\n",
              "  '2¬™',\n",
              "  'parcela',\n",
              "  'aux√≠lio',\n",
              "  'emergencial',\n",
              "  '#coronavirus',\n",
              "  '#covid_19',\n",
              "  '#covid‚Ä¶'],\n",
              " ['amanh√£',\n",
              "  'estado',\n",
              "  'pernambuco',\n",
              "  'estar√°',\n",
              "  'lockdown',\n",
              "  'queremos',\n",
              "  'pedir',\n",
              "  'todos',\n",
              "  'respeitem',\n",
              "  'orienta√ß√µes,',\n",
              "  'conforme',\n",
              "  'i‚Ä¶'],\n",
              " ['falta',\n",
              "  'representatividade',\n",
              "  'poder',\n",
              "  'd√°',\n",
              "  'nisso',\n",
              "  'completo',\n",
              "  'desconhecimento',\n",
              "  'realidade',\n",
              "  'pa√≠s',\n",
              "  '(ou',\n",
              "  'm√°',\n",
              "  'f√©',\n",
              "  'mesmo,',\n",
              "  'pe‚Ä¶'],\n",
              " ['gente',\n",
              "  'sexta',\n",
              "  'casa!!',\n",
              "  '#40tena',\n",
              "  '#coronga',\n",
              "  '#covid',\n",
              "  '#sextou',\n",
              "  '#rebola',\n",
              "  '#instabola',\n",
              "  '#bolarebola',\n",
              "  '#tremetreme‚Ä¶'],\n",
              " ['cloroquina',\n",
              "  'jesuis',\n",
              "  'tiririca',\n",
              "  'ministro',\n",
              "  'sa√∫de',\n",
              "  'salva√ß√£o',\n",
              "  'pior',\n",
              "  't√°',\n",
              "  'fica!',\n",
              "  '#brasil',\n",
              "  '#teich',\n",
              "  '#mandetta‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'vagas',\n",
              "  'emprego',\n",
              "  'hospital',\n",
              "  'regional',\n",
              "  'guarapuava/pr',\n",
              "  '|',\n",
              "  'jnot√≠cias'],\n",
              " ['insista',\n",
              "  'm√©dico',\n",
              "  'prescrever',\n",
              "  'medicamentos,',\n",
              "  'sabe',\n",
              "  'melhor',\n",
              "  'tome',\n",
              "  '#cloroquina',\n",
              "  'c‚Ä¶'],\n",
              " ['partir',\n",
              "  '19',\n",
              "  'maio,',\n",
              "  'macap√°',\n",
              "  'entrar√°',\n",
              "  'isolamento',\n",
              "  'social',\n",
              "  'r√≠gido',\n",
              "  'combater',\n",
              "  'cont√°gio',\n",
              "  'corona',\n",
              "  'v√≠rus‚Ä¶'],\n",
              " ['‚Äúbrasil',\n",
              "  '14817',\n",
              "  'mortes',\n",
              "  '218223',\n",
              "  'casos',\n",
              "  'confirmados',\n",
              "  'novo',\n",
              "  'coronav√≠rus,',\n",
              "  'diz',\n",
              "  'minist√©rio‚Äù',\n",
              "  '#coronavirus',\n",
              "  '#covid‚Ä¶'],\n",
              " ['@xicograziano',\n",
              "  'onde',\n",
              "  'est√°?',\n",
              "  'acaba',\n",
              "  'pandemia',\n",
              "  'gastan√ßa',\n",
              "  'dinheiro',\n",
              "  'federal',\n",
              "  'licita√ß√£o,',\n",
              "  'economia',\n",
              "  'volta‚Ä¶'],\n",
              " ['disse',\n",
              "  '@luizbacci',\n",
              "  '\"',\n",
              "  'favor',\n",
              "  'isolamento',\n",
              "  'social',\n",
              "  'condi√ß√µes\"',\n",
              "  'adianta',\n",
              "  'querer',\n",
              "  'travar',\n",
              "  'qu‚Ä¶'],\n",
              " ['acho',\n",
              "  'trump',\n",
              "  'method',\n",
              "  'similar',\n",
              "  'm√©todo',\n",
              "  'bolsonaro',\n",
              "  '#forabolsonaro',\n",
              "  '#ci√™ncia',\n",
              "  '#m√©todocientifico',\n",
              "  '#covid'],\n",
              " ['ainda',\n",
              "  'esperan√ßa!',\n",
              "  'recife',\n",
              "  'come√ßa',\n",
              "  'reagir',\n",
              "  'contra',\n",
              "  'governador',\n",
              "  'paulo',\n",
              "  'c√¢mara',\n",
              "  'pernambuco',\n",
              "  'come√ßa',\n",
              "  'reagir',\n",
              "  'sob‚Ä¶'],\n",
              " ['fique',\n",
              "  'casa',\n",
              "  'promo√ß√£o',\n",
              "  'artes',\n",
              "  'divulga√ß√£o',\n",
              "  'produtos#bbb20',\n",
              "  '#redebbb',\n",
              "  '#perguntacorona',\n",
              "  '#globo',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['8/365',\n",
              "  '(sem',\n",
              "  'legenda',\n",
              "  '#illustration',\n",
              "  '#drawing',\n",
              "  '#bolsonaro',\n",
              "  '#covid',\n",
              "  '#digitalart'],\n",
              " ['filmes',\n",
              "  'gospel',\n",
              "  'beb√™',\n",
              "  'outubro',\n",
              "  'link',\n",
              "  'ap√≥s',\n",
              "  'ir',\n",
              "  'parar',\n",
              "  'hospital',\n",
              "  's√©rios',\n",
              "  'problemas',\n",
              "  's‚Ä¶'],\n",
              " ['ministro',\n",
              "  'educa√ß√£o',\n",
              "  'explicando',\n",
              "  'meritocracia',\n",
              "  '‚Äú',\n",
              "  '@proenemoficial',\n",
              "  'resolver',\n",
              "  'problema',\n",
              "  'social,',\n",
              "  'escolh‚Ä¶'],\n",
              " ['sindicato',\n",
              "  'm√©dicos',\n",
              "  '#cear√°',\n",
              "  'denuncia',\n",
              "  'press√£o',\n",
              "  'atestar',\n",
              "  '#covid',\n",
              "  '√≥bitos'],\n",
              " ['casos',\n",
              "  '#covid',\n",
              "  '#guarulhos',\n",
              "  'chegam',\n",
              "  '1426,',\n",
              "  '160',\n",
              "  'mortes',\n",
              "  'fonte',\n",
              "  'seade,',\n",
              "  '15/05',\n",
              "  '1400'],\n",
              " ['caos,',\n",
              "  'resumindo',\n",
              "  'mitologia',\n",
              "  'grega',\n",
              "  'origem',\n",
              "  'palavra',\n",
              "  'come√ßo',\n",
              "  'fim',\n",
              "  'tudo',\n",
              "  'separa√ß√£o,',\n",
              "  'abismo',\n",
              "  'que‚Ä¶'],\n",
              " ['presidente',\n",
              "  'chin√™ses,',\n",
              "  'xi',\n",
              "  'jinping,',\n",
              "  'sabe',\n",
              "  'quanto',\n",
              "  'perigoso',\n",
              "  'conter',\n",
              "  'covid19,',\n",
              "  'respons√°vel',\n",
              "  'milh‚Ä¶'],\n",
              " ['not√≠cias',\n",
              "  'dia!',\n",
              "  '#lockdown',\n",
              "  'prorrogado',\n",
              "  'par√°!',\n",
              "  'an√∫ncio',\n",
              "  'feito',\n",
              "  'governador',\n",
              "  '@helderbarbalho',\n",
              "  '#noticias‚Ä¶'],\n",
              " ['objetivo',\n",
              "  'controlar',\n",
              "  'pandemia,',\n",
              "  'liberado,',\n",
              "  'minist√©rio',\n",
              "  'sa√∫de,',\n",
              "  'telemedicinaüë©üî¨üë®üî¨üë©üíªüë®üíª',\n",
              "  '‚†Ä',\n",
              "  'üë®üíª',\n",
              "  'mark‚Ä¶'],\n",
              " ['nojo',\n",
              "  'dessa',\n",
              "  '#damares',\n",
              "  '#foraguedes',\n",
              "  '#impeachmentdobolsonarourgente',\n",
              "  '#forabraganetto',\n",
              "  '#foraosmarterra‚Ä¶'],\n",
              " ['usar',\n",
              "  'm√°scaras',\n",
              "  'ajuda',\n",
              "  'estimular',\n",
              "  'contato',\n",
              "  'olho',\n",
              "  'olho,',\n",
              "  'pode',\n",
              "  'ser',\n",
              "  'bom',\n",
              "  'rela√ß√µes',\n",
              "  'humanas',\n",
              "  'pois',\n",
              "  'olhar‚Ä¶'],\n",
              " ['dia',\n",
              "  'ministro',\n",
              "  'sa√∫de',\n",
              "  'alertar',\n",
              "  'efeitos',\n",
              "  'colaterais,',\n",
              "  'presidente',\n",
              "  'quer',\n",
              "  'rem√©dio',\n",
              "  'usado',\n",
              "  'paci‚Ä¶'],\n",
              " ['assistindo',\n",
              "  'trecho',\n",
              "  'titanic',\n",
              "  'tv',\n",
              "  'fez',\n",
              "  'lembrar',\n",
              "  'sensa√ß√£o',\n",
              "  'ler',\n",
              "  'not√≠cias',\n",
              "  'brasil!',\n",
              "  '#tenso‚Ä¶'],\n",
              " ['maldito',\n",
              "  'ta',\n",
              "  'fazendo',\n",
              "  '#terrorismo',\n",
              "  '#osmarterraterrorista',\n",
              "  '#covid',\n",
              "  '#forabolsonaro',\n",
              "  '#impeachmentbolsonarourgente'],\n",
              " ['bolsonaro',\n",
              "  'manda',\n",
              "  'general',\n",
              "  'assinar',\n",
              "  'decreto',\n",
              "  'libera√ß√£o',\n",
              "  'cloroquina',\n",
              "  '#jairbolsonaro',\n",
              "  '#bolsonaro',\n",
              "  '#cloroquina',\n",
              "  '#stf‚Ä¶'],\n",
              " ['jap√£o',\n",
              "  'inicia',\n",
              "  'fornecimento',\n",
              "  'antiviral',\n",
              "  'tratar',\n",
              "  'pacientes',\n",
              "  '#covid19',\n",
              "  '#doenca',\n",
              "  '#saude',\n",
              "  '#coronavirus'],\n",
              " ['aguento',\n",
              "  'discutir',\n",
              "  'sobre',\n",
              "  '#desgoverno',\n",
              "  'sobre',\n",
              "  '#covid',\n",
              "  'tentar',\n",
              "  'colocar',\n",
              "  'pouco',\n",
              "  'humanidade',\n",
              "  'cora‚Ä¶'],\n",
              " ['respiradores',\n",
              "  'montes',\n",
              "  'jogados',\n",
              "  'canto',\n",
              "  'desse',\n",
              "  'brasilz√£o',\n",
              "  'futuro',\n",
              "  'distantesim',\n",
              "  'certeza?',\n",
              "  '#covid',\n",
              "  'üáßüá∑'],\n",
              " ['dia',\n",
              "  'seguinte',\n",
              "  'rio',\n",
              "  'bate',\n",
              "  'novo',\n",
              "  'recorde',\n",
              "  'mortes',\n",
              "  '#covid',\n",
              "  ',',\n",
              "  'governador',\n",
              "  '@wilsonwitzel',\n",
              "  'comanda',\n",
              "  'mega‚Ä¶'],\n",
              " ['futuro', 'prossimo', '#covid', '#delazione', '@kevinjames', '#short'],\n",
              " ['campina',\n",
              "  'grande',\n",
              "  '101',\n",
              "  'novos',\n",
              "  'casos',\n",
              "  'positivos',\n",
              "  'pra',\n",
              "  'covid19',\n",
              "  'dia!',\n",
              "  'cidade',\n",
              "  'saiu',\n",
              "  '160',\n",
              "  'casos',\n",
              "  '261',\n",
              "  'result‚Ä¶'],\n",
              " ['vamos',\n",
              "  'falar',\n",
              "  'sobre',\n",
              "  '#recupera√ß√£ojudicial',\n",
              "  'raz√£o',\n",
              "  '#covid19?',\n",
              "  'acessar',\n",
              "  'artigos,',\n",
              "  'acessem',\n",
              "  'sit‚Ä¶'],\n",
              " ['fique',\n",
              "  'casa',\n",
              "  'promo√ß√£o',\n",
              "  'artes',\n",
              "  'divulga√ß√£o',\n",
              "  'produtos#bbb20',\n",
              "  '#redebbb',\n",
              "  '#perguntacorona',\n",
              "  '#globo',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['recurso',\n",
              "  'conta!!',\n",
              "  'parab√©ns',\n",
              "  'bancada',\n",
              "  'federal',\n",
              "  'amap√°',\n",
              "  'trabalhado',\n",
              "  'incansavelmente',\n",
              "  'conseguir',\n",
              "  'recursos',\n",
              "  'p‚Ä¶'],\n",
              " ['confira',\n",
              "  'n√∫meros',\n",
              "  'pandemia',\n",
              "  'covid19',\n",
              "  'brasil',\n",
              "  'mundo',\n",
              "  'hoje',\n",
              "  '(15/05',\n",
              "  'boletim',\n",
              "  'cognys',\n",
              "  'desta',\n",
              "  'semana',\n",
              "  '‚†Ä‚Ä¶'],\n",
              " ['fossemos',\n",
              "  'prever',\n",
              "  'situa√ß√£o',\n",
              "  'casos',\n",
              "  '#covid',\n",
              "  '#novaigua√ßu',\n",
              "  'seria?'],\n",
              " ['pa√≠s',\n",
              "  'mortes',\n",
              "  'pandemia',\n",
              "  '#covid19,',\n",
              "  'eua',\n",
              "  'reabrir√£o',\n",
              "  'economia',\n",
              "  'trump',\n",
              "  '‚Äúest√°',\n",
              "  'tentando',\n",
              "  'for√ßar',\n",
              "  'economi‚Ä¶'],\n",
              " ['#mec',\n",
              "  'prorroga',\n",
              "  'autoriza√ß√£o',\n",
              "  'cursos',\n",
              "  'dist√¢ncia',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid'],\n",
              " ['#covid19',\n",
              "  '|',\n",
              "  'acompanhe',\n",
              "  'evolu√ß√£o',\n",
              "  'doen√ßa',\n",
              "  'munic√≠pio',\n",
              "  '#sigacariacica',\n",
              "  '#fiqueemcasa',\n",
              "  '#fiqueemcasaparasalvarvidas‚Ä¶'],\n",
              " ['primeira',\n",
              "  'mentira',\n",
              "  'toda',\n",
              "  'verdade',\n",
              "  'vira',\n",
              "  'd√∫vida',\n",
              "  '#coronavirus',\n",
              "  '#covid__19',\n",
              "  '#covid',\n",
              "  '#goiania',\n",
              "  '#brasil',\n",
              "  '#kuwait',\n",
              "  '#lebanon',\n",
              "  '#curfew',\n",
              "  '#you'],\n",
              " ['passe',\n",
              "  'm√°gica',\n",
              "  'torna',\n",
              "  'melhor',\n",
              "  'm√©dico',\n",
              "  'mundo,',\n",
              "  'equilibrado,',\n",
              "  'coerente',\n",
              "  's√©rio,',\n",
              "  'mostra',\n",
              "  'q',\n",
              "  'raiva',\n",
              "  's√≥‚Ä¶'],\n",
              " ['ministro',\n",
              "  'paulo',\n",
              "  'guedes',\n",
              "  'acha',\n",
              "  'tirando',\n",
              "  'impostos',\n",
              "  'sobre',\n",
              "  'empres√°rio',\n",
              "  'trabalhadores',\n",
              "  'receber√£o',\n",
              "  'maior',\n",
              "  'sal√°rio',\n",
              "  'no‚Ä¶'],\n",
              " ['povo',\n",
              "  't√°',\n",
              "  'debochando',\n",
              "  'artigo',\n",
              "  'chin√™s',\n",
              "  'sobre',\n",
              "  'cloroquina',\n",
              "  'sabe',\n",
              "  'ventiladores,as',\n",
              "  'm√°scaras,luvas',\n",
              "  'outros',\n",
              "  'u‚Ä¶'],\n",
              " ['#rnp', 'combate', '#covid', 'percam', '@tvbrasil'],\n",
              " ['psicologia',\n",
              "  'reversa,',\n",
              "  'super',\n",
              "  'funciona!!!',\n",
              "  '√≥tima',\n",
              "  'ideia',\n",
              "  '@bolsonarosp',\n",
              "  '@jairbolsonaro',\n",
              "  '#covid‚Ä¶'],\n",
              " ['@recifeordinario',\n",
              "  'ficar',\n",
              "  'casa',\n",
              "  '√∫nica',\n",
              "  'forma',\n",
              "  'eficaz',\n",
              "  'proteger',\n",
              "  'proteger',\n",
              "  'outros',\n",
              "  '#covid',\n",
              "  'quantas',\n",
              "  'pessoa‚Ä¶'],\n",
              " ['@profpaulamarisa',\n",
              "  'pior',\n",
              "  'cego',\n",
              "  'ver,',\n",
              "  'gostaria',\n",
              "  'saber',\n",
              "  'quanto',\n",
              "  'cada',\n",
              "  'adorador',\n",
              "  '@jairbolsonaro',\n",
              "  'ganha',\n",
              "  'p‚Ä¶'],\n",
              " ['pacientes',\n",
              "  'q',\n",
              "  'quadro',\n",
              "  'doen√ßa',\n",
              "  'grave,',\n",
              "  'acho',\n",
              "  'q',\n",
              "  'governo',\n",
              "  'l√°',\n",
              "  'tbm',\n",
              "  'deve',\n",
              "  'ser',\n",
              "  'louco',\n",
              "  'n√©,',\n",
              "  'ah!',\n",
              "  'piau√≠',\n",
              "  'tbm',\n",
              "  'est√£‚Ä¶'],\n",
              " ['deus',\n",
              "  'miseric√≥rdia',\n",
              "  'n√≥s,',\n",
              "  'pq',\n",
              "  'depender',\n",
              "  '\"certa',\n",
              "  'pessoa\"',\n",
              "  'todos',\n",
              "  'mortos',\n",
              "  '!',\n",
              "  '#covid1948',\n",
              "  '#covid',\n",
              "  '#coronavirus'],\n",
              " ['15/5',\n",
              "  '#covid',\n",
              "  '#paran√°',\n",
              "  '(3/3',\n",
              "  '#fiqueemcasa',\n",
              "  '1047(+250',\n",
              "  'investig',\n",
              "  '1477(+28',\n",
              "  'recuperados',\n",
              "  '19796(+852',\n",
              "  'exames',\n",
              "  '17273(+55‚Ä¶'],\n",
              " ['conquista',\n",
              "  'lidera',\n",
              "  'vilas',\n",
              "  'cachoeira',\n",
              "  'nazar√©',\n",
              "  '¬¥o√°sis¬¥',\n",
              "  'pandemia',\n",
              "  'ilh√©us'],\n",
              " ['fique',\n",
              "  'casa',\n",
              "  'promo√ß√£o',\n",
              "  'artes',\n",
              "  'divulga√ß√£o',\n",
              "  'produtos#bbb20',\n",
              "  '#redebbb',\n",
              "  '#perguntacorona',\n",
              "  '#globo',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['gostaria',\n",
              "  'acreditar,',\n",
              "  'infelizmente',\n",
              "  '#megarodizio',\n",
              "  '@prefsp',\n",
              "  'fazendo',\n",
              "  'efeito',\n",
              "  'desej√°vel',\n",
              "  'deve',\n",
              "  'ser‚Ä¶'],\n",
              " ['#covid',\n",
              "  'm√©dica',\n",
              "  'medicina',\n",
              "  'interna',\n",
              "  'centro',\n",
              "  'hospital',\n",
              "  't√¢mega',\n",
              "  'sousa,',\n",
              "  'rita',\n",
              "  'neto,',\n",
              "  'partilha',\n",
              "  'imagens',\n",
              "  'urg√™ncia',\n",
              "  'c‚Ä¶'],\n",
              " ['vamos', 'ajudar!', '#covid', '#manaus', '#catadores', '@tjamazonas'],\n",
              " ['gente',\n",
              "  'salta',\n",
              "  'olhos,',\n",
              "  'rep√≥rter',\n",
              "  'corta',\n",
              "  'entrevistado',\n",
              "  'hora',\n",
              "  'q',\n",
              "  'vai',\n",
              "  'citar',\n",
              "  'nome',\n",
              "  '#cloroquina',\n",
              "  'rem√©dio',\n",
              "  'q‚Ä¶'],\n",
              " ['doutores',\n",
              "  'samba',\n",
              "  'banda',\n",
              "  'm√©dicos',\n",
              "  'faz',\n",
              "  'parte',\n",
              "  'hist√≥ria',\n",
              "  'acad√™mica',\n",
              "  'unife‚Ä¶'],\n",
              " ['siga',\n",
              "  'recomenda√ß√µes',\n",
              "  'prevenir',\n",
              "  'propaga√ß√£o',\n",
              "  'novo',\n",
              "  'coronav√≠rus',\n",
              "  '#coronavirus',\n",
              "  '#coronav√≠rus',\n",
              "  '#coronavirusbrazil‚Ä¶'],\n",
              " ['atualiza√ß√£o',\n",
              "  '1505',\n",
              "  'painel',\n",
              "  '#covid19',\n",
              "  '#covid',\n",
              "  '#coronav√≠rus',\n",
              "  '#powerbi',\n",
              "  '#teres√≥polis'],\n",
              " ['confesso',\n",
              "  'ser',\n",
              "  'desligado',\n",
              "  'momento',\n",
              "  'pandemia',\n",
              "  'dois',\n",
              "  'rec√©m',\n",
              "  'nascidos',\n",
              "  'casa',\n",
              "  '(por',\n",
              "  'fofinhos',\n",
              "  'se‚Ä¶'],\n",
              " ['tragote',\n",
              "  'verdades',\n",
              "  '#covid',\n",
              "  '#bolsonaro',\n",
              "  '#pt',\n",
              "  '#midia',\n",
              "  '#globolixo'],\n",
              " ['live',\n",
              "  'hoje',\n",
              "  '18h',\n",
              "  '&gt',\n",
              "  '‚Äúmoradia',\n",
              "  'estudantil',\n",
              "  '#unicamp',\n",
              "  '#covid19‚Äù',\n",
              "  'unicamp',\n",
              "  'confirma',\n",
              "  'primeiro',\n",
              "  'caso',\n",
              "  'covid19‚Ä¶'],\n",
              " ['combate',\n",
              "  '#covid19',\n",
              "  'continua!',\n",
              "  'roraima',\n",
              "  'instaladas',\n",
              "  '15',\n",
              "  'esta√ß√µes',\n",
              "  'lavagem',\n",
              "  'm√£os',\n",
              "  '23',\n",
              "  'caixas',\n",
              "  'abastec‚Ä¶'],\n",
              " ['estudo',\n",
              "  'mostra',\n",
              "  'combina√ß√£o',\n",
              "  'hidroxicloroquinazinco',\n",
              "  'eficaz',\n",
              "  'contra',\n",
              "  'covid19',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid'],\n",
              " ['cadeia',\n",
              "  'sempre',\n",
              "  'lugar',\n",
              "  'pra',\n",
              "  'm√£os',\n",
              "  'um!!!',\n",
              "  '#bolsonarorainhalouca',\n",
              "  '#bolsonaroassassino',\n",
              "  '#bolsonaroficaquieto',\n",
              "  '#bolsonaro‚Ä¶'],\n",
              " ['aten√ß√£o',\n",
              "  'tuita√ßo!',\n",
              "  'üåäüåäüåä',\n",
              "  '#enem2020',\n",
              "  '#enem',\n",
              "  '#educa√ß√£o',\n",
              "  '#adiaenem',\n",
              "  '#forabolsonaro',\n",
              "  '#foraweintraub‚Ä¶'],\n",
              " ['rumo',\n",
              "  'caos',\n",
              "  'via',\n",
              "  '@guiasobrevivent',\n",
              "  '#prepara√ß√£o',\n",
              "  '#sobrevivencialismo',\n",
              "  '#xequemate',\n",
              "  '#teich',\n",
              "  '#covid',\n",
              "  '#guiadosobrevivente'],\n",
              " ['terras',\n",
              "  'bouro',\n",
              "  'assegura',\n",
              "  'transporte',\n",
              "  'alunos',\n",
              "  '11¬∫',\n",
              "  '12¬∫',\n",
              "  'anos',\n",
              "  '#covid19',\n",
              "  '#educa√ß√£o',\n",
              "  '#terrasdebouro'],\n",
              " ['dia',\n",
              "  '12/3',\n",
              "  'dia',\n",
              "  '14/5,',\n",
              "  'recebidas',\n",
              "  '#funedmg',\n",
              "  '17222',\n",
              "  'amostras',\n",
              "  'casos',\n",
              "  'notificados',\n",
              "  's√≠ndromes',\n",
              "  'respirat√≥r‚Ä¶'],\n",
              " ['(multim√≠dia',\n",
              "  '#china',\n",
              "  'apoia',\n",
              "  'firmemente',\n",
              "  'luta',\n",
              "  '#r√∫ssia',\n",
              "  'contra',\n",
              "  '#covid19,',\n",
              "  'diz',\n",
              "  'portavoz'],\n",
              " ['13',\n",
              "  'mil',\n",
              "  'afetados',\n",
              "  '98',\n",
              "  'perderam',\n",
              "  'vida',\n",
              "  'segundo',\n",
              "  '\\u2066@cofen_oficial\\u2069',\n",
              "  'enfermeiros,',\n",
              "  't√©cnicos,',\n",
              "  'auxiliares',\n",
              "  'outros',\n",
              "  'profissi‚Ä¶'],\n",
              " ['ficam',\n",
              "  'rindo,',\n",
              "  'mas,',\n",
              "  'assim',\n",
              "  'g√™meos',\n",
              "  'batizados',\n",
              "  '#covid',\n",
              "  '#corona,',\n",
              "  'breve',\n",
              "  'v√°rias',\n",
              "  'c‚Ä¶'],\n",
              " ['fique',\n",
              "  'casa',\n",
              "  'promo√ß√£o',\n",
              "  'artes',\n",
              "  'divulga√ß√£o',\n",
              "  'produtos#bbb20',\n",
              "  '#redebbb',\n",
              "  '#perguntacorona',\n",
              "  '#globo',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['dist√¢ncia',\n",
              "  'ideal',\n",
              "  'fazer',\n",
              "  'atividade',\n",
              "  'f√≠sica',\n",
              "  'ar',\n",
              "  'livre',\n",
              "  'nessa',\n",
              "  '#quarentena',\n",
              "  '#covid19',\n",
              "  '?',\n",
              "  'infogr√°fico',\n",
              "  'simula‚Ä¶'],\n",
              " ['#matogrosso',\n",
              "  '#indea',\n",
              "  'fechado',\n",
              "  'ap√≥s',\n",
              "  'servidor',\n",
              "  'testar',\n",
              "  'positivo',\n",
              "  '#covid19'],\n",
              " ['fraco',\n",
              "  'fragil',\n",
              "  'estupido',\n",
              "  '#eugostodevoce',\n",
              "  '#inmaturo',\n",
              "  '#jao',\n",
              "  '#lobos',\n",
              "  '#brasil',\n",
              "  '#sp',\n",
              "  '#saopaulo',\n",
              "  '#cover',\n",
              "  '#pop',\n",
              "  '#instagay‚Ä¶'],\n",
              " ['cinco',\n",
              "  'jornalistas',\n",
              "  'infectados',\n",
              "  '#covid',\n",
              "  'dois',\n",
              "  'rio,',\n",
              "  'paulo,',\n",
              "  'cear√°',\n",
              "  'maranh√£o‚Ä¶'],\n",
              " ['#l√≠deres',\n",
              "  'paran√°',\n",
              "  'a√ß√£o',\n",
              "  's√©rie',\n",
              "  'lives',\n",
              "  'conceito',\n",
              "  'informar',\n",
              "  'conectar',\n",
              "  'l√≠deres',\n",
              "  'reflex√µes',\n",
              "  'sobre',\n",
              "  'o‚Ä¶'],\n",
              " ['‚òëchapec√≥',\n",
              "  'divulga',\n",
              "  'partir',\n",
              "  'hoje',\n",
              "  'n√∫meros',\n",
              "  'casos',\n",
              "  'confirmados',\n",
              "  'bairros,',\n",
              "  'loteamentos',\n",
              "  'distritos,',\n",
              "  'onde',\n",
              "  'houve‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'deve',\n",
              "  'ser',\n",
              "  'tratada',\n",
              "  'doen√ßa',\n",
              "  'tromb√≥tica,',\n",
              "  'afirma',\n",
              "  'm√©dica',\n",
              "  'brasileira'],\n",
              " ['mundo',\n",
              "  'p√≥s',\n",
              "  '#covid19,',\n",
              "  'vai',\n",
              "  'ser?',\n",
              "  'confira',\n",
              "  'texto',\n",
              "  'blog',\n",
              "  'deixe',\n",
              "  'coment√°rio',\n",
              "  'aqui',\n",
              "  '=]‚Ä¶'],\n",
              " ['pesquisadores',\n",
              "  '#israel',\n",
              "  'criaram',\n",
              "  'aparelho',\n",
              "  'semelhante',\n",
              "  'baf√¥metro',\n",
              "  'capaz',\n",
              "  'detectar',\n",
              "  'presen√ßa',\n",
              "  '#covid19',\n",
              "  'na‚Ä¶'],\n",
              " ['hoje',\n",
              "  'gente',\n",
              "  'quer',\n",
              "  'desejar',\n",
              "  '√≥timo',\n",
              "  'final',\n",
              "  'semana',\n",
              "  'fam√≠lia',\n",
              "  '‚ù§',\n",
              "  'viva',\n",
              "  'fam√≠lia',\n",
              "  'üòò',\n",
              "  'üëâ',\n",
              "  '15',\n",
              "  'maio',\n",
              "  'dia‚Ä¶'],\n",
              " ['fique',\n",
              "  'casa',\n",
              "  'promo√ß√£o',\n",
              "  'artes',\n",
              "  'divulga√ß√£o',\n",
              "  'produtos#bbb20',\n",
              "  '#redebbb',\n",
              "  '#perguntacorona',\n",
              "  '#globo',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['boletim',\n",
              "  'turismo',\n",
              "  '|',\n",
              "  'covid19',\n",
              "  'mar√ßo',\n",
              "  '2020',\n",
              "  'brasil',\n",
              "  'retra√ß√£o',\n",
              "  '30%',\n",
              "  '√≠ndice',\n",
              "  'atividades',\n",
              "  'tur√≠sticas',\n",
              "  'n‚Ä¶'],\n",
              " ['\\U0001f9a0\\U0001f9a0',\n",
              "  'boletim',\n",
              "  'coronav√≠rus',\n",
              "  '#covid19',\n",
              "  '|',\n",
              "  'confira',\n",
              "  'atualiza√ß√£o',\n",
              "  'boletim',\n",
              "  'municipal',\n",
              "  'desta',\n",
              "  'sexta',\n",
              "  '(15/05'],\n",
              " ['boletim',\n",
              "  'coronav√≠rus',\n",
              "  '#covid19',\n",
              "  '|',\n",
              "  'confira',\n",
              "  'atualiza√ß√£o',\n",
              "  'boletim',\n",
              "  'municipal',\n",
              "  'desta',\n",
              "  'sextafeira',\n",
              "  '(15/05',\n",
              "  'info‚Ä¶'],\n",
              " ['paciente',\n",
              "  'casos',\n",
              "  'suspeitos',\n",
              "  'notificados',\n",
              "  'vigil√¢ncia',\n",
              "  'epidemiol√≥gica',\n",
              "  '#coronavirusitabira',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['for√ßatarefa',\n",
              "  'higieniza√ß√£o',\n",
              "  'locais',\n",
              "  'p√∫blico',\n",
              "  '#covid19',\n",
              "  '|',\n",
              "  'a√ß√µes',\n",
              "  'higieniza√ß√£o',\n",
              "  'unidades',\n",
              "  'hospitalares,',\n",
              "  'ter‚Ä¶'],\n",
              " ['cen√°rio',\n",
              "  'povo',\n",
              "  'brasileiro',\n",
              "  'milhares',\n",
              "  'mortos',\n",
              "  'hospitais',\n",
              "  'lotados',\n",
              "  'dificuldade',\n",
              "  'p/',\n",
              "  'sacar',\n",
              "  '$600',\n",
              "  'empresas',\n",
              "  'quebran‚Ä¶'],\n",
              " ['@drguiga1',\n",
              "  '@alessandrojferreira',\n",
              "  '@mfrancomed',\n",
              "  '@franciscoguedess',\n",
              "  '@danielcmrocha',\n",
              "  '#novidade',\n",
              "  '#agentefazbemparavoc√™‚Ä¶'],\n",
              " ['alguns',\n",
              "  'servi√ßos',\n",
              "  'prazos',\n",
              "  'atendimento',\n",
              "  'prorrogados',\n",
              "  'ans',\n",
              "  'significa',\n",
              "  'suspens√£o',\n",
              "  'todas‚Ä¶'],\n",
              " ['parques',\n",
              "  'campismo',\n",
              "  'podem',\n",
              "  'reabrir',\n",
              "  'segundafeira',\n",
              "  'dois',\n",
              "  'ter√ßos',\n",
              "  'lota√ß√£o',\n",
              "  '#covid19',\n",
              "  '#economia',\n",
              "  '#turismo'],\n",
              " ['uso',\n",
              "  'm√°scara',\n",
              "  'passa',\n",
              "  'ser',\n",
              "  'obrigat√≥rio',\n",
              "  'partir',\n",
              "  '10',\n",
              "  'anos',\n",
              "  '#covid19',\n",
              "  '#m√°scaras',\n",
              "  '#sa√∫de'],\n",
              " ['v√£o',\n",
              "  'deixar',\n",
              "  'brasil',\n",
              "  'morrer',\n",
              "  'm√£os',\n",
              "  'cidad√£o',\n",
              "  'possui',\n",
              "  'cargo',\n",
              "  'alto',\n",
              "  'democracia?',\n",
              "  'senhores‚Ä¶'],\n",
              " ['#acmneto',\n",
              "  '#covid',\n",
              "  '#deus',\n",
              "  '#salvador',\n",
              "  '#ufba',\n",
              "  '#uneb',\n",
              "  '#marinhadobrasil',\n",
              "  '@geografia',\n",
              "  '#historia',\n",
              "  '#universidade',\n",
              "  '#universitarios‚Ä¶'],\n",
              " ['prestou',\n",
              "  'esclarecimentos',\n",
              "  'comiss√£o',\n",
              "  'parlamentares',\n",
              "  'acompanha',\n",
              "  'medidas',\n",
              "  'governo',\n",
              "  'durante',\n",
              "  'per√≠odo',\n",
              "  'ca‚Ä¶'],\n",
              " ['sextou!!',\n",
              "  'bora',\n",
              "  'pro',\n",
              "  'show',\n",
              "  'drive',\n",
              "  'in!',\n",
              "  '#futerock',\n",
              "  '#blogfuterock',\n",
              "  '#quarentena',\n",
              "  '#covid19',\n",
              "  '#covid„Éº19',\n",
              "  '#covid',\n",
              "  '#covid_19‚Ä¶'],\n",
              " ['@teichnelson',\n",
              "  'obrigada',\n",
              "  'tudo,',\n",
              "  'culpa',\n",
              "  'sua,',\n",
              "  '2018!',\n",
              "  '#fiqueemcasa',\n",
              "  '#covid'],\n",
              " ['@tuliogadelha',\n",
              "  '@rodrigomaia',\n",
              "  'presidente',\n",
              "  'quer',\n",
              "  'ter',\n",
              "  'discurso',\n",
              "  'eleitoral',\n",
              "  'independente',\n",
              "  'fazer',\n",
              "  'bem',\n",
              "  'quer',\n",
              "  'cloroquin‚Ä¶'],\n",
              " ['5', 'v√≠timas', '#covid', 'complexo', 'alem√£o'],\n",
              " ['ano',\n",
              "  '2025',\n",
              "  'brasil,',\n",
              "  'pa√≠s',\n",
              "  'ainda',\n",
              "  'quarentena',\n",
              "  'apesar',\n",
              "  'nunca',\n",
              "  't√™la',\n",
              "  'feito',\n",
              "  'fato',\n",
              "  '#coronavirusnobrasil‚Ä¶'],\n",
              " ['fique',\n",
              "  'casa',\n",
              "  'promo√ß√£o',\n",
              "  'artes',\n",
              "  'divulga√ß√£o',\n",
              "  'produtos#bbb20',\n",
              "  '#redebbb',\n",
              "  '#perguntacorona',\n",
              "  '#globo',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['multadas',\n",
              "  '60',\n",
              "  'pessoas',\n",
              "  'usarem',\n",
              "  'm√°scara',\n",
              "  'transportes',\n",
              "  'p√∫blicos',\n",
              "  '#covid19',\n",
              "  '#m√°scaras'],\n",
              " ['(multim√≠dia',\n",
              "  '#wuhan',\n",
              "  'far√°',\n",
              "  'testes',\n",
              "  'cidade',\n",
              "  'inteira',\n",
              "  'detectar',\n",
              "  'casos',\n",
              "  'assintom√°ticos',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['estrat√©gias',\n",
              "  'dados',\n",
              "  'an√°lise',\n",
              "  'empresas',\n",
              "  'desmoronaram',\n",
              "  '#covid19',\n",
              "  '#vmware',\n",
              "  '#vmw_carbonblack‚Ä¶'],\n",
              " ['estrat√©gias',\n",
              "  'dados',\n",
              "  'an√°lise',\n",
              "  'empresas',\n",
              "  'desmoronaram',\n",
              "  '#covid19',\n",
              "  '#vmware',\n",
              "  '#vmw_carbonblack‚Ä¶'],\n",
              " ['utilidade',\n",
              "  'p√∫blica!',\n",
              "  'calend√°rio',\n",
              "  'pagamento',\n",
              "  '2',\n",
              "  'parcela',\n",
              "  '#auxilioemergecial',\n",
              "  'segue',\n",
              "  'liga',\n",
              "  'ai‚Ä¶'],\n",
              " ['#ferrari',\n",
              "  'instituto',\n",
              "  'italiano',\n",
              "  'tecnologia',\n",
              "  'produzem',\n",
              "  'novo',\n",
              "  'respirador',\n",
              "  'pacientes',\n",
              "  'covid19',\n",
              "  '#colunista',\n",
              "  '#covid'],\n",
              " ['dizem?',\n",
              "  '#covid19',\n",
              "  '#coronavirusplantao',\n",
              "  '#covid',\n",
              "  '#plandemic',\n",
              "  '#pandemia',\n",
              "  '#conspiracytheory',\n",
              "  '#socorro'],\n",
              " ['braga',\n",
              "  '62',\n",
              "  'mortos,',\n",
              "  '1332',\n",
              "  'infetados',\n",
              "  '699',\n",
              "  'recuperados',\n",
              "  '#braga',\n",
              "  '#covid19',\n",
              "  '#emdestaque'],\n",
              " ['costa',\n",
              "  'admite',\n",
              "  'levantar',\n",
              "  'limite',\n",
              "  'lota√ß√£o',\n",
              "  'restaurantes',\n",
              "  'partir',\n",
              "  'junho',\n",
              "  '#ant√≥niocosta',\n",
              "  '#covid19',\n",
              "  '#economia'],\n",
              " ['seguran√ßa',\n",
              "  'social',\n",
              "  'pagou',\n",
              "  '284',\n",
              "  'milh√µes',\n",
              "  'empresas',\n",
              "  '‚Äòlayoff‚Äô',\n",
              "  '#covid19',\n",
              "  '#economia',\n",
              "  '#seguran√ßasocial'],\n",
              " ['@allantercalivre',\n",
              "  'totalmente',\n",
              "  'despropositada',\n",
              "  'coletiva',\n",
              "  'imprensa',\n",
              "  'ministro',\n",
              "  'ministro',\n",
              "  'pediu',\n",
              "  'demiss√£o‚Ä¶'],\n",
              " ['florian√≥polis',\n",
              "  'nesta',\n",
              "  'sextafeira',\n",
              "  '(15',\n",
              "  '#covid',\n",
              "  '#covid19',\n",
              "  '#pandemia',\n",
              "  '#coronav√≠rus',\n",
              "  '#floripa',\n",
              "  '#sc',\n",
              "  '#santacatarina',\n",
              "  '#centro‚Ä¶'],\n",
              " ['(multim√≠dia',\n",
              "  '#china',\n",
              "  'completar√°',\n",
              "  'testes',\n",
              "  'cl√≠nicos',\n",
              "  'segunda',\n",
              "  'fase',\n",
              "  'vacinas',\n",
              "  '#covid19',\n",
              "  'julho,',\n",
              "  'diz',\n",
              "  'funcion√°rio‚Ä¶'],\n",
              " ['restaurantes',\n",
              "  'lojas',\n",
              "  '400',\n",
              "  'metros',\n",
              "  'quadrados',\n",
              "  'reabrem',\n",
              "  'dia',\n",
              "  '18',\n",
              "  '#com√©rcio',\n",
              "  '#covid19',\n",
              "  '#economia'],\n",
              " ['@psdboficial',\n",
              "  '@eduardoleite_',\n",
              "  'totalmente',\n",
              "  'despropositada',\n",
              "  'coletiva',\n",
              "  'imprensa',\n",
              "  'ministro',\n",
              "  'ministro',\n",
              "  'ped‚Ä¶'],\n",
              " ['governo',\n",
              "  'prop√µe',\n",
              "  'prolongamento',\n",
              "  '01',\n",
              "  'setembro',\n",
              "  'empr√©stimos',\n",
              "  'rendas',\n",
              "  '#covid19',\n",
              "  '#economia',\n",
              "  '#rendas'],\n",
              " ['@radiobandnewsfm',\n",
              "  'totalmente',\n",
              "  'despropositada',\n",
              "  'coletiva',\n",
              "  'imprensa',\n",
              "  'ministro',\n",
              "  'ministro',\n",
              "  'pediu',\n",
              "  'demiss√£o‚Ä¶'],\n",
              " ['@biakicis',\n",
              "  'totalmente',\n",
              "  'despropositada',\n",
              "  'coletiva',\n",
              "  'imprensa',\n",
              "  'ministro',\n",
              "  'ministro',\n",
              "  'pediu',\n",
              "  'demiss√£o',\n",
              "  'cai',\n",
              "  'fo‚Ä¶'],\n",
              " ['@andreiasadi',\n",
              "  'totalmente',\n",
              "  'despropositada',\n",
              "  'coletiva',\n",
              "  'imprensa',\n",
              "  'ministro',\n",
              "  'ministro',\n",
              "  'pediu',\n",
              "  'demiss√£o',\n",
              "  'cai‚Ä¶'],\n",
              " ['@gianeguerra',\n",
              "  '@gauchazh',\n",
              "  'totalmente',\n",
              "  'despropositada',\n",
              "  'coletiva',\n",
              "  'imprensa',\n",
              "  'ministro',\n",
              "  'ministro',\n",
              "  'pediu',\n",
              "  'de‚Ä¶'],\n",
              " ['costa',\n",
              "  'afirma',\n",
              "  'resultados',\n",
              "  'permitem',\n",
              "  'dar',\n",
              "  'novo',\n",
              "  'passo',\n",
              "  'reabertura',\n",
              "  'atividades',\n",
              "  '#ant√≥niocosta',\n",
              "  '#covid19',\n",
              "  '#pol√≠tica'],\n",
              " ['@bandnews',\n",
              "  'totalmente',\n",
              "  'despropositada',\n",
              "  'coletiva',\n",
              "  'imprensa',\n",
              "  'ministro',\n",
              "  'ministro',\n",
              "  'pediu',\n",
              "  'demiss√£o',\n",
              "  'cai',\n",
              "  'fo‚Ä¶'],\n",
              " ['totalmente',\n",
              "  'despropositada',\n",
              "  'coletiva',\n",
              "  'imprensa',\n",
              "  'ministro',\n",
              "  'ministro',\n",
              "  'pediu',\n",
              "  'demiss√£o',\n",
              "  'cai',\n",
              "  'fora!',\n",
              "  'vai',\n",
              "  'da‚Ä¶'],\n",
              " ['@jornaldarecord',\n",
              "  'assustador',\n",
              "  'n√∫mero',\n",
              "  'mortes',\n",
              "  '#covid',\n",
              "  'estado',\n",
              "  '#saopaulo',\n",
              "  '@governosp',\n",
              "  '@jdoriajr',\n",
              "  'isolament‚Ä¶'],\n",
              " ['situa√ß√£o',\n",
              "  'calamidade',\n",
              "  'prorrogada',\n",
              "  'final',\n",
              "  'maio',\n",
              "  '#ant√≥niocosta',\n",
              "  '#covid19',\n",
              "  '#pol√≠tica'],\n",
              " ['üí™vem',\n",
              "  'somar',\n",
              "  'for√ßas!',\n",
              "  'pnuma',\n",
              "  'apoia',\n",
              "  '\"alian√ßa',\n",
              "  'povos',\n",
              "  'ind√≠genas',\n",
              "  'popula√ß√µes',\n",
              "  'tradicionais',\n",
              "  'organiza√ß√µes',\n",
              "  'parceira‚Ä¶'],\n",
              " ['fique',\n",
              "  'casa',\n",
              "  'promo√ß√£o',\n",
              "  'artes',\n",
              "  'divulga√ß√£o',\n",
              "  'produtos#bbb20',\n",
              "  '#redebbb',\n",
              "  '#perguntacorona',\n",
              "  '#globo',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['pcp',\n",
              "  'apoia',\n",
              "  '‚Äúa',\n",
              "  'justa',\n",
              "  'luta‚Äù',\n",
              "  'feirantes',\n",
              "  'viana',\n",
              "  'castelo',\n",
              "  '#covid19',\n",
              "  '#feiras',\n",
              "  '#vianadocastelo'],\n",
              " ['primeiro',\n",
              "  'v√≠deo',\n",
              "  'canal,',\n",
              "  'compartilhem',\n",
              "  '#cloroquina',\n",
              "  '#hidroxicloroquina',\n",
              "  '#covid19',\n",
              "  '#covid',\n",
              "  '#ciencia',\n",
              "  '#universocortical'],\n",
              " ['conci√™ncia',\n",
              "  'realidade',\n",
              "  'periferia',\n",
              "  'imposs√≠vel',\n",
              "  '#covid',\n",
              "  '#trabalhar',\n",
              "  '#periferia',\n",
              "  '#jornalistas',\n",
              "  '#sim√£o',\n",
              "  '#trendtopics‚Ä¶'],\n",
              " ['clique',\n",
              "  'link',\n",
              "  'veja',\n",
              "  'ponto',\n",
              "  'arrecada√ß√£o',\n",
              "  'pr√≥ximo',\n",
              "  '#covid19',\n",
              "  '#covid‚Ä¶'],\n",
              " ['#forabolsonarourgente',\n",
              "  '#forabolÂçêonaro',\n",
              "  '#forabolsonaro',\n",
              "  '#impeachmentdobolsonarourgente',\n",
              "  '#impeachmentdebolsonaro‚Ä¶'],\n",
              " ['chega',\n",
              "  'tirem',\n",
              "  'urgente',\n",
              "  'genocida',\n",
              "  'a√≠',\n",
              "  'pro',\n",
              "  'povo',\n",
              "  'pra',\n",
              "  'economia',\n",
              "  'trar√°',\n",
              "  'psicopata',\n",
              "  'quer',\n",
              "  've‚Ä¶'],\n",
              " ['@lottenberg',\n",
              "  'excelente',\n",
              "  'posicionamento!',\n",
              "  '@cnnbrasil',\n",
              "  'vis√£o',\n",
              "  'cnn',\n",
              "  'concordo',\n",
              "  'ter',\n",
              "  'discuss√µes',\n",
              "  't√©cnicas‚Ä¶'],\n",
              " ['@eumanosilva',\n",
              "  'presidente',\n",
              "  'quer',\n",
              "  'ter',\n",
              "  'discurso',\n",
              "  'eleitoral',\n",
              "  'independente',\n",
              "  'fazer',\n",
              "  'bem',\n",
              "  'quer',\n",
              "  'cloroquina',\n",
              "  'pra',\n",
              "  'casos',\n",
              "  'le‚Ä¶'],\n",
              " ['@brunogagliasso',\n",
              "  'presidente',\n",
              "  'quer',\n",
              "  'ter',\n",
              "  'discurso',\n",
              "  'eleitoral',\n",
              "  'independente',\n",
              "  'fazer',\n",
              "  'bem',\n",
              "  'quer',\n",
              "  'cloroquina',\n",
              "  'pra',\n",
              "  'casos‚Ä¶'],\n",
              " ['t√¥',\n",
              "  'mesa',\n",
              "  '4',\n",
              "  'cadeiras,',\n",
              "  'aqui',\n",
              "  '3',\n",
              "  'enganados',\n",
              "  '#ministrodasaude',\n",
              "  '#covid',\n",
              "  '#forabolsonarourgente‚Ä¶'],\n",
              " ['cego',\n",
              "  'planalto',\n",
              "  'brasil',\n",
              "  '2020,',\n",
              "  '#coronavirus',\n",
              "  '#covid',\n",
              "  '#teich',\n",
              "  '#forabolÂçêonaro'],\n",
              " ['@revistacrusoe',\n",
              "  'lockdown',\n",
              "  'salvou',\n",
              "  'vidas',\n",
              "  'europa',\n",
              "  'assista',\n",
              "  '#lockdown',\n",
              "  '#covid'],\n",
              " ['agora,', 't√°', 'rindo?', '#daciolo', '#covid', '#urgente'],\n",
              " ['parab√©ns',\n",
              "  '@spleituras',\n",
              "  '#bibliotecas',\n",
              "  '#aprendizagem',\n",
              "  '#planejamento',\n",
              "  '#bibliotec√°rios',\n",
              "  '#covid'],\n",
              " ['segundo',\n",
              "  'pesquisadores',\n",
              "  'canadenses,',\n",
              "  '#maconha',\n",
              "  'pode',\n",
              "  'ajudar',\n",
              "  'tratamento',\n",
              "  'contra',\n",
              "  '#coronavirus',\n",
              "  '#covid'],\n",
              " ['inscri√ß√µes',\n",
              "  '#mestrado',\n",
              "  '#doutorado',\n",
              "  'programa',\n",
              "  'pesquisa',\n",
              "  'cl√≠nica',\n",
              "  'doen√ßas',\n",
              "  'infecciosas',\n",
              "  '@inifiocruz‚Ä¶'],\n",
              " ['altice',\n",
              "  'forum',\n",
              "  'braga',\n",
              "  'reabre',\n",
              "  'segundafeira',\n",
              "  'reagendou',\n",
              "  'espet√°culos',\n",
              "  '#alticeforum',\n",
              "  '#braga',\n",
              "  '#covid19'],\n",
              " ['fique',\n",
              "  'casa',\n",
              "  'promo√ß√£o',\n",
              "  'artes',\n",
              "  'divulga√ß√£o',\n",
              "  'produtos#bbb20',\n",
              "  '#redebbb',\n",
              "  '#perguntacorona',\n",
              "  '#globo',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['@lhmandetta',\n",
              "  'monte',\n",
              "  'gente',\n",
              "  'tomando',\n",
              "  'cloroquina',\n",
              "  'morrendo',\n",
              "  'casa,',\n",
              "  'problemas',\n",
              "  'card√≠acos',\n",
              "  'decorrente',\n",
              "  'uso‚Ä¶'],\n",
              " ['criminoso',\n",
              "  'vai',\n",
              "  'cair',\n",
              "  '#impeachmentbolsonaro',\n",
              "  '#jairbolsonaro',\n",
              "  '#covid',\n",
              "  '#covid_19',\n",
              "  '#cloroquina',\n",
              "  '#sueciaüá∏üá™',\n",
              "  '#argentina‚Ä¶'],\n",
              " ['@miltonneves',\n",
              "  '@joelpinheiro85',\n",
              "  'presidente',\n",
              "  'quer',\n",
              "  'ter',\n",
              "  'discurso',\n",
              "  'eleitoral',\n",
              "  'independente',\n",
              "  'fazer',\n",
              "  'bem',\n",
              "  'quer',\n",
              "  'cloroqu‚Ä¶'],\n",
              " ['@xicograziano',\n",
              "  '@joelpinheiro85',\n",
              "  'presidente',\n",
              "  'quer',\n",
              "  'ter',\n",
              "  'discurso',\n",
              "  'eleitoral',\n",
              "  'independente',\n",
              "  'fazer',\n",
              "  'bem',\n",
              "  'quer',\n",
              "  'cloroq‚Ä¶'],\n",
              " ['@brasil247',\n",
              "  'presidente',\n",
              "  'quer',\n",
              "  'ter',\n",
              "  'discurso',\n",
              "  'eleitoral',\n",
              "  'independente',\n",
              "  'fazer',\n",
              "  'bem',\n",
              "  'quer',\n",
              "  'cloroquina',\n",
              "  'pra',\n",
              "  'casos',\n",
              "  'leve‚Ä¶'],\n",
              " ['@bernardomf',\n",
              "  'presidente',\n",
              "  'quer',\n",
              "  'ter',\n",
              "  'discurso',\n",
              "  'eleitoral',\n",
              "  'independente',\n",
              "  'fazer',\n",
              "  'bem',\n",
              "  'quer',\n",
              "  'cloroquina',\n",
              "  'pra',\n",
              "  'casos',\n",
              "  'lev‚Ä¶'],\n",
              " ['@bragal0ures',\n",
              "  '@lhmandetta',\n",
              "  'extremistas',\n",
              "  'direita',\n",
              "  'assinar',\n",
              "  'termo',\n",
              "  'aceita√ß√£o',\n",
              "  'servi√ßos',\n",
              "  'm√©dicos‚Ä¶'],\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYGiRPQCk-11",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "f8bd05c6-c090-4629-acc8-fd0dd0bb9a1b"
      },
      "source": [
        "phrases = Phrases(sent, min_count=30, progress_per=10000)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 14:12:26: collecting all words and their counts\n",
            "INFO - 14:12:26: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
            "INFO - 14:12:27: PROGRESS: at sentence #10000, processed 104026 words and 97237 word types\n",
            "INFO - 14:12:27: PROGRESS: at sentence #20000, processed 205867 words and 170938 word types\n",
            "INFO - 14:12:27: PROGRESS: at sentence #30000, processed 306361 words and 238343 word types\n",
            "INFO - 14:12:27: PROGRESS: at sentence #40000, processed 407874 words and 301827 word types\n",
            "INFO - 14:12:27: PROGRESS: at sentence #50000, processed 509384 words and 364125 word types\n",
            "INFO - 14:12:28: PROGRESS: at sentence #60000, processed 610794 words and 431743 word types\n",
            "INFO - 14:12:28: PROGRESS: at sentence #70000, processed 711725 words and 491391 word types\n",
            "INFO - 14:12:28: PROGRESS: at sentence #80000, processed 810918 words and 547391 word types\n",
            "INFO - 14:12:28: PROGRESS: at sentence #90000, processed 911020 words and 600180 word types\n",
            "INFO - 14:12:28: PROGRESS: at sentence #100000, processed 1012683 words and 652674 word types\n",
            "INFO - 14:12:28: collected 674495 word types from a corpus of 1048210 words (unigram + bigrams) and 103364 sentences\n",
            "INFO - 14:12:28: using 674495 counts as vocab in Phrases<0 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a28rb0mltnwB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "983a8660-214b-4a11-a42c-bf8cc774d1ae"
      },
      "source": [
        "#Construindo modelo baseado em Bigram, para a detec√ß√£o de palavras (√∫nicas) que s√£o formadas por outras duas.\n",
        "bigram = Phraser(phrases)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 14:12:28: source_vocab length 674495\n",
            "INFO - 14:12:34: Phraser built with 861 phrasegrams\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtiPEzyvmVfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = bigram[sent]"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3_capprlL2K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d958e230-6fce-4c97-e079-f3f93eded6fb"
      },
      "source": [
        "#Percorrendo os dados e fazendo uma contagem para verificar as palavras mais frequentes da base.\n",
        "word_freq = defaultdict(int)\n",
        "for sent in sentences:\n",
        "    for i in sent:\n",
        "        word_freq[i] += 1\n",
        "len(word_freq)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "117576"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NilpgoImlzjj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a94acf56-95ab-472a-ab0f-18abda8025cb"
      },
      "source": [
        "#Exibindo as 10 palavras mais frequentes da base de dados.\n",
        "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['coronav√≠rus',\n",
              " 'covid19',\n",
              " 'lockdown',\n",
              " 'coronavirus',\n",
              " 'brasil',\n",
              " 'pra',\n",
              " 'casos',\n",
              " 'sobre',\n",
              " 'mortes',\n",
              " 'contra']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8E9qBS87Uiq",
        "colab_type": "text"
      },
      "source": [
        "# Criando o Modelo Word2VEC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoYBoaSIl4ZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importando biblioteca e m√≥dulo do Gensim, para a implementa√ß√£o do Word2VEC.\n",
        "import multiprocessing\n",
        "\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fq89FR4oq2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fun√ß√£o que conta o n√∫mero de cores da m√°quina.\n",
        "cores = multiprocessing.cpu_count()"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkS_Ofefok0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Instanciando modelo Word2VEC a partir dos mesmos par√¢metros estabelecidos pelo artigo.\n",
        "w2v_model = Word2Vec(min_count=3,\n",
        "                     window=4,\n",
        "                     size=300,\n",
        "                     sample=0.8, \n",
        "                     alpha=0.03, \n",
        "                     min_alpha=0.0007, \n",
        "                     negative=20,\n",
        "                     workers=multiprocessing.cpu_count()-1)"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPcSopbConnQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "d575c074-ca96-449f-e688-a31e6098c507"
      },
      "source": [
        "#Construindo vocabul√°rio a partir das senten√ßas.\n",
        "w2v_model.build_vocab(sentences, progress_per=10000)"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 14:50:08: collecting all words and their counts\n",
            "INFO - 14:50:08: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "INFO - 14:50:08: PROGRESS: at sentence #10000, processed 98386 words, keeping 26703 word types\n",
            "INFO - 14:50:09: PROGRESS: at sentence #20000, processed 194307 words, keeping 41176 word types\n",
            "INFO - 14:50:09: PROGRESS: at sentence #30000, processed 289323 words, keeping 53198 word types\n",
            "INFO - 14:50:09: PROGRESS: at sentence #40000, processed 384343 words, keeping 63822 word types\n",
            "INFO - 14:50:10: PROGRESS: at sentence #50000, processed 480594 words, keeping 73460 word types\n",
            "INFO - 14:50:10: PROGRESS: at sentence #60000, processed 577296 words, keeping 82906 word types\n",
            "INFO - 14:50:10: PROGRESS: at sentence #70000, processed 672253 words, keeping 91879 word types\n",
            "INFO - 14:50:11: PROGRESS: at sentence #80000, processed 765282 words, keeping 100227 word types\n",
            "INFO - 14:50:11: PROGRESS: at sentence #90000, processed 858298 words, keeping 107673 word types\n",
            "INFO - 14:50:11: PROGRESS: at sentence #100000, processed 953320 words, keeping 114711 word types\n",
            "INFO - 14:50:12: collected 117576 word types from a corpus of 987411 raw words and 103364 sentences\n",
            "INFO - 14:50:12: Loading a fresh vocabulary\n",
            "INFO - 14:50:12: effective_min_count=3 retains 30785 unique words (26% of original 117576, drops 86791)\n",
            "INFO - 14:50:12: effective_min_count=3 leaves 885593 word corpus (89% of original 987411, drops 101818)\n",
            "INFO - 14:50:12: deleting the raw counts dictionary of 117576 items\n",
            "INFO - 14:50:12: sample=0.8 downsamples 0 most-common words\n",
            "INFO - 14:50:12: downsampling leaves estimated 885593 word corpus (100.0% of prior 885593)\n",
            "INFO - 14:50:12: estimated required memory for 30785 words and 300 dimensions: 89276500 bytes\n",
            "INFO - 14:50:12: resetting layer weights\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USvaq5m3VnPJ",
        "colab_type": "text"
      },
      "source": [
        "# Treinando o Modelo Word2VEC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elb-e0LpoulX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "13f9ec0b-9eac-4a52-8f77-da0a576ad317"
      },
      "source": [
        "#Treiando modelo Word2VEC.\n",
        "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 14:50:18: training model with 1 workers on 30785 vocabulary and 300 features, using sg=0 hs=0 sample=0.8 negative=20 window=4\n",
            "INFO - 14:50:19: EPOCH 1 - PROGRESS: at 8.80% examples, 73340 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:20: EPOCH 1 - PROGRESS: at 17.90% examples, 75978 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:21: EPOCH 1 - PROGRESS: at 27.07% examples, 76975 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:22: EPOCH 1 - PROGRESS: at 36.27% examples, 77279 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:23: EPOCH 1 - PROGRESS: at 45.23% examples, 74528 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:24: EPOCH 1 - PROGRESS: at 54.26% examples, 75451 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:25: EPOCH 1 - PROGRESS: at 63.40% examples, 76200 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:26: EPOCH 1 - PROGRESS: at 72.65% examples, 76627 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:27: EPOCH 1 - PROGRESS: at 81.94% examples, 77053 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:28: EPOCH 1 - PROGRESS: at 91.36% examples, 77452 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:50:29: EPOCH - 1 : training on 987411 raw words (885593 effective words) took 11.3s, 78228 effective words/s\n",
            "INFO - 14:50:30: EPOCH 2 - PROGRESS: at 8.80% examples, 73632 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:32: EPOCH 2 - PROGRESS: at 18.90% examples, 77829 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:33: EPOCH 2 - PROGRESS: at 29.08% examples, 78773 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:34: EPOCH 2 - PROGRESS: at 38.24% examples, 79064 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:35: EPOCH 2 - PROGRESS: at 48.29% examples, 79785 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:36: EPOCH 2 - PROGRESS: at 58.28% examples, 80402 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:37: EPOCH 2 - PROGRESS: at 68.49% examples, 80706 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:38: EPOCH 2 - PROGRESS: at 78.88% examples, 80904 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:39: EPOCH 2 - PROGRESS: at 89.27% examples, 81198 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:40: EPOCH 2 - PROGRESS: at 99.27% examples, 81875 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:40: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:50:40: EPOCH - 2 : training on 987411 raw words (885593 effective words) took 10.8s, 82036 effective words/s\n",
            "INFO - 14:50:41: EPOCH 3 - PROGRESS: at 8.80% examples, 76245 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:42: EPOCH 3 - PROGRESS: at 18.90% examples, 79118 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 14:50:43: EPOCH 3 - PROGRESS: at 29.08% examples, 80511 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:44: EPOCH 3 - PROGRESS: at 38.24% examples, 80503 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:45: EPOCH 3 - PROGRESS: at 48.29% examples, 81125 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:47: EPOCH 3 - PROGRESS: at 58.28% examples, 81514 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:48: EPOCH 3 - PROGRESS: at 68.49% examples, 81675 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:49: EPOCH 3 - PROGRESS: at 78.88% examples, 81797 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:50: EPOCH 3 - PROGRESS: at 89.27% examples, 81994 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:51: EPOCH 3 - PROGRESS: at 99.27% examples, 82591 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:51: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:50:51: EPOCH - 3 : training on 987411 raw words (885593 effective words) took 10.7s, 82723 effective words/s\n",
            "INFO - 14:50:52: EPOCH 4 - PROGRESS: at 8.80% examples, 77611 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:53: EPOCH 4 - PROGRESS: at 18.90% examples, 80426 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:54: EPOCH 4 - PROGRESS: at 29.08% examples, 81303 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:55: EPOCH 4 - PROGRESS: at 39.24% examples, 81436 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:56: EPOCH 4 - PROGRESS: at 49.28% examples, 81903 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:57: EPOCH 4 - PROGRESS: at 59.25% examples, 82228 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:58: EPOCH 4 - PROGRESS: at 69.53% examples, 82264 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:50:59: EPOCH 4 - PROGRESS: at 79.88% examples, 82298 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:01: EPOCH 4 - PROGRESS: at 90.32% examples, 82393 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:02: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:51:02: EPOCH - 4 : training on 987411 raw words (885593 effective words) took 10.7s, 83038 effective words/s\n",
            "INFO - 14:51:03: EPOCH 5 - PROGRESS: at 8.80% examples, 77409 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:04: EPOCH 5 - PROGRESS: at 18.90% examples, 80604 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:05: EPOCH 5 - PROGRESS: at 29.08% examples, 81339 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:06: EPOCH 5 - PROGRESS: at 37.26% examples, 78301 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:07: EPOCH 5 - PROGRESS: at 47.25% examples, 79304 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:08: EPOCH 5 - PROGRESS: at 57.30% examples, 80048 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:09: EPOCH 5 - PROGRESS: at 67.46% examples, 80574 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:10: EPOCH 5 - PROGRESS: at 77.84% examples, 80825 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:11: EPOCH 5 - PROGRESS: at 88.22% examples, 81076 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:12: EPOCH 5 - PROGRESS: at 98.33% examples, 81574 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:12: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:51:12: EPOCH - 5 : training on 987411 raw words (885593 effective words) took 10.8s, 81956 effective words/s\n",
            "INFO - 14:51:13: EPOCH 6 - PROGRESS: at 8.80% examples, 76744 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:14: EPOCH 6 - PROGRESS: at 18.90% examples, 79726 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:16: EPOCH 6 - PROGRESS: at 29.08% examples, 81135 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:17: EPOCH 6 - PROGRESS: at 39.24% examples, 81848 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:18: EPOCH 6 - PROGRESS: at 49.28% examples, 82175 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:19: EPOCH 6 - PROGRESS: at 59.25% examples, 82467 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:20: EPOCH 6 - PROGRESS: at 69.53% examples, 82612 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:21: EPOCH 6 - PROGRESS: at 79.88% examples, 82706 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:22: EPOCH 6 - PROGRESS: at 90.32% examples, 82884 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:23: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:51:23: EPOCH - 6 : training on 987411 raw words (885593 effective words) took 10.6s, 83525 effective words/s\n",
            "INFO - 14:51:24: EPOCH 7 - PROGRESS: at 8.80% examples, 77198 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:25: EPOCH 7 - PROGRESS: at 18.90% examples, 80452 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:26: EPOCH 7 - PROGRESS: at 29.08% examples, 81709 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:27: EPOCH 7 - PROGRESS: at 39.24% examples, 82294 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:28: EPOCH 7 - PROGRESS: at 49.28% examples, 82683 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:29: EPOCH 7 - PROGRESS: at 59.25% examples, 82963 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:30: EPOCH 7 - PROGRESS: at 69.53% examples, 83033 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:31: EPOCH 7 - PROGRESS: at 79.88% examples, 83091 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:33: EPOCH 7 - PROGRESS: at 90.32% examples, 83214 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:34: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:51:34: EPOCH - 7 : training on 987411 raw words (885593 effective words) took 10.6s, 83938 effective words/s\n",
            "INFO - 14:51:35: EPOCH 8 - PROGRESS: at 8.80% examples, 78177 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:36: EPOCH 8 - PROGRESS: at 18.90% examples, 80546 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:37: EPOCH 8 - PROGRESS: at 29.08% examples, 81361 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:38: EPOCH 8 - PROGRESS: at 39.24% examples, 81968 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:39: EPOCH 8 - PROGRESS: at 49.28% examples, 82210 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:40: EPOCH 8 - PROGRESS: at 59.25% examples, 82556 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:41: EPOCH 8 - PROGRESS: at 69.53% examples, 82724 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:42: EPOCH 8 - PROGRESS: at 79.88% examples, 82892 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:43: EPOCH 8 - PROGRESS: at 90.32% examples, 83091 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:44: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:51:44: EPOCH - 8 : training on 987411 raw words (885593 effective words) took 10.6s, 83826 effective words/s\n",
            "INFO - 14:51:45: EPOCH 9 - PROGRESS: at 8.80% examples, 78079 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:46: EPOCH 9 - PROGRESS: at 18.90% examples, 80696 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:47: EPOCH 9 - PROGRESS: at 27.07% examples, 77728 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:48: EPOCH 9 - PROGRESS: at 37.26% examples, 79333 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:49: EPOCH 9 - PROGRESS: at 47.25% examples, 80295 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:50: EPOCH 9 - PROGRESS: at 57.30% examples, 81030 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:51: EPOCH 9 - PROGRESS: at 67.46% examples, 81418 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:53: EPOCH 9 - PROGRESS: at 77.84% examples, 81824 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:54: EPOCH 9 - PROGRESS: at 88.22% examples, 81999 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:55: EPOCH 9 - PROGRESS: at 98.33% examples, 82481 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:51:55: EPOCH - 9 : training on 987411 raw words (885593 effective words) took 10.7s, 82852 effective words/s\n",
            "INFO - 14:51:56: EPOCH 10 - PROGRESS: at 8.80% examples, 78094 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:57: EPOCH 10 - PROGRESS: at 18.90% examples, 81137 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:58: EPOCH 10 - PROGRESS: at 29.08% examples, 82436 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:51:59: EPOCH 10 - PROGRESS: at 39.24% examples, 82966 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:00: EPOCH 10 - PROGRESS: at 49.28% examples, 83280 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:01: EPOCH 10 - PROGRESS: at 59.25% examples, 83394 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:02: EPOCH 10 - PROGRESS: at 69.53% examples, 83540 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:03: EPOCH 10 - PROGRESS: at 79.88% examples, 83666 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:04: EPOCH 10 - PROGRESS: at 90.32% examples, 83783 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:05: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:52:05: EPOCH - 10 : training on 987411 raw words (885593 effective words) took 10.5s, 84467 effective words/s\n",
            "INFO - 14:52:06: EPOCH 11 - PROGRESS: at 8.80% examples, 78429 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:07: EPOCH 11 - PROGRESS: at 18.90% examples, 81419 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:08: EPOCH 11 - PROGRESS: at 29.08% examples, 82607 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:09: EPOCH 11 - PROGRESS: at 39.24% examples, 83347 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:11: EPOCH 11 - PROGRESS: at 49.28% examples, 83692 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:12: EPOCH 11 - PROGRESS: at 59.25% examples, 84082 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:13: EPOCH 11 - PROGRESS: at 69.53% examples, 84206 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:14: EPOCH 11 - PROGRESS: at 79.88% examples, 84202 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:15: EPOCH 11 - PROGRESS: at 90.32% examples, 84083 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:16: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:52:16: EPOCH - 11 : training on 987411 raw words (885593 effective words) took 10.5s, 84736 effective words/s\n",
            "INFO - 14:52:17: EPOCH 12 - PROGRESS: at 8.80% examples, 78432 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:18: EPOCH 12 - PROGRESS: at 18.90% examples, 81712 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:19: EPOCH 12 - PROGRESS: at 29.08% examples, 82609 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:20: EPOCH 12 - PROGRESS: at 39.24% examples, 83111 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:21: EPOCH 12 - PROGRESS: at 49.28% examples, 83503 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:22: EPOCH 12 - PROGRESS: at 59.25% examples, 83684 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:23: EPOCH 12 - PROGRESS: at 69.53% examples, 83754 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 14:52:24: EPOCH 12 - PROGRESS: at 79.88% examples, 83865 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:25: EPOCH 12 - PROGRESS: at 90.32% examples, 83987 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:26: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:52:26: EPOCH - 12 : training on 987411 raw words (885593 effective words) took 10.5s, 84734 effective words/s\n",
            "INFO - 14:52:27: EPOCH 13 - PROGRESS: at 8.80% examples, 78390 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:28: EPOCH 13 - PROGRESS: at 16.89% examples, 74972 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:29: EPOCH 13 - PROGRESS: at 27.07% examples, 78466 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:30: EPOCH 13 - PROGRESS: at 37.26% examples, 80301 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:31: EPOCH 13 - PROGRESS: at 47.25% examples, 81279 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:32: EPOCH 13 - PROGRESS: at 57.30% examples, 81977 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:34: EPOCH 13 - PROGRESS: at 67.46% examples, 82414 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:35: EPOCH 13 - PROGRESS: at 77.84% examples, 82649 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:36: EPOCH 13 - PROGRESS: at 88.22% examples, 82927 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:37: EPOCH 13 - PROGRESS: at 98.33% examples, 83483 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:37: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:52:37: EPOCH - 13 : training on 987411 raw words (885593 effective words) took 10.6s, 83869 effective words/s\n",
            "INFO - 14:52:38: EPOCH 14 - PROGRESS: at 9.82% examples, 80013 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:39: EPOCH 14 - PROGRESS: at 19.93% examples, 82201 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:40: EPOCH 14 - PROGRESS: at 30.07% examples, 82886 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:41: EPOCH 14 - PROGRESS: at 40.26% examples, 83278 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:42: EPOCH 14 - PROGRESS: at 50.30% examples, 83645 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:43: EPOCH 14 - PROGRESS: at 60.26% examples, 83861 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 14:52:44: EPOCH 14 - PROGRESS: at 70.56% examples, 84129 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:45: EPOCH 14 - PROGRESS: at 80.91% examples, 84166 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:46: EPOCH 14 - PROGRESS: at 91.36% examples, 84282 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:47: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:52:47: EPOCH - 14 : training on 987411 raw words (885593 effective words) took 10.4s, 84983 effective words/s\n",
            "INFO - 14:52:48: EPOCH 15 - PROGRESS: at 9.82% examples, 80594 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:49: EPOCH 15 - PROGRESS: at 19.93% examples, 82969 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:50: EPOCH 15 - PROGRESS: at 30.07% examples, 83520 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:52: EPOCH 15 - PROGRESS: at 40.26% examples, 83829 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:53: EPOCH 15 - PROGRESS: at 50.30% examples, 83995 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:54: EPOCH 15 - PROGRESS: at 60.26% examples, 84063 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 14:52:55: EPOCH 15 - PROGRESS: at 70.56% examples, 84171 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:56: EPOCH 15 - PROGRESS: at 80.91% examples, 84271 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:57: EPOCH 15 - PROGRESS: at 91.36% examples, 84294 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:52:58: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:52:58: EPOCH - 15 : training on 987411 raw words (885593 effective words) took 10.4s, 85019 effective words/s\n",
            "INFO - 14:52:59: EPOCH 16 - PROGRESS: at 9.82% examples, 79922 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:00: EPOCH 16 - PROGRESS: at 19.93% examples, 81982 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:01: EPOCH 16 - PROGRESS: at 30.07% examples, 82845 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:02: EPOCH 16 - PROGRESS: at 40.26% examples, 83768 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:03: EPOCH 16 - PROGRESS: at 50.30% examples, 84175 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:04: EPOCH 16 - PROGRESS: at 60.26% examples, 84423 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 14:53:05: EPOCH 16 - PROGRESS: at 70.56% examples, 84582 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:06: EPOCH 16 - PROGRESS: at 80.91% examples, 84530 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 14:53:07: EPOCH 16 - PROGRESS: at 91.36% examples, 84668 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:08: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:53:08: EPOCH - 16 : training on 987411 raw words (885593 effective words) took 10.4s, 85443 effective words/s\n",
            "INFO - 14:53:09: EPOCH 17 - PROGRESS: at 7.77% examples, 66380 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:10: EPOCH 17 - PROGRESS: at 17.90% examples, 75482 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:11: EPOCH 17 - PROGRESS: at 28.08% examples, 78856 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:12: EPOCH 17 - PROGRESS: at 38.24% examples, 80466 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 14:53:13: EPOCH 17 - PROGRESS: at 48.29% examples, 81537 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:14: EPOCH 17 - PROGRESS: at 58.28% examples, 82246 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:15: EPOCH 17 - PROGRESS: at 68.49% examples, 82645 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:16: EPOCH 17 - PROGRESS: at 78.88% examples, 82988 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:18: EPOCH 17 - PROGRESS: at 89.27% examples, 83226 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:19: EPOCH 17 - PROGRESS: at 99.27% examples, 83778 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:19: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:53:19: EPOCH - 17 : training on 987411 raw words (885593 effective words) took 10.6s, 83940 effective words/s\n",
            "INFO - 14:53:20: EPOCH 18 - PROGRESS: at 9.82% examples, 79688 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:21: EPOCH 18 - PROGRESS: at 19.93% examples, 82828 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:22: EPOCH 18 - PROGRESS: at 30.07% examples, 83549 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:23: EPOCH 18 - PROGRESS: at 40.26% examples, 84206 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:24: EPOCH 18 - PROGRESS: at 50.30% examples, 84444 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:25: EPOCH 18 - PROGRESS: at 60.26% examples, 84802 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:26: EPOCH 18 - PROGRESS: at 70.56% examples, 84890 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:27: EPOCH 18 - PROGRESS: at 80.91% examples, 85079 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:28: EPOCH 18 - PROGRESS: at 91.36% examples, 85209 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:53:29: EPOCH - 18 : training on 987411 raw words (885593 effective words) took 10.3s, 85829 effective words/s\n",
            "INFO - 14:53:30: EPOCH 19 - PROGRESS: at 9.82% examples, 80983 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:31: EPOCH 19 - PROGRESS: at 19.93% examples, 83060 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:32: EPOCH 19 - PROGRESS: at 30.07% examples, 83955 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:33: EPOCH 19 - PROGRESS: at 40.26% examples, 84403 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:34: EPOCH 19 - PROGRESS: at 50.30% examples, 84719 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:35: EPOCH 19 - PROGRESS: at 60.26% examples, 84931 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:36: EPOCH 19 - PROGRESS: at 70.56% examples, 85062 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:37: EPOCH 19 - PROGRESS: at 80.91% examples, 85144 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:38: EPOCH 19 - PROGRESS: at 91.36% examples, 85128 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:39: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:53:39: EPOCH - 19 : training on 987411 raw words (885593 effective words) took 10.3s, 85728 effective words/s\n",
            "INFO - 14:53:40: EPOCH 20 - PROGRESS: at 9.82% examples, 80314 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:41: EPOCH 20 - PROGRESS: at 19.93% examples, 82540 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:42: EPOCH 20 - PROGRESS: at 30.07% examples, 83138 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:44: EPOCH 20 - PROGRESS: at 40.26% examples, 83952 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:45: EPOCH 20 - PROGRESS: at 50.30% examples, 84265 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:46: EPOCH 20 - PROGRESS: at 60.26% examples, 84402 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:47: EPOCH 20 - PROGRESS: at 70.56% examples, 84566 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:48: EPOCH 20 - PROGRESS: at 80.91% examples, 84709 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:49: EPOCH 20 - PROGRESS: at 90.32% examples, 83422 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:50: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:53:50: EPOCH - 20 : training on 987411 raw words (885593 effective words) took 10.5s, 84155 effective words/s\n",
            "INFO - 14:53:51: EPOCH 21 - PROGRESS: at 8.80% examples, 78874 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:52: EPOCH 21 - PROGRESS: at 18.90% examples, 82105 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:53: EPOCH 21 - PROGRESS: at 29.08% examples, 83355 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:54: EPOCH 21 - PROGRESS: at 39.24% examples, 83977 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:55: EPOCH 21 - PROGRESS: at 49.28% examples, 84460 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:56: EPOCH 21 - PROGRESS: at 59.25% examples, 84788 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:57: EPOCH 21 - PROGRESS: at 69.53% examples, 84848 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:58: EPOCH 21 - PROGRESS: at 79.88% examples, 85028 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:53:59: EPOCH 21 - PROGRESS: at 90.32% examples, 85156 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:00: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:54:00: EPOCH - 21 : training on 987411 raw words (885593 effective words) took 10.3s, 85960 effective words/s\n",
            "INFO - 14:54:01: EPOCH 22 - PROGRESS: at 9.82% examples, 80394 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:02: EPOCH 22 - PROGRESS: at 19.93% examples, 82734 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:03: EPOCH 22 - PROGRESS: at 30.07% examples, 83803 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:04: EPOCH 22 - PROGRESS: at 40.26% examples, 84421 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:05: EPOCH 22 - PROGRESS: at 50.30% examples, 84854 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:06: EPOCH 22 - PROGRESS: at 60.26% examples, 85077 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:07: EPOCH 22 - PROGRESS: at 70.56% examples, 85231 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:09: EPOCH 22 - PROGRESS: at 80.91% examples, 85249 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:10: EPOCH 22 - PROGRESS: at 91.36% examples, 85352 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:10: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:54:10: EPOCH - 22 : training on 987411 raw words (885593 effective words) took 10.3s, 86013 effective words/s\n",
            "INFO - 14:54:11: EPOCH 23 - PROGRESS: at 8.80% examples, 78269 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:12: EPOCH 23 - PROGRESS: at 18.90% examples, 81910 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:14: EPOCH 23 - PROGRESS: at 29.08% examples, 82771 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:15: EPOCH 23 - PROGRESS: at 39.24% examples, 83293 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:16: EPOCH 23 - PROGRESS: at 49.28% examples, 83749 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:17: EPOCH 23 - PROGRESS: at 59.25% examples, 84066 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:18: EPOCH 23 - PROGRESS: at 69.53% examples, 84350 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:19: EPOCH 23 - PROGRESS: at 79.88% examples, 84561 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:20: EPOCH 23 - PROGRESS: at 90.32% examples, 84716 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:21: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:54:21: EPOCH - 23 : training on 987411 raw words (885593 effective words) took 10.4s, 85493 effective words/s\n",
            "INFO - 14:54:22: EPOCH 24 - PROGRESS: at 9.82% examples, 79373 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 14:54:23: EPOCH 24 - PROGRESS: at 19.93% examples, 82144 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:24: EPOCH 24 - PROGRESS: at 30.07% examples, 83224 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:25: EPOCH 24 - PROGRESS: at 40.26% examples, 83679 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:26: EPOCH 24 - PROGRESS: at 50.30% examples, 84027 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:27: EPOCH 24 - PROGRESS: at 60.26% examples, 84285 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:28: EPOCH 24 - PROGRESS: at 70.56% examples, 84361 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:29: EPOCH 24 - PROGRESS: at 79.88% examples, 82962 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:30: EPOCH 24 - PROGRESS: at 90.32% examples, 83158 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:31: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:54:31: EPOCH - 24 : training on 987411 raw words (885593 effective words) took 10.5s, 83960 effective words/s\n",
            "INFO - 14:54:32: EPOCH 25 - PROGRESS: at 9.82% examples, 80038 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:34: EPOCH 25 - PROGRESS: at 19.93% examples, 82855 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:35: EPOCH 25 - PROGRESS: at 30.07% examples, 83661 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:36: EPOCH 25 - PROGRESS: at 40.26% examples, 84246 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:37: EPOCH 25 - PROGRESS: at 50.30% examples, 84513 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:38: EPOCH 25 - PROGRESS: at 60.26% examples, 84626 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:39: EPOCH 25 - PROGRESS: at 70.56% examples, 84643 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:40: EPOCH 25 - PROGRESS: at 80.91% examples, 84579 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:41: EPOCH 25 - PROGRESS: at 91.36% examples, 84436 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:42: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:54:42: EPOCH - 25 : training on 987411 raw words (885593 effective words) took 10.4s, 85012 effective words/s\n",
            "INFO - 14:54:43: EPOCH 26 - PROGRESS: at 8.80% examples, 78036 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 14:54:44: EPOCH 26 - PROGRESS: at 18.90% examples, 81485 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:45: EPOCH 26 - PROGRESS: at 29.08% examples, 82411 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:46: EPOCH 26 - PROGRESS: at 39.24% examples, 83228 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:47: EPOCH 26 - PROGRESS: at 49.28% examples, 83419 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 14:54:48: EPOCH 26 - PROGRESS: at 59.25% examples, 83642 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:49: EPOCH 26 - PROGRESS: at 69.53% examples, 83651 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:50: EPOCH 26 - PROGRESS: at 79.88% examples, 83734 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:51: EPOCH 26 - PROGRESS: at 90.32% examples, 83809 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:52: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:54:52: EPOCH - 26 : training on 987411 raw words (885593 effective words) took 10.5s, 84572 effective words/s\n",
            "INFO - 14:54:53: EPOCH 27 - PROGRESS: at 9.82% examples, 79663 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:54: EPOCH 27 - PROGRESS: at 19.93% examples, 82389 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:55: EPOCH 27 - PROGRESS: at 30.07% examples, 83019 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:57: EPOCH 27 - PROGRESS: at 40.26% examples, 83478 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:58: EPOCH 27 - PROGRESS: at 50.30% examples, 83694 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:54:59: EPOCH 27 - PROGRESS: at 60.26% examples, 84049 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:00: EPOCH 27 - PROGRESS: at 70.56% examples, 84132 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:01: EPOCH 27 - PROGRESS: at 80.91% examples, 84180 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:02: EPOCH 27 - PROGRESS: at 91.36% examples, 84305 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:03: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:55:03: EPOCH - 27 : training on 987411 raw words (885593 effective words) took 10.4s, 84945 effective words/s\n",
            "INFO - 14:55:04: EPOCH 28 - PROGRESS: at 8.80% examples, 78041 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:05: EPOCH 28 - PROGRESS: at 18.90% examples, 81964 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:06: EPOCH 28 - PROGRESS: at 29.08% examples, 82743 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:07: EPOCH 28 - PROGRESS: at 39.24% examples, 83359 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:08: EPOCH 28 - PROGRESS: at 49.28% examples, 83746 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:09: EPOCH 28 - PROGRESS: at 59.25% examples, 83763 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:10: EPOCH 28 - PROGRESS: at 67.46% examples, 82040 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:11: EPOCH 28 - PROGRESS: at 77.84% examples, 82271 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:12: EPOCH 28 - PROGRESS: at 88.22% examples, 82625 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:13: EPOCH 28 - PROGRESS: at 98.33% examples, 83036 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:13: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:55:13: EPOCH - 28 : training on 987411 raw words (885593 effective words) took 10.6s, 83412 effective words/s\n",
            "INFO - 14:55:14: EPOCH 29 - PROGRESS: at 9.82% examples, 79681 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:16: EPOCH 29 - PROGRESS: at 19.93% examples, 81483 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:17: EPOCH 29 - PROGRESS: at 30.07% examples, 82692 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:18: EPOCH 29 - PROGRESS: at 40.26% examples, 83214 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:19: EPOCH 29 - PROGRESS: at 50.30% examples, 83522 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:20: EPOCH 29 - PROGRESS: at 60.26% examples, 83670 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:21: EPOCH 29 - PROGRESS: at 70.56% examples, 83741 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:22: EPOCH 29 - PROGRESS: at 80.91% examples, 83803 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:23: EPOCH 29 - PROGRESS: at 91.36% examples, 83947 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:24: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:55:24: EPOCH - 29 : training on 987411 raw words (885593 effective words) took 10.5s, 84592 effective words/s\n",
            "INFO - 14:55:25: EPOCH 30 - PROGRESS: at 8.80% examples, 78899 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:26: EPOCH 30 - PROGRESS: at 18.90% examples, 81803 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:27: EPOCH 30 - PROGRESS: at 29.08% examples, 82840 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:28: EPOCH 30 - PROGRESS: at 39.24% examples, 83759 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:29: EPOCH 30 - PROGRESS: at 49.28% examples, 84292 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:30: EPOCH 30 - PROGRESS: at 59.25% examples, 84669 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:31: EPOCH 30 - PROGRESS: at 69.53% examples, 84903 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:32: EPOCH 30 - PROGRESS: at 79.88% examples, 84989 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:33: EPOCH 30 - PROGRESS: at 90.32% examples, 85211 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 14:55:34: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 14:55:34: EPOCH - 30 : training on 987411 raw words (885593 effective words) took 10.3s, 86023 effective words/s\n",
            "INFO - 14:55:34: training on a 29622330 raw words (26567790 effective words) took 316.1s, 84048 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26567790, 29622330)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4aa0DVvow3R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ca30036-ebcc-4f48-9c59-722f7bf927ad"
      },
      "source": [
        "#Tornando o modelo mais eficiente em quest√µes de uso de mem√≥ria.\n",
        "w2v_model.init_sims(replace=True)"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 14:55:34: precomputing L2-norms of word weight vectors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMEQVcaV6K-t",
        "colab_type": "text"
      },
      "source": [
        "**A partir do Word2VEC podemos verificar a similaridade de outras palavras para determinados termos.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG8WLQdaqJpZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "5cef2991-73bd-45cb-dbc9-67d261fac3b7"
      },
      "source": [
        "w2v_model.wv.most_similar([\"vacina\"])"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('vacina_contra', 0.609605073928833),\n",
              " ('vacina_chinesa', 0.5751551985740662),\n",
              " ('tomar_vacina', 0.5486936569213867),\n",
              " ('\"vacina', 0.5384091138839722),\n",
              " ('vacinas', 0.5198544263839722),\n",
              " ('doses_vacina', 0.5139744281768799),\n",
              " ('cura_pro', 0.493501752614975),\n",
              " ('testes_vacina', 0.46525266766548157),\n",
              " ('#vacina', 0.45659971237182617),\n",
              " ('vacina_oxford', 0.447509229183197)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzHB_w9O67oU",
        "colab_type": "text"
      },
      "source": [
        "**Podemos determinar filtros para uma verifica√ß√£o de similaridade.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsZeL1qQ62sP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "022cd24d-3d05-44d2-f842-d2c5da35831c"
      },
      "source": [
        "w2v_model.wv.most_similar([\"recuperados\"])"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('curados', 0.671785295009613),\n",
              " ('pacientes_recuperados', 0.667811930179596),\n",
              " ('pessoas_recuperadas', 0.6040254235267639),\n",
              " ('casos_ativos', 0.588263988494873),\n",
              " ('pessoas_curadas', 0.5835896730422974),\n",
              " ('v√≠timas_fatais', 0.5382181406021118),\n",
              " ('recuperados‚Ä¶', 0.531403124332428),\n",
              " ('confirma√ß√µes', 0.5296151041984558),\n",
              " ('mortes_confirmadas', 0.5178470015525818),\n",
              " ('pessoas_infectadas', 0.5082339644432068)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rduVJL697A28",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "dac72ae9-c3d5-4915-e3fc-766f1ba476b5"
      },
      "source": [
        "w2v_model.wv.most_similar([\"mortes\"])"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('mortes_causadas', 0.7485598921775818),\n",
              " ('novas_mortes', 0.701056957244873),\n",
              " ('mortes_confirmadas', 0.6430712938308716),\n",
              " ('mortes,', 0.6371706128120422),\n",
              " ('vidas_perdidas', 0.6332045197486877),\n",
              " ('√≥bitos', 0.6250780820846558),\n",
              " ('1300_mortes', 0.6233320236206055),\n",
              " ('mortos', 0.6231629252433777),\n",
              " ('mortes_di√°rias', 0.6212472915649414),\n",
              " ('mil_mortes', 0.6204636096954346)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GnO8u4J6fnY",
        "colab_type": "text"
      },
      "source": [
        "**Podemos compararar a taxa de similaridade para termos espec√≠ficos.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSZ3e0qeqR0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "5d490a12-54a6-45f5-9b11-d510f2dfe5ee"
      },
      "source": [
        "w2v_model.wv.similarity(\"coronavirus\", 'mortes')"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.3836797"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNOuLotAqZuy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "3d81aa47-9b4b-4124-d7a4-513a99904635"
      },
      "source": [
        "w2v_model.wv.similarity(\"coronavirus\", 'casos')"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.40394896"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrv67Or1qc0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "cd3267c7-e0e1-4506-f012-ddc99d2fd9d9"
      },
      "source": [
        "w2v_model.wv.similarity(\"pandemia\", 'coronavirus')"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.10929663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg6Us2Tp9NwJ",
        "colab_type": "text"
      },
      "source": [
        "# Aplicando K-Means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r9qksJG9-Wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importando algoritmo KMeans da biblioteca Sklearn.\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnjRhOa0XRzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_vectors = w2v_model.wv\n",
        "model = KMeans(n_clusters=3, init='k-means++', max_iter=1000, n_init=50).fit(X=word_vectors.vectors)\n",
        "positive_cluster_center = model.cluster_centers_[0]\n",
        "negative_cluster_center = model.cluster_centers_[1]\n",
        "neutral_cluster_center = model.cluster_centers_[2]"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqR8eQhEXbCm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "91244f1f-f9f6-45ba-ec18-98c4677033db"
      },
      "source": [
        "word_vectors.vectors"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.0081975 ,  0.04720695, -0.04763551, ...,  0.01966804,\n",
              "         0.11293161, -0.07009899],\n",
              "       [ 0.0133413 ,  0.10912789, -0.05271741, ...,  0.03482201,\n",
              "         0.09564679, -0.10163205],\n",
              "       [-0.01201384, -0.09868426,  0.04223893, ..., -0.05724829,\n",
              "        -0.06662759, -0.02191113],\n",
              "       ...,\n",
              "       [-0.03365825, -0.00169525,  0.06411723, ...,  0.0335671 ,\n",
              "        -0.02276869,  0.06044143],\n",
              "       [ 0.0180357 ,  0.01752128, -0.02925419, ...,  0.02912579,\n",
              "         0.00297402,  0.00167207],\n",
              "       [ 0.04025285,  0.03373059, -0.02376372, ..., -0.02053193,\n",
              "        -0.00142729,  0.04017974]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KqEfIOPXKbb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a958bdca-60b9-494e-9e63-a1de9878632b"
      },
      "source": [
        "model.cluster_centers_"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.69353129e-02, -1.28714060e-02,  1.18289161e-02,\n",
              "        -8.39804113e-03, -1.28686344e-02,  4.41465527e-05,\n",
              "        -2.90056523e-02,  1.15854386e-02, -1.67149282e-03,\n",
              "        -3.71328294e-02, -1.38816666e-02, -3.42764296e-02,\n",
              "         1.55072119e-02,  1.80993397e-02,  2.20879875e-02,\n",
              "         4.55052918e-03,  4.11116984e-04,  1.23869535e-03,\n",
              "         2.72744056e-03, -8.67928937e-03, -2.24724039e-02,\n",
              "        -3.66220810e-02,  2.15306431e-02,  4.53119725e-03,\n",
              "        -8.47364124e-03, -2.32212003e-02,  1.71815231e-02,\n",
              "        -9.19501763e-03,  1.63319856e-02,  7.27554457e-03,\n",
              "         1.79597382e-02,  1.65261850e-02, -7.74508249e-03,\n",
              "        -7.94370379e-03,  2.81177391e-03,  6.44521601e-03,\n",
              "         1.13219740e-02, -9.63797793e-03, -2.57210294e-03,\n",
              "        -2.19659992e-02, -1.55437228e-04,  1.39029641e-02,\n",
              "        -3.06272730e-02, -9.10585467e-03,  3.75240557e-02,\n",
              "        -1.82352811e-02,  1.06848043e-03,  1.18571417e-02,\n",
              "        -2.60140672e-02,  3.09641995e-02,  2.81891972e-03,\n",
              "         2.72018649e-03,  6.63522817e-03,  7.01281428e-03,\n",
              "         2.18930952e-02, -1.75318979e-02, -1.52697433e-02,\n",
              "         2.62772441e-02,  4.02146019e-03, -1.40379770e-02,\n",
              "        -2.16051713e-02,  3.00511327e-02,  3.66817415e-03,\n",
              "         3.96691076e-02,  2.67663971e-03, -2.86460482e-02,\n",
              "         4.28360887e-03, -9.60156880e-03,  2.73043867e-02,\n",
              "        -2.04061698e-02,  5.44934161e-03, -3.73769067e-02,\n",
              "         1.68224741e-02,  2.21765637e-02, -7.95204006e-03,\n",
              "        -8.28217529e-03, -2.02516280e-03, -3.81737575e-03,\n",
              "        -1.05666984e-02, -1.09417364e-02, -3.00154686e-02,\n",
              "         1.27302855e-02, -1.31413005e-02, -3.17826234e-02,\n",
              "         2.00985204e-02,  6.22034306e-03,  2.12448463e-02,\n",
              "        -1.34535320e-03,  3.00872792e-02,  2.20853128e-02,\n",
              "         2.66219005e-02,  3.93462777e-02, -3.23807374e-02,\n",
              "        -3.33340419e-03, -6.04161527e-03,  5.33787534e-03,\n",
              "         9.29467659e-03, -1.62745006e-02, -1.92789640e-03,\n",
              "         3.84254009e-03,  1.58916991e-02,  5.18547744e-03,\n",
              "         1.51770227e-02, -2.39966381e-02, -4.82183369e-03,\n",
              "         1.39956567e-02,  1.00110080e-02,  1.50768440e-02,\n",
              "        -2.24903226e-03, -2.72074752e-02,  3.49031202e-02,\n",
              "         1.54344691e-02,  1.22866612e-02,  9.68893059e-03,\n",
              "        -1.30259916e-02,  9.22144298e-03,  1.74173713e-02,\n",
              "        -7.17448071e-04, -6.96043484e-04,  1.75535702e-03,\n",
              "        -1.44719388e-02, -1.30506502e-02, -9.82615538e-03,\n",
              "         3.87562439e-02, -3.99924163e-03,  7.90082850e-03,\n",
              "        -1.93054266e-02, -1.30706523e-02,  2.32783817e-02,\n",
              "         2.06502099e-02, -1.67186968e-02, -3.16435867e-03,\n",
              "         3.62917781e-04,  4.00292221e-03, -3.58204334e-03,\n",
              "        -3.03843170e-02,  3.59668396e-02, -1.45435138e-02,\n",
              "        -1.74732301e-02, -4.61972784e-03, -7.27641955e-03,\n",
              "        -4.70883120e-03, -7.88162369e-03,  1.15583502e-02,\n",
              "        -2.37266198e-02, -8.81582731e-04, -3.31200380e-03,\n",
              "        -2.10717730e-02, -1.23451427e-02,  1.36963222e-02,\n",
              "        -3.91327590e-02,  1.71676837e-02, -1.21475141e-02,\n",
              "        -6.69218833e-03, -3.31600532e-02, -4.44091856e-05,\n",
              "        -2.68768966e-02, -1.03200059e-02,  9.36408527e-03,\n",
              "        -1.38996299e-02,  1.93629134e-02, -7.26153236e-03,\n",
              "         1.48483813e-02,  8.54477193e-03,  5.18633891e-03,\n",
              "        -6.48436928e-03,  3.40183079e-02,  1.38196703e-02,\n",
              "        -1.79873332e-02, -2.36141086e-02,  5.39825391e-03,\n",
              "         1.58967637e-02,  5.81105100e-03, -1.11935218e-03,\n",
              "        -1.16867330e-02, -1.62269715e-02, -2.29576807e-02,\n",
              "        -4.30982001e-03, -8.24223179e-03,  8.11587088e-05,\n",
              "         2.29545683e-02, -2.33752932e-02,  8.31520185e-03,\n",
              "        -2.40558963e-02, -2.76471693e-02,  3.48214880e-02,\n",
              "        -7.50759011e-03, -4.91399132e-03, -2.85076872e-02,\n",
              "        -1.93535686e-02, -2.58435160e-02,  1.24821039e-02,\n",
              "         1.07332878e-02, -1.91311985e-02, -2.76820455e-03,\n",
              "        -2.42353678e-02,  3.77266761e-03,  2.45999303e-02,\n",
              "         1.23091526e-02,  3.77001837e-02, -1.77584421e-02,\n",
              "        -2.80358009e-02,  1.08746614e-03, -1.62188858e-02,\n",
              "        -2.04502493e-02, -2.20714994e-02, -1.82839334e-02,\n",
              "         3.51452362e-03,  2.32574865e-02, -3.79500836e-02,\n",
              "         1.87725183e-02,  1.23910895e-02,  6.83285296e-04,\n",
              "        -2.40054522e-02,  1.74714122e-02,  1.66593492e-03,\n",
              "        -9.92949400e-03,  3.97766428e-03, -2.53371708e-02,\n",
              "         1.57819800e-02, -3.12360423e-03,  4.00843332e-04,\n",
              "         8.73851497e-03,  4.48531844e-03, -2.62269601e-02,\n",
              "        -2.95483414e-03, -1.67798642e-02, -2.75681913e-02,\n",
              "        -1.17527070e-02, -1.86338201e-02,  5.38558327e-03,\n",
              "         1.94645133e-02, -2.27843896e-02,  1.66377460e-03,\n",
              "         2.12273076e-02,  1.30533706e-02,  1.07238116e-02,\n",
              "        -3.36684324e-02,  1.50353545e-02,  2.89613046e-02,\n",
              "        -2.40331534e-02,  6.70251995e-03,  4.28396277e-04,\n",
              "        -1.50651513e-02,  4.06927802e-02, -3.63550149e-04,\n",
              "         4.06519100e-02,  2.37655118e-02,  3.14075835e-02,\n",
              "        -2.92881243e-02,  1.82599369e-02,  9.84386913e-03,\n",
              "        -2.45682932e-02,  4.14035097e-02, -3.11774183e-02,\n",
              "        -3.45248096e-02, -1.20103136e-02,  1.15597965e-02,\n",
              "         1.60865802e-02,  6.29833993e-03, -2.12701485e-02,\n",
              "         1.58337802e-02, -4.30732500e-03,  1.53314676e-02,\n",
              "        -8.59916210e-04, -3.96937132e-03, -8.93422030e-03,\n",
              "        -4.55981344e-02,  1.64009109e-02, -1.78057738e-02,\n",
              "         2.15995852e-02, -1.18670352e-02,  1.30047128e-02,\n",
              "         1.00549422e-02,  9.96964145e-03,  4.84729186e-04,\n",
              "         2.91925250e-03,  1.41774239e-02,  2.04684790e-02,\n",
              "         9.52520687e-03, -7.37749971e-03, -5.00379764e-02,\n",
              "         3.80371651e-03, -8.35105591e-03,  7.03797676e-03,\n",
              "         1.77434795e-02, -1.37146320e-02, -1.59046240e-02,\n",
              "         4.77148034e-03, -2.57591531e-03, -1.61288530e-02,\n",
              "        -5.11955097e-03,  7.73608126e-03, -2.31746584e-02,\n",
              "         4.50664498e-02,  2.63354946e-02, -2.25750450e-03,\n",
              "        -1.96994878e-02, -6.20197970e-03,  2.61136442e-02],\n",
              "       [ 2.12198291e-02,  3.15490505e-03, -2.38714069e-02,\n",
              "         1.12706330e-03, -1.12250196e-02, -2.10822336e-02,\n",
              "        -3.12545411e-02, -1.50514976e-03,  9.21240426e-04,\n",
              "         1.14355590e-02, -1.68761052e-02, -1.59646999e-02,\n",
              "         3.66123542e-02,  1.31476214e-02, -9.88591928e-04,\n",
              "         1.45054003e-03, -8.28487985e-03,  3.07741109e-02,\n",
              "        -8.82524438e-03,  1.29881073e-02, -5.84709980e-02,\n",
              "         2.18949188e-03,  3.80628109e-02,  1.61867775e-02,\n",
              "         1.65899750e-02, -1.84059665e-02, -2.11554542e-02,\n",
              "        -2.33161822e-02,  3.51044461e-02, -2.87282234e-03,\n",
              "        -2.23296368e-03,  2.55300235e-02, -2.02918351e-02,\n",
              "         1.52718164e-02, -3.28536332e-03, -3.36007513e-02,\n",
              "         2.21795961e-02,  3.30817550e-02,  1.38424411e-02,\n",
              "        -2.68357005e-02, -2.48919986e-03,  2.56258845e-02,\n",
              "        -1.90076940e-02, -1.74641795e-02, -2.37792488e-02,\n",
              "        -5.68350032e-02, -3.45645822e-03,  4.86749820e-02,\n",
              "        -2.22491845e-02,  3.23125422e-02, -1.82082690e-02,\n",
              "         4.15047705e-02,  3.02168541e-02, -2.71077314e-03,\n",
              "         2.48111673e-02, -8.60818755e-03, -4.32351418e-03,\n",
              "         1.18850358e-03, -8.52824841e-03,  2.58191209e-03,\n",
              "        -1.44450851e-02,  3.30815017e-02,  3.87096917e-03,\n",
              "         4.35539708e-03,  1.86583251e-02, -7.43627269e-03,\n",
              "         1.75121322e-03,  2.05197446e-02,  3.04761995e-02,\n",
              "        -7.65069108e-03,  1.01507558e-02, -2.62338817e-02,\n",
              "         2.03533564e-04,  2.97370646e-02, -2.13241130e-02,\n",
              "        -7.29077961e-03, -4.10436392e-02, -4.43296209e-02,\n",
              "        -4.42934921e-04,  1.24680717e-02, -1.40339490e-02,\n",
              "         4.45285067e-02, -6.76002819e-03, -2.21795086e-02,\n",
              "         2.87899897e-02, -1.22640291e-02,  8.42390954e-03,\n",
              "         3.17785628e-02,  1.02483593e-02,  7.47313164e-03,\n",
              "         4.07624319e-02,  2.41793171e-02, -3.75812612e-02,\n",
              "        -2.24664109e-03,  2.23248191e-02,  1.77065935e-03,\n",
              "        -1.88549852e-03, -2.95741521e-02, -1.03405369e-02,\n",
              "         1.23492694e-02, -1.07237808e-02,  5.69397062e-02,\n",
              "        -1.27623789e-03, -1.80225670e-02,  9.10986587e-03,\n",
              "        -2.52169445e-02,  2.06251219e-02, -2.28063706e-02,\n",
              "        -4.94121388e-03, -4.12861481e-02,  1.90924853e-02,\n",
              "        -1.34227201e-02,  3.29435989e-02, -5.25945798e-05,\n",
              "         1.04753533e-02,  2.43286304e-02,  2.90188305e-02,\n",
              "         3.18135954e-02, -1.58511065e-02,  7.23581063e-03,\n",
              "        -4.23796140e-02, -1.34776160e-02,  1.78722497e-02,\n",
              "         3.94005030e-02, -1.94929074e-02,  3.98322707e-03,\n",
              "        -7.47119635e-03,  3.81808332e-03,  3.18939518e-03,\n",
              "         1.84426904e-02, -3.45645510e-02,  6.52876031e-03,\n",
              "         3.96373216e-04,  1.13072731e-02, -1.08606098e-02,\n",
              "        -1.76263489e-02,  4.44545820e-02, -2.01912224e-02,\n",
              "        -2.24467814e-02,  6.04893547e-03, -3.76310647e-02,\n",
              "         2.06456333e-02,  1.89659484e-02,  2.22687870e-02,\n",
              "         3.08094062e-02,  3.71905509e-04, -2.88345329e-02,\n",
              "        -2.57284101e-02, -1.33388946e-02, -1.30669381e-02,\n",
              "        -2.30334848e-02,  2.88104601e-02,  7.35617662e-03,\n",
              "        -1.47102633e-02, -8.41324404e-03, -2.36532092e-02,\n",
              "        -4.40521836e-02,  6.51986804e-04,  8.39470234e-03,\n",
              "        -7.84423109e-03,  6.26326129e-02, -3.46450508e-02,\n",
              "         4.65815067e-02, -7.14039756e-03, -3.48865986e-02,\n",
              "         4.81867697e-03,  1.74996592e-02,  5.63551020e-03,\n",
              "        -1.28427614e-02, -1.40139796e-02, -8.55891220e-03,\n",
              "        -1.97945675e-03, -1.43011343e-02, -6.16844278e-03,\n",
              "         6.25507301e-03, -3.67490388e-02, -1.46633936e-02,\n",
              "         3.33250463e-02, -5.27865440e-02, -1.86940543e-02,\n",
              "         4.26360406e-04, -3.98737416e-02,  4.63584810e-02,\n",
              "        -2.01435685e-02, -2.78208125e-02,  2.61727925e-02,\n",
              "        -2.22562067e-02, -3.88173573e-02, -4.45570238e-03,\n",
              "        -1.31186359e-02, -1.38319731e-02,  1.30367894e-02,\n",
              "        -6.93016965e-03, -2.87355594e-02, -1.52502572e-02,\n",
              "        -2.27191187e-02,  1.48744397e-02,  1.98156238e-02,\n",
              "         2.52188500e-02, -8.48055352e-03,  5.40350191e-03,\n",
              "        -6.24050573e-03, -1.79862529e-02, -1.41372588e-02,\n",
              "         1.81079544e-02, -3.23112980e-02,  1.48241483e-02,\n",
              "        -1.17512047e-03,  2.54913680e-02, -1.32415909e-03,\n",
              "         1.07169785e-02, -9.13765561e-03,  3.71210240e-02,\n",
              "         2.26301290e-02,  8.64772964e-03, -1.98526084e-02,\n",
              "        -2.48859301e-02,  5.65532176e-03,  1.75073482e-02,\n",
              "        -2.65228818e-03, -1.69903152e-02, -9.86128580e-04,\n",
              "        -1.99984480e-03, -2.62080180e-03,  6.02990808e-03,\n",
              "         1.75470971e-02, -5.33347279e-02, -2.58827601e-02,\n",
              "         1.51385097e-02, -1.57018416e-02,  4.89723589e-03,\n",
              "         1.71767212e-02, -1.76846504e-03, -1.12548070e-02,\n",
              "         5.54178879e-02,  5.15073985e-02,  2.91416608e-02,\n",
              "         1.54902674e-02,  6.54125470e-04, -4.04024031e-03,\n",
              "        -1.07932556e-02,  3.81731661e-03, -1.51801500e-02,\n",
              "        -3.58059779e-02,  3.87434177e-02,  4.70474269e-03,\n",
              "         1.51600689e-05,  1.51318647e-02, -1.07914796e-02,\n",
              "        -2.03707665e-02,  3.60642150e-02, -3.62852402e-03,\n",
              "         4.66148369e-04, -2.32113041e-02, -4.77209054e-02,\n",
              "        -1.35841360e-02, -4.88342345e-02, -8.95095710e-03,\n",
              "         5.90509921e-03, -8.10742553e-04, -9.84259509e-03,\n",
              "         3.25361118e-02, -1.62063148e-02,  5.26472777e-02,\n",
              "        -1.28835263e-02,  1.61021352e-02, -1.90317035e-02,\n",
              "        -6.48699254e-02, -2.48289704e-02, -1.14798993e-02,\n",
              "         3.63898873e-02,  1.99479936e-03, -1.90997170e-03,\n",
              "        -9.83590819e-03,  1.27598783e-03, -2.15824991e-02,\n",
              "        -8.32469855e-03, -1.76049694e-02, -2.65209749e-03,\n",
              "         3.72694656e-02, -2.80212015e-02, -2.05033720e-02,\n",
              "         7.23725511e-03,  1.09205442e-03,  8.51927511e-03,\n",
              "         2.39310078e-02, -1.20857656e-02, -2.29464397e-02,\n",
              "         4.40546833e-02, -4.56773024e-03, -4.90928069e-02,\n",
              "         7.21894670e-04,  4.71375044e-03,  1.73370503e-02,\n",
              "         2.22261511e-02,  2.17489731e-02,  2.98582274e-03,\n",
              "         2.53348378e-03, -6.08773995e-03,  4.93038725e-03],\n",
              "       [ 3.49145965e-03,  4.15248871e-02,  5.35654835e-03,\n",
              "        -1.36806592e-02, -1.23352613e-02, -1.94235072e-02,\n",
              "        -1.53373238e-02, -1.33597455e-03,  9.39172413e-03,\n",
              "         1.73857138e-02, -1.68761443e-02, -2.26469226e-02,\n",
              "         8.86113755e-03,  3.51982657e-03, -8.62298161e-03,\n",
              "        -1.38864946e-02, -4.68834955e-03,  6.10573962e-03,\n",
              "        -1.88288162e-03,  1.10620644e-03, -2.18937676e-02,\n",
              "         2.56144255e-03,  3.54755595e-02,  1.82371847e-02,\n",
              "         2.08092593e-02, -8.42419360e-03, -1.48054389e-02,\n",
              "        -2.61388868e-02,  3.01507767e-02, -5.00354823e-03,\n",
              "        -2.96892831e-03,  8.63808207e-03, -3.32884043e-02,\n",
              "        -2.34795036e-03, -2.89695011e-03, -3.68883014e-02,\n",
              "         2.03133039e-02,  2.49340236e-02,  5.42150997e-03,\n",
              "        -2.06776354e-02,  3.28679290e-03,  2.07261182e-02,\n",
              "        -7.48473406e-03, -1.89986434e-02, -1.90268196e-02,\n",
              "        -3.10497060e-02,  2.13039038e-03,  1.54146003e-02,\n",
              "         1.84227899e-02, -2.33085826e-03, -1.30751999e-02,\n",
              "         3.10220290e-02, -2.36730352e-02,  7.33738299e-03,\n",
              "         2.38911733e-02,  8.97644367e-03,  2.26773359e-02,\n",
              "        -1.44300144e-03,  8.78470112e-03,  7.21087540e-03,\n",
              "         4.14895546e-03,  2.17305459e-02,  1.57526117e-02,\n",
              "        -5.63977100e-03,  1.31241055e-02, -1.00418534e-02,\n",
              "        -4.55284584e-03,  1.78482607e-02,  4.56751660e-02,\n",
              "        -1.04518738e-02,  2.08118185e-02, -1.76110547e-02,\n",
              "         2.93904822e-03, -8.69140401e-03, -9.89463367e-03,\n",
              "        -4.93011344e-03, -2.19621379e-02, -3.76566388e-02,\n",
              "         1.27949538e-02,  1.01529313e-02, -1.75670981e-02,\n",
              "         2.04502754e-02, -2.25805845e-02, -2.65131611e-02,\n",
              "         1.98514070e-02, -1.91354360e-02,  7.11021107e-03,\n",
              "         2.35918984e-02,  2.59145889e-02, -7.71181844e-03,\n",
              "         3.09871230e-02,  4.23114523e-02, -1.78036541e-02,\n",
              "        -2.05330597e-03,  1.40093332e-02, -2.21219677e-02,\n",
              "        -1.97076909e-02, -2.86183301e-02, -1.65996328e-02,\n",
              "         1.77999157e-02,  2.42699347e-02,  3.56396474e-02,\n",
              "         1.36648882e-02, -1.74625553e-02,  1.73802313e-03,\n",
              "         1.16503211e-02,  2.41812095e-02, -4.22585160e-02,\n",
              "         1.09675704e-02, -3.18579376e-02,  5.24509698e-03,\n",
              "        -1.19739501e-02,  1.56594329e-02,  2.06257626e-02,\n",
              "         4.60042618e-02,  4.13833335e-02,  3.96899655e-02,\n",
              "         2.30044182e-02,  6.71287999e-05, -9.50289331e-03,\n",
              "         5.04613109e-03,  1.02137867e-02, -9.72876884e-03,\n",
              "         1.55190881e-02, -2.42896639e-02,  1.77433826e-02,\n",
              "         1.11880489e-02,  2.25176327e-02,  9.79753863e-03,\n",
              "         1.88254099e-03, -3.48559618e-02, -1.18469540e-02,\n",
              "        -1.17178550e-02,  6.79458026e-03, -3.01263062e-03,\n",
              "        -2.09459029e-02,  1.00581646e-02, -5.49979415e-03,\n",
              "        -1.45880682e-02,  1.25569338e-03, -3.28538977e-02,\n",
              "        -3.42353657e-02,  1.91305578e-02, -6.36009220e-03,\n",
              "         1.85453631e-02,  1.23496270e-02, -4.24915552e-03,\n",
              "        -2.17316896e-02, -6.52151741e-03, -3.32566467e-03,\n",
              "        -3.82482447e-03,  3.42662409e-02, -1.15195476e-02,\n",
              "        -1.26112588e-02,  5.83846867e-03, -3.63456532e-02,\n",
              "        -6.96003437e-03, -4.79360297e-03,  8.39818828e-03,\n",
              "         5.35341306e-03,  4.68073338e-02, -8.12354684e-03,\n",
              "         2.58422662e-02, -9.08927433e-03, -5.66495489e-03,\n",
              "         2.57051364e-02,  3.10471412e-02,  4.48270421e-03,\n",
              "        -2.90485658e-03, -9.17471759e-03,  6.50225114e-03,\n",
              "         4.30861767e-03,  1.24047315e-02, -4.83611319e-03,\n",
              "        -9.58323944e-03, -2.14083157e-02, -3.14964764e-02,\n",
              "         2.12519821e-02, -9.01368726e-03, -3.74389975e-03,\n",
              "         3.00969323e-03, -4.49192971e-02,  3.37083079e-02,\n",
              "        -2.58699600e-02,  1.37448180e-02,  3.07631083e-02,\n",
              "        -1.50339762e-02,  1.66864023e-02, -6.99124997e-03,\n",
              "        -2.03349460e-02, -9.53582581e-03,  1.29403453e-03,\n",
              "         1.48865515e-02, -4.97990139e-02,  1.22315576e-02,\n",
              "        -7.70113990e-03,  5.74243069e-03,  2.09161527e-02,\n",
              "         3.07481587e-02, -5.61798178e-03, -2.16827430e-02,\n",
              "        -1.67481788e-03,  2.46490426e-02, -1.95144117e-02,\n",
              "        -2.70540384e-03, -1.22486269e-02, -1.16682108e-02,\n",
              "        -2.11679116e-02,  1.23955496e-03,  1.46307694e-02,\n",
              "         2.95852832e-02,  1.91863813e-02,  7.57559855e-03,\n",
              "        -9.48040374e-03,  6.18054299e-03, -1.08584603e-02,\n",
              "        -3.31698917e-02, -1.76084670e-03, -1.90553144e-02,\n",
              "        -3.06021306e-03,  9.25420690e-03,  1.17945597e-02,\n",
              "         2.41813250e-02, -5.13649127e-03,  2.76735518e-04,\n",
              "         2.09413730e-02, -3.19449268e-02, -1.23696961e-02,\n",
              "         1.70812849e-03,  5.98725583e-03,  6.45823125e-03,\n",
              "         2.55867094e-03,  1.68110337e-02,  1.40275573e-02,\n",
              "         2.02222988e-02,  2.87878998e-02, -1.09648956e-02,\n",
              "         1.40342582e-02, -1.68696474e-02, -4.12583724e-03,\n",
              "        -3.10074091e-02,  1.44436108e-02, -3.35825160e-02,\n",
              "        -9.11020767e-03,  1.50481146e-02, -2.51780748e-02,\n",
              "         1.38018522e-02, -4.23125923e-04, -1.39125548e-02,\n",
              "         9.79685783e-03, -3.83587554e-04,  1.41456909e-03,\n",
              "        -2.31543230e-03, -1.96627714e-02, -1.02314893e-02,\n",
              "        -2.13096533e-02, -1.28725888e-02, -2.35242806e-02,\n",
              "         1.30345579e-02, -4.69703926e-03, -2.23442018e-02,\n",
              "         2.32778993e-02, -2.98242271e-02,  1.23601221e-02,\n",
              "        -1.95984207e-02,  2.74606831e-02,  1.01040825e-02,\n",
              "        -4.22464237e-02, -7.38080451e-03, -2.19271202e-02,\n",
              "         1.82743147e-02,  2.70902691e-03, -4.04114602e-03,\n",
              "        -1.68816503e-02,  1.56836980e-03, -1.45737119e-02,\n",
              "         8.70168023e-03, -2.11796239e-02,  2.87625715e-02,\n",
              "         1.81968231e-02, -3.21527161e-02, -4.33917753e-02,\n",
              "        -1.49700269e-02,  2.19783243e-02,  1.74030624e-02,\n",
              "        -1.34995813e-02, -4.98083467e-03, -1.35587575e-02,\n",
              "         2.30728164e-02, -2.86418200e-02, -4.19157408e-02,\n",
              "         2.90303864e-02, -1.88331287e-02,  2.74471333e-03,\n",
              "         2.19502598e-02,  2.01286320e-02,  4.54998342e-03,\n",
              "         1.31445192e-03,  6.37605973e-03,  2.31655277e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRQpEqHj_BEc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e85d1ee6-f486-4c3f-a7a6-0efa1e6ecc4e"
      },
      "source": [
        "len(model.labels_)"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30785"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScCYPYk0XnoI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84f613ee-f491-46f1-a67a-0b71f6fad75e"
      },
      "source": [
        "model.labels_"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, ..., 2, 0, 1], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqLT1tBQXrkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_kmeans = pd.DataFrame(data=model.labels_, columns=['text'])"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzwCr24tXyWZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "deedd33f-3622-4242-a596-6b29d2a0d1dd"
      },
      "source": [
        "df_kmeans"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30780</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30781</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30782</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30783</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30784</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30785 rows √ó 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       text\n",
              "0         1\n",
              "1         1\n",
              "2         0\n",
              "3         0\n",
              "4         0\n",
              "...     ...\n",
              "30780     1\n",
              "30781     2\n",
              "30782     2\n",
              "30783     0\n",
              "30784     1\n",
              "\n",
              "[30785 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9nS7aCbZuJ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0cf4971d-9a82-4f25-a35c-b5295728fb6f"
      },
      "source": [
        "df_kmeans['text'].value_counts()"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    11152\n",
              "2    10041\n",
              "1     9592\n",
              "Name: text, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkmCimHTaxyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02f5f941-a807-46e5-84e7-4612f10982a0"
      },
      "source": [
        "df_kmeans['text'].unique()"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciL422cOcYzu",
        "colab_type": "text"
      },
      "source": [
        "# Aplicando Mean Shift"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBQUbKzRcPEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importando algoritmo da Biblioteca Sklearn.\n",
        "from sklearn.cluster import MeanShift"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGGNvgILnTTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Criando inst√¢ncia do algoritmo.\n",
        "word_vectors = w2v_model.wv\n",
        "clustering = MeanShift(bandwidth=2).fit(X=word_vectors.vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia8AA1sqnmJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Verificando os labels originados.\n",
        "clustering.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1ZHNdT1TfCx6",
        "colab": {}
      },
      "source": [
        "df_meanshift = pd.DataFrame(data=model.labels_, columns=['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7bm87iXofCx-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "deedd33f-3622-4242-a596-6b29d2a0d1dd"
      },
      "source": [
        "df_meanshift"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30780</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30781</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30782</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30783</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30784</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30785 rows √ó 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       text\n",
              "0         1\n",
              "1         1\n",
              "2         0\n",
              "3         0\n",
              "4         0\n",
              "...     ...\n",
              "30780     1\n",
              "30781     2\n",
              "30782     2\n",
              "30783     0\n",
              "30784     1\n",
              "\n",
              "[30785 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wrRilpIkfCyE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0cf4971d-9a82-4f25-a35c-b5295728fb6f"
      },
      "source": [
        "df_meanshift['text'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    11152\n",
              "2    10041\n",
              "1     9592\n",
              "Name: text, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fn5iCjArfCyI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02f5f941-a807-46e5-84e7-4612f10982a0"
      },
      "source": [
        "df_meanshift['text'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0LhdN-BdGFj",
        "colab_type": "text"
      },
      "source": [
        "# Aplicando DBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HiOC6EVu0qo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importando algoritmo da Biblioteca Sklearn.\n",
        "from sklearn.cluster import DBSCAN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFdbW0juu4xB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Criando inst√¢ncia do algoritmo e treinando o modelo com os dados.\n",
        "clustering = DBSCAN(eps=0.5, min_samples=2).fit(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O94gra1vu5_4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc90c4eb-6e8f-4101-ea74-7d84a08e0591"
      },
      "source": [
        "#Verificando os labels originados.\n",
        "clustering.labels_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1, -1, -1, ..., -1, -1, -1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwMI9Q7e7L6B",
        "colab_type": "text"
      },
      "source": [
        "# Sumarizando Resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ391gZt-0gF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#word_vectors.similar_by_vector(model.cluster_centers_[0], topn=10, restrict_vocab=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5FaEkU_-4vM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#word_vectors.similar_by_vector(model.cluster_centers_[1], topn=10, restrict_vocab=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Excj38ru7lRU",
        "colab_type": "text"
      },
      "source": [
        "**t-SNE √© um algoritmo de redu√ß√£o de dimensionalidade n√£o linear que tenta representar dados de alta dimens√£o e as rela√ß√µes subjacentes entre vetores em um espa√ßo de dimens√£o inferior.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upsTW7eC7rst",
        "colab_type": "text"
      },
      "source": [
        "**Importando Bibliotecas.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IB17Slv7nb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        " \n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-88tEAO7u9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tsnescatterplot(model, word, list_names):\n",
        "    arrays = np.empty((0, 300), dtype='f')\n",
        "    word_labels = [word]\n",
        "    color_list  = ['red']\n",
        "\n",
        "    # adds the vector of the query word\n",
        "    arrays = np.append(arrays, model.wv.__getitem__([word]), axis=0)\n",
        "    \n",
        "    # gets list of most similar words\n",
        "    close_words = model.wv.most_similar([word])\n",
        "    \n",
        "    # adds the vector for each of the closest words to the array\n",
        "    for wrd_score in close_words:\n",
        "        wrd_vector = model.wv.__getitem__([wrd_score[0]])\n",
        "        word_labels.append(wrd_score[0])\n",
        "        color_list.append('blue')\n",
        "        arrays = np.append(arrays, wrd_vector, axis=0)\n",
        "    \n",
        "    # adds the vector for each of the words from list_names to the array\n",
        "    for wrd in list_names:\n",
        "        wrd_vector = model.wv.__getitem__([wrd])\n",
        "        word_labels.append(wrd)\n",
        "        color_list.append('green')\n",
        "        arrays = np.append(arrays, wrd_vector, axis=0)\n",
        "        \n",
        "    # Reduces the dimensionality from 300 to 50 dimensions with PCA\n",
        "    reduc = PCA(n_components=50).fit_transform(arrays)\n",
        "    \n",
        "    # Finds t-SNE coordinates for 2 dimensions\n",
        "    np.set_printoptions(suppress=True)\n",
        "    \n",
        "    Y = TSNE(n_components=2, random_state=0, perplexity=15).fit_transform(reduc)\n",
        "    \n",
        "    # Sets everything up to plot\n",
        "    df = pd.DataFrame({'x': [x for x in Y[:, 0]],\n",
        "                       'y': [y for y in Y[:, 1]],\n",
        "                       'words': word_labels,\n",
        "                       'color': color_list})\n",
        "    \n",
        "    fig, _ = plt.subplots()\n",
        "    fig.set_size_inches(9, 9)\n",
        "    \n",
        "    # Basic plot\n",
        "    p1 = sns.regplot(data=df,\n",
        "                     x=\"x\",\n",
        "                     y=\"y\",\n",
        "                     fit_reg=False,\n",
        "                     marker=\"o\",\n",
        "                     scatter_kws={'s': 40,\n",
        "                                  'facecolors': df['color']\n",
        "                                 }\n",
        "                    )\n",
        "    \n",
        "    # Adds annotations one by one with a loop\n",
        "    for line in range(0, df.shape[0]):\n",
        "         p1.text(df[\"x\"][line],\n",
        "                 df['y'][line],\n",
        "                 '  ' + df[\"words\"][line].title(),\n",
        "                 horizontalalignment='left',\n",
        "                 verticalalignment='bottom', size='medium',\n",
        "                 color=df['color'][line],\n",
        "                 weight='normal'\n",
        "                ).set_size(15)\n",
        "\n",
        "    \n",
        "    plt.xlim(Y[:, 0].min()-50, Y[:, 0].max()+50)\n",
        "    plt.ylim(Y[:, 1].min()-50, Y[:, 1].max()+50)\n",
        "            \n",
        "    plt.title('t-SNE visualization for {}'.format(word.title()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A0ca8NY8AgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tsnescatterplot(w2v_model, 'coronavirus', ['pandemia', 'mortes', 'vacina', 'casos', 'virus', 'lockdown'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}