{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Apresentação-PID-Implementação.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QrMuIDhZdOVm",
        "4IM7NpH3gWma",
        "gkC8_WYKbZzk",
        "ODGTbFZojcmE",
        "AyJflrkppvx-",
        "T8E9qBS87Uiq",
        "USvaq5m3VnPJ",
        "eg6Us2Tp9NwJ",
        "x0LhdN-BdGFj",
        "ciL422cOcYzu"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMhbHvVD6KmZ3PDF2agK71o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/italolima04/monitoria-probabilidade-estatistica/blob/master/Pesquisa-PID/Implementa%C3%A7%C3%A3o-Algoritmos/Apresenta%C3%A7%C3%A3o_PID_Implementa%C3%A7%C3%A3o.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrMuIDhZdOVm",
        "colab_type": "text"
      },
      "source": [
        "# Aprendizado Não-Supervisionado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHF3ifAbiTD1",
        "colab_type": "text"
      },
      "source": [
        "\"*O aprendizado não supervisionado é um ramo do Machine Learning que aprende com dados de teste que não foram rotulados, classificados ou categorizados previamente. Em vez de responder à programação de um operador, o aprendizado não supervisionado identifica semelhanças nos dados e reage com base na presença ou ausência de tais semelhanças em cada novo dado*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NZFkvCagZCO",
        "colab_type": "text"
      },
      "source": [
        "**Essa abordagem de Aprendizado de Máquina é útil quando não possuímos rótulos (Labels) para os nossos dados. Isto é importante pelo fato de que em muitos contexos possuir esses dados pode ser difícil e/ou custoso.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9U4habTh8Ii",
        "colab_type": "text"
      },
      "source": [
        "Nesse caso de estudo, pelo fato da base de dados ser atual, real e ter sido coletada em um contexto de uma rede social, não se faz possível possuir rótulos para a classificação de textos. Dessa forma, objetiva-se agrupar os dados de forma não supervisionada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IM7NpH3gWma",
        "colab_type": "text"
      },
      "source": [
        "# Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6tuGZLwdTQZ",
        "colab_type": "text"
      },
      "source": [
        "**Clustering é uma técnica de Aprendizado de Máquina que envolve o agrupamento de pontos de dados.**\n",
        "\n",
        "Utiliza-se algoritmos de clustering para agrupar pontos de dados em grupos específicos, cujos, na teoria devem possuir propriedades/características semelhantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9j8dXGwdqlI",
        "colab_type": "text"
      },
      "source": [
        "**K-Means**\n",
        "\n",
        "K-Means é um método de Clustering que tem como objetivo o particionamento de n observações dentre k grupos, onde cada observação pertence ao grupo mais próximo da média.\n",
        "\n",
        "\n",
        "A execução do K-Means segue um conjunto de passos, descritos abaixo:\n",
        "\n",
        "1. Selecionar um número de classes/grupos para utilizar e inicializarmos aleatoriamente seus respectivos pontos centrais (Centróides). Esses grupos podem ser definidos de acordo com a regra do negócio ou a perspectiva do problema.\n",
        "2. Cada de ponto de dados é classificado, baseando-se na distância entre esse ponto e o centro do grupo.\n",
        "3. Com base nos pontos classificados, recalcula-se o centróide, a partir da média das distâncias de todos os vetores do grupo.  \n",
        "\n",
        "Esses dois últimos passos são repetidos, até que o limite de iterações pré-determinado seja atingido, ou quando os centróides não sofrerem alterações significantes de uma iteração para outra.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfIbkTePfrSh",
        "colab_type": "text"
      },
      "source": [
        "**Vantagens:**\n",
        "\n",
        "- É rápido, visto que o que é feito é somente calcular as distâncias entre os pontos e os centróides do grupo. Possui então complexidade linear O(n). \n",
        "\n",
        "- É simples de aplicar e se mostra eficiente.\n",
        "\n",
        "**Desvantagens:**\n",
        "\n",
        "- Dificuldade para determinar a quantidade de clusters (Dependendo do Objetivo).\n",
        "\n",
        "- Pode ser inconsistente, a depende do conjunto de dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkC8_WYKbZzk",
        "colab_type": "text"
      },
      "source": [
        "# Importando Bibliotecas, Módulos e Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EslyX3HlbG4v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6ae1d3b-36a2-4684-85a2-3908df079686"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXYfvKDAbeZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Criando Data Frame a partir dos dados.\n",
        "data = pd.read_csv('dados-pesquisa.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODGTbFZojcmE",
        "colab_type": "text"
      },
      "source": [
        "# Visualizando e Explorando os dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrcjQhYxjqS0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0ad0a91-36e9-4a9e-b26e-a3a84338700d"
      },
      "source": [
        "#Visualizando as 5 primeiras linhas.\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>created_at</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>user</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Mon May 18 17:53:01 +0000 2020</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tudo mudou na nossa forma de trabalhar, mas na...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Mon May 18 17:52:17 +0000 2020</td>\n",
              "      <td>NaN</td>\n",
              "      <td>McDonald’s já reabriu lojas ao público https:/...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Mon May 18 17:50:40 +0000 2020</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sindicato, está atento em tudo o que envolve s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Mon May 18 17:49:17 +0000 2020</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Nossos problemas da saúde definitivamente acab...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Mon May 18 17:49:06 +0000 2020</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fábricas de todo o mundo se viram obrigadas a ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                      created_at  ...  user lang\n",
              "0           0  Mon May 18 17:53:01 +0000 2020  ...   NaN   pt\n",
              "1           1  Mon May 18 17:52:17 +0000 2020  ...   NaN   pt\n",
              "2           2  Mon May 18 17:50:40 +0000 2020  ...   NaN   pt\n",
              "3           3  Mon May 18 17:49:17 +0000 2020  ...   NaN   pt\n",
              "4           4  Mon May 18 17:49:06 +0000 2020  ...   NaN   pt\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH2O2KSKj6q-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "249d37df-1b61-445c-ce9d-42762ef1ad5f"
      },
      "source": [
        "#Visualizando as 5 últimas linhas.\n",
        "data.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>created_at</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>user</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>109959</th>\n",
              "      <td>109959</td>\n",
              "      <td>Mon Jul 20 15:04:14 +0000 2020</td>\n",
              "      <td>1.285229e+18</td>\n",
              "      <td>porto alegre perigando a entrar em lockdown e ...</td>\n",
              "      <td>{'id': 1245313171, 'id_str': '1245313171', 'na...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109960</th>\n",
              "      <td>109960</td>\n",
              "      <td>Mon Jul 20 15:03:35 +0000 2020</td>\n",
              "      <td>1.285229e+18</td>\n",
              "      <td>Nunca que a Mídia vai falar isso!\\nAMB, CFM e ...</td>\n",
              "      <td>{'id': 40697641, 'id_str': '40697641', 'name':...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109961</th>\n",
              "      <td>109961</td>\n",
              "      <td>Mon Jul 20 15:03:33 +0000 2020</td>\n",
              "      <td>1.285229e+18</td>\n",
              "      <td>@joaopiresrj Eu não sou cientista mas esse LOC...</td>\n",
              "      <td>{'id': 942176977, 'id_str': '942176977', 'name...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109962</th>\n",
              "      <td>109962</td>\n",
              "      <td>Mon Jul 20 15:01:54 +0000 2020</td>\n",
              "      <td>1.285228e+18</td>\n",
              "      <td>Q&amp;amp;A - Recessão ou Lockdown. O que é pior? ...</td>\n",
              "      <td>{'id': 1136982345137958912, 'id_str': '1136982...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109963</th>\n",
              "      <td>109963</td>\n",
              "      <td>Mon Jul 20 15:01:38 +0000 2020</td>\n",
              "      <td>1.285228e+18</td>\n",
              "      <td>O prefeito de Los Angeles está preste a decret...</td>\n",
              "      <td>{'id': 494366716, 'id_str': '494366716', 'name...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0  ... lang\n",
              "109959      109959  ...   pt\n",
              "109960      109960  ...   pt\n",
              "109961      109961  ...   pt\n",
              "109962      109962  ...   pt\n",
              "109963      109963  ...   pt\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65DcCYvPjbmk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79dff6f1-21ad-4a76-b5e0-452ec1e2fa2d"
      },
      "source": [
        "#Verificando a estrutura inicial dos dados.\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(109964, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL74IZlBjrv9",
        "colab_type": "text"
      },
      "source": [
        "**Podemos observar aproximadamente 110 mil linhas e 6 colunas.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyJflrkppvx-",
        "colab_type": "text"
      },
      "source": [
        "# Tratando os dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntMjmA1hj_pB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Removendo dados duplicados na coluna de Texto e substituindo dentro do próprio Data Frame.\n",
        "data.drop_duplicates(['text'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyhrarbekOUJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f958066e-66ee-4bfc-b7f5-32e966259246"
      },
      "source": [
        "#Verificando novamente a estrutura dos dados para observar a quantidade de dados únicos.\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(103364, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh3k65gwlje8",
        "colab_type": "text"
      },
      "source": [
        "6600 linhas foram removidas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJlkTrKzktJl",
        "colab_type": "text"
      },
      "source": [
        "**Iremos trabalhar com os Dados de Texto, por isso, selecionaremos apenas a coluna associada ao conteúdo dos tweets.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQyFyq6Bk29W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Utilizando notação comum em estudos de Aprendizado de Máquina.\n",
        "X = data['text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bKpOB7-k-JH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bce12e7-b351-4634-d7f9-f4e0ddb2e993"
      },
      "source": [
        "#Visualizando as 15 primeiras linhas. \n",
        "X[:15]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     Tudo mudou na nossa forma de trabalhar, mas na...\n",
              "1     McDonald’s já reabriu lojas ao público https:/...\n",
              "2     Sindicato, está atento em tudo o que envolve s...\n",
              "3     Nossos problemas da saúde definitivamente acab...\n",
              "4     Fábricas de todo o mundo se viram obrigadas a ...\n",
              "5     @g1 @RedeGlobo @jornalhoje o governo de @jairb...\n",
              "6     Lei N° 6666, nos #EUA, que pretende traçar e i...\n",
              "7     https://t.co/mcftUwJr5F o governo precisa ser ...\n",
              "8     Blockchain: a tecnologia que popularizou o #bi...\n",
              "9     VOCÊS CONHECEM ALGUM PAÍS ALÉM DO BRASIL QUE T...\n",
              "10    Itajuípe recebe o Centro Municipal de Isolamen...\n",
              "11    📣 NOTÍCIA / NEWS / NOUVELLES \\n\\n🇵🇹 Manual de ...\n",
              "12    Enquanto o governo Bolsonaro permanecer Irresp...\n",
              "13    Faça a diferença! Seja um doador sem fronteira...\n",
              "14    Manaus, maio de 2020. Reportagem sobre o colap...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdsZzO1uiR3E",
        "colab_type": "text"
      },
      "source": [
        "**Devido ao fato de os dados serem proveninentes de uma rede social, se faz necessária uma etapa de pré-processamento nos mesmos.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDt6G21ntIhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Preprocessing_data(instance):\n",
        "      instance = re.sub(r\"http\\S+\", \"\", instance).lower().replace('.', '').replace(';','').replace('-','').replace(':', '').replace(')', '')\n",
        "      stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
        "      words = [i for i in instance.split() if not i in stopwords]\n",
        "      return (\" \".join(words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0mXGAG5isR0",
        "colab_type": "text"
      },
      "source": [
        "**Função que remove links, urls, sinais de pontuação, padroniza os caracteres como minúsculos e remove as stopwords através de um dos módulos da biblioteca NLTK.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqm7JgNUmsVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Aplicando a função na nossa base de dados.\n",
        "X = [Preprocessing_data(i) for i in X]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suoFiiJ2mzaR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a98c251-bfc0-4ab9-91cf-c576e7fdb298"
      },
      "source": [
        "#Visualizando novamente as 15 primeiras linhas, agora após o pré-processamento.\n",
        "X[:15]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tudo mudou forma trabalhar, nada mudou objetivo informar #jornalismo #imprensa…',\n",
              " 'mcdonald’s reabriu lojas público #comida #covid19 #mcdonalds',\n",
              " 'sindicato, atento tudo envolve saúde condições trabalho nessa pandemia #covid @spbancarios',\n",
              " 'problemas saúde definitivamente acabaram #saude #forabolsonaro #covid',\n",
              " 'fábricas todo mundo viram obrigadas dispensarem funcionários decorrência #covid19 antes m…',\n",
              " '@g1 @redeglobo @jornalhoje governo @jairbolsonaro vai socorrer ninguém vai enrolar! pois minto quer r…',\n",
              " 'lei n° 6666, #eua, pretende traçar investigar percurso pessoas tivestes contatos, usand…',\n",
              " 'governo precisa ser responsabilizado #covid #covid19',\n",
              " 'blockchain tecnologia popularizou #bitcoin sendo testada combate #covid19 sistema capaz de…',\n",
              " 'conhecem algum país além brasil torcida organizada coronavirus???? #covid #covid19',\n",
              " 'itajuípe recebe centro municipal isolamento covid19 #covid19 #isolamentosocial #covid @rctitajuipe',\n",
              " '📣 notícia / news / nouvelles 🇵🇹 manual boas práticas – algarve clean &amp safe 🇬🇧 good practice guide algarve c…',\n",
              " 'enquanto governo bolsonaro permanecer irresponsável, povo paga vida #calabocabolsonaro #covid…',\n",
              " 'faça diferença! doador fronteiras sou! #covid #covid19 @msf_brasil',\n",
              " 'manaus, maio 2020 reportagem sobre colapso sus @veja dessa semana, mostra situação pacientes em…']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZe4t3fIk5I1",
        "colab_type": "text"
      },
      "source": [
        "**É atribuído um número para cada palavra encontrada na base de dados.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8E9qBS87Uiq",
        "colab_type": "text"
      },
      "source": [
        "# Criando o Modelo Word2VEC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoYBoaSIl4ZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importando biblioteca e módulo do Gensim, para a implementação do Word2VEC.\n",
        "import multiprocessing\n",
        "\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fq89FR4oq2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Função que conta o número de cores da máquina.\n",
        "cores = multiprocessing.cpu_count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkS_Ofefok0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Instanciando modelo Word2VEC a partir dos mesmos parâmetros estabelecidos pelo artigo.\n",
        "w2v_model = Word2Vec(min_count=3,\n",
        "                     window=4,\n",
        "                     size=300,\n",
        "                     sample=0.8, \n",
        "                     alpha=0.03, \n",
        "                     min_alpha=0.0007, \n",
        "                     negative=20,\n",
        "                     workers=multiprocessing.cpu_count()-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPcSopbConnQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e5ffaae-3766-46be-fe1d-684ed78ee63b"
      },
      "source": [
        "#Construindo vocabulário a partir das sentenças.\n",
        "w2v_model.build_vocab(sentences, progress_per=10000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 15:13:08: collecting all words and their counts\n",
            "INFO - 15:13:08: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "INFO - 15:13:08: PROGRESS: at sentence #10000, processed 98386 words, keeping 26703 word types\n",
            "INFO - 15:13:08: PROGRESS: at sentence #20000, processed 194307 words, keeping 41176 word types\n",
            "INFO - 15:13:09: PROGRESS: at sentence #30000, processed 289323 words, keeping 53198 word types\n",
            "INFO - 15:13:09: PROGRESS: at sentence #40000, processed 384343 words, keeping 63822 word types\n",
            "INFO - 15:13:09: PROGRESS: at sentence #50000, processed 480594 words, keeping 73460 word types\n",
            "INFO - 15:13:10: PROGRESS: at sentence #60000, processed 577296 words, keeping 82906 word types\n",
            "INFO - 15:13:10: PROGRESS: at sentence #70000, processed 672253 words, keeping 91879 word types\n",
            "INFO - 15:13:10: PROGRESS: at sentence #80000, processed 765282 words, keeping 100227 word types\n",
            "INFO - 15:13:11: PROGRESS: at sentence #90000, processed 858298 words, keeping 107673 word types\n",
            "INFO - 15:13:11: PROGRESS: at sentence #100000, processed 953320 words, keeping 114711 word types\n",
            "INFO - 15:13:11: collected 117576 word types from a corpus of 987411 raw words and 103364 sentences\n",
            "INFO - 15:13:11: Loading a fresh vocabulary\n",
            "INFO - 15:13:11: effective_min_count=3 retains 30785 unique words (26% of original 117576, drops 86791)\n",
            "INFO - 15:13:11: effective_min_count=3 leaves 885593 word corpus (89% of original 987411, drops 101818)\n",
            "INFO - 15:13:11: deleting the raw counts dictionary of 117576 items\n",
            "INFO - 15:13:11: sample=0.8 downsamples 0 most-common words\n",
            "INFO - 15:13:12: downsampling leaves estimated 885593 word corpus (100.0% of prior 885593)\n",
            "INFO - 15:13:12: estimated required memory for 30785 words and 300 dimensions: 89276500 bytes\n",
            "INFO - 15:13:12: resetting layer weights\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USvaq5m3VnPJ",
        "colab_type": "text"
      },
      "source": [
        "# Treinando o Modelo Word2VEC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elb-e0LpoulX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2839a7-6d6a-47fc-f048-520555ad0ec6"
      },
      "source": [
        "#Treiando modelo Word2VEC.\n",
        "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 15:13:19: training model with 1 workers on 30785 vocabulary and 300 features, using sg=0 hs=0 sample=0.8 negative=20 window=4\n",
            "INFO - 15:13:20: EPOCH 1 - PROGRESS: at 4.74% examples, 40726 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:13:21: EPOCH 1 - PROGRESS: at 12.85% examples, 53578 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:22: EPOCH 1 - PROGRESS: at 20.95% examples, 59079 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:23: EPOCH 1 - PROGRESS: at 29.08% examples, 62017 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:24: EPOCH 1 - PROGRESS: at 37.26% examples, 62779 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:25: EPOCH 1 - PROGRESS: at 45.23% examples, 64092 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:26: EPOCH 1 - PROGRESS: at 54.26% examples, 65402 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:27: EPOCH 1 - PROGRESS: at 63.40% examples, 66297 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:29: EPOCH 1 - PROGRESS: at 71.62% examples, 66785 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:30: EPOCH 1 - PROGRESS: at 79.88% examples, 67264 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:31: EPOCH 1 - PROGRESS: at 88.22% examples, 67644 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:32: EPOCH 1 - PROGRESS: at 96.37% examples, 68007 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:32: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:13:32: EPOCH - 1 : training on 987411 raw words (885593 effective words) took 12.9s, 68536 effective words/s\n",
            "INFO - 15:13:33: EPOCH 2 - PROGRESS: at 7.77% examples, 66674 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:34: EPOCH 2 - PROGRESS: at 15.88% examples, 68553 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:13:35: EPOCH 2 - PROGRESS: at 24.04% examples, 67597 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:36: EPOCH 2 - PROGRESS: at 31.06% examples, 66399 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:13:37: EPOCH 2 - PROGRESS: at 38.24% examples, 64852 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:13:38: EPOCH 2 - PROGRESS: at 44.23% examples, 62108 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:39: EPOCH 2 - PROGRESS: at 50.30% examples, 60828 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:13:40: EPOCH 2 - PROGRESS: at 57.30% examples, 60693 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:13:41: EPOCH 2 - PROGRESS: at 64.41% examples, 60674 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:13:42: EPOCH 2 - PROGRESS: at 71.62% examples, 60770 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:44: EPOCH 2 - PROGRESS: at 79.88% examples, 61009 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:45: EPOCH 2 - PROGRESS: at 87.21% examples, 61138 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:13:46: EPOCH 2 - PROGRESS: at 95.36% examples, 61379 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:13:46: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:13:46: EPOCH - 2 : training on 987411 raw words (885593 effective words) took 14.3s, 61807 effective words/s\n",
            "INFO - 15:13:47: EPOCH 3 - PROGRESS: at 7.77% examples, 64748 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:48: EPOCH 3 - PROGRESS: at 15.88% examples, 67427 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:13:49: EPOCH 3 - PROGRESS: at 24.04% examples, 68600 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:50: EPOCH 3 - PROGRESS: at 32.10% examples, 68943 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:51: EPOCH 3 - PROGRESS: at 40.26% examples, 69293 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:52: EPOCH 3 - PROGRESS: at 48.29% examples, 69414 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:53: EPOCH 3 - PROGRESS: at 56.31% examples, 69719 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:54: EPOCH 3 - PROGRESS: at 64.41% examples, 69971 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:55: EPOCH 3 - PROGRESS: at 72.65% examples, 70080 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:56: EPOCH 3 - PROGRESS: at 80.91% examples, 70098 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:58: EPOCH 3 - PROGRESS: at 89.27% examples, 70015 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:59: EPOCH 3 - PROGRESS: at 97.37% examples, 70150 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:13:59: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:13:59: EPOCH - 3 : training on 987411 raw words (885593 effective words) took 12.6s, 70550 effective words/s\n",
            "INFO - 15:14:00: EPOCH 4 - PROGRESS: at 7.77% examples, 66250 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:01: EPOCH 4 - PROGRESS: at 15.88% examples, 67968 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:02: EPOCH 4 - PROGRESS: at 24.04% examples, 66570 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:03: EPOCH 4 - PROGRESS: at 32.10% examples, 67536 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:04: EPOCH 4 - PROGRESS: at 40.26% examples, 68186 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:05: EPOCH 4 - PROGRESS: at 48.29% examples, 68552 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:06: EPOCH 4 - PROGRESS: at 57.30% examples, 69104 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:07: EPOCH 4 - PROGRESS: at 65.43% examples, 69275 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:08: EPOCH 4 - PROGRESS: at 73.69% examples, 69469 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:09: EPOCH 4 - PROGRESS: at 81.94% examples, 69656 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:10: EPOCH 4 - PROGRESS: at 90.32% examples, 69767 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:11: EPOCH 4 - PROGRESS: at 99.27% examples, 70146 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:11: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:14:11: EPOCH - 4 : training on 987411 raw words (885593 effective words) took 12.6s, 70213 effective words/s\n",
            "INFO - 15:14:13: EPOCH 5 - PROGRESS: at 7.77% examples, 65667 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:14:14: EPOCH 5 - PROGRESS: at 15.88% examples, 68401 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:15: EPOCH 5 - PROGRESS: at 24.04% examples, 69060 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:16: EPOCH 5 - PROGRESS: at 32.10% examples, 69626 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:17: EPOCH 5 - PROGRESS: at 40.26% examples, 69857 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:18: EPOCH 5 - PROGRESS: at 48.29% examples, 70112 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:19: EPOCH 5 - PROGRESS: at 56.31% examples, 70237 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:20: EPOCH 5 - PROGRESS: at 64.41% examples, 70262 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:21: EPOCH 5 - PROGRESS: at 72.65% examples, 70204 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:14:22: EPOCH 5 - PROGRESS: at 80.91% examples, 70262 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:23: EPOCH 5 - PROGRESS: at 89.27% examples, 70247 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:24: EPOCH 5 - PROGRESS: at 97.37% examples, 70375 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:24: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:14:24: EPOCH - 5 : training on 987411 raw words (885593 effective words) took 12.5s, 70773 effective words/s\n",
            "INFO - 15:14:25: EPOCH 6 - PROGRESS: at 7.77% examples, 67406 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:26: EPOCH 6 - PROGRESS: at 15.88% examples, 69188 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:27: EPOCH 6 - PROGRESS: at 24.04% examples, 69762 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:14:28: EPOCH 6 - PROGRESS: at 33.14% examples, 70516 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:29: EPOCH 6 - PROGRESS: at 42.26% examples, 70980 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:30: EPOCH 6 - PROGRESS: at 51.29% examples, 71341 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:31: EPOCH 6 - PROGRESS: at 60.26% examples, 71465 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:33: EPOCH 6 - PROGRESS: at 69.53% examples, 71582 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:34: EPOCH 6 - PROGRESS: at 77.84% examples, 71459 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:35: EPOCH 6 - PROGRESS: at 87.21% examples, 71560 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:36: EPOCH 6 - PROGRESS: at 95.36% examples, 70950 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:36: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:14:36: EPOCH - 6 : training on 987411 raw words (885593 effective words) took 12.4s, 71357 effective words/s\n",
            "INFO - 15:14:37: EPOCH 7 - PROGRESS: at 7.77% examples, 65527 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:38: EPOCH 7 - PROGRESS: at 15.88% examples, 68340 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:39: EPOCH 7 - PROGRESS: at 24.04% examples, 69329 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:41: EPOCH 7 - PROGRESS: at 33.14% examples, 70020 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:42: EPOCH 7 - PROGRESS: at 42.26% examples, 70564 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:43: EPOCH 7 - PROGRESS: at 50.30% examples, 70652 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:44: EPOCH 7 - PROGRESS: at 58.28% examples, 70718 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:45: EPOCH 7 - PROGRESS: at 67.46% examples, 70895 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:46: EPOCH 7 - PROGRESS: at 75.77% examples, 70964 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:47: EPOCH 7 - PROGRESS: at 84.04% examples, 71068 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:48: EPOCH 7 - PROGRESS: at 92.38% examples, 71155 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:49: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:14:49: EPOCH - 7 : training on 987411 raw words (885593 effective words) took 12.4s, 71565 effective words/s\n",
            "INFO - 15:14:50: EPOCH 8 - PROGRESS: at 7.77% examples, 67377 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:14:51: EPOCH 8 - PROGRESS: at 15.88% examples, 69337 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:52: EPOCH 8 - PROGRESS: at 24.04% examples, 69753 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:53: EPOCH 8 - PROGRESS: at 32.10% examples, 70006 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:54: EPOCH 8 - PROGRESS: at 40.26% examples, 70310 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:55: EPOCH 8 - PROGRESS: at 48.29% examples, 70405 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:56: EPOCH 8 - PROGRESS: at 57.30% examples, 70641 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:57: EPOCH 8 - PROGRESS: at 66.44% examples, 70796 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:14:58: EPOCH 8 - PROGRESS: at 75.77% examples, 70989 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:14:59: EPOCH 8 - PROGRESS: at 85.12% examples, 71155 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:00: EPOCH 8 - PROGRESS: at 93.38% examples, 71241 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:01: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:15:01: EPOCH - 8 : training on 987411 raw words (885593 effective words) took 12.3s, 71739 effective words/s\n",
            "INFO - 15:15:02: EPOCH 9 - PROGRESS: at 7.77% examples, 68579 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:03: EPOCH 9 - PROGRESS: at 16.89% examples, 71592 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:04: EPOCH 9 - PROGRESS: at 26.08% examples, 71876 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:05: EPOCH 9 - PROGRESS: at 35.24% examples, 72235 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:07: EPOCH 9 - PROGRESS: at 44.23% examples, 72339 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:08: EPOCH 9 - PROGRESS: at 53.26% examples, 72410 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:09: EPOCH 9 - PROGRESS: at 62.33% examples, 72540 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:10: EPOCH 9 - PROGRESS: at 70.56% examples, 71809 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:11: EPOCH 9 - PROGRESS: at 79.88% examples, 71936 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:12: EPOCH 9 - PROGRESS: at 89.27% examples, 72082 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:13: EPOCH 9 - PROGRESS: at 97.37% examples, 72052 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:13: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:15:13: EPOCH - 9 : training on 987411 raw words (885593 effective words) took 12.2s, 72454 effective words/s\n",
            "INFO - 15:15:14: EPOCH 10 - PROGRESS: at 7.77% examples, 68847 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:16: EPOCH 10 - PROGRESS: at 16.89% examples, 70435 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:15:17: EPOCH 10 - PROGRESS: at 26.08% examples, 71241 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:18: EPOCH 10 - PROGRESS: at 35.24% examples, 71605 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:19: EPOCH 10 - PROGRESS: at 44.23% examples, 71779 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:20: EPOCH 10 - PROGRESS: at 53.26% examples, 71988 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:21: EPOCH 10 - PROGRESS: at 62.33% examples, 72162 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:22: EPOCH 10 - PROGRESS: at 70.56% examples, 71675 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:15:23: EPOCH 10 - PROGRESS: at 78.88% examples, 71508 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:24: EPOCH 10 - PROGRESS: at 87.21% examples, 71533 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:25: EPOCH 10 - PROGRESS: at 96.37% examples, 71689 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:26: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:15:26: EPOCH - 10 : training on 987411 raw words (885593 effective words) took 12.3s, 72180 effective words/s\n",
            "INFO - 15:15:27: EPOCH 11 - PROGRESS: at 7.77% examples, 68630 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:28: EPOCH 11 - PROGRESS: at 16.89% examples, 70888 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:29: EPOCH 11 - PROGRESS: at 26.08% examples, 71358 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:30: EPOCH 11 - PROGRESS: at 35.24% examples, 71834 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:31: EPOCH 11 - PROGRESS: at 44.23% examples, 71868 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:32: EPOCH 11 - PROGRESS: at 53.26% examples, 72133 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:33: EPOCH 11 - PROGRESS: at 62.33% examples, 72223 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:34: EPOCH 11 - PROGRESS: at 71.62% examples, 72417 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:36: EPOCH 11 - PROGRESS: at 80.91% examples, 72573 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:37: EPOCH 11 - PROGRESS: at 90.32% examples, 72721 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:38: EPOCH 11 - PROGRESS: at 99.27% examples, 73190 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:38: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:15:38: EPOCH - 11 : training on 987411 raw words (885593 effective words) took 12.1s, 73272 effective words/s\n",
            "INFO - 15:15:39: EPOCH 12 - PROGRESS: at 7.77% examples, 69630 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:15:40: EPOCH 12 - PROGRESS: at 16.89% examples, 71613 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:41: EPOCH 12 - PROGRESS: at 25.05% examples, 70332 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:15:42: EPOCH 12 - PROGRESS: at 34.17% examples, 71156 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:43: EPOCH 12 - PROGRESS: at 43.25% examples, 71478 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:44: EPOCH 12 - PROGRESS: at 51.29% examples, 70671 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:15:45: EPOCH 12 - PROGRESS: at 60.26% examples, 71360 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:46: EPOCH 12 - PROGRESS: at 69.53% examples, 71791 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:47: EPOCH 12 - PROGRESS: at 78.88% examples, 72098 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:49: EPOCH 12 - PROGRESS: at 88.22% examples, 72315 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:50: EPOCH 12 - PROGRESS: at 97.37% examples, 72546 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:50: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:15:50: EPOCH - 12 : training on 987411 raw words (885593 effective words) took 12.1s, 72989 effective words/s\n",
            "INFO - 15:15:51: EPOCH 13 - PROGRESS: at 7.77% examples, 68309 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:52: EPOCH 13 - PROGRESS: at 16.89% examples, 71115 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:53: EPOCH 13 - PROGRESS: at 26.08% examples, 72394 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:54: EPOCH 13 - PROGRESS: at 35.24% examples, 72973 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:55: EPOCH 13 - PROGRESS: at 44.23% examples, 73428 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:56: EPOCH 13 - PROGRESS: at 53.26% examples, 73636 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:57: EPOCH 13 - PROGRESS: at 62.33% examples, 73711 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:15:59: EPOCH 13 - PROGRESS: at 71.62% examples, 73614 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:00: EPOCH 13 - PROGRESS: at 80.91% examples, 73614 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:01: EPOCH 13 - PROGRESS: at 90.32% examples, 73663 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:02: EPOCH 13 - PROGRESS: at 99.27% examples, 74067 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:02: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:16:02: EPOCH - 13 : training on 987411 raw words (885593 effective words) took 11.9s, 74186 effective words/s\n",
            "INFO - 15:16:03: EPOCH 14 - PROGRESS: at 7.77% examples, 68580 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:04: EPOCH 14 - PROGRESS: at 16.89% examples, 71342 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:05: EPOCH 14 - PROGRESS: at 26.08% examples, 72216 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:06: EPOCH 14 - PROGRESS: at 35.24% examples, 72727 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:07: EPOCH 14 - PROGRESS: at 44.23% examples, 72838 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:08: EPOCH 14 - PROGRESS: at 53.26% examples, 73178 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:09: EPOCH 14 - PROGRESS: at 62.33% examples, 73393 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:10: EPOCH 14 - PROGRESS: at 71.62% examples, 73486 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:12: EPOCH 14 - PROGRESS: at 80.91% examples, 73473 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:13: EPOCH 14 - PROGRESS: at 89.27% examples, 73175 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:16:14: EPOCH 14 - PROGRESS: at 98.33% examples, 73469 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:14: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:16:14: EPOCH - 14 : training on 987411 raw words (885593 effective words) took 12.0s, 73694 effective words/s\n",
            "INFO - 15:16:15: EPOCH 15 - PROGRESS: at 7.77% examples, 68221 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:16: EPOCH 15 - PROGRESS: at 15.88% examples, 67474 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:17: EPOCH 15 - PROGRESS: at 25.05% examples, 69293 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:18: EPOCH 15 - PROGRESS: at 34.17% examples, 70463 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:19: EPOCH 15 - PROGRESS: at 43.25% examples, 71112 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:16:20: EPOCH 15 - PROGRESS: at 52.26% examples, 71571 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:21: EPOCH 15 - PROGRESS: at 61.29% examples, 71789 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:16:23: EPOCH 15 - PROGRESS: at 70.56% examples, 72064 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:24: EPOCH 15 - PROGRESS: at 79.88% examples, 72307 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:25: EPOCH 15 - PROGRESS: at 89.27% examples, 72550 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:26: EPOCH 15 - PROGRESS: at 98.33% examples, 72986 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:26: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:16:26: EPOCH - 15 : training on 987411 raw words (885593 effective words) took 12.1s, 73253 effective words/s\n",
            "INFO - 15:16:27: EPOCH 16 - PROGRESS: at 8.80% examples, 71637 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:28: EPOCH 16 - PROGRESS: at 17.90% examples, 73486 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:29: EPOCH 16 - PROGRESS: at 27.07% examples, 73738 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:16:30: EPOCH 16 - PROGRESS: at 36.27% examples, 73698 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:31: EPOCH 16 - PROGRESS: at 45.23% examples, 73833 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:33: EPOCH 16 - PROGRESS: at 54.26% examples, 73849 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:16:34: EPOCH 16 - PROGRESS: at 63.40% examples, 74024 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:35: EPOCH 16 - PROGRESS: at 72.65% examples, 73955 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:36: EPOCH 16 - PROGRESS: at 81.94% examples, 73949 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:37: EPOCH 16 - PROGRESS: at 91.36% examples, 73900 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:38: EPOCH 16 - PROGRESS: at 100.00% examples, 74315 words/s, in_qsize 0, out_qsize 1\n",
            "INFO - 15:16:38: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:16:38: EPOCH - 16 : training on 987411 raw words (885593 effective words) took 11.9s, 74294 effective words/s\n",
            "INFO - 15:16:39: EPOCH 17 - PROGRESS: at 7.77% examples, 68984 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:40: EPOCH 17 - PROGRESS: at 16.89% examples, 71164 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:41: EPOCH 17 - PROGRESS: at 26.08% examples, 71989 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:42: EPOCH 17 - PROGRESS: at 35.24% examples, 72188 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:43: EPOCH 17 - PROGRESS: at 44.23% examples, 72318 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:16:44: EPOCH 17 - PROGRESS: at 53.26% examples, 72777 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:45: EPOCH 17 - PROGRESS: at 62.33% examples, 72988 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:47: EPOCH 17 - PROGRESS: at 71.62% examples, 73112 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:48: EPOCH 17 - PROGRESS: at 80.91% examples, 73279 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:49: EPOCH 17 - PROGRESS: at 90.32% examples, 73375 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:50: EPOCH 17 - PROGRESS: at 99.27% examples, 73782 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:50: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:16:50: EPOCH - 17 : training on 987411 raw words (885593 effective words) took 12.0s, 73896 effective words/s\n",
            "INFO - 15:16:51: EPOCH 18 - PROGRESS: at 6.76% examples, 59333 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:52: EPOCH 18 - PROGRESS: at 15.88% examples, 67081 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:53: EPOCH 18 - PROGRESS: at 25.05% examples, 69812 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:54: EPOCH 18 - PROGRESS: at 34.17% examples, 71088 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:55: EPOCH 18 - PROGRESS: at 43.25% examples, 71821 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:56: EPOCH 18 - PROGRESS: at 52.26% examples, 72216 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:57: EPOCH 18 - PROGRESS: at 61.29% examples, 72608 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:16:58: EPOCH 18 - PROGRESS: at 70.56% examples, 72812 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:00: EPOCH 18 - PROGRESS: at 79.88% examples, 72960 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:17:01: EPOCH 18 - PROGRESS: at 89.27% examples, 73202 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:02: EPOCH 18 - PROGRESS: at 98.33% examples, 73585 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:02: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:17:02: EPOCH - 18 : training on 987411 raw words (885593 effective words) took 12.0s, 73870 effective words/s\n",
            "INFO - 15:17:03: EPOCH 19 - PROGRESS: at 8.80% examples, 71355 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:04: EPOCH 19 - PROGRESS: at 17.90% examples, 73260 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:05: EPOCH 19 - PROGRESS: at 27.07% examples, 73583 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:06: EPOCH 19 - PROGRESS: at 36.27% examples, 73914 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:07: EPOCH 19 - PROGRESS: at 45.23% examples, 73898 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:08: EPOCH 19 - PROGRESS: at 54.26% examples, 74062 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:09: EPOCH 19 - PROGRESS: at 63.40% examples, 74130 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:11: EPOCH 19 - PROGRESS: at 72.65% examples, 74126 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:12: EPOCH 19 - PROGRESS: at 81.94% examples, 74174 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:13: EPOCH 19 - PROGRESS: at 91.36% examples, 74240 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:14: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:17:14: EPOCH - 19 : training on 987411 raw words (885593 effective words) took 11.9s, 74725 effective words/s\n",
            "INFO - 15:17:15: EPOCH 20 - PROGRESS: at 7.77% examples, 69857 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:16: EPOCH 20 - PROGRESS: at 16.89% examples, 72220 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:17: EPOCH 20 - PROGRESS: at 26.08% examples, 72963 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:18: EPOCH 20 - PROGRESS: at 35.24% examples, 73118 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:19: EPOCH 20 - PROGRESS: at 44.23% examples, 73296 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:20: EPOCH 20 - PROGRESS: at 53.26% examples, 73440 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:21: EPOCH 20 - PROGRESS: at 62.33% examples, 73600 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:22: EPOCH 20 - PROGRESS: at 70.56% examples, 72911 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:23: EPOCH 20 - PROGRESS: at 79.88% examples, 72984 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:25: EPOCH 20 - PROGRESS: at 89.27% examples, 73147 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:26: EPOCH 20 - PROGRESS: at 98.33% examples, 73457 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:26: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:17:26: EPOCH - 20 : training on 987411 raw words (885593 effective words) took 12.0s, 73667 effective words/s\n",
            "INFO - 15:17:27: EPOCH 21 - PROGRESS: at 8.80% examples, 70645 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:28: EPOCH 21 - PROGRESS: at 17.90% examples, 72590 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:29: EPOCH 21 - PROGRESS: at 27.07% examples, 73235 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:30: EPOCH 21 - PROGRESS: at 36.27% examples, 73654 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:31: EPOCH 21 - PROGRESS: at 45.23% examples, 73822 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:32: EPOCH 21 - PROGRESS: at 54.26% examples, 74010 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:33: EPOCH 21 - PROGRESS: at 63.40% examples, 74153 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:34: EPOCH 21 - PROGRESS: at 72.65% examples, 74169 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:36: EPOCH 21 - PROGRESS: at 81.94% examples, 74171 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:37: EPOCH 21 - PROGRESS: at 91.36% examples, 74198 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:17:38: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:17:38: EPOCH - 21 : training on 987411 raw words (885593 effective words) took 11.8s, 74763 effective words/s\n",
            "INFO - 15:17:39: EPOCH 22 - PROGRESS: at 7.77% examples, 69945 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:40: EPOCH 22 - PROGRESS: at 16.89% examples, 72480 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:41: EPOCH 22 - PROGRESS: at 26.08% examples, 73272 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:42: EPOCH 22 - PROGRESS: at 35.24% examples, 73705 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:43: EPOCH 22 - PROGRESS: at 44.23% examples, 74014 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:44: EPOCH 22 - PROGRESS: at 53.26% examples, 74038 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:45: EPOCH 22 - PROGRESS: at 62.33% examples, 74141 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:46: EPOCH 22 - PROGRESS: at 71.62% examples, 74163 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:47: EPOCH 22 - PROGRESS: at 80.91% examples, 74269 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:48: EPOCH 22 - PROGRESS: at 90.32% examples, 74446 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:49: EPOCH 22 - PROGRESS: at 99.27% examples, 74880 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:49: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:17:49: EPOCH - 22 : training on 987411 raw words (885593 effective words) took 11.8s, 74993 effective words/s\n",
            "INFO - 15:17:50: EPOCH 23 - PROGRESS: at 7.77% examples, 69126 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:52: EPOCH 23 - PROGRESS: at 16.89% examples, 71823 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:17:53: EPOCH 23 - PROGRESS: at 26.08% examples, 72874 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:54: EPOCH 23 - PROGRESS: at 34.17% examples, 71587 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:55: EPOCH 23 - PROGRESS: at 43.25% examples, 72264 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:56: EPOCH 23 - PROGRESS: at 52.26% examples, 72581 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:57: EPOCH 23 - PROGRESS: at 60.26% examples, 72483 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:17:58: EPOCH 23 - PROGRESS: at 69.53% examples, 72651 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:17:59: EPOCH 23 - PROGRESS: at 78.88% examples, 72922 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:00: EPOCH 23 - PROGRESS: at 88.22% examples, 73042 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:01: EPOCH 23 - PROGRESS: at 97.37% examples, 73175 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:01: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:18:01: EPOCH - 23 : training on 987411 raw words (885593 effective words) took 12.0s, 73594 effective words/s\n",
            "INFO - 15:18:03: EPOCH 24 - PROGRESS: at 7.77% examples, 69566 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:04: EPOCH 24 - PROGRESS: at 16.89% examples, 72535 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:05: EPOCH 24 - PROGRESS: at 26.08% examples, 73595 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:06: EPOCH 24 - PROGRESS: at 35.24% examples, 74056 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:18:07: EPOCH 24 - PROGRESS: at 44.23% examples, 74342 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:08: EPOCH 24 - PROGRESS: at 53.26% examples, 74255 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:09: EPOCH 24 - PROGRESS: at 62.33% examples, 74425 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:10: EPOCH 24 - PROGRESS: at 71.62% examples, 74433 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:11: EPOCH 24 - PROGRESS: at 80.91% examples, 74433 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:12: EPOCH 24 - PROGRESS: at 90.32% examples, 74537 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:13: EPOCH 24 - PROGRESS: at 99.27% examples, 74826 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:13: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:18:13: EPOCH - 24 : training on 987411 raw words (885593 effective words) took 11.8s, 74946 effective words/s\n",
            "INFO - 15:18:14: EPOCH 25 - PROGRESS: at 7.77% examples, 69976 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:15: EPOCH 25 - PROGRESS: at 16.89% examples, 72895 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:16: EPOCH 25 - PROGRESS: at 26.08% examples, 73758 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:18: EPOCH 25 - PROGRESS: at 35.24% examples, 74112 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:19: EPOCH 25 - PROGRESS: at 44.23% examples, 74245 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:20: EPOCH 25 - PROGRESS: at 53.26% examples, 74586 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:21: EPOCH 25 - PROGRESS: at 62.33% examples, 74729 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:22: EPOCH 25 - PROGRESS: at 71.62% examples, 74757 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:18:23: EPOCH 25 - PROGRESS: at 80.91% examples, 74873 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:24: EPOCH 25 - PROGRESS: at 90.32% examples, 74919 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:25: EPOCH 25 - PROGRESS: at 99.27% examples, 75187 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:25: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:18:25: EPOCH - 25 : training on 987411 raw words (885593 effective words) took 11.8s, 75292 effective words/s\n",
            "INFO - 15:18:26: EPOCH 26 - PROGRESS: at 6.76% examples, 60860 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:27: EPOCH 26 - PROGRESS: at 15.88% examples, 67746 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:28: EPOCH 26 - PROGRESS: at 25.05% examples, 69998 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:29: EPOCH 26 - PROGRESS: at 34.17% examples, 71391 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:30: EPOCH 26 - PROGRESS: at 43.25% examples, 72097 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:31: EPOCH 26 - PROGRESS: at 52.26% examples, 72617 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:33: EPOCH 26 - PROGRESS: at 61.29% examples, 73041 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:34: EPOCH 26 - PROGRESS: at 70.56% examples, 73300 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:35: EPOCH 26 - PROGRESS: at 79.88% examples, 73460 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:36: EPOCH 26 - PROGRESS: at 89.27% examples, 73718 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:37: EPOCH 26 - PROGRESS: at 98.33% examples, 74118 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:37: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:18:37: EPOCH - 26 : training on 987411 raw words (885593 effective words) took 11.9s, 74370 effective words/s\n",
            "INFO - 15:18:38: EPOCH 27 - PROGRESS: at 8.80% examples, 70646 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:39: EPOCH 27 - PROGRESS: at 17.90% examples, 72561 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:40: EPOCH 27 - PROGRESS: at 27.07% examples, 73574 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:41: EPOCH 27 - PROGRESS: at 36.27% examples, 74041 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:42: EPOCH 27 - PROGRESS: at 45.23% examples, 74485 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:43: EPOCH 27 - PROGRESS: at 54.26% examples, 74557 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:45: EPOCH 27 - PROGRESS: at 63.40% examples, 74780 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:18:46: EPOCH 27 - PROGRESS: at 72.65% examples, 74831 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:47: EPOCH 27 - PROGRESS: at 81.94% examples, 74927 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:48: EPOCH 27 - PROGRESS: at 91.36% examples, 74990 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:49: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:18:49: EPOCH - 27 : training on 987411 raw words (885593 effective words) took 11.7s, 75455 effective words/s\n",
            "INFO - 15:18:50: EPOCH 28 - PROGRESS: at 7.77% examples, 69645 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:51: EPOCH 28 - PROGRESS: at 16.89% examples, 72293 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:52: EPOCH 28 - PROGRESS: at 26.08% examples, 73478 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:53: EPOCH 28 - PROGRESS: at 35.24% examples, 74008 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:54: EPOCH 28 - PROGRESS: at 44.23% examples, 74313 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:55: EPOCH 28 - PROGRESS: at 53.26% examples, 74306 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:56: EPOCH 28 - PROGRESS: at 62.33% examples, 74394 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 15:18:57: EPOCH 28 - PROGRESS: at 70.56% examples, 73578 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:58: EPOCH 28 - PROGRESS: at 79.88% examples, 73813 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:18:59: EPOCH 28 - PROGRESS: at 89.27% examples, 74000 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:19:00: EPOCH 28 - PROGRESS: at 98.33% examples, 74404 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:19:01: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:19:01: EPOCH - 28 : training on 987411 raw words (885593 effective words) took 11.9s, 74678 effective words/s\n",
            "INFO - 15:19:02: EPOCH 29 - PROGRESS: at 8.80% examples, 71122 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:19:03: EPOCH 29 - PROGRESS: at 17.90% examples, 73118 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:19:04: EPOCH 29 - PROGRESS: at 27.07% examples, 73995 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:19:05: EPOCH 29 - PROGRESS: at 36.27% examples, 74462 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:19:06: EPOCH 29 - PROGRESS: at 45.23% examples, 74756 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:19:07: EPOCH 29 - PROGRESS: at 54.26% examples, 74958 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:19:08: EPOCH 29 - PROGRESS: at 63.40% examples, 75087 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:19:09: EPOCH 29 - PROGRESS: at 72.65% examples, 74997 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:19:10: EPOCH 29 - PROGRESS: at 81.94% examples, 74947 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:19:11: EPOCH 29 - PROGRESS: at 91.36% examples, 74928 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:19:12: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:19:12: EPOCH - 29 : training on 987411 raw words (885593 effective words) took 11.7s, 75415 effective words/s\n",
            "INFO - 15:19:14: EPOCH 30 - PROGRESS: at 8.80% examples, 70425 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:19:15: EPOCH 30 - PROGRESS: at 17.90% examples, 73046 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:19:16: EPOCH 30 - PROGRESS: at 27.07% examples, 73527 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:19:17: EPOCH 30 - PROGRESS: at 36.27% examples, 73938 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:19:18: EPOCH 30 - PROGRESS: at 45.23% examples, 73954 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:19:19: EPOCH 30 - PROGRESS: at 54.26% examples, 73897 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:19:20: EPOCH 30 - PROGRESS: at 63.40% examples, 74033 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:19:21: EPOCH 30 - PROGRESS: at 72.65% examples, 74097 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:19:22: EPOCH 30 - PROGRESS: at 81.94% examples, 74058 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:19:23: EPOCH 30 - PROGRESS: at 91.36% examples, 74161 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 15:19:24: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:19:24: EPOCH - 30 : training on 987411 raw words (885593 effective words) took 11.9s, 74631 effective words/s\n",
            "INFO - 15:19:24: training on a 29622330 raw words (26567790 effective words) took 365.3s, 72733 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26567790, 29622330)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4aa0DVvow3R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "046a23d2-6131-47be-b62c-31368a54c011"
      },
      "source": [
        "#Tornando o modelo mais eficiente em questões de uso de memória.\n",
        "w2v_model.init_sims(replace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 15:19:24: precomputing L2-norms of word weight vectors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMEQVcaV6K-t",
        "colab_type": "text"
      },
      "source": [
        "**A partir do Word2VEC podemos verificar a similaridade de outras palavras para determinados termos.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG8WLQdaqJpZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acbfd71d-e22a-4ba0-9927-9915a4e721c6"
      },
      "source": [
        "w2v_model.wv.most_similar([\"vacina\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('vacina_contra', 0.5999780893325806),\n",
              " ('vacina_chinesa', 0.5734825134277344),\n",
              " ('tomar_vacina', 0.5448654890060425),\n",
              " ('\"vacina', 0.5391110181808472),\n",
              " ('vacinas', 0.5349497199058533),\n",
              " ('doses_vacina', 0.5105684995651245),\n",
              " ('cura_pro', 0.4802631735801697),\n",
              " ('#vacina', 0.46188271045684814),\n",
              " ('testes_vacina', 0.4576757252216339),\n",
              " ('vacina_oxford', 0.4500918984413147)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzHB_w9O67oU",
        "colab_type": "text"
      },
      "source": [
        "**Podemos determinar filtros para uma verificação de similaridade.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsZeL1qQ62sP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0133e131-38eb-4aba-e192-4a31f7b104ee"
      },
      "source": [
        "w2v_model.wv.most_similar([\"recuperados\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('curados', 0.6696262359619141),\n",
              " ('pacientes_recuperados', 0.6550328731536865),\n",
              " ('pessoas_recuperadas', 0.6002197265625),\n",
              " ('pessoas_curadas', 0.5826815366744995),\n",
              " ('casos_ativos', 0.5721123218536377),\n",
              " ('vítimas_fatais', 0.5445606112480164),\n",
              " ('recuperados…', 0.5399713516235352),\n",
              " ('confirmações', 0.5295443534851074),\n",
              " ('mortes_confirmadas', 0.520463228225708),\n",
              " ('recuperados,', 0.5047532320022583)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rduVJL697A28",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74fe822d-77ae-42d4-9171-760dee6286ef"
      },
      "source": [
        "w2v_model.wv.most_similar([\"mortes\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('mortes_causadas', 0.750665545463562),\n",
              " ('novas_mortes', 0.704981803894043),\n",
              " ('mortes_confirmadas', 0.6422505974769592),\n",
              " ('mortes,', 0.6406204700469971),\n",
              " ('vidas_perdidas', 0.6357656717300415),\n",
              " ('mortos', 0.6347059011459351),\n",
              " ('mortes_diárias', 0.6335180401802063),\n",
              " ('óbitos', 0.6294437646865845),\n",
              " ('1300_mortes', 0.6261337995529175),\n",
              " ('mil_mortes', 0.6245402097702026)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GnO8u4J6fnY",
        "colab_type": "text"
      },
      "source": [
        "**Podemos compararar a taxa de similaridade para termos específicos.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSZ3e0qeqR0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c21f889-c44c-46b2-db22-78af90cac3e4"
      },
      "source": [
        "w2v_model.wv.similarity(\"coronavirus\", 'mortes')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.38125765"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNOuLotAqZuy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6c011da-a3e4-415b-bdc9-d7a8bfdbf938"
      },
      "source": [
        "w2v_model.wv.similarity(\"coronavirus\", 'casos')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.40818962"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrv67Or1qc0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e6826d4-48c7-4612-8f9c-bea72926c174"
      },
      "source": [
        "w2v_model.wv.similarity(\"pandemia\", 'coronavirus')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.10278622"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg6Us2Tp9NwJ",
        "colab_type": "text"
      },
      "source": [
        "# Aplicando K-Means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r9qksJG9-Wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importando algoritmo KMeans da biblioteca Sklearn.\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnjRhOa0XRzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Carregando modelo Word2VEC.\n",
        "word_vectors = w2v_model.wv\n",
        "#Criando instância do algoritmo K-Means e passando como entrada os vetores originados pelo Word2VEC.\n",
        "model = KMeans(n_clusters=2, init='k-means++', max_iter=1000, n_init=50).fit(X=word_vectors.vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj7oNOz4xZVl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "5b8eea6f-2ee4-47d9-d95d-e997a157a7c4"
      },
      "source": [
        "word_vectors.similar_by_vector(model.cluster_centers_[0], topn=10, restrict_vocab=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('@guicidade', 0.9998173713684082),\n",
              " ('padaria,', 0.9998025894165039),\n",
              " ('@maumeirelles', 0.9997973442077637),\n",
              " ('antibiotico', 0.9997907876968384),\n",
              " ('critico', 0.9997900724411011),\n",
              " ('otaku', 0.9997895956039429),\n",
              " ('@prudmin', 0.9997768998146057),\n",
              " ('banaliza', 0.9997758865356445),\n",
              " ('influenza,', 0.9997735023498535),\n",
              " ('fatos,', 0.9997729063034058)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 407
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFWaDlYYxtoT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "8e1b4fcc-7c4a-4e5e-9a78-7e5c8142f911"
      },
      "source": [
        "word_vectors.similar_by_vector(model.cluster_centers_[1], topn=10, restrict_vocab=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('6,5', 0.9983620643615723),\n",
              " ('#cbnlondrina', 0.9981963634490967),\n",
              " ('280', 0.9977450370788574),\n",
              " ('atu…', 0.9976952075958252),\n",
              " ('ajuste', 0.9976508617401123),\n",
              " ('mantémse', 0.9975696802139282),\n",
              " ('divulgou,', 0.9974309206008911),\n",
              " ('vilhena', 0.9974086284637451),\n",
              " ('veranópolis', 0.9972860813140869),\n",
              " ('concentra', 0.9972808361053467)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 408
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL-MDRTTx0G6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#word_vectors.similar_by_vector(model.cluster_centers_[2], topn=10, restrict_vocab=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIpDjbcQxa0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "positive_cluster_center = model.cluster_centers_[0]\n",
        "negative_cluster_center = model.cluster_centers_[1]\n",
        "#neutral_cluster_center = model.cluster_centers_[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqR8eQhEXbCm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "39e94bf2-3504-4895-96cd-abc3406732b2"
      },
      "source": [
        "#Verificando os vetores que foram entradas para o algoritmo, criados pelo modelo Word2VEC.\n",
        "word_vectors.vectors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.04830528, -0.0888536 ,  0.0121821 , ...,  0.02902986,\n",
              "        -0.06335721, -0.04157186],\n",
              "       [-0.01620184, -0.08371107, -0.02201089, ...,  0.00480282,\n",
              "        -0.02898812, -0.00793971],\n",
              "       [-0.03907719, -0.04570566,  0.07377318, ..., -0.06223137,\n",
              "        -0.10727366,  0.07251507],\n",
              "       ...,\n",
              "       [-0.07516849, -0.02846682,  0.05661228, ..., -0.04819285,\n",
              "        -0.09105309,  0.01191978],\n",
              "       [-0.07529917, -0.02962228,  0.068182  , ..., -0.05000691,\n",
              "        -0.10008409,  0.02093332],\n",
              "       [-0.0758184 , -0.02824306,  0.06028139, ..., -0.04901572,\n",
              "        -0.08991348,  0.01396022]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 411
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KqEfIOPXKbb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0a28bef9-3859-4a84-faef-752b0a5ecf64"
      },
      "source": [
        "model.cluster_centers_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-7.21572861e-02, -2.74464209e-02,  6.33466169e-02,\n",
              "         1.63704399e-02,  7.07888529e-02, -2.70095584e-03,\n",
              "        -5.42753004e-02, -1.25905806e-02,  3.67578156e-02,\n",
              "        -5.69887226e-03,  7.08400533e-02, -7.03297630e-02,\n",
              "         9.57227312e-05, -6.25459924e-02,  5.14166765e-02,\n",
              "         2.14814395e-02, -4.90327254e-02, -1.23748612e-02,\n",
              "        -1.67479794e-02,  1.23052765e-02, -3.51850837e-02,\n",
              "        -3.25769209e-03,  3.64111364e-02, -3.41699198e-02,\n",
              "         1.56835943e-01,  8.15555975e-02, -1.29096329e-01,\n",
              "         8.46559182e-02, -8.70009661e-02,  3.61581706e-02,\n",
              "        -8.24830905e-02, -6.15216792e-02,  2.83797793e-02,\n",
              "        -1.47375241e-01,  1.36916647e-02, -7.47230202e-02,\n",
              "        -8.03454220e-02,  5.34621328e-02,  5.24857454e-02,\n",
              "        -3.83956591e-03, -4.94446270e-02, -8.64642411e-02,\n",
              "         2.88445177e-03, -7.58034214e-02,  5.08014001e-02,\n",
              "         1.43853566e-02, -5.76101467e-02,  2.54720971e-02,\n",
              "         2.34782360e-02,  3.54748368e-02,  1.42947969e-03,\n",
              "         1.04011893e-01, -8.28602910e-03, -1.93013214e-02,\n",
              "         6.40942156e-02, -1.46711050e-02,  6.58455044e-02,\n",
              "        -4.12345938e-02, -5.82106374e-02, -1.16652764e-01,\n",
              "         4.88477610e-02, -6.07246980e-02,  8.43724832e-02,\n",
              "         2.60330290e-02, -2.86692921e-02,  2.53315587e-02,\n",
              "        -3.99613380e-02,  1.93672515e-02,  9.31292698e-02,\n",
              "        -1.99596509e-02, -8.23679268e-02,  7.36695305e-02,\n",
              "         1.50754191e-02,  4.47510295e-02, -3.51063423e-02,\n",
              "        -1.15068205e-01, -5.35853654e-02, -4.76902686e-02,\n",
              "         4.75622900e-02,  3.73504050e-02, -1.10387348e-01,\n",
              "        -1.10837854e-02,  5.54920221e-03,  1.25702191e-02,\n",
              "         8.99933577e-02,  1.70001783e-03,  7.73343258e-04,\n",
              "         1.66450869e-02, -4.29672701e-03, -4.85006012e-02,\n",
              "        -1.91150559e-03, -2.88037187e-03, -4.15770970e-02,\n",
              "        -7.27651641e-02,  9.26952288e-02, -6.80635497e-02,\n",
              "         4.55567576e-02,  9.62755159e-02, -3.64632122e-02,\n",
              "        -7.52980355e-03,  1.10753812e-02,  5.77100329e-02,\n",
              "         9.72990841e-02,  6.80258647e-02,  7.91437253e-02,\n",
              "        -5.76540977e-02,  1.06309675e-01,  3.47707495e-02,\n",
              "         3.10877748e-02, -8.12092498e-02, -3.99681516e-02,\n",
              "         3.78986560e-02, -3.76844183e-02,  2.58572511e-02,\n",
              "        -1.75424293e-02,  2.65491642e-02, -2.18964759e-02,\n",
              "         3.74309979e-02, -5.43493032e-02,  1.06968105e-01,\n",
              "        -8.20872411e-02,  4.57010493e-02, -7.90361017e-02,\n",
              "        -4.41273600e-02, -3.61466780e-02, -7.58378431e-02,\n",
              "        -3.02854702e-02, -7.81638082e-03,  1.52123393e-02,\n",
              "         1.13013878e-01,  8.05374160e-02,  4.67821211e-02,\n",
              "        -1.93969160e-03, -3.45464125e-02, -3.79943289e-02,\n",
              "         2.23612227e-02, -4.84371781e-02,  2.61958987e-02,\n",
              "        -3.47606391e-02, -4.75704893e-02,  3.19702588e-02,\n",
              "        -3.78867462e-02, -2.83919200e-02,  8.72542523e-03,\n",
              "         4.96772006e-02, -2.71769688e-02, -3.57221514e-02,\n",
              "         8.22604820e-02, -4.25605811e-02,  7.43934438e-02,\n",
              "        -1.98195577e-02, -1.22493416e-01,  4.70979847e-02,\n",
              "        -3.79400700e-02, -7.08938241e-02, -5.33505492e-02,\n",
              "        -1.30407885e-01, -7.49215111e-02,  1.28670651e-02,\n",
              "        -4.03561331e-02,  1.05338860e-02, -3.90480347e-02,\n",
              "         3.43062468e-02, -1.50251295e-02,  8.54869634e-02,\n",
              "         2.96145678e-02, -8.74841437e-02, -2.63336897e-02,\n",
              "        -6.75375387e-03,  4.31515574e-02, -4.47513200e-02,\n",
              "         2.67295726e-02,  3.15384492e-02,  2.58734357e-02,\n",
              "         1.07507072e-02,  1.09831197e-02,  9.66229737e-02,\n",
              "        -8.45738575e-02,  6.27901778e-02, -5.39699756e-02,\n",
              "         1.08361185e-01, -5.10578007e-02,  9.59008038e-02,\n",
              "         4.34193648e-02,  1.61722093e-03,  7.50769302e-02,\n",
              "        -5.25307329e-03, -9.13295057e-03, -1.14026226e-01,\n",
              "         1.40769795e-01,  5.09491004e-03, -6.83887675e-02,\n",
              "         5.75423911e-02, -7.13124424e-02,  3.78300473e-02,\n",
              "        -8.78627747e-02, -3.50806415e-02,  6.52595162e-02,\n",
              "        -1.01334248e-02, -8.11875425e-03, -1.58176031e-02,\n",
              "        -4.97793406e-02, -9.26737785e-02,  3.89006361e-02,\n",
              "         1.59475449e-02,  2.09611524e-02,  8.15030113e-02,\n",
              "        -1.44930277e-02,  3.75162158e-03, -5.13537563e-02,\n",
              "        -1.07193366e-02, -5.15834875e-02,  5.12095075e-03,\n",
              "        -1.27405431e-02,  2.48287199e-03,  5.58167957e-02,\n",
              "         5.22498973e-04,  7.72348940e-02, -1.29981935e-02,\n",
              "         1.71741862e-02,  5.94920740e-02, -8.20521563e-02,\n",
              "        -1.04641832e-01,  2.80461600e-03,  4.66874894e-03,\n",
              "         8.71420372e-03,  3.17570334e-03,  9.11665633e-02,\n",
              "         7.78574497e-03,  2.63255127e-02,  1.48425121e-02,\n",
              "         7.77951032e-02, -7.93550536e-02,  8.69527832e-03,\n",
              "         7.82389417e-02,  3.74210253e-02,  2.86742300e-03,\n",
              "         8.61480609e-02,  1.10268705e-02,  1.13755196e-01,\n",
              "         9.05583426e-02, -1.47491153e-02, -3.33479382e-02,\n",
              "        -8.13310128e-03, -5.72979590e-03,  2.29005404e-02,\n",
              "        -5.89529388e-02, -3.84204797e-02,  5.10162786e-02,\n",
              "         1.21211343e-01,  2.97163166e-02, -6.92736804e-02,\n",
              "        -1.94666162e-02, -9.54848751e-02,  1.34753957e-02,\n",
              "         1.21316668e-02,  1.20919822e-02,  4.93700430e-02,\n",
              "        -7.96062425e-02,  5.20559922e-02,  3.01804598e-02,\n",
              "         3.25662792e-02, -2.12997347e-02,  7.03638867e-02,\n",
              "         6.12220578e-02,  3.23186330e-02,  2.40150671e-02,\n",
              "        -5.71798794e-02,  6.35460950e-03, -4.21611555e-02,\n",
              "         9.09139216e-02,  4.84902859e-02, -1.09587029e-01,\n",
              "        -2.07542405e-02, -2.52223779e-02, -9.54650566e-02,\n",
              "        -9.02420655e-03, -2.13111192e-02, -1.63943991e-02,\n",
              "         4.85504977e-02,  3.43145616e-02,  6.40207082e-02,\n",
              "         8.15038085e-02,  1.80203095e-02, -1.12082139e-02,\n",
              "         4.98708561e-02,  1.93952098e-02, -4.29380313e-02,\n",
              "        -4.27328199e-02, -5.11892959e-02, -6.85653090e-02,\n",
              "        -3.31825837e-02,  1.30032701e-02,  3.47903706e-02,\n",
              "        -1.54891480e-02,  3.06825228e-02,  1.01389224e-02,\n",
              "        -4.95193079e-02, -9.39628109e-02,  1.64097510e-02],\n",
              "       [-6.55119568e-02, -2.82498486e-02,  3.21488529e-02,\n",
              "        -2.71949358e-03,  8.40950608e-02,  1.73783451e-02,\n",
              "        -5.82973585e-02, -3.35184634e-02,  5.07294014e-02,\n",
              "         3.29852104e-02,  7.04170614e-02, -8.38844329e-02,\n",
              "        -1.87401492e-02, -6.07039668e-02,  5.89899719e-02,\n",
              "         1.42300259e-02, -2.43900418e-02,  2.87933312e-02,\n",
              "        -3.02813761e-03,  3.55105996e-02, -3.90417092e-02,\n",
              "        -1.56367533e-02,  3.01113762e-02, -2.72494182e-02,\n",
              "         1.27500907e-01,  4.39432934e-02, -1.28373116e-01,\n",
              "         5.07640317e-02, -9.99137163e-02,  4.04735580e-02,\n",
              "        -7.83660635e-02, -7.09299818e-02,  2.37372853e-02,\n",
              "        -1.22549675e-01,  1.46761565e-02, -6.42119274e-02,\n",
              "        -5.34440354e-02,  5.08457161e-02,  8.67090672e-02,\n",
              "        -2.44469438e-02, -5.29349148e-02, -9.50939059e-02,\n",
              "         2.70445533e-02, -5.55681735e-02,  3.92147005e-02,\n",
              "         6.60342164e-04, -5.85426092e-02,  9.07728728e-03,\n",
              "         3.67886722e-02,  6.56717047e-02, -8.86812527e-03,\n",
              "         6.61433637e-02,  7.54906889e-03, -2.81526223e-02,\n",
              "         1.02172561e-01, -3.16235386e-02,  6.00666292e-02,\n",
              "        -5.87338991e-02, -7.41815343e-02, -1.07334986e-01,\n",
              "         3.66057903e-02, -5.92921935e-02,  9.86136496e-02,\n",
              "         2.36708205e-02, -5.32725751e-02,  9.16137081e-03,\n",
              "        -3.78025919e-02,  4.03920971e-02,  7.87299275e-02,\n",
              "        -5.30055538e-03, -4.42905128e-02,  6.10117465e-02,\n",
              "        -2.27994565e-03,  6.60575330e-02, -2.92145386e-02,\n",
              "        -9.45530087e-02, -3.56477797e-02, -2.09381469e-02,\n",
              "         6.74325675e-02,  1.65958963e-02, -9.37140435e-02,\n",
              "        -2.37215143e-02,  2.97901146e-02,  2.04262249e-02,\n",
              "         8.78423750e-02, -8.66349135e-03,  1.97856128e-02,\n",
              "         2.65429970e-02,  2.25900356e-02, -6.12047315e-02,\n",
              "         3.12071480e-02, -2.84000463e-03, -5.25906049e-02,\n",
              "        -8.83718356e-02,  7.17108101e-02, -7.37424567e-02,\n",
              "         4.78501022e-02,  7.40959942e-02, -4.83400449e-02,\n",
              "         1.21663650e-03,  3.77038643e-02,  3.91934998e-02,\n",
              "         1.02362826e-01,  6.96264878e-02,  5.86606190e-02,\n",
              "        -7.15710148e-02,  1.00888245e-01,  5.30595034e-02,\n",
              "         3.57126817e-02, -6.20198213e-02, -2.04666127e-02,\n",
              "         4.98961657e-02, -4.14677039e-02, -1.55551452e-02,\n",
              "        -9.79452953e-03,  9.04150587e-03, -2.48909667e-02,\n",
              "         2.21740846e-02, -1.85891446e-02,  5.61139025e-02,\n",
              "        -5.29986396e-02,  7.35290200e-02, -7.64819980e-02,\n",
              "        -3.20149213e-02, -1.91229116e-02, -5.15716970e-02,\n",
              "        -2.90478971e-02, -2.07271101e-03,  8.62991624e-03,\n",
              "         1.04923800e-01,  5.63971177e-02,  4.09693494e-02,\n",
              "        -2.32955664e-02, -6.70532361e-02, -5.84703945e-02,\n",
              "         1.27723683e-02, -5.86926267e-02,  1.64465979e-02,\n",
              "        -1.34971514e-02, -5.82809448e-02,  1.57279260e-02,\n",
              "        -2.02029012e-02, -5.73220253e-02,  2.32933257e-02,\n",
              "         2.71634553e-02, -2.87331771e-02, -2.69174390e-02,\n",
              "         7.26724565e-02, -3.61668915e-02,  8.82304162e-02,\n",
              "        -4.49400097e-02, -5.97763620e-02,  5.37960865e-02,\n",
              "        -2.01000031e-02, -3.99467349e-02, -5.31654619e-02,\n",
              "        -8.24720040e-02, -4.61713225e-02,  3.64857465e-02,\n",
              "        -4.03177589e-02,  2.28849500e-02, -2.92410310e-02,\n",
              "         1.68962404e-02,  2.05589943e-02,  7.47839287e-02,\n",
              "         3.66837494e-02, -7.64665529e-02, -8.68020020e-03,\n",
              "         2.07550731e-03,  5.01112118e-02, -3.72264534e-04,\n",
              "         7.52073973e-02,  5.05487323e-02,  2.20607873e-02,\n",
              "        -1.49602666e-02,  2.91626714e-02,  4.41328250e-02,\n",
              "        -6.19054437e-02,  4.95309010e-02, -7.33972937e-02,\n",
              "         9.51685160e-02, -5.48907593e-02,  1.10160552e-01,\n",
              "         2.53638439e-02,  1.41110579e-02,  9.92038324e-02,\n",
              "        -1.40680373e-02, -9.15863924e-03, -7.73693770e-02,\n",
              "         1.42163977e-01, -3.13607417e-02, -6.22860864e-02,\n",
              "         7.41595998e-02, -6.69061542e-02,  2.60616392e-02,\n",
              "        -7.79635534e-02, -4.10624705e-02,  6.94964305e-02,\n",
              "         5.92861231e-03,  7.51979090e-03, -2.26163417e-02,\n",
              "        -2.14673132e-02, -6.33884147e-02,  4.65979762e-02,\n",
              "        -1.06478473e-02,  1.73828304e-02,  4.85502928e-02,\n",
              "        -3.89423966e-02,  3.65311839e-02, -5.35232686e-02,\n",
              "        -1.31905237e-02, -7.56925493e-02, -2.78520267e-02,\n",
              "        -1.56142842e-03,  1.46039240e-02,  6.20717891e-02,\n",
              "         3.73968557e-02,  2.67803147e-02, -8.02620500e-03,\n",
              "         2.58472618e-02,  5.25950715e-02, -9.10273418e-02,\n",
              "        -1.03011422e-01,  3.43621671e-02, -1.72930118e-02,\n",
              "        -1.17209386e-02, -7.54734501e-03,  8.32665339e-02,\n",
              "        -3.46811535e-03,  3.04794908e-02,  1.89161953e-03,\n",
              "         7.28654563e-02, -2.90971063e-02, -1.86932310e-02,\n",
              "         5.26922569e-02,  2.63862349e-02, -2.10316200e-03,\n",
              "         6.70254603e-02, -9.56922770e-04,  1.01318032e-01,\n",
              "         1.00547686e-01, -2.26374399e-02, -4.14989665e-02,\n",
              "        -1.44066270e-02,  2.53438465e-02,  1.22764781e-02,\n",
              "        -6.83867037e-02, -4.11244892e-02,  2.41124146e-02,\n",
              "         9.19530764e-02,  3.00635826e-02, -7.83673599e-02,\n",
              "        -2.89393887e-02, -1.11443639e-01,  1.48127871e-02,\n",
              "        -3.48275900e-03,  7.40171317e-03,  4.68372591e-02,\n",
              "        -7.42278546e-02,  6.83691353e-02, -2.06370130e-02,\n",
              "         3.42563279e-02, -2.70337146e-02,  2.67375410e-02,\n",
              "         1.67256370e-02, -1.21295936e-02, -6.69354573e-04,\n",
              "        -6.92533106e-02, -1.32234069e-03, -2.26211138e-02,\n",
              "         7.76049346e-02,  4.41602059e-02, -4.52496000e-02,\n",
              "        -3.20733972e-02, -2.44052820e-02, -7.05260262e-02,\n",
              "        -8.07551108e-03, -1.78487822e-02,  5.91798406e-03,\n",
              "         5.70516512e-02,  8.28807801e-02,  5.08884378e-02,\n",
              "         8.83044973e-02,  1.02431607e-02,  7.14153051e-04,\n",
              "         5.71084656e-02, -1.96578503e-02, -3.70427482e-02,\n",
              "        -6.14347160e-02, -6.13192022e-02, -5.18376827e-02,\n",
              "        -4.80250418e-02,  1.15419980e-02,  3.43603641e-03,\n",
              "        -4.90625110e-03,  4.20257524e-02,  3.22799804e-03,\n",
              "        -3.27016190e-02, -6.20010495e-02,  8.91167112e-03]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 412
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRQpEqHj_BEc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4f59d90-1ec3-48dc-a198-58a31532b1c7"
      },
      "source": [
        "len(model.labels_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33032"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 413
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScCYPYk0XnoI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "783efffa-cf3f-4f74-eb0a-c148e0929d1f"
      },
      "source": [
        "#Verificando os labels originados pelo modelo.\n",
        "model.labels_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, ..., 0, 0, 0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 414
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqLT1tBQXrkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Criando DataFrame com as classificações para os tweets.\n",
        "df_kmeans = pd.DataFrame(data=model.labels_, columns=['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzwCr24tXyWZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "56bfacb8-d84f-4da6-f554-b120ea26a244"
      },
      "source": [
        "#Visualizando o novo DataFrame criado.\n",
        "df_kmeans"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33027</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33028</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33029</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33030</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33031</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33032 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       text\n",
              "0         1\n",
              "1         1\n",
              "2         0\n",
              "3         0\n",
              "4         1\n",
              "...     ...\n",
              "33027     0\n",
              "33028     0\n",
              "33029     0\n",
              "33030     0\n",
              "33031     0\n",
              "\n",
              "[33032 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 416
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9nS7aCbZuJ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b7440cc7-68b3-4e19-d87e-0ec2c4477fac"
      },
      "source": [
        "#Distruibuição das sentenças nos clusters pelo algoritmo K-Means.\n",
        "df_kmeans['text'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    25640\n",
              "1     7392\n",
              "Name: text, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 417
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pPCQMzx63bX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b2fcf329-5325-4d88-ac8a-7d34d3414281"
      },
      "source": [
        "#Porcentagem que representa a distribuição das sentenças nos clusters pelo algoritmo K-Means.\n",
        "df_kmeans['text'].value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.776217\n",
              "1    0.223783\n",
              "Name: text, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 418
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkmCimHTaxyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25391a65-8db0-459b-ebd7-b7d0919b957a"
      },
      "source": [
        "#Verificando os clusters únicos.\n",
        "df_kmeans['text'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 419
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSMHnyZg6rgd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "59e486f3-1ea8-4584-fe56-ff3ea6bfd8f8"
      },
      "source": [
        "#Criando Vocabulário em formato de Dicionário para o sentimento das palavras.\n",
        "words = pd.DataFrame(word_vectors.vocab.keys())\n",
        "#Nomeando a coluna do DataFrame.\n",
        "words.columns = ['words']\n",
        "#Atribuindo as palavras a classe positiva ou negativa, de acordo com a clusterização.\n",
        "words['vectors'] = words.words.apply(lambda x: word_vectors.wv[f'{x}'])\n",
        "words['cluster'] = words.vectors.apply(lambda x: model.predict([np.array(x)]))\n",
        "words.cluster = words.cluster.apply(lambda x: x[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXCf-GaVvYCd",
        "colab_type": "text"
      },
      "source": [
        "*Explicação para Função Lambda que atribui um sentimento em potencial para as palavras.*\n",
        "\n",
        "**Para atribuir uma pontuação de sentimento para cada palavra foi realizada uma multiplicação pelo quão próximos eles estavam de seu cluster (para denotar o quão potencialmente positivos / negativos os termos são). Como a pontuação que o algoritmo K-means produz é a distância de ambos os clusters, para ponderá-los corretamente, foi feita a multiplicação pelo inverso da pontuação de proximidade (divisão da pontuação de sentimento pela pontuação de proximidade).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exlvF0Qd6ulu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Para o cluster 0 atribuiu-se o sentimento como positivo e para o outro cluster atribuiu-se o sentimento negativo.\n",
        "words['cluster_value'] = [1 if i==0 else -1 for i in words.cluster]\n",
        "words['closeness_score'] = words.apply(lambda x: 1/(model.transform([x.vectors]).min()), axis=1)\n",
        "words['sentiment_coeff'] = words.closeness_score * words.cluster_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HamQZYMm6v56",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "01803219-2c3d-4e7c-cdbf-8a1311c0e1a2"
      },
      "source": [
        "words.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>vectors</th>\n",
              "      <th>cluster</th>\n",
              "      <th>cluster_value</th>\n",
              "      <th>closeness_score</th>\n",
              "      <th>sentiment_coeff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tudo</td>\n",
              "      <td>[-0.055858582, -0.034655627, 0.07575433, 0.025...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.317277</td>\n",
              "      <td>1.317277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mudou</td>\n",
              "      <td>[-0.06306405, -0.02387166, 0.057486724, 0.0313...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.083671</td>\n",
              "      <td>3.083671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>forma</td>\n",
              "      <td>[-0.056214195, -0.014575296, 0.05572673, 0.030...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.737905</td>\n",
              "      <td>2.737905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>trabalhar,</td>\n",
              "      <td>[-0.062424235, -0.029514665, 0.07425506, 0.033...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.929287</td>\n",
              "      <td>1.929287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nada</td>\n",
              "      <td>[-0.05544726, -0.029607985, 0.08812149, 0.0292...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.322934</td>\n",
              "      <td>1.322934</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        words  ... sentiment_coeff\n",
              "0        tudo  ...        1.317277\n",
              "1       mudou  ...        3.083671\n",
              "2       forma  ...        2.737905\n",
              "3  trabalhar,  ...        1.929287\n",
              "4        nada  ...        1.322934\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 422
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXIc3OkQv9tv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "285ce5b1-378d-4818-bc56-f8d748557770"
      },
      "source": [
        "words.tail(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>vectors</th>\n",
              "      <th>cluster</th>\n",
              "      <th>cluster_value</th>\n",
              "      <th>closeness_score</th>\n",
              "      <th>sentiment_coeff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33027</th>\n",
              "      <td>@bresciia</td>\n",
              "      <td>[-0.07572785, -0.02133777, 0.06326089, 0.01852...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>13.614501</td>\n",
              "      <td>13.614501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33028</th>\n",
              "      <td>@theluks21</td>\n",
              "      <td>[-0.07558556, -0.028088983, 0.0642249, 0.01247...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15.027169</td>\n",
              "      <td>15.027169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33029</th>\n",
              "      <td>@kozixmana</td>\n",
              "      <td>[-0.07529917, -0.02962228, 0.068182, 0.0175566...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>13.216446</td>\n",
              "      <td>13.216446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33030</th>\n",
              "      <td>@victorkazoo</td>\n",
              "      <td>[-0.07681176, -0.026911363, 0.0656198, 0.02408...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>14.671299</td>\n",
              "      <td>14.671299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33031</th>\n",
              "      <td>#renunciaperes</td>\n",
              "      <td>[-0.0758184, -0.028243065, 0.06028139, 0.01308...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>11.633633</td>\n",
              "      <td>11.633633</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                words  ... sentiment_coeff\n",
              "33027       @bresciia  ...       13.614501\n",
              "33028      @theluks21  ...       15.027169\n",
              "33029      @kozixmana  ...       13.216446\n",
              "33030    @victorkazoo  ...       14.671299\n",
              "33031  #renunciaperes  ...       11.633633\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 423
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj1gMCxnwDP0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be49e6ed-2149-4f6b-c3d0-dfa4c8f8baee"
      },
      "source": [
        "words.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33032, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 424
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3uHRA4m6xbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words[['words', 'sentiment_coeff']].to_csv('sentiment_dictionary.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eluHDoFM3ZMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0LhdN-BdGFj",
        "colab_type": "text"
      },
      "source": [
        "# Aplicando DBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g-HDXU_ziblw",
        "colab": {}
      },
      "source": [
        "#Importando algoritmo da Biblioteca Sklearn.\n",
        "from sklearn.cluster import DBSCAN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7YBEXSD0uyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_vectors = w2v_model.wv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_l9Yqasjibl5",
        "colab": {}
      },
      "source": [
        "#Criando instância do algoritmo e treinando o modelo com os dados.\n",
        "clustering = DBSCAN(eps=0.5, min_samples=2).fit(X=word_vectors.vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aGK_Ovp_ibmA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91cc7a8c-e745-4a4b-da5d-8c0b7765922c"
      },
      "source": [
        "#Verificando os labels originados.\n",
        "clustering.labels_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1, -1,  0, ...,  0,  0,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aR1JSKli1oOx",
        "colab": {}
      },
      "source": [
        "df_dbscan = pd.DataFrame(data=clustering.labels_, columns=['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BKipYs_51oO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32e48499-ea57-43d3-b772-8d650803e220"
      },
      "source": [
        "df_dbscan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30780</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30781</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30782</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30783</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30784</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30785 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       text\n",
              "0        -1\n",
              "1        -1\n",
              "2         0\n",
              "3         0\n",
              "4        -1\n",
              "...     ...\n",
              "30780     0\n",
              "30781     0\n",
              "30782     0\n",
              "30783     0\n",
              "30784     0\n",
              "\n",
              "[30785 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c-FH5rGA1oPB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "784542ad-1b1f-4956-d97d-d0835d6b0787"
      },
      "source": [
        "df_dbscan['text'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0     30653\n",
              "-1        46\n",
              " 5        12\n",
              " 6         7\n",
              " 12        6\n",
              " 2         6\n",
              " 14        6\n",
              " 8         5\n",
              " 4         5\n",
              " 7         4\n",
              " 11        4\n",
              " 19        4\n",
              " 1         4\n",
              " 15        4\n",
              " 13        3\n",
              " 3         3\n",
              " 10        3\n",
              " 17        3\n",
              " 16        3\n",
              " 9         2\n",
              " 18        2\n",
              "Name: text, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rWYb1hz91oPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f07ae31-843e-4875-f2e3-c16dcf17c362"
      },
      "source": [
        "df_dbscan['text'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
              "       16, 17, 18, 19])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ391gZt-0gF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#word_vectors.similar_by_vector(model.cluster_centers_[0], topn=10, restrict_vocab=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5FaEkU_-4vM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#word_vectors.similar_by_vector(model.cluster_centers_[1], topn=10, restrict_vocab=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciL422cOcYzu",
        "colab_type": "text"
      },
      "source": [
        "# Aplicando Mean Shift"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XoMyAqzEibkT",
        "colab": {}
      },
      "source": [
        "#Importando algoritmo da Biblioteca Sklearn.\n",
        "#from sklearn.cluster import MeanShift"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YOZ3e-iJibkn",
        "colab": {}
      },
      "source": [
        "#Criando instância do algoritmo.\n",
        "#word_vectors = w2v_model.wv\n",
        "#clustering = MeanShift(bandwidth=2).fit(X=word_vectors.vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wszzL4TIibk1",
        "colab": {}
      },
      "source": [
        "#Verificando os labels originados.\n",
        "#clustering.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1ZHNdT1TfCx6",
        "colab": {}
      },
      "source": [
        "#df_meanshift = pd.DataFrame(data=clustering.labels_, columns=['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7bm87iXofCx-",
        "colab": {}
      },
      "source": [
        "#df_meanshift"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wrRilpIkfCyE",
        "colab": {}
      },
      "source": [
        "#df_meanshift['text'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fn5iCjArfCyI",
        "colab": {}
      },
      "source": [
        "#df_meanshift['text'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}