{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Apresenta√ß√£o-PID-Implementa√ß√£o.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QrMuIDhZdOVm",
        "4IM7NpH3gWma"
      ],
      "authorship_tag": "ABX9TyO/OrEZnAQS0DI/XWwkAjYE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/italolima04/monitoria-probabilidade-estatistica/blob/master/Pesquisa-PID/Implementa%C3%A7%C3%A3o-Algoritmos/Apresenta%C3%A7%C3%A3o_PID_Implementa%C3%A7%C3%A3o.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrMuIDhZdOVm",
        "colab_type": "text"
      },
      "source": [
        "# Aprendizado N√£o-Supervisionado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHF3ifAbiTD1",
        "colab_type": "text"
      },
      "source": [
        "\"*O aprendizado n√£o supervisionado √© um ramo do Machine Learning que aprende com dados de teste que n√£o foram rotulados, classificados ou categorizados previamente. Em vez de responder √† programa√ß√£o de um operador, o aprendizado n√£o supervisionado identifica semelhan√ßas nos dados e reage com base na presen√ßa ou aus√™ncia de tais semelhan√ßas em cada novo dado*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NZFkvCagZCO",
        "colab_type": "text"
      },
      "source": [
        "**Essa abordagem de Aprendizado de M√°quina √© √∫til quando n√£o possu√≠mos r√≥tulos (Labels) para os nossos dados. Isto √© importante pelo fato de que em muitos contexos possuir esses dados pode ser dif√≠cil e/ou custoso.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9U4habTh8Ii",
        "colab_type": "text"
      },
      "source": [
        "Nesse caso de estudo, pelo fato da base de dados ser atual, real e ter sido coletada em um contexto de uma rede social, n√£o se faz poss√≠vel possuir r√≥tulos para a classifica√ß√£o de textos. Dessa forma, objetiva-se agrupar os dados de forma n√£o supervisionada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IM7NpH3gWma",
        "colab_type": "text"
      },
      "source": [
        "# Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6tuGZLwdTQZ",
        "colab_type": "text"
      },
      "source": [
        "**Clustering √© uma t√©cnica de Aprendizado de M√°quina que envolve o agrupamento de pontos de dados.**\n",
        "\n",
        "Utiliza-se algoritmos de clustering para agrupar pontos de dados em grupos espec√≠ficos, cujos, na teoria devem possuir propriedades/caracter√≠sticas semelhantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9j8dXGwdqlI",
        "colab_type": "text"
      },
      "source": [
        "**K-Means**\n",
        "\n",
        "K-Means √© um m√©todo de Clustering que tem como objetivo o particionamento de n observa√ß√µes dentre k grupos, onde cada observa√ß√£o pertence ao grupo mais pr√≥ximo da m√©dia.\n",
        "\n",
        "\n",
        "A execu√ß√£o do K-Means segue um conjunto de passos, descritos abaixo:\n",
        "\n",
        "1. Selecionar um n√∫mero de classes/grupos para utilizar e inicializarmos aleatoriamente seus respectivos pontos centrais (Centr√≥ides). Esses grupos podem ser definidos de acordo com a regra do neg√≥cio ou a perspectiva do problema.\n",
        "2. Cada de ponto de dados √© classificado, baseando-se na dist√¢ncia entre esse ponto e o centro do grupo.\n",
        "3. Com base nos pontos classificados, recalcula-se o centr√≥ide, a partir da m√©dia das dist√¢ncias de todos os vetores do grupo.  \n",
        "\n",
        "Esses dois √∫ltimos passos s√£o repetidos, at√© que o limite de itera√ß√µes pr√©-determinado seja atingido, ou quando os centr√≥ides n√£o sofrerem altera√ß√µes significantes de uma itera√ß√£o para outra.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfIbkTePfrSh",
        "colab_type": "text"
      },
      "source": [
        "**Vantagens:**\n",
        "\n",
        "- √â r√°pido, visto que o que √© feito √© somente calcular as dist√¢ncias entre os pontos e os centr√≥ides do grupo. Possui ent√£o complexidade linear O(n). \n",
        "\n",
        "- √â simples de aplicar e se mostra eficiente.\n",
        "\n",
        "**Desvantagens:**\n",
        "\n",
        "- Dificuldade para determinar a quantidade de clusters (Dependendo do Objetivo).\n",
        "\n",
        "- Pode ser inconsistente, a depende do conjunto de dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkC8_WYKbZzk",
        "colab_type": "text"
      },
      "source": [
        "# Importando Bibliotecas, M√≥dulos e Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EslyX3HlbG4v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fe60c506-c73a-4bdf-bca0-5bed9be3ce4e"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy  \n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import re  \n",
        "from collections import defaultdict \n",
        "import logging \n",
        "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXYfvKDAbeZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Criando Data Frame a partir dos dados.\n",
        "data = pd.read_csv('dados-pesquisa.csv')\n",
        "data = data[['created_at', 'text', 'lang']]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODGTbFZojcmE",
        "colab_type": "text"
      },
      "source": [
        "# Visualizando e Explorando os dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrcjQhYxjqS0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6760469f-7d34-4971-9d3d-3e60302ab74d"
      },
      "source": [
        "#Visualizando as 5 primeiras linhas.\n",
        "data.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mon May 18 17:53:01 +0000 2020</td>\n",
              "      <td>Tudo mudou na nossa forma de trabalhar, mas na...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mon May 18 17:52:17 +0000 2020</td>\n",
              "      <td>McDonald‚Äôs j√° reabriu lojas ao p√∫blico https:/...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mon May 18 17:50:40 +0000 2020</td>\n",
              "      <td>Sindicato, est√° atento em tudo o que envolve s...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mon May 18 17:49:17 +0000 2020</td>\n",
              "      <td>Nossos problemas da sa√∫de definitivamente acab...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mon May 18 17:49:06 +0000 2020</td>\n",
              "      <td>F√°bricas de todo o mundo se viram obrigadas a ...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       created_at  ... lang\n",
              "0  Mon May 18 17:53:01 +0000 2020  ...   pt\n",
              "1  Mon May 18 17:52:17 +0000 2020  ...   pt\n",
              "2  Mon May 18 17:50:40 +0000 2020  ...   pt\n",
              "3  Mon May 18 17:49:17 +0000 2020  ...   pt\n",
              "4  Mon May 18 17:49:06 +0000 2020  ...   pt\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH2O2KSKj6q-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "99f1282c-02d4-49da-87b9-8c76f50d9949"
      },
      "source": [
        "#Visualizando as 5 √∫ltimas linhas.\n",
        "data.tail()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>109959</th>\n",
              "      <td>Mon Jul 20 15:04:14 +0000 2020</td>\n",
              "      <td>porto alegre perigando a entrar em lockdown e ...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109960</th>\n",
              "      <td>Mon Jul 20 15:03:35 +0000 2020</td>\n",
              "      <td>Nunca que a M√≠dia vai falar isso!\\nAMB, CFM e ...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109961</th>\n",
              "      <td>Mon Jul 20 15:03:33 +0000 2020</td>\n",
              "      <td>@joaopiresrj Eu n√£o sou cientista mas esse LOC...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109962</th>\n",
              "      <td>Mon Jul 20 15:01:54 +0000 2020</td>\n",
              "      <td>Q&amp;amp;A - Recess√£o ou Lockdown. O que √© pior? ...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109963</th>\n",
              "      <td>Mon Jul 20 15:01:38 +0000 2020</td>\n",
              "      <td>O prefeito de Los Angeles est√° preste a decret...</td>\n",
              "      <td>pt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            created_at  ... lang\n",
              "109959  Mon Jul 20 15:04:14 +0000 2020  ...   pt\n",
              "109960  Mon Jul 20 15:03:35 +0000 2020  ...   pt\n",
              "109961  Mon Jul 20 15:03:33 +0000 2020  ...   pt\n",
              "109962  Mon Jul 20 15:01:54 +0000 2020  ...   pt\n",
              "109963  Mon Jul 20 15:01:38 +0000 2020  ...   pt\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65DcCYvPjbmk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "adb9c602-139b-46c7-87b3-742873c0a70d"
      },
      "source": [
        "#Verificando a estrutura inicial dos dados.\n",
        "data.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(109964, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL74IZlBjrv9",
        "colab_type": "text"
      },
      "source": [
        "**Podemos observar aproximadamente 110 mil linhas e 6 colunas.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyJflrkppvx-",
        "colab_type": "text"
      },
      "source": [
        "# Pr√©-Processando os dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntMjmA1hj_pB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Removendo dados duplicados na coluna de Texto e substituindo dentro do pr√≥prio Data Frame.\n",
        "data.drop_duplicates(['text'], inplace=True)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyhrarbekOUJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b022d33e-a1ac-46bf-bc2f-aae02a1b57fd"
      },
      "source": [
        "#Verificando novamente a estrutura dos dados para observar a quantidade de dados √∫nicos.\n",
        "data.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(103364, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh3k65gwlje8",
        "colab_type": "text"
      },
      "source": [
        "6600 linhas foram removidas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJlkTrKzktJl",
        "colab_type": "text"
      },
      "source": [
        "**Iremos trabalhar com os Dados de Texto, por isso, selecionaremos apenas a coluna associada ao conte√∫do dos tweets.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQyFyq6Bk29W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Utilizando nota√ß√£o comum em estudos de Aprendizado de M√°quina.\n",
        "X = data['text']"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bKpOB7-k-JH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "0edd8966-1e4f-4709-c508-41056f61fe79"
      },
      "source": [
        "#Visualizando as 15 primeiras linhas. \n",
        "X[:15]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     Tudo mudou na nossa forma de trabalhar, mas na...\n",
              "1     McDonald‚Äôs j√° reabriu lojas ao p√∫blico https:/...\n",
              "2     Sindicato, est√° atento em tudo o que envolve s...\n",
              "3     Nossos problemas da sa√∫de definitivamente acab...\n",
              "4     F√°bricas de todo o mundo se viram obrigadas a ...\n",
              "5     @g1 @RedeGlobo @jornalhoje o governo de @jairb...\n",
              "6     Lei N¬∞ 6666, nos #EUA, que pretende tra√ßar e i...\n",
              "7     https://t.co/mcftUwJr5F o governo precisa ser ...\n",
              "8     Blockchain: a tecnologia que popularizou o #bi...\n",
              "9     VOC√äS CONHECEM ALGUM PA√çS AL√âM DO BRASIL QUE T...\n",
              "10    Itaju√≠pe recebe o Centro Municipal de Isolamen...\n",
              "11    üì£ NOT√çCIA / NEWS / NOUVELLES \\n\\nüáµüáπ Manual de ...\n",
              "12    Enquanto o governo Bolsonaro permanecer Irresp...\n",
              "13    Fa√ßa a diferen√ßa! Seja um doador sem fronteira...\n",
              "14    Manaus, maio de 2020. Reportagem sobre o colap...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdsZzO1uiR3E",
        "colab_type": "text"
      },
      "source": [
        "**Devido ao fato de os dados serem proveninentes de uma rede social, se faz necess√°ria uma etapa de pr√©-processamento nos mesmos.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDt6G21ntIhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Preprocessing_data(instance):\n",
        "      instance = re.sub(r\"http\\S+\", \"\", instance).lower().replace('.', '').replace(';','').replace('-','').replace(':', '').replace(')', '')\n",
        "      stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
        "      words = [i for i in instance.split() if not i in stopwords]\n",
        "      return (\" \".join(words))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0mXGAG5isR0",
        "colab_type": "text"
      },
      "source": [
        "**Fun√ß√£o que remove links, urls, sinais de pontua√ß√£o, padroniza os caracteres como min√∫sculos e remove as stopwords atrav√©s de um dos m√≥dulos da biblioteca NLTK.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqm7JgNUmsVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Aplicando a fun√ß√£o na nossa base de dados.\n",
        "X = [Preprocessing_data(i) for i in X]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suoFiiJ2mzaR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "b34ba5bd-48fb-47c7-f629-6cc3aa1ed9b7"
      },
      "source": [
        "#Visualizando novamente as 15 primeiras linhas, agora ap√≥s o pr√©-processamento.\n",
        "X[:15]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tudo mudou forma trabalhar, nada mudou objetivo informar #jornalismo #imprensa‚Ä¶',\n",
              " 'mcdonald‚Äôs reabriu lojas p√∫blico #comida #covid19 #mcdonalds',\n",
              " 'sindicato, atento tudo envolve sa√∫de condi√ß√µes trabalho nessa pandemia #covid @spbancarios',\n",
              " 'problemas sa√∫de definitivamente acabaram #saude #forabolsonaro #covid',\n",
              " 'f√°bricas todo mundo viram obrigadas dispensarem funcion√°rios decorr√™ncia #covid19 antes m‚Ä¶',\n",
              " '@g1 @redeglobo @jornalhoje governo @jairbolsonaro vai socorrer ningu√©m vai enrolar! pois minto quer r‚Ä¶',\n",
              " 'lei n¬∞ 6666, #eua, pretende tra√ßar investigar percurso pessoas tivestes contatos, usand‚Ä¶',\n",
              " 'governo precisa ser responsabilizado #covid #covid19',\n",
              " 'blockchain tecnologia popularizou #bitcoin sendo testada combate #covid19 sistema capaz de‚Ä¶',\n",
              " 'conhecem algum pa√≠s al√©m brasil torcida organizada coronavirus???? #covid #covid19',\n",
              " 'itaju√≠pe recebe centro municipal isolamento covid19 #covid19 #isolamentosocial #covid @rctitajuipe',\n",
              " 'üì£ not√≠cia / news / nouvelles üáµüáπ manual boas pr√°ticas ‚Äì algarve clean &amp safe üá¨üáß good practice guide algarve c‚Ä¶',\n",
              " 'enquanto governo bolsonaro permanecer irrespons√°vel, povo paga vida #calabocabolsonaro #covid‚Ä¶',\n",
              " 'fa√ßa diferen√ßa! doador fronteiras sou! #covid #covid19 @msf_brasil',\n",
              " 'manaus, maio 2020 reportagem sobre colapso sus @veja dessa semana, mostra situa√ß√£o pacientes em‚Ä¶']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaWheGjoTu0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Criando DataFrame com os dados pr√©-processados.\n",
        "data_text = pd.DataFrame(data=X, columns=['text'])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qpCXQu4T4ej",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "df10331a-b2c3-47a5-8e72-1becdbc39cb2"
      },
      "source": [
        "#Visualizando DataFrame.\n",
        "data_text"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tudo mudou forma trabalhar, nada mudou objetiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mcdonald‚Äôs reabriu lojas p√∫blico #comida #covi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sindicato, atento tudo envolve sa√∫de condi√ß√µes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>problemas sa√∫de definitivamente acabaram #saud...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>f√°bricas todo mundo viram obrigadas dispensare...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103359</th>\n",
              "      <td>porto alegre perigando entrar lockdown √¥nibus ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103360</th>\n",
              "      <td>nunca m√≠dia vai falar isso! amb, cfm crms, tod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103361</th>\n",
              "      <td>@joaopiresrj cientista lockdown acho q duas se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103362</th>\n",
              "      <td>q&amp;ampa recess√£o lockdown pior? | fiique tranqu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103363</th>\n",
              "      <td>prefeito los angeles preste decretar lockdown ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>103364 rows √ó 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text\n",
              "0       tudo mudou forma trabalhar, nada mudou objetiv...\n",
              "1       mcdonald‚Äôs reabriu lojas p√∫blico #comida #covi...\n",
              "2       sindicato, atento tudo envolve sa√∫de condi√ß√µes...\n",
              "3       problemas sa√∫de definitivamente acabaram #saud...\n",
              "4       f√°bricas todo mundo viram obrigadas dispensare...\n",
              "...                                                   ...\n",
              "103359  porto alegre perigando entrar lockdown √¥nibus ...\n",
              "103360  nunca m√≠dia vai falar isso! amb, cfm crms, tod...\n",
              "103361  @joaopiresrj cientista lockdown acho q duas se...\n",
              "103362  q&ampa recess√£o lockdown pior? | fiique tranqu...\n",
              "103363  prefeito los angeles preste decretar lockdown ...\n",
              "\n",
              "[103364 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5FfBf044igm",
        "colab_type": "text"
      },
      "source": [
        "# Transformando os Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3vFCKCKkoCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importando m√≥dulos do Gensim, biblioteca que auxilia na implementa√ß√£o do Modelo Word2VEC.\n",
        "from gensim.models.phrases import Phrases, Phraser"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-REPzwemo9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Quebrando as frases por palavra.\n",
        "sent = [row.split() for row in data_text['text']]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiKuzgSOm-6u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2d629a9f-99c2-4638-a778-4f4077a71c2f"
      },
      "source": [
        "#Visualizando a representa√ß√£o criada acima.\n",
        "sent"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['tudo',\n",
              "  'mudou',\n",
              "  'forma',\n",
              "  'trabalhar,',\n",
              "  'nada',\n",
              "  'mudou',\n",
              "  'objetivo',\n",
              "  'informar',\n",
              "  '#jornalismo',\n",
              "  '#imprensa‚Ä¶'],\n",
              " ['mcdonald‚Äôs',\n",
              "  'reabriu',\n",
              "  'lojas',\n",
              "  'p√∫blico',\n",
              "  '#comida',\n",
              "  '#covid19',\n",
              "  '#mcdonalds'],\n",
              " ['sindicato,',\n",
              "  'atento',\n",
              "  'tudo',\n",
              "  'envolve',\n",
              "  'sa√∫de',\n",
              "  'condi√ß√µes',\n",
              "  'trabalho',\n",
              "  'nessa',\n",
              "  'pandemia',\n",
              "  '#covid',\n",
              "  '@spbancarios'],\n",
              " ['problemas',\n",
              "  'sa√∫de',\n",
              "  'definitivamente',\n",
              "  'acabaram',\n",
              "  '#saude',\n",
              "  '#forabolsonaro',\n",
              "  '#covid'],\n",
              " ['f√°bricas',\n",
              "  'todo',\n",
              "  'mundo',\n",
              "  'viram',\n",
              "  'obrigadas',\n",
              "  'dispensarem',\n",
              "  'funcion√°rios',\n",
              "  'decorr√™ncia',\n",
              "  '#covid19',\n",
              "  'antes',\n",
              "  'm‚Ä¶'],\n",
              " ['@g1',\n",
              "  '@redeglobo',\n",
              "  '@jornalhoje',\n",
              "  'governo',\n",
              "  '@jairbolsonaro',\n",
              "  'vai',\n",
              "  'socorrer',\n",
              "  'ningu√©m',\n",
              "  'vai',\n",
              "  'enrolar!',\n",
              "  'pois',\n",
              "  'minto',\n",
              "  'quer',\n",
              "  'r‚Ä¶'],\n",
              " ['lei',\n",
              "  'n¬∞',\n",
              "  '6666,',\n",
              "  '#eua,',\n",
              "  'pretende',\n",
              "  'tra√ßar',\n",
              "  'investigar',\n",
              "  'percurso',\n",
              "  'pessoas',\n",
              "  'tivestes',\n",
              "  'contatos,',\n",
              "  'usand‚Ä¶'],\n",
              " ['governo', 'precisa', 'ser', 'responsabilizado', '#covid', '#covid19'],\n",
              " ['blockchain',\n",
              "  'tecnologia',\n",
              "  'popularizou',\n",
              "  '#bitcoin',\n",
              "  'sendo',\n",
              "  'testada',\n",
              "  'combate',\n",
              "  '#covid19',\n",
              "  'sistema',\n",
              "  'capaz',\n",
              "  'de‚Ä¶'],\n",
              " ['conhecem',\n",
              "  'algum',\n",
              "  'pa√≠s',\n",
              "  'al√©m',\n",
              "  'brasil',\n",
              "  'torcida',\n",
              "  'organizada',\n",
              "  'coronavirus????',\n",
              "  '#covid',\n",
              "  '#covid19'],\n",
              " ['itaju√≠pe',\n",
              "  'recebe',\n",
              "  'centro',\n",
              "  'municipal',\n",
              "  'isolamento',\n",
              "  'covid19',\n",
              "  '#covid19',\n",
              "  '#isolamentosocial',\n",
              "  '#covid',\n",
              "  '@rctitajuipe'],\n",
              " ['üì£',\n",
              "  'not√≠cia',\n",
              "  '/',\n",
              "  'news',\n",
              "  '/',\n",
              "  'nouvelles',\n",
              "  'üáµüáπ',\n",
              "  'manual',\n",
              "  'boas',\n",
              "  'pr√°ticas',\n",
              "  '‚Äì',\n",
              "  'algarve',\n",
              "  'clean',\n",
              "  '&amp',\n",
              "  'safe',\n",
              "  'üá¨üáß',\n",
              "  'good',\n",
              "  'practice',\n",
              "  'guide',\n",
              "  'algarve',\n",
              "  'c‚Ä¶'],\n",
              " ['enquanto',\n",
              "  'governo',\n",
              "  'bolsonaro',\n",
              "  'permanecer',\n",
              "  'irrespons√°vel,',\n",
              "  'povo',\n",
              "  'paga',\n",
              "  'vida',\n",
              "  '#calabocabolsonaro',\n",
              "  '#covid‚Ä¶'],\n",
              " ['fa√ßa',\n",
              "  'diferen√ßa!',\n",
              "  'doador',\n",
              "  'fronteiras',\n",
              "  'sou!',\n",
              "  '#covid',\n",
              "  '#covid19',\n",
              "  '@msf_brasil'],\n",
              " ['manaus,',\n",
              "  'maio',\n",
              "  '2020',\n",
              "  'reportagem',\n",
              "  'sobre',\n",
              "  'colapso',\n",
              "  'sus',\n",
              "  '@veja',\n",
              "  'dessa',\n",
              "  'semana,',\n",
              "  'mostra',\n",
              "  'situa√ß√£o',\n",
              "  'pacientes',\n",
              "  'em‚Ä¶'],\n",
              " ['am√©m',\n",
              "  '#maythe4thbewithyou',\n",
              "  '#matarife',\n",
              "  '#staysafe',\n",
              "  '#Ï†ÑÏ†ïÍµ≠ÏÇ¨ÎûëÌï¥',\n",
              "  '#covid',\n",
              "  '#zurena',\n",
              "  '#covid19',\n",
              "  '#Ïû¨ÌòÑÏïÑÏÇ¨ÎûëÌï¥',\n",
              "  '#coloresperanza2020',\n",
              "  '#„Éè„É≥„Çø„Éº„Éè„É≥„Çø„Éº‚Ä¶'],\n",
              " ['#covid',\n",
              "  '#coronav√≠rus',\n",
              "  'agravase',\n",
              "  'problema',\n",
              "  '#inclus√£odigital',\n",
              "  'advogado',\n",
              "  'det√©m',\n",
              "  'condi√ß√£o',\n",
              "  'econ√¥mica',\n",
              "  '@tjbahia‚Ä¶'],\n",
              " ['boa',\n",
              "  'not√≠cia!',\n",
              "  'vacina',\n",
              "  'sendo',\n",
              "  'testada',\n",
              "  'eua',\n",
              "  'come√ßa',\n",
              "  'ter',\n",
              "  'resultados',\n",
              "  'promissores',\n",
              "  '#corona',\n",
              "  '#vacina‚Ä¶'],\n",
              " ['m√©dico',\n",
              "  'alerta',\n",
              "  'riscos',\n",
              "  'hipertens√£o',\n",
              "  'arterial',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid'],\n",
              " ['novo',\n",
              "  'coronav√≠rus',\n",
              "  'andar',\n",
              "  '#carro',\n",
              "  'pode',\n",
              "  'ser',\n",
              "  'perigoso?',\n",
              "  '#covid19',\n",
              "  '#covid'],\n",
              " ['melhor',\n",
              "  'lembran√ßa',\n",
              "  '@flamengo',\n",
              "  '#libertadores2019,',\n",
              "  'd√∫vidas,',\n",
              "  'imagem',\n",
              "  '@gabigol',\n",
              "  'fazendo',\n",
              "  'lixo',\n",
              "  'do‚Ä¶'],\n",
              " ['v√≠deo',\n",
              "  'dessa',\n",
              "  'vez',\n",
              "  'tema',\n",
              "  'popula√ß√£o',\n",
              "  'situa√ß√£o',\n",
              "  'rua',\n",
              "  'covid19#racismo',\n",
              "  '#covid'],\n",
              " ['hotelaria',\n",
              "  'galiza',\n",
              "  'quer',\n",
              "  'portugueses',\n",
              "  'fa√ßam',\n",
              "  'teste',\n",
              "  'r√°pido',\n",
              "  '#covid19',\n",
              "  '#economia',\n",
              "  '#galiza'],\n",
              " ['tamanho',\n",
              "  'grupo',\n",
              "  'risco',\n",
              "  '#covid19',\n",
              "  'brasil?',\n",
              "  'pesquisadores',\n",
              "  '@unifesp',\n",
              "  'tentam',\n",
              "  'esclarecer',\n",
              "  'quest‚Ä¶'],\n",
              " ['articula√ß√£o',\n",
              "  'povos',\n",
              "  'ind√≠genas',\n",
              "  'brasil',\n",
              "  'apib',\n",
              "  '|',\n",
              "  '18/05/2020',\n",
              "  'resumo',\n",
              "  'casos',\n",
              "  'registrados',\n",
              "  'comit√™',\n",
              "  'nacional',\n",
              "  'pela‚Ä¶'],\n",
              " ['governo',\n",
              "  'estado',\n",
              "  'garantiu',\n",
              "  'entrega',\n",
              "  '29',\n",
              "  'respiradores',\n",
              "  'abertura',\n",
              "  'novos',\n",
              "  'leitos',\n",
              "  'uti',\n",
              "  'pacientes‚Ä¶'],\n",
              " ['partilho',\n",
              "  'opini√£o',\n",
              "  'dei',\n",
              "  'algumas',\n",
              "  'semanas',\n",
              "  '@andrebiernath,',\n",
              "  'revista',\n",
              "  '@vejasaude',\n",
              "  'üáßüá∑,',\n",
              "  'sobre',\n",
              "  'acreditava‚Ä¶'],\n",
              " ['rapaziada',\n",
              "  'fiquem',\n",
              "  'espertos!',\n",
              "  'existem',\n",
              "  'umas',\n",
              "  'minas',\n",
              "  'tipo',\n",
              "  '#covid,',\n",
              "  'al√©m',\n",
              "  'voc√™,',\n",
              "  '5',\n",
              "  'casos',\n",
              "  'confirmados',\n",
              "  '2',\n",
              "  'amigos',\n",
              "  'suspeitos'],\n",
              " ['cara',\n",
              "  'deseja',\n",
              "  'ter',\n",
              "  'estabilidade',\n",
              "  'financeira',\n",
              "  'liberdade',\n",
              "  'geogr√°fica',\n",
              "  'poder',\n",
              "  'trabalhar',\n",
              "  'conforto',\n",
              "  'casa',\n",
              "  'voc‚Ä¶'],\n",
              " ['esque√ßa',\n",
              "  'passado,',\n",
              "  'perdoe',\n",
              "  'recomece',\n",
              "  '#meditation',\n",
              "  '#meditopia',\n",
              "  '#nostress',\n",
              "  '#focus',\n",
              "  '#covid'],\n",
              " ['#12emponto98',\n",
              "  'saiba',\n",
              "  'tudo',\n",
              "  'sobre',\n",
              "  'pagamento',\n",
              "  'segunda',\n",
              "  'parcela',\n",
              "  'aux√≠lio',\n",
              "  'emergencial',\n",
              "  'assistindo',\n",
              "  'programa',\n",
              "  'complet‚Ä¶'],\n",
              " ['contato',\n",
              "  'compliance',\n",
              "  'control',\n",
              "  'saiba',\n",
              "  '#somosoquefazemos',\n",
              "  '#compliancecontrol',\n",
              "  '#transparencia‚Ä¶'],\n",
              " ['conhe√ßa',\n",
              "  'melhores',\n",
              "  'pr√°ticas',\n",
              "  'preven√ß√£o',\n",
              "  '#covid19',\n",
              "  'colaboradores',\n",
              "  'empresa',\n",
              "  'garanta',\n",
              "  'sa√∫de‚Ä¶'],\n",
              " ['falta',\n",
              "  'pr√≥ximas',\n",
              "  'elei√ß√µes',\n",
              "  'presidenciais?',\n",
              "  'vejo',\n",
              "  'hora!',\n",
              "  '\\U0001f9d8\\u200d‚ôÄÔ∏è',\n",
              "  '#covid19',\n",
              "  '#eleicoes',\n",
              "  '#presidente',\n",
              "  '#covid',\n",
              "  '#vacinabrasil',\n",
              "  '#socorro'],\n",
              " ['preocupa',\n",
              "  'pode',\n",
              "  'acontecer',\n",
              "  'poderia',\n",
              "  'ter',\n",
              "  'acontecido,',\n",
              "  'perde',\n",
              "  'acontecendo',\n",
              "  'agora‚Ä¶'],\n",
              " ['tentativas',\n",
              "  'desastradas',\n",
              "  'prefeitura',\n",
              "  'paulo',\n",
              "  'pra',\n",
              "  'aumentar',\n",
              "  'isolamento',\n",
              "  'conseguiram',\n",
              "  'oposto',\n",
              "  'preciso',\n",
              "  'planej‚Ä¶'],\n",
              " ['enquanto',\n",
              "  'esperan√ßa',\n",
              "  'determina√ß√£o,',\n",
              "  'haver√°',\n",
              "  'possibilidades!',\n",
              "  'üî•',\n",
              "  '#quarentena',\n",
              "  '#vamosvencerjuntos',\n",
              "  '#vamosaluta‚Ä¶'],\n",
              " ['maioria',\n",
              "  'popula√ß√£o',\n",
              "  'anticorpos',\n",
              "  'contra',\n",
              "  '#covid19',\n",
              "  'declara√ß√£o',\n",
              "  'diretorgeral',\n",
              "  '#oms,',\n",
              "  'tedros',\n",
              "  'adhanom‚Ä¶'],\n",
              " ['q',\n",
              "  'absurdo',\n",
              "  'pa√≠s,passaremos',\n",
              "  'pandemia',\n",
              "  'nunca',\n",
              "  'ter',\n",
              "  'tido',\n",
              "  'quarentena',\n",
              "  'd',\n",
              "  'verdade',\n",
              "  'governo',\n",
              "  'pedindo',\n",
              "  'pr‚Ä¶'],\n",
              " ['devasta', '#covid19', 'comunidades', 'ind√≠genas', '#onu', '#internacional'],\n",
              " ['#covid',\n",
              "  'estragando',\n",
              "  'tudo!',\n",
              "  'espero',\n",
              "  'todo',\n",
              "  'mundo',\n",
              "  'use',\n",
              "  'quarentena',\n",
              "  'pra',\n",
              "  'repensar',\n",
              "  'atitudes,',\n",
              "  'valores,',\n",
              "  'se‚Ä¶'],\n",
              " ['riqueza',\n",
              "  'maior',\n",
              "  'neste',\n",
              "  'mundo',\n",
              "  'paz',\n",
              "  'esp√≠rito',\n",
              "  '#meditation',\n",
              "  '#relax',\n",
              "  '#covid',\n",
              "  '#nostress',\n",
              "  '#peace'],\n",
              " ['idosa',\n",
              "  'cadeirante',\n",
              "  'ganha',\n",
              "  'festa',\n",
              "  '82',\n",
              "  'dentro',\n",
              "  'carro',\n",
              "  'pra√ßa',\n",
              "  'covid',\n",
              "  '#sonoticiaboa',\n",
              "  '#goodnews‚Ä¶'],\n",
              " ['#fiqueemcasa',\n",
              "  'rio',\n",
              "  'janeiro',\n",
              "  '85%',\n",
              "  'leitos',\n",
              "  'uti',\n",
              "  'ocupados',\n",
              "  'sus',\n",
              "  '1720',\n",
              "  'pacientes',\n",
              "  'internados',\n",
              "  'suspeita‚Ä¶'],\n",
              " ['km',\n",
              "  'cargo',\n",
              "  'v√™m',\n",
              "  'trabalhando',\n",
              "  'transporte',\n",
              "  'medicamentos',\n",
              "  'relacionado',\n",
              "  'covid19',\n",
              "  'frota',\n",
              "  'caminh√µes',\n",
              "  'e‚Ä¶'],\n",
              " ['preocupe',\n",
              "  'pensamentos',\n",
              "  'durante',\n",
              "  'medita√ß√£o',\n",
              "  'apenas',\n",
              "  'observe',\n",
              "  'entenda',\n",
              "  'si',\n",
              "  '#meditation',\n",
              "  '#relax‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'diminui',\n",
              "  'estoque',\n",
              "  'leite',\n",
              "  'materno',\n",
              "  'df',\n",
              "  'm√™s',\n",
              "  'abril',\n",
              "  'fechou',\n",
              "  'd√©ficit',\n",
              "  '11%',\n",
              "  '@secsaudedf',\n",
              "  '‚û°Ô∏è‚Ä¶'],\n",
              " ['#sp1',\n",
              "  'btarde!',\n",
              "  '@cesartralli',\n",
              "  '#rogeriolins',\n",
              "  '#prefeito',\n",
              "  '#osasco,',\n",
              "  'fazendo',\n",
              "  'vista',\n",
              "  'grossa',\n",
              "  '#covid',\n",
              "  'todo',\n",
              "  'com‚Ä¶'],\n",
              " ['coral',\n",
              "  'rob√¥',\n",
              "  '#magon',\n",
              "  '#marcelomagon',\n",
              "  '#charges',\n",
              "  '#charge',\n",
              "  '#politica',\n",
              "  '#corona',\n",
              "  '#covid',\n",
              "  '#corona',\n",
              "  '#coronavirus',\n",
              "  '#cloroquina‚Ä¶'],\n",
              " ['porque',\n",
              "  'depender',\n",
              "  'desses',\n",
              "  'ignorantes',\n",
              "  'presidente,',\n",
              "  'naturalidade',\n",
              "  'brasileiro(a',\n",
              "  'vai',\n",
              "  'ser',\n",
              "  'extinta!',\n",
              "  '#coronavirus‚Ä¶'],\n",
              " ['#covid',\n",
              "  '#coronav√≠rus',\n",
              "  'lado,',\n",
              "  'nazistas',\n",
              "  'diziam',\n",
              "  '\"es',\n",
              "  'ist',\n",
              "  'zu',\n",
              "  'ihrer',\n",
              "  'sicherheit\"',\n",
              "  '(isso',\n",
              "  'seguran√ßa‚Ä¶'],\n",
              " ['sair',\n",
              "  'rua',\n",
              "  'desrespeitando',\n",
              "  'regras',\n",
              "  'cont√°gio',\n",
              "  '#covid19,',\n",
              "  'justificativa',\n",
              "  'pessoa',\n",
              "  'prerrogativ‚Ä¶'],\n",
              " ['culpa',\n",
              "  'bolsonaro,',\n",
              "  'ficaremos',\n",
              "  'receber',\n",
              "  'vacina',\n",
              "  'contra',\n",
              "  'coronavirus',\n",
              "  '#culpadobozo',\n",
              "  '#culpadobozo‚Ä¶'],\n",
              " ['culpa',\n",
              "  'bolsonaro,',\n",
              "  'ficaremos',\n",
              "  'receber',\n",
              "  'vacina',\n",
              "  'contra',\n",
              "  'coronavirus',\n",
              "  '#culpadobozo',\n",
              "  '#culpadobozo‚Ä¶'],\n",
              " ['conte',\n",
              "  'arco√≠ris',\n",
              "  'tempestades',\n",
              "  '#meditation',\n",
              "  '#meditopia',\n",
              "  '#nostress',\n",
              "  '#covid'],\n",
              " ['atualiza√ß√£o',\n",
              "  '#covid19',\n",
              "  'mundo',\n",
              "  'atualiza√ß√£o',\n",
              "  '18/05/2020',\n",
              "  '154314',\n",
              "  'utc',\n",
              "  'casos',\n",
              "  '4841007',\n",
              "  'casos',\n",
              "  'hoje',\n",
              "  '41741',\n",
              "  'mortes',\n",
              "  '31736‚Ä¶'],\n",
              " ['farmac√™utica',\n",
              "  'diz',\n",
              "  'ter',\n",
              "  'encontrado',\n",
              "  'anti',\n",
              "  'corpo',\n",
              "  'protege',\n",
              "  '100%',\n",
              "  'contra',\n",
              "  '#covid',\n",
              "  '19',\n",
              "  '#fe',\n",
              "  '#vida'],\n",
              " ['v√≠deos',\n",
              "  'novos!',\n",
              "  'lembrando',\n",
              "  'hoje',\n",
              "  'ocorrer√°',\n",
              "  'pagamento',\n",
              "  'segunda',\n",
              "  'parcela',\n",
              "  'benef√≠cio',\n",
              "  '#covid19',\n",
              "  '#covid‚Ä¶'],\n",
              " ['antes',\n",
              "  'responsabilidade',\n",
              "  'rela√ß√µes',\n",
              "  '√≠ntimas,',\n",
              "  'preven√ß√£o',\n",
              "  'dst‚Äôs',\n",
              "  'uso',\n",
              "  'camisinha',\n",
              "  'agora',\n",
              "  'tem‚Ä¶'],\n",
              " ['#covid19', 'fiqueemcasa', '#comigo'],\n",
              " ['m√©dica',\n",
              "  'licen√ßa',\n",
              "  'maternidade',\n",
              "  'negada',\n",
              "  'morre',\n",
              "  'coronav√≠rus',\n",
              "  'arg√©lia',\n",
              "  '#covid19',\n",
              "  '#covid‚Ä¶'],\n",
              " ['agora', 'vai!', '@minsaude', '@jairbolsonaro', '#covid', '#fy'],\n",
              " ['agora', 'acerta,', 'confia', '#covid', '#nisenasaude'],\n",
              " ['@nataliabteles',\n",
              "  '@mmipexrenata',\n",
              "  '@dfdanielfreitas',\n",
              "  '@lalbert95519675',\n",
              "  'aceita',\n",
              "  'vacina',\n",
              "  'china?',\n",
              "  'china',\n",
              "  'completar√°',\n",
              "  'testes‚Ä¶'],\n",
              " ['ninguem',\n",
              "  'faz',\n",
              "  'aniversario',\n",
              "  'ano!',\n",
              "  'marca',\n",
              "  'amigo',\n",
              "  'perdeu',\n",
              "  'festa',\n",
              "  'aniversario',\n",
              "  'acham',\n",
              "  'nao',\n",
              "  'vai',\n",
              "  'perde‚Ä¶'],\n",
              " ['semana',\n",
              "  'assembleia',\n",
              "  'geral',\n",
              "  '@who',\n",
              "  'isso,',\n",
              "  'v√°rios',\n",
              "  'eventos',\n",
              "  'sendo',\n",
              "  'transmitidos',\n",
              "  'online',\n",
              "  'hoje,',\n",
              "  'aco‚Ä¶'],\n",
              " ['vida',\n",
              "  'supro',\n",
              "  'valor',\n",
              "  'pequenas',\n",
              "  'coisas',\n",
              "  'vida',\n",
              "  'principalmente',\n",
              "  'pessoas',\n",
              "  'ama,at√©',\n",
              "  'por‚Ä¶'],\n",
              " ['sociedade',\n",
              "  'brasileira',\n",
              "  'imunologia',\n",
              "  'conclui',\n",
              "  'precoce',\n",
              "  'recomenda√ß√£o',\n",
              "  'uso',\n",
              "  'deste',\n",
              "  'medicamento',\n",
              "  'covid19‚Ä¶'],\n",
              " ['luta',\n",
              "  'contra',\n",
              "  'inimigo',\n",
              "  'invis√≠vel',\n",
              "  'sentimento',\n",
              "  '#enfermeiros',\n",
              "  'trabalham',\n",
              "  'diretamente',\n",
              "  'pacientes',\n",
              "  'de‚Ä¶'],\n",
              " ['forma',\n",
              "  'eficaz',\n",
              "  'proteger',\n",
              "  'contra',\n",
              "  'coronav√≠rus!',\n",
              "  '#ficaemcasa',\n",
              "  '#cuidadocoletivo',\n",
              "  '#quarentena',\n",
              "  '#covid‚Ä¶'],\n",
              " ['escolas',\n",
              "  '80%',\n",
              "  'alunos',\n",
              "  'falta',\n",
              "  'alguns',\n",
              "  'professores',\n",
              "  '#covid19',\n",
              "  '#escolas'],\n",
              " ['fenprof',\n",
              "  'acusa',\n",
              "  'minist√©rio',\n",
              "  '‚Äúalguma',\n",
              "  'imprud√™ncia‚Äù',\n",
              "  'reabertura',\n",
              "  'escolas',\n",
              "  '#covid19',\n",
              "  '#fenprof',\n",
              "  '#professores'],\n",
              " ['cliente',\n",
              "  'feliz,',\n",
              "  'lugalma',\n",
              "  'feliz',\n",
              "  '\\U0001f970\\U0001f970‚ù§üôèüò∑',\n",
              "  '#m√°scaraprote√ß√£o',\n",
              "  '#m√°scarapersonalizada',\n",
              "  '#covid19',\n",
              "  '#protejase',\n",
              "  '#prote√ß√£ocomestilo‚Ä¶'],\n",
              " ['reorganizadas',\n",
              "  '√°reas',\n",
              "  'destinadas',\n",
              "  'doentes',\n",
              "  'covid',\n",
              "  'alto',\n",
              "  'minho',\n",
              "  '#covid19',\n",
              "  '#emdestaque',\n",
              "  '#hospitais'],\n",
              " ['concello',\n",
              "  '#op√°ramo',\n",
              "  '#bases',\n",
              "  'axudas,',\n",
              "  'dirixidas',\n",
              "  '√°',\n",
              "  '#compra',\n",
              "  '#alimentos',\n",
              "  'produtos',\n",
              "  '1¬™',\n",
              "  'necesidade',\n",
              "  'para‚Ä¶'],\n",
              " ['vai', 'pa', 'onde?', '#covid', '#fiqueemcasa'],\n",
              " ['guimar√£es',\n",
              "  'define',\n",
              "  'plano',\n",
              "  'a√ß√£o',\n",
              "  'apoiar',\n",
              "  'artistas',\n",
              "  'locais',\n",
              "  '#artes',\n",
              "  '#covid19',\n",
              "  '#cultura'],\n",
              " ['l√°',\n",
              "  'facebook',\n",
              "  'ainda',\n",
              "  'acredito',\n",
              "  'mundo',\n",
              "  'jeito!',\n",
              "  'puder',\n",
              "  'precisar,',\n",
              "  'entra',\n",
              "  'l√°',\n",
              "  'vamos',\n",
              "  'ajudar!',\n",
              "  'hora',\n",
              "  'de‚Ä¶'],\n",
              " ['ainda',\n",
              "  'bem',\n",
              "  'animais',\n",
              "  'dom√©sticos',\n",
              "  'transmitem',\n",
              "  '#covid',\n",
              "  'precisam',\n",
              "  'tomar',\n",
              "  'rem√©dio',\n",
              "  'pra',\n",
              "  'tratar',\n",
              "  'pensou',\n",
              "  'esse‚Ä¶'],\n",
              " ['sad',\n",
              "  'op√µese',\n",
              "  'presidente',\n",
              "  'desportivo',\n",
              "  'aves',\n",
              "  'impugna√ß√£o',\n",
              "  'i',\n",
              "  'liga',\n",
              "  '#covid19',\n",
              "  '#futebol',\n",
              "  '#iliga'],\n",
              " ['fundo',\n",
              "  'solid√°rio',\n",
              "  'angaria',\n",
              "  '291',\n",
              "  'mil',\n",
              "  'euros',\n",
              "  'equipar',\n",
              "  'hospital',\n",
              "  'braga',\n",
              "  '#braga',\n",
              "  '#covid19',\n",
              "  '#emdestaque'],\n",
              " ['carga',\n",
              "  'composta',\n",
              "  'm√°scaras',\n",
              "  'respirat√≥rias',\n",
              "  'vestu√°rios',\n",
              "  'prote√ß√£o',\n",
              "  'saiba'],\n",
              " ['vamos',\n",
              "  'participar?',\n",
              "  'üìå',\n",
              "  '19/05,',\n",
              "  '16h',\n",
              "  'üìù',\n",
              "  'inscri√ß√µes',\n",
              "  'gratuitas'],\n",
              " ['#calamidade',\n",
              "  '#estadodecalamidade',\n",
              "  '#covid',\n",
              "  '#covid19',\n",
              "  '#coronavirus',\n",
              "  '#streetphotography',\n",
              "  '#lisboa',\n",
              "  '#portugal',\n",
              "  '#paulocaladophoto‚Ä¶'],\n",
              " ['informamos',\n",
              "  'amanh√£,',\n",
              "  'dia',\n",
              "  '19',\n",
              "  'maio,',\n",
              "  'refeit√≥rio',\n",
              "  'estar√°',\n",
              "  'portas',\n",
              "  'abertas',\n",
              "  'receber',\n",
              "  'todas',\n",
              "  'me‚Ä¶'],\n",
              " ['dinheiro',\n",
              "  'provavelmente',\n",
              "  'maior',\n",
              "  'vetor',\n",
              "  'contamina√ß√£o',\n",
              "  'ningu√©m',\n",
              "  'fala',\n",
              "  'nisso?',\n",
              "  'china',\n",
              "  'desinfetaram',\n",
              "  'usaram',\n",
              "  'u‚Ä¶'],\n",
              " ['#balancogeralrj',\n",
              "  'desejo',\n",
              "  'mal',\n",
              "  'pra',\n",
              "  'ningu√©m',\n",
              "  'por√©m',\n",
              "  '#covid',\n",
              "  '19',\n",
              "  'pegar',\n",
              "  'ladr√µes'],\n",
              " ['drivethru',\n",
              "  '#testagem',\n",
              "  '#covid19',\n",
              "  'retornou',\n",
              "  'nesta',\n",
              "  'segunda',\n",
              "  '(18',\n",
              "  'segue',\n",
              "  'pr√≥xima',\n",
              "  'sexta',\n",
              "  '(se',\n",
              "  'disponibi‚Ä¶'],\n",
              " ['ap√≥s',\n",
              "  '78',\n",
              "  'dias,',\n",
              "  'it√°lia',\n",
              "  'come√ßou',\n",
              "  'semana',\n",
              "  'retornando',\n",
              "  'algumas',\n",
              "  'atividades',\n",
              "  'paralisadas',\n",
              "  '#covid',\n",
              "  '@arthurvneto'],\n",
              " ['maioria',\n",
              "  'estudos',\n",
              "  'mostra',\n",
              "  'cloroquina',\n",
              "  'ineficaz',\n",
              "  'contra',\n",
              "  '#covid19',\n",
              "  'simples',\n",
              "  'assim',\n",
              "  'cabe',\n",
              "  'opini√£o',\n",
              "  'uso‚Ä¶'],\n",
              " ['hospitais',\n",
              "  'braga',\n",
              "  'guimar√£es',\n",
              "  'negam',\n",
              "  'falta',\n",
              "  'material',\n",
              "  'combate',\n",
              "  'covid19',\n",
              "  '#braga',\n",
              "  '#covid19',\n",
              "  '#emdestaque'],\n",
              " ['tatuadores',\n",
              "  'minho',\n",
              "  'vendem',\n",
              "  'bens',\n",
              "  'pagar',\n",
              "  'renda',\n",
              "  '‚Äúdeixemnos',\n",
              "  'trabalhar,',\n",
              "  'd',\n",
              "  '#com√©rcio',\n",
              "  '#covid19',\n",
              "  '#economia'],\n",
              " ['al√¥',\n",
              "  '@cnnbrasil',\n",
              "  'prefeito',\n",
              "  'teres√≥polis',\n",
              "  'diz',\n",
              "  'servi√ßos',\n",
              "  'essenciais',\n",
              "  'liberados',\n",
              "  'documento,',\n",
              "  'assim‚Ä¶'],\n",
              " ['causa',\n",
              "  'alecrim',\n",
              "  'dourado',\n",
              "  'brasil',\n",
              "  '√∫ltimos',\n",
              "  'fila',\n",
              "  'vacina',\n",
              "  '#covid',\n",
              "  'no√ß√£o',\n",
              "  'disso',\n",
              "  '?',\n",
              "  'um‚Ä¶'],\n",
              " ['espet√°culo!',\n",
              "  '#fortaleza',\n",
              "  '#cear√°',\n",
              "  '#praia',\n",
              "  '#shot',\n",
              "  '#photography',\n",
              "  '#natgeoyourshot',\n",
              "  '#clouds',\n",
              "  '#sunrise‚Ä¶'],\n",
              " ['pro',\n",
              "  'dia',\n",
              "  'nascer',\n",
              "  'feliz',\n",
              "  'vem',\n",
              "  'logo',\n",
              "  'vacina!',\n",
              "  '#fortaleza',\n",
              "  '#cear√°',\n",
              "  '#praia',\n",
              "  '#shot',\n",
              "  '#photography‚Ä¶'],\n",
              " ['novidades', 'sobre', 'vacina', 'coronav√≠rus!!üôèüôèüôè', '#covid', '#covid„Éº19'],\n",
              " ['passa',\n",
              "  '1,5',\n",
              "  'milh√£o',\n",
              "  'n√∫mero',\n",
              "  'recuperados',\n",
              "  'covid19',\n",
              "  'mundo',\n",
              "  'marca',\n",
              "  '1502468',\n",
              "  'batida',\n",
              "  'sextafeira‚Ä¶'],\n",
              " ['fazendo', 'parte', 'estat√≠stica', '#covid'],\n",
              " ['contato',\n",
              "  'solicite',\n",
              "  'visita',\n",
              "  'avalia√ß√£o',\n",
              "  'or√ßamento',\n",
              "  '#higiene',\n",
              "  '#solucao',\n",
              "  '#limpezaprofissional‚Ä¶'],\n",
              " ['ibc', '2020', 'cancelado', '#ibcshow', '#covid', '#cancel'],\n",
              " ['receita',\n",
              "  'diminuiu?',\n",
              "  'aumentar',\n",
              "  'busca',\n",
              "  'empresa?',\n",
              "  'outras',\n",
              "  'd√∫vidas',\n",
              "  'respondidas',\n",
              "  'blog!',\n",
              "  'con‚Ä¶'],\n",
              " ['@concelloribeira',\n",
              "  'celebrar√°',\n",
              "  'un',\n",
              "  '#pleno',\n",
              "  'telem√°tico',\n",
              "  'encaixar',\n",
              "  'axudas',\n",
              "  'polo',\n",
              "  '#covid',\n",
              "  '#orzamentos'],\n",
              " ['#covid19,',\n",
              "  'menina',\n",
              "  'cinco',\n",
              "  'anos',\n",
              "  'luta',\n",
              "  'contra',\n",
              "  'doen√ßa',\n",
              "  'kawasaki'],\n",
              " ['desabafo!',\n",
              "  'ass',\n",
              "  'eli√©verson',\n",
              "  'louren√ßo',\n",
              "  'silva',\n",
              "  '#pandemia',\n",
              "  '#pandemia2020',\n",
              "  '#covid19',\n",
              "  '#covid_19',\n",
              "  '#covid',\n",
              "  '#cacoal',\n",
              "  '#rond√¥nia‚Ä¶'],\n",
              " ['@jornaloglobo',\n",
              "  'imagina',\n",
              "  'todo',\n",
              "  'dinheiro',\n",
              "  'licita√ß√£o',\n",
              "  'usando',\n",
              "  'combate',\n",
              "  '#covid'],\n",
              " ['observando',\n",
              "  'aumento',\n",
              "  'contaminados',\n",
              "  '#covid,',\n",
              "  'devido',\n",
              "  'grande',\n",
              "  'ideia',\n",
              "  '√∫ltima',\n",
              "  'semana',\n",
              "  'rod√≠zio',\n",
              "  '#par',\n",
              "  '#impar',\n",
              "  'do‚Ä¶'],\n",
              " ['arthur',\n",
              "  'virg√≠lio,',\n",
              "  'fez',\n",
              "  'apelo',\n",
              "  'popula√ß√£o,',\n",
              "  'mantidos',\n",
              "  'cuidados',\n",
              "  'preventivos',\n",
              "  'respeito',\n",
              "  'isolamen‚Ä¶'],\n",
              " ['cloroquina', 'cura', '#covid', 'tanto', 'quanto', 'copa√≠baarrisca', 'quer'],\n",
              " ['@statedeptpm',\n",
              "  '@asstsecpm',\n",
              "  'r',\n",
              "  'clarke',\n",
              "  'cooper',\n",
              "  'sb',\n",
              "  'investimentos',\n",
              "  'longo',\n",
              "  'prazo',\n",
              "  '@statedeptpm',\n",
              "  '@usforeignassist',\n",
              "  'e‚Ä¶'],\n",
              " ['@amastharompre', 'parab√©ns', 'posicionamento', 'l√∫cido', 'üëèüëèüëè', '#covid'],\n",
              " ['rio',\n",
              "  'janeiro',\n",
              "  '2,7',\n",
              "  'mil',\n",
              "  'mortes',\n",
              "  'covid19',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid'],\n",
              " ['china',\n",
              "  'completar√°',\n",
              "  'testes',\n",
              "  'cl√≠nicos',\n",
              "  'segunda',\n",
              "  'fase',\n",
              "  'vacinas',\n",
              "  '#covid19',\n",
              "  'julho,',\n",
              "  'diz',\n",
              "  'funcion√°rio‚Ä¶'],\n",
              " ['covid19',\n",
              "  'concelho',\n",
              "  'maia',\n",
              "  'volta',\n",
              "  'ter',\n",
              "  'casos',\n",
              "  'infe√ß√£o',\n",
              "  '#atualiza√ß√£o',\n",
              "  '#boletim',\n",
              "  '#covid',\n",
              "  '#dgs',\n",
              "  '#infe√ß√µes'],\n",
              " ['\"se',\n",
              "  '25',\n",
              "  'anos,',\n",
              "  'saud√°vel',\n",
              "  '#covid,',\n",
              "  '99%',\n",
              "  'probabilidade',\n",
              "  'ter',\n",
              "  'forma',\n",
              "  'leve',\n",
              "  'sair',\n",
              "  'bem',\n",
              "  'se‚Ä¶'],\n",
              " ['tocantins',\n",
              "  'decreta',\n",
              "  'lockdown',\n",
              "  'ap√≥s',\n",
              "  'reabrir',\n",
              "  'com√©rcio',\n",
              "  'abril',\n",
              "  '#tocantins',\n",
              "  '#covid19',\n",
              "  '#covid',\n",
              "  '#to‚Ä¶'],\n",
              " ['confira',\n",
              "  'artigo',\n",
              "  '@arquivossbc',\n",
              "  'destaque',\n",
              "  '@redescielo',\n",
              "  'exerc√≠cio',\n",
              "  'f√≠sico',\n",
              "  'pacientes',\n",
              "  'cardiopatas',\n",
              "  'popula√ß‚Ä¶'],\n",
              " ['dist√¢ncia',\n",
              "  's√©rie',\n",
              "  'quarenteners',\n",
              "  '#bnw',\n",
              "  '#quarantine',\n",
              "  '#quarentena',\n",
              "  '#quarentenou',\n",
              "  '#caution',\n",
              "  '#isolation',\n",
              "  '#warning‚Ä¶'],\n",
              " ['dilemas',\n",
              "  'alternativas',\n",
              "  'tempos',\n",
              "  'covid19',\n",
              "  'via',\n",
              "  '@diariope',\n",
              "  '#covid',\n",
              "  '#covid19',\n",
              "  '#lockdown',\n",
              "  '#pernambuco'],\n",
              " ['todos', 'dias', 'mudam', 'opini√£o?', '#covid', 'via', '@tvi24pt'],\n",
              " ['#covid',\n",
              "  '@agenciabrasil',\n",
              "  'aonde',\n",
              "  'politico',\n",
              "  '@dataprev',\n",
              "  '@caixa',\n",
              "  '@saude',\n",
              "  '@onyz',\n",
              "  'reginaldo',\n",
              "  'romanini',\n",
              "  'oliveira',\n",
              "  'aguas',\n",
              "  'de‚Ä¶'],\n",
              " ['proje√ß√µes',\n",
              "  'pib',\n",
              "  'brasileiro',\n",
              "  '2020',\n",
              "  'perturbadoras',\n",
              "  'tudo',\n",
              "  'indica,',\n",
              "  'maior',\n",
              "  'queda',\n",
              "  'pib',\n",
              "  'desde',\n",
              "  '1‚Ä¶'],\n",
              " ['\"#covid19',\n",
              "  'cooperamos',\n",
              "  'futuro',\n",
              "  'nenhum\"',\n",
              "  'leonardo',\n",
              "  'boff',\n",
              "  '#fiqueemcasa'],\n",
              " ['associa√ß√£o',\n",
              "  'europeia',\n",
              "  'fornecedores',\n",
              "  'sector',\n",
              "  'autom√≥vel',\n",
              "  '(clepa',\n",
              "  'fez',\n",
              "  'estudo',\n",
              "  'avaliar',\n",
              "  'impacto',\n",
              "  'pandemia‚Ä¶'],\n",
              " ['coisa',\n",
              "  'podem',\n",
              "  'negar',\n",
              "  'carnaval',\n",
              "  '2020',\n",
              "  'contagiante!',\n",
              "  '#covid',\n",
              "  '#quarentena'],\n",
              " ['#saopaulo',\n",
              "  '#covid19',\n",
              "  '#covid„Éº19',\n",
              "  '#lockdown',\n",
              "  '#rushhour',\n",
              "  '#rush',\n",
              "  '#usemascaranoonibus',\n",
              "  '#saude',\n",
              "  '#oms',\n",
              "  '#jairbolsonaro‚Ä¶'],\n",
              " ['seguidores',\n",
              "  'bolsonaro',\n",
              "  'radicais',\n",
              "  'alma,',\n",
              "  'respeitam',\n",
              "  'dor',\n",
              "  'outro',\n",
              "  '#impeachmentbolsonaro‚Ä¶'],\n",
              " ['escroto',\n",
              "  'privada,',\n",
              "  'vamos',\n",
              "  'dar',\n",
              "  'descarga',\n",
              "  'esperamos',\n",
              "  'bosta',\n",
              "  'descer',\n",
              "  'dois',\n",
              "  'juntos?',\n",
              "  '#lavajato‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'uso',\n",
              "  '#cloroquina',\n",
              "  '#nutriz',\n",
              "  '#lactante',\n",
              "  'impede',\n",
              "  '#amamenta√ß√£o,',\n",
              "  'contudo',\n",
              "  'droga',\n",
              "  'recomendada‚Ä¶'],\n",
              " ['rede',\n",
              "  'upas',\n",
              "  'agora',\n",
              "  'dedicada',\n",
              "  'totalmente',\n",
              "  'casos',\n",
              "  '#covid19',\n",
              "  'hospitais',\n",
              "  'credenciados',\n",
              "  'vicente,',\n",
              "  'nova',\n",
              "  'es‚Ä¶'],\n",
              " ['comunidade',\n",
              "  'intermunicipal',\n",
              "  '(cim',\n",
              "  'regi√£o',\n",
              "  'coimbra',\n",
              "  'registou',\n",
              "  'segundafeira',\n",
              "  'dois',\n",
              "  'novos',\n",
              "  'casos',\n",
              "  'infe√ß√£o',\n",
              "  'cov‚Ä¶'],\n",
              " ['empresa',\n",
              "  'oportunidade',\n",
              "  'treinar',\n",
              "  'funcion√°rios',\n",
              "  'sobre',\n",
              "  'fundamentos',\n",
              "  'b√°sicos',\n",
              "  'seguran√ßa',\n",
              "  'informa√ß√£o‚Ä¶'],\n",
              " ['atualiza√ß√£o',\n",
              "  '#covid19',\n",
              "  'mundo',\n",
              "  'atualiza√ß√£o',\n",
              "  '18/05/2020',\n",
              "  '115310',\n",
              "  'utc',\n",
              "  'casos',\n",
              "  '4820543',\n",
              "  'casos',\n",
              "  'hoje',\n",
              "  '21277',\n",
              "  'mortes',\n",
              "  '31698‚Ä¶'],\n",
              " ['impacto',\n",
              "  '#covid19',\n",
              "  'traz',\n",
              "  'convic√ß√£o',\n",
              "  'buscar',\n",
              "  'nova',\n",
              "  'forma',\n",
              "  'fazer',\n",
              "  '#neg√≥cios',\n",
              "  'crescer',\n",
              "  'quest√£o',\n",
              "  'de‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'v√≠rus',\n",
              "  'pode',\n",
              "  'transmitir',\n",
              "  'atrav√©s',\n",
              "  'superf√≠cies',\n",
              "  'objetos'],\n",
              " ['terapia',\n",
              "  'anticorpos',\n",
              "  'contra',\n",
              "  'covid19',\n",
              "  'inicia',\n",
              "  'testes',\n",
              "  'junho',\n",
              "  'setembro',\n",
              "  'leia',\n",
              "  '+',\n",
              "  'portal',\n",
              "  'enfermagem‚Ä¶'],\n",
              " ['saiba',\n",
              "  'algu√©m',\n",
              "  'pode',\n",
              "  'ser',\n",
              "  'considerado',\n",
              "  'curado',\n",
              "  '#covid19',\n",
              "  'conhe√ßa',\n",
              "  'crit√©rios',\n",
              "  'avalia√ß√µes',\n",
              "  'envolvidos',\n",
              "  'recup‚Ä¶'],\n",
              " ['escolha',\n",
              "  'vantagem',\n",
              "  'enviar',\n",
              "  'rapidez!',\n",
              "  '#mercadofinanceiro',\n",
              "  '#economizar',\n",
              "  '#savemoney',\n",
              "  '#enviorapido',\n",
              "  '#facilidade‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'projeto',\n",
              "  'mapeia',\n",
              "  'iniciativas',\n",
              "  'economia',\n",
              "  'solid√°ria',\n",
              "  'pandemia',\n",
              "  'iniciativa,',\n",
              "  're√∫ne',\n",
              "  'pesquisadores',\n",
              "  'da‚Ä¶'],\n",
              " ['vez',\n",
              "  'c√£o',\n",
              "  'chameilhe',\n",
              "  '\"fica\"',\n",
              "  'qd',\n",
              "  'ia',\n",
              "  'passear',\n",
              "  'dizialhe',\n",
              "  'fica,',\n",
              "  'anda',\n",
              "  'c√°!',\n",
              "  'fica,',\n",
              "  'anda',\n",
              "  'c√°!',\n",
              "  'coitado‚Ä¶'],\n",
              " ['volume',\n",
              "  'clientes',\n",
              "  'zonas',\n",
              "  'raianas',\n",
              "  'alto',\n",
              "  'minho',\n",
              "  'chega',\n",
              "  '20%',\n",
              "  '#ceval',\n",
              "  '#com√©rcio',\n",
              "  '#covid19'],\n",
              " ['comunidade',\n",
              "  'cigana',\n",
              "  'barcelos',\n",
              "  'novos',\n",
              "  'casos',\n",
              "  'positivos',\n",
              "  '#barcelos',\n",
              "  '#covid19'],\n",
              " ['cl√≠nica',\n",
              "  'm√©dica,',\n",
              "  'elevador!',\n",
              "  'todos',\n",
              "  'falam',\n",
              "  'evitem',\n",
              "  'elevadores!',\n",
              "  'a√≠',\n",
              "  'm√©dicos',\n",
              "  'enfermeiras',\n",
              "  'usam',\n",
              "  'escada‚Ä¶'],\n",
              " ['menino',\n",
              "  '12',\n",
              "  'cria',\n",
              "  'ferramenta',\n",
              "  'protege',\n",
              "  'contra',\n",
              "  'coronav√≠rus',\n",
              "  '#sonoticiaboa',\n",
              "  '#goodnews',\n",
              "  '#digita‚Ä¶'],\n",
              " ['oficial',\n",
              "  '1794',\n",
              "  'pessoas',\n",
              "  'recuperaram',\n",
              "  '√∫ltimas',\n",
              "  '24',\n",
              "  'horas',\n",
              "  'pa√≠s',\n",
              "  '#covid19',\n",
              "  '#dgs',\n",
              "  '#emdestaque'],\n",
              " ['bbc',\n",
              "  'news',\n",
              "  'coronavirus',\n",
              "  'hospitals',\n",
              "  'in',\n",
              "  \"brazil's\",\n",
              "  'paulo',\n",
              "  \"'near\",\n",
              "  \"collapse'\",\n",
              "  '#covid'],\n",
              " ['#covid19',\n",
              "  'calor',\n",
              "  'europa',\n",
              "  'primavera',\n",
              "  'eua',\n",
              "  'testam',\n",
              "  'novas',\n",
              "  'regras',\n",
              "  'pa√≠ses',\n",
              "  'flexibilizam',\n",
              "  'gradualmente',\n",
              "  'restri√ß√µes‚Ä¶'],\n",
              " ['caso',\n",
              "  'positivo',\n",
              "  'adia',\n",
              "  'reabertura',\n",
              "  'creche',\n",
              "  'cruz',\n",
              "  'vermelha',\n",
              "  'braga',\n",
              "  '#braga',\n",
              "  '#covid19',\n",
              "  '#creches'],\n",
              " ['brasil',\n",
              "  'hoje',\n",
              "  '(18/05/2020',\n",
              "  '130836',\n",
              "  'doentes',\n",
              "  'conta',\n",
              "  '#coronav√≠rus,',\n",
              "  'al√©m',\n",
              "  '94122',\n",
              "  'pessoas',\n",
              "  'curad‚Ä¶'],\n",
              " ['vemos',\n",
              "  'agora',\n",
              "  'nessa',\n",
              "  'altura',\n",
              "  '#covid19',\n",
              "  '#covid__19',\n",
              "  '#covid',\n",
              "  '#stayathome'],\n",
              " ['#cloroquina',\n",
              "  'volta',\n",
              "  'holofotes,',\n",
              "  'estudos',\n",
              "  'recentes',\n",
              "  'indicam',\n",
              "  'droga',\n",
              "  'ineficaz',\n",
              "  'contra',\n",
              "  '#covid19',\n",
              "  '#coronavirus'],\n",
              " ['#ci√™ncia',\n",
              "  '&amp',\n",
              "  '#covid19',\n",
              "  'belo',\n",
              "  'recado',\n",
              "  'entende',\n",
              "  'biodiversidade',\n",
              "  'thomas',\n",
              "  'lovejoy',\n",
              "  'vale',\n",
              "  'pena',\n",
              "  'conferir‚Ä¶'],\n",
              " ['caixa',\n",
              "  'inicia,',\n",
              "  'partir',\n",
              "  'desta',\n",
              "  'segundafeira',\n",
              "  '(18,',\n",
              "  'disponibiliza√ß√£o',\n",
              "  'parcela',\n",
              "  '2',\n",
              "  'aux√≠lio',\n",
              "  'emergencial',\n",
              "  'govern‚Ä¶'],\n",
              " ['resum√£o',\n",
              "  'fim',\n",
              "  'semana',\n",
              "  'heran√ßa',\n",
              "  'gugu,',\n",
              "  'gente',\n",
              "  'alienada',\n",
              "  'acha',\n",
              "  'covid',\n",
              "  'golpe,',\n",
              "  'presidente',\n",
              "  'filtro,',\n",
              "  'paulo',\n",
              "  'g‚Ä¶'],\n",
              " ['passo',\n",
              "  'tempo',\n",
              "  'umbral',\n",
              "  'vou',\n",
              "  'torcer',\n",
              "  'pro',\n",
              "  '#covid19',\n",
              "  'levar',\n",
              "  'monte',\n",
              "  'bolsominiom'],\n",
              " ['it√°lia',\n",
              "  'irlanda',\n",
              "  'retomam',\n",
              "  'atividades',\n",
              "  'ap√≥s',\n",
              "  'isolamento',\n",
              "  '#sonoticiaboa',\n",
              "  '#goodnews',\n",
              "  '#italia‚Ä¶'],\n",
              " ['futurosüìä',\n",
              "  '18/05/2020',\n",
              "  'ewz',\n",
              "  '+1,08%',\n",
              "  '(adr',\n",
              "  'brasil',\n",
              "  'dji',\n",
              "  '+1,55%',\n",
              "  'sp500',\n",
              "  '+1,49%',\n",
              "  'vix',\n",
              "  '4,90%',\n",
              "  '(aos',\n",
              "  '2055',\n",
              "  'min√©rio',\n",
              "  'ferro',\n",
              "  '5,41‚Ä¶'],\n",
              " ['mandetta',\n",
              "  'hoje,',\n",
              "  'qua',\n",
              "  'fala',\n",
              "  '200',\n",
              "  'mil',\n",
              "  '√≥bitos',\n",
              "  'passamos',\n",
              "  'apenas',\n",
              "  '1/3',\n",
              "  'pandemia',\n",
              "  'janeiro',\n",
              "  'd‚Ä¶'],\n",
              " ['feirantes',\n",
              "  'exigem',\n",
              "  'reabertura',\n",
              "  'total',\n",
              "  'feira',\n",
              "  'barcelos',\n",
              "  '#barcelos',\n",
              "  '#covid19',\n",
              "  '#economia'],\n",
              " ['exaltar',\n",
              "  'perseguir',\n",
              "  'medicamento',\n",
              "  'raz√£o',\n",
              "  'pol√≠tica',\n",
              "  'atitude',\n",
              "  'deprimente',\n",
              "  'contradi√ß√µes',\n",
              "  'patentes',\n",
              "  'nesse',\n",
              "  'artigo‚Ä¶'],\n",
              " ['papa',\n",
              "  'reza',\n",
              "  'cuidam',\n",
              "  'limpeza',\n",
              "  'ruas',\n",
              "  '#hospitais',\n",
              "  '#covid',\n",
              "  '#not√≠cias'],\n",
              " ['vale',\n",
              "  'refor√ßar',\n",
              "  'sair',\n",
              "  'casa,',\n",
              "  'saia',\n",
              "  'sempre',\n",
              "  'm√°scara',\n",
              "  '√°lcool',\n",
              "  'gel',\n",
              "  'm√£os',\n",
              "  'voltar',\n",
              "  'casa',\n",
              "  'ev‚Ä¶'],\n",
              " ['visitas',\n",
              "  'lares',\n",
              "  'permitidas',\n",
              "  'partir',\n",
              "  'hoje',\n",
              "  '#covid19',\n",
              "  '#emdestaque',\n",
              "  '#leresdeidosos'],\n",
              " ['#fiqueemcasa',\n",
              "  'limpe',\n",
              "  'quintal!',\n",
              "  '#covid19',\n",
              "  '#dengue',\n",
              "  'castigam',\n",
              "  'brasileiros',\n",
              "  'norte',\n",
              "  'sul',\n",
              "  'saiba',\n",
              "  'na‚Ä¶'],\n",
              " ['@tocantins79',\n",
              "  '@chico_dangelo',\n",
              "  '@zehdeabreu',\n",
              "  'sei',\n",
              "  '(posso',\n",
              "  'estar',\n",
              "  'enganada',\n",
              "  'deu',\n",
              "  'origem',\n",
              "  'descoberta,',\n",
              "  'foi‚Ä¶'],\n",
              " ['#brasil',\n",
              "  'atinge',\n",
              "  '16118',\n",
              "  'mortes',\n",
              "  '#coronav√≠rus',\n",
              "  '#oms',\n",
              "  '#epidemia',\n",
              "  '#covid19',\n",
              "  '#jairbolsonaro',\n",
              "  '#saludmundial'],\n",
              " ['l√∫cio',\n",
              "  'crespo,',\n",
              "  'diretor',\n",
              "  't√©cnico',\n",
              "  'gold',\n",
              "  'partner',\n",
              "  '@incentea',\n",
              "  'participantes',\n",
              "  'entrevista',\n",
              "  'virtual',\n",
              "  'conduz‚Ä¶'],\n",
              " ['exdiretor',\n",
              "  '#oms',\n",
              "  '\"√©',\n",
              "  'realmente',\n",
              "  'poss√≠vel',\n",
              "  'v√≠rus',\n",
              "  'queime',\n",
              "  'naturalmente',\n",
              "  'antes',\n",
              "  'haver',\n",
              "  'vacina\"‚Ä¶'],\n",
              " ['photos',\n",
              "  'from',\n",
              "  'vgma',\n",
              "  'covid',\n",
              "  '19',\n",
              "  'heroes',\n",
              "  'concert',\n",
              "  '@efya_nokturnal',\n",
              "  '@kinaatagh',\n",
              "  '@akwaboahmusic',\n",
              "  '@amandziba',\n",
              "  '#vgma',\n",
              "  '#ghanamusic‚Ä¶'],\n",
              " ['conhe√ßa',\n",
              "  'roomoffice,',\n",
              "  'sa√≠da',\n",
              "  'setor',\n",
              "  'hoteleiro',\n",
              "  '#pandemia',\n",
              "  '#covid'],\n",
              " ['us',\n",
              "  'to',\n",
              "  'deport',\n",
              "  '161',\n",
              "  'indians',\n",
              "  '#unitedstates',\n",
              "  '#indians',\n",
              "  '#deport',\n",
              "  '#corona',\n",
              "  '#coronacrisis',\n",
              "  '#coronavirus',\n",
              "  '#coronavirusoutbreak‚Ä¶'],\n",
              " ['mundo',\n",
              "  'reinventou',\n",
              "  'agora',\n",
              "  'reuni√µes',\n",
              "  'virtuais',\n",
              "  'ferramentas',\n",
              "  'sendo',\n",
              "  'utilizadas,',\n",
              "  'seguras?',\n",
              "  'iss‚Ä¶'],\n",
              " ['rusia',\n",
              "  'xa',\n",
              "  'superou',\n",
              "  'guaiomin√≠',\n",
              "  'segundo',\n",
              "  'pa√≠s',\n",
              "  'mundo',\n",
              "  'con',\n",
              "  'm√°is',\n",
              "  '#covid,',\n",
              "  'detr√°s',\n",
              "  'eua,',\n",
              "  'claro',\n",
              "  '#guerrafr√≠a'],\n",
              " ['tomem',\n",
              "  'cuidado',\n",
              "  'pois',\n",
              "  'pior',\n",
              "  'ra√ßa',\n",
              "  'vi',\n",
              "  '√∫ltimos',\n",
              "  'tempos',\n",
              "  '#bolsonarorainhalouca',\n",
              "  '#bolsonaroassassino‚Ä¶'],\n",
              " ['√≥tima',\n",
              "  'semana',\n",
              "  'todos',\n",
              "  'üôèüåûüåûüò∑',\n",
              "  '#semana',\n",
              "  '#desejo',\n",
              "  '#boasemana',\n",
              "  '#otimasemana',\n",
              "  '#fiqueemcasa',\n",
              "  '#stayhome',\n",
              "  '#covid',\n",
              "  '#brasil',\n",
              "  '#saopaulo‚Ä¶'],\n",
              " ['libertar√°',\n",
              "  '#bolsonarorainhalouca',\n",
              "  '#bolsonaroassassino',\n",
              "  '#bolsonaroficaquieto',\n",
              "  '#bolsonaro',\n",
              "  '#brasil‚Ä¶'],\n",
              " ['provinha', 'pra', 'vcs', '#covid', '#divulgaai'],\n",
              " ['@vitoriamailla',\n",
              "  'dias',\n",
              "  'fim',\n",
              "  '?',\n",
              "  'kkk',\n",
              "  'nome',\n",
              "  'desse',\n",
              "  'filme',\n",
              "  '#covid',\n",
              "  '19',\n",
              "  'kkkk',\n",
              "  '40tena',\n",
              "  '?kkk'],\n",
              " ['l√°vate',\n",
              "  'constantemente',\n",
              "  'las',\n",
              "  'manos!',\n",
              "  '#covid',\n",
              "  '#quedateencasa',\n",
              "  '#lavatelasmanos'],\n",
              " ['casualmente',\n",
              "  'intern√™',\n",
              "  '#chicoc√©sar',\n",
              "  'd√°',\n",
              "  'soco',\n",
              "  'meio',\n",
              "  'cara',\n",
              "  'achei',\n",
              "  'hoje',\n",
              "  'ia',\n",
              "  'chorar',\n",
              "  'antes',\n",
              "  'dormir‚Ä¶'],\n",
              " ['sobrevivermos',\n",
              "  'torna',\n",
              "  'leve',\n",
              "  'fardo',\n",
              "  'morte',\n",
              "  'sobre',\n",
              "  'consci√™ncia',\n",
              "  'coletiva,',\n",
              "  'nunca',\n",
              "  'esquecer',\n",
              "  'so‚Ä¶'],\n",
              " ['bbc',\n",
              "  'news',\n",
              "  'coronavirus',\n",
              "  'hospitals',\n",
              "  'in',\n",
              "  \"brazil's\",\n",
              "  'paulo',\n",
              "  \"'near\",\n",
              "  \"collapse'\",\n",
              "  '#covid19',\n",
              "  '#brazil',\n",
              "  '#coronavirus',\n",
              "  '#bbcnews‚Ä¶'],\n",
              " ['@luciano_hang',\n",
              "  'faz',\n",
              "  'seguinte',\n",
              "  'trabalha',\n",
              "  'meio',\n",
              "  'pov√£o',\n",
              "  'ruas',\n",
              "  'lojas',\n",
              "  'm√™s',\n",
              "  'tipo,',\n",
              "  'mistura',\n",
              "  'messsmoooo‚Ä¶'],\n",
              " ['promovendo',\n",
              "  'pr√°ticas',\n",
              "  'saud√°veis',\n",
              "  'cuidados',\n",
              "  'contra',\n",
              "  'covid19',\n",
              "  'acesse',\n",
              "  'v√≠deo',\n",
              "  'üëâ'],\n",
              " ['vou',\n",
              "  'ajudar',\n",
              "  'sa√≠rem',\n",
              "  't√©dio',\n",
              "  'nessa',\n",
              "  'pandemia',\n",
              "  'criei',\n",
              "  'perfil',\n",
              "  'onde',\n",
              "  'farei',\n",
              "  'lives',\n",
              "  'sexo,',\n",
              "  'masturba√ß√£o',\n",
              "  'corr‚Ä¶'],\n",
              " ['fa√ßa', 'eu,', 'use', 'mascara', '#covidse'],\n",
              " ['pa√≠s',\n",
              "  '√≥bitos',\n",
              "  'casos',\n",
              "  '1',\n",
              "  'üá∫üá∏',\n",
              "  '89932',\n",
              "  '1516343',\n",
              "  '2',\n",
              "  'üá¨üáß',\n",
              "  '34716',\n",
              "  '244995',\n",
              "  '3',\n",
              "  'üáÆüáπ',\n",
              "  '31908‚Ä¶'],\n",
              " ['hora',\n",
              "  'retirar',\n",
              "  'm√°scara,',\n",
              "  'fa√ßa',\n",
              "  'partir',\n",
              "  'el√°stico',\n",
              "  'tiras',\n",
              "  'parte',\n",
              "  'tr√°s',\n",
              "  'imagem',\n",
              "  'frida',\n",
              "  'kahlo,',\n",
              "  'reimag‚Ä¶'],\n",
              " ['precisa',\n",
              "  'sair',\n",
              "  'rua',\n",
              "  'ir',\n",
              "  'trabalhar',\n",
              "  'ir',\n",
              "  'mercado?',\n",
              "  'use',\n",
              "  'm√°scara!',\n",
              "  'pode',\n",
              "  'ser',\n",
              "  'pano',\n",
              "  'deve',\n",
              "  'cobrir',\n",
              "  'nariz',\n",
              "  'boca‚Ä¶'],\n",
              " ['ver',\n",
              "  'imagens',\n",
              "  '#praias',\n",
              "  'parques',\n",
              "  '#portugal',\n",
              "  'so',\n",
              "  'vem',\n",
              "  'cabe√ßa,',\n",
              "  '‚Äùmas',\n",
              "  'gente',\n",
              "  'bem',\n",
              "  'cornos,',\n",
              "  'qu‚Ä¶'],\n",
              " ['desaparecido!',\n",
              "  'enfim,',\n",
              "  'caos',\n",
              "  'a√≠',\n",
              "  'outro',\n",
              "  'maior',\n",
              "  'chegando!',\n",
              "  'a√≠',\n",
              "  'lembro',\n",
              "  'ensinamentos',\n",
              "  'pai',\n",
              "  'p‚Ä¶'],\n",
              " ['verdadeiro',\n",
              "  'estado',\n",
              "  'terror,',\n",
              "  'inocentes',\n",
              "  'sendo',\n",
              "  'presos',\n",
              "  'andarem',\n",
              "  's√≥s',\n",
              "  'lugares',\n",
              "  'desertos,',\n",
              "  'cidad√£os',\n",
              "  'obrigados',\n",
              "  'f‚Ä¶'],\n",
              " ['economia',\n",
              "  'prefeitura',\n",
              "  'santa',\n",
              "  'b√°rbara',\n",
              "  'publica',\n",
              "  'novo',\n",
              "  'decreto',\n",
              "  'flexibilizando',\n",
              "  'abertura',\n",
              "  'com√©rcio',\n",
              "  'partir',\n",
              "  'quartaf‚Ä¶'],\n",
              " ['pib',\n",
              "  'brasil',\n",
              "  'deve',\n",
              "  'cair',\n",
              "  '4,11%',\n",
              "  '2020,',\n",
              "  'prev√™',\n",
              "  'mercado',\n",
              "  '#covid'],\n",
              " ['#coronav√≠rus',\n",
              "  '#hidroxicloroquina',\n",
              "  '#covid',\n",
              "  'hidroxicloroquina',\n",
              "  'c/',\n",
              "  'drs',\n",
              "  'paolo',\n",
              "  'zanotto',\n",
              "  'usp',\n",
              "  'pedro',\n",
              "  'batista',\n",
              "  'jr',\n",
              "  'prevent',\n",
              "  'sen‚Ä¶'],\n",
              " ['inclusive',\n",
              "  'dia',\n",
              "  '21/04',\n",
              "  'fiz',\n",
              "  'publica√ß√£o',\n",
              "  'instagram',\n",
              "  'correlacionando',\n",
              "  'pa√≠ses',\n",
              "  'mortes',\n",
              "  'covid19‚Ä¶'],\n",
              " ['presidente?',\n",
              "  'vc',\n",
              "  'formador',\n",
              "  'opini√£o',\n",
              "  'perdeu',\n",
              "  'consci√™ncia?',\n",
              "  'ganhando',\n",
              "  'isso?',\n",
              "  'qto',\n",
              "  'ganhava',\n",
              "  'antes‚Ä¶'],\n",
              " ['texto',\n",
              "  'anterior',\n",
              "  'sa√≠da',\n",
              "  'teich',\n",
              "  '\"o',\n",
              "  'tratamento',\n",
              "  'covid',\n",
              "  'pede',\n",
              "  'ci√™ncia,',\n",
              "  'voluntarismo\"'],\n",
              " ['orgulho',\n",
              "  'maninha',\n",
              "  'linha',\n",
              "  'frente',\n",
              "  'combate',\n",
              "  'co',\n",
              "  '#covid',\n",
              "  'mana',\n",
              "  'deus',\n",
              "  'proteja',\n",
              "  'todos',\n",
              "  'pacientes‚Ä¶'],\n",
              " ['importante',\n",
              "  'perdermos',\n",
              "  'controle,',\n",
              "  'sen√£o',\n",
              "  'manteremos',\n",
              "  'calma',\n",
              "  '#brasil',\n",
              "  '#covid'],\n",
              " ['excelente',\n",
              "  'not√≠cia',\n",
              "  'apenas',\n",
              "  '13',\n",
              "  'pa√≠ses',\n",
              "  'todo',\n",
              "  'planeta',\n",
              "  'terra',\n",
              "  '50',\n",
              "  'mortes',\n",
              "  'covid19',\n",
              "  'dia',\n",
              "  '17/05/202‚Ä¶'],\n",
              " ['agenda',\n",
              "  'aberta',\n",
              "  'devidos',\n",
              "  'cuidados',\n",
              "  'gente',\n",
              "  'consegue',\n",
              "  'fuder',\n",
              "  'gostoso',\n",
              "  't√°',\n",
              "  'esperando',\n",
              "  'que?',\n",
              "  'quer',\n",
              "  'namorado',\n",
              "  'para‚Ä¶'],\n",
              " ['vc',\n",
              "  'compra',\n",
              "  '#tv',\n",
              "  '@samsungbrasil',\n",
              "  'sai',\n",
              "  'defeito',\n",
              "  'loja,',\n",
              "  'compra',\n",
              "  '@tcl_oficialbr',\n",
              "  '1',\n",
              "  'ano',\n",
              "  'co‚Ä¶'],\n",
              " ['boletim', 'cabo', 'santo', 'agostinho', '#covid19'],\n",
              " ['\"n√≥s',\n",
              "  'aprendemos',\n",
              "  'hist√≥ria,',\n",
              "  'brasil,',\n",
              "  'coronav√≠rus',\n",
              "  'compromete',\n",
              "  'crian√ßas,',\n",
              "  'essa‚Ä¶'],\n",
              " ['stf',\n",
              "  'diplomatas',\n",
              "  'venezuelanos',\n",
              "  'podem',\n",
              "  'ficar',\n",
              "  'brasil',\n",
              "  'fim',\n",
              "  '#pandemia',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid'],\n",
              " ['parte',\n",
              "  '#inumer√°veis',\n",
              "  'faz',\n",
              "  'ficar',\n",
              "  'garganta',\n",
              "  'fechada',\n",
              "  'querendo',\n",
              "  'chorar',\n",
              "  '#fantastico',\n",
              "  '#covid',\n",
              "  '#17demaio',\n",
              "  '#forabolsonaro'],\n",
              " ['#bostonaroüí©',\n",
              "  'virou',\n",
              "  'v√≠deo',\n",
              "  'ridicularizando',\n",
              "  'decis√µes',\n",
              "  '#bostonaroüí©',\n",
              "  'diante',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['saiu',\n",
              "  'segundo',\n",
              "  'epis√≥dio',\n",
              "  'humanos',\n",
              "  'quarentena,',\n",
              "  'dessa',\n",
              "  'vez',\n",
              "  '@fehavila',\n",
              "  'batemos',\n",
              "  'papo',\n",
              "  'sobre',\n",
              "  'roti‚Ä¶'],\n",
              " ['#maranh√£o,',\n",
              "  'estado',\n",
              "  'ningu√©m',\n",
              "  'morre',\n",
              "  'outra',\n",
              "  'coisa,',\n",
              "  '#covid,',\n",
              "  'melhor,',\n",
              "  'mortes',\n",
              "  'outras',\n",
              "  'raz√µes',\n",
              "  'e‚Ä¶'],\n",
              " ['17/5',\n",
              "  '#covid',\n",
              "  '#paran√°',\n",
              "  '(3/3',\n",
              "  '#fiqueemcasa',\n",
              "  '884(+193',\n",
              "  'investig',\n",
              "  '1477',\n",
              "  'recup',\n",
              "  '21006(+193',\n",
              "  'exames',\n",
              "  '18538(+1265',\n",
              "  'result',\n",
              "  'n‚Ä¶'],\n",
              " ['busca',\n",
              "  'rem√©dio',\n",
              "  'auxilie',\n",
              "  'tratamento',\n",
              "  'casos',\n",
              "  '#covid19',\n",
              "  'pauta',\n",
              "  'brasil',\n",
              "  'mundo',\n",
              "  'discuss√£o',\n",
              "  'ini‚Ä¶'],\n",
              " ['#covid',\n",
              "  '#dadosn√£omentem,',\n",
              "  'informa√ß√£o',\n",
              "  'maior',\n",
              "  'arma,',\n",
              "  'perfil',\n",
              "  '#brasil',\n",
              "  'mortes',\n",
              "  'covid,',\n",
              "  '#pneumonia,',\n",
              "  '#srag,',\n",
              "  's√≠ndrome',\n",
              "  're‚Ä¶'],\n",
              " ['@bleierfilho',\n",
              "  '@jmarciopenha',\n",
              "  '@jdoriajr',\n",
              "  'n√£o!',\n",
              "  'perdi',\n",
              "  'conhecido',\n",
              "  'covid',\n",
              "  'confirmado,',\n",
              "  'tomou',\n",
              "  'medicamento',\n",
              "  'ho‚Ä¶'],\n",
              " ['causas',\n",
              "  'mortes',\n",
              "  'devidamente',\n",
              "  'informadas,',\n",
              "  'sugest√£o',\n",
              "  'vi√©s',\n",
              "  'dados',\n",
              "  'clara#covid‚Ä¶'],\n",
              " ['#covid',\n",
              "  '#dadosn√£omentem,',\n",
              "  'figura',\n",
              "  'anexo',\n",
              "  'conseguem',\n",
              "  'entender',\n",
              "  'pouco',\n",
              "  'dados,',\n",
              "  'indicadores',\n",
              "  'mortes',\n",
              "  'por‚Ä¶'],\n",
              " ['2020', 'aprendi', 'lavar', 'm√£os!', '#covid', '#alcoolgel'],\n",
              " ['deve',\n",
              "  'ser',\n",
              "  'extremamente',\n",
              "  'desgastante',\n",
              "  'ser',\n",
              "  'pessoa',\n",
              "  'grande',\n",
              "  'visibilidade',\n",
              "  'minimamente',\n",
              "  'coerente,',\n",
              "  'brasil',\n",
              "  'hoje!‚Ä¶'],\n",
              " ['0bora',\n",
              "  'participar',\n",
              "  'pessoal!?',\n",
              "  'responde',\n",
              "  'a√≠',\n",
              "  'compartilhem',\n",
              "  'vai',\n",
              "  'ser',\n",
              "  'primeira',\n",
              "  'atitude',\n",
              "  'sair',\n",
              "  'quarenten‚Ä¶'],\n",
              " ['saiba',\n",
              "  'tudo',\n",
              "  'sobre',\n",
              "  'projeto',\n",
              "  'lei',\n",
              "  'pode',\n",
              "  'ajudar',\n",
              "  'milhares',\n",
              "  'pessoas',\n",
              "  'empresas',\n",
              "  'enfrentamento',\n",
              "  'crise',\n",
              "  'provocad‚Ä¶'],\n",
              " ['@correio24horas',\n",
              "  'usa',\n",
              "  'bandeira,',\n",
              "  'maior',\n",
              "  's√≠mbolo',\n",
              "  'agredir',\n",
              "  'professional',\n",
              "  'trabalhando?',\n",
              "  'isso‚Ä¶'],\n",
              " ['#covid',\n",
              "  'avan√ßa',\n",
              "  'rio',\n",
              "  'negro',\n",
              "  'perde',\n",
              "  'feliz',\n",
              "  'i',\n",
              "  'copi√¥,',\n",
              "  'parente',\n",
              "  'epis√≥dio',\n",
              "  '146',\n",
              "  'via',\n",
              "  '@youtube'],\n",
              " ['@apenasfehh',\n",
              "  '@minsaude',\n",
              "  '@gabbardojoao',\n",
              "  '@jairbolsonaro',\n",
              "  'exemplo,',\n",
              "  'acredita',\n",
              "  'todos',\n",
              "  '√≥bitos',\n",
              "  'anotados',\n",
              "  'como‚Ä¶'],\n",
              " ['16',\n",
              "  'mil',\n",
              "  'mortes',\n",
              "  'dois',\n",
              "  'meses',\n",
              "  'domingo',\n",
              "  'completa',\n",
              "  'dois',\n",
              "  'meses',\n",
              "  'primeira',\n",
              "  'morte',\n",
              "  'oficial,',\n",
              "  'registrada',\n",
              "  '17‚Ä¶'],\n",
              " ['@barbaragancia',\n",
              "  '@riqfreire',\n",
              "  'imaginem',\n",
              "  'quanto',\n",
              "  '#covid',\n",
              "  'galerinha',\n",
              "  'levar√°',\n",
              "  'volta',\n",
              "  'pras',\n",
              "  'cidades',\n",
              "  'podemos',\n",
              "  'dizer‚Ä¶'],\n",
              " ['entenderam',\n",
              "  'desespero',\n",
              "  'm√≠dia',\n",
              "  'governadores',\n",
              "  'quest√£o',\n",
              "  'hcq,',\n",
              "  'querendo',\n",
              "  'dizer',\n",
              "  'funciona',\n",
              "  '(e',\n",
              "  'bat‚Ä¶'],\n",
              " ['#fantastico',\n",
              "  'pq',\n",
              "  'vcs',\n",
              "  'mostram',\n",
              "  'empresas',\n",
              "  'q',\n",
              "  'fechando',\n",
              "  'portas',\n",
              "  '?',\n",
              "  'f√°cil',\n",
              "  'postar',\n",
              "  '#ficaemcasa',\n",
              "  'qndo',\n",
              "  't√°‚Ä¶'],\n",
              " ['rio',\n",
              "  'janeiro',\n",
              "  'vez',\n",
              "  'p√°ginas',\n",
              "  'pol√≠cias,',\n",
              "  'furto',\n",
              "  'dinheiro',\n",
              "  'combate',\n",
              "  '#covid19,',\n",
              "  'cadeia',\n",
              "  'resp‚Ä¶'],\n",
              " ['deus',\n",
              "  'bom',\n",
              "  'dms',\n",
              "  '!',\n",
              "  'üôè‚ù§Ô∏è',\n",
              "  '#blessed',\n",
              "  '#gratid√£o',\n",
              "  '#agradecer',\n",
              "  '#covid'],\n",
              " ['#brasil,üáßüá∑',\n",
              "  '#covid19',\n",
              "  '#brasil,',\n",
              "  'relacionados',\n",
              "  '485',\n",
              "  'obitos',\n",
              "  '24',\n",
              "  'horas',\n",
              "  '16,118',\n",
              "  'mortes'],\n",
              " ['pesquisadores',\n",
              "  'autoriza√ß√£o',\n",
              "  'pra',\n",
              "  'fazer',\n",
              "  'pesquisa',\n",
              "  'conseguem',\n",
              "  'fazer',\n",
              "  'trabalho',\n",
              "  'impressionante',\n",
              "  'brasil',\n",
              "  'm‚Ä¶'],\n",
              " ['brasil',\n",
              "  'registra',\n",
              "  '485',\n",
              "  'novas',\n",
              "  'mortes',\n",
              "  '#covid19',\n",
              "  '√∫ltimas',\n",
              "  '24',\n",
              "  'horas,',\n",
              "  'totalizando',\n",
              "  '16118',\n",
              "  'n√∫mero',\n",
              "  'recuperados,',\n",
              "  'd‚Ä¶'],\n",
              " ['#cloroquina', 'rem√©dio', 'corrup√ß√£o', '#covid'],\n",
              " ['terror',\n",
              "  'lockdown',\n",
              "  'estrat√©gias',\n",
              "  'governadores!',\n",
              "  '15',\n",
              "  'dias',\n",
              "  'lockdown',\n",
              "  'recife,',\n",
              "  'luiz,',\n",
              "  'diver‚Ä¶'],\n",
              " ['telesus',\n",
              "  'criado',\n",
              "  'aproximar',\n",
              "  'minist√©rio',\n",
              "  'sa√∫de',\n",
              "  'modo',\n",
              "  'combate',\n",
              "  'coronav√≠rus',\n",
              "  'faci‚Ä¶'],\n",
              " ['d√∫vida',\n",
              "  'proteger',\n",
              "  '√≥culos',\n",
              "  'contra',\n",
              "  'coronav√≠rus?',\n",
              "  'dicas',\n",
              "  'v√£o',\n",
              "  'ajudar',\n",
              "  'hora',\n",
              "  'higienizar',\n",
              "  's‚Ä¶'],\n",
              " ['rio',\n",
              "  'janeiro',\n",
              "  '2,7',\n",
              "  'mil',\n",
              "  'mortes',\n",
              "  '#covid19',\n",
              "  'casos',\n",
              "  'confirmados,',\n",
              "  '17557',\n",
              "  'pacientes',\n",
              "  'recuperaram‚Ä¶'],\n",
              " ['curva', '#covid', '#argentina', 'an√°lisis', '@totinfraire', 'üëá'],\n",
              " ['queria',\n",
              "  'passar',\n",
              "  'pros',\n",
              "  'navegantes',\n",
              "  'quanto',\n",
              "  'extremamente',\n",
              "  'importante',\n",
              "  'lixos',\n",
              "  'recolhidos',\n",
              "  'garis',\n",
              "  'com‚Ä¶'],\n",
              " ['nunca',\n",
              "  'acreditei',\n",
              "  'mundo,',\n",
              "  'pessoas,',\n",
              "  'iria',\n",
              "  'voltar',\n",
              "  'outro',\n",
              "  '#covid',\n",
              "  'vai!'],\n",
              " ['#projetopoemanaquarentenams',\n",
              "  '1¬∫',\n",
              "  'teaser',\n",
              "  '2¬™',\n",
              "  'temporada',\n",
              "  'projeto',\n",
              "  'poema',\n",
              "  'quarentena',\n",
              "  'ms,',\n",
              "  're√∫ne',\n",
              "  '28',\n",
              "  'poetas',\n",
              "  'ma‚Ä¶'],\n",
              " ['‚Äúcrise',\n",
              "  'prolongada',\n",
              "  'dolorosa‚Äù',\n",
              "  'prevista',\n",
              "  'turismo',\n",
              "  'minho',\n",
              "  '#braga',\n",
              "  '#covid19',\n",
              "  '#emdestaque'],\n",
              " ['casos',\n",
              "  '#covid',\n",
              "  '#guarulhos',\n",
              "  'chegam',\n",
              "  '1528,',\n",
              "  '165',\n",
              "  'mortes',\n",
              "  'fonte',\n",
              "  'seade,',\n",
              "  '17/05',\n",
              "  '1710'],\n",
              " ['basta',\n",
              "  '#covid',\n",
              "  'trazer',\n",
              "  'v√°rios',\n",
              "  'sintomas',\n",
              "  'aleat√≥rios',\n",
              "  'rem√©dio',\n",
              "  'd√°',\n",
              "  'dor',\n",
              "  'est√¥mago',\n",
              "  'a√≠',\n",
              "  'tomar',\n",
              "  'rem‚Ä¶'],\n",
              " ['n√∫meros',\n",
              "  'podem',\n",
              "  'aumentar',\n",
              "  'pr√≥ximas',\n",
              "  'semanas',\n",
              "  'autoriza√ß√£o',\n",
              "  '@prefeiturabh',\n",
              "  '@alexandrekalil',\n",
              "  'reabertura',\n",
              "  'do‚Ä¶'],\n",
              " ['vantagens',\n",
              "  'usar',\n",
              "  'm√°scara',\n",
              "  'pano',\n",
              "  '#corona',\n",
              "  '#covid',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid19'],\n",
              " ['#gripe',\n",
              "  'espanhola',\n",
              "  '(1918',\n",
              "  '#covid19',\n",
              "  '(2020',\n",
              "  'pouco',\n",
              "  'tempo',\n",
              "  '(historicamente',\n",
              "  'falando',\n",
              "  'mundo',\n",
              "  'muda‚Ä¶'],\n",
              " ['ibope',\n",
              "  'impedido',\n",
              "  'fazer',\n",
              "  'pesquisa',\n",
              "  'sobre',\n",
              "  'covid',\n",
              "  'cobrou',\n",
              "  'r$',\n",
              "  '10',\n",
              "  'milh√µes',\n",
              "  '#coronavirus‚Ä¶'],\n",
              " ['aterrador!', 'cremat√≥rio', 'funciona', 'escala', 'industrial', '#covid'],\n",
              " ['live',\n",
              "  'evolu√ß√£o',\n",
              "  'dimensional',\n",
              "  '#dakilapesquisas',\n",
              "  '#17demaio',\n",
              "  '#livedobem',\n",
              "  '#covid',\n",
              "  '#evolu√ß√£o',\n",
              "  '#etbilu'],\n",
              " ['pessoas',\n",
              "  'obedecendo',\n",
              "  'quarentena?',\n",
              "  'entenda',\n",
              "  'partir',\n",
              "  'deste',\n",
              "  'v√≠deo!',\n",
              "  '#politica',\n",
              "  '#economia‚Ä¶'],\n",
              " ['sair',\n",
              "  'rapidamente',\n",
              "  'carro',\n",
              "  'pouco,',\n",
              "  'alguns',\n",
              "  'lugares',\n",
              "  'gente',\n",
              "  'domingos',\n",
              "  '‚Äúnormais‚Äù',\n",
              "  '(sem',\n",
              "  'pan‚Ä¶'],\n",
              " ['covid19',\n",
              "  'brasil',\n",
              "  '15,3',\n",
              "  'mil',\n",
              "  'novos',\n",
              "  'casos',\n",
              "  'total',\n",
              "  'chega',\n",
              "  '218,2',\n",
              "  'mil',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid'],\n",
              " ['eua',\n",
              "  'aliados',\n",
              "  'ocidente',\n",
              "  '(',\n",
              "  'incluindo',\n",
              "  'brasil',\n",
              "  'temer,',\n",
              "  'bozo,',\n",
              "  'a√©cio,',\n",
              "  'fhc,',\n",
              "  'm√≠dia,',\n",
              "  'igrejas,',\n",
              "  'judici√°ri‚Ä¶'],\n",
              " ['üóíÔ∏è',\n",
              "  '#coronav√≠rus',\n",
              "  'boletim',\n",
              "  '17/05/20',\n",
              "  'neste',\n",
              "  'domingo,',\n",
              "  'seviep',\n",
              "  '#santos',\n",
              "  'recebeu',\n",
              "  'notifica√ß√£o',\n",
              "  '50',\n",
              "  'novos',\n",
              "  'casos',\n",
              "  'c‚Ä¶'],\n",
              " ['acesse',\n",
              "  'dados',\n",
              "  'p√°gina',\n",
              "  'instagram',\n",
              "  'üëâ',\n",
              "  '#renovarobrasil',\n",
              "  '#renovabrcovid19',\n",
              "  '#renovabr‚Ä¶'],\n",
              " ['ivermectina',\n",
              "  'medicamento',\n",
              "  'parasitas',\n",
              "  'exemplo',\n",
              "  'piolho!!',\n",
              "  '#covid',\n",
              "  '#governo',\n",
              "  'inventa',\n",
              "  'cada',\n",
              "  'marmota',\n",
              "  'jesus'],\n",
              " ['gente',\n",
              "  'porque',\n",
              "  'galera',\n",
              "  't√°',\n",
              "  'tomando',\n",
              "  'ivermectina',\n",
              "  'pro',\n",
              "  'covid?',\n",
              "  '#covid',\n",
              "  '#caos',\n",
              "  '#voltajesus'],\n",
              " ['verdade',\n",
              "  'gripe',\n",
              "  'chinesa',\n",
              "  'contratada',\n",
              "  '#flamengo',\n",
              "  'absoluto',\n",
              "  'ano',\n",
              "  'novo',\n",
              "  '#mengao',\n",
              "  '#covid'],\n",
              " ['#stf',\n",
              "  'destina',\n",
              "  'r$',\n",
              "  '153',\n",
              "  'milh√µes',\n",
              "  'lava',\n",
              "  'jato',\n",
              "  'combater',\n",
              "  '#pandemia',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid'],\n",
              " ['acb',\n",
              "  '|',\n",
              "  '√≠ndice',\n",
              "  'isolamento',\n",
              "  'x',\n",
              "  'novo',\n",
              "  'rod√≠zio',\n",
              "  'suspens√£o',\n",
              "  '#covid',\n",
              "  '#covid19',\n",
              "  '#governoestadual',\n",
              "  '#governofederal‚Ä¶'],\n",
              " ['enquanto',\n",
              "  'coloca',\n",
              "  'm√°scara',\n",
              "  'pra',\n",
              "  'trabalhar,',\n",
              "  'sinh√°',\n",
              "  'coloca',\n",
              "  'm√°scara',\n",
              "  'pra',\n",
              "  'correr',\n",
              "  'cal√ßad√£o',\n",
              "  'fique',\n",
              "  'casa',\n",
              "  'p‚Ä¶'],\n",
              " ['boletim',\n",
              "  'coronav√≠rus',\n",
              "  '#covid19',\n",
              "  '|',\n",
              "  'confira',\n",
              "  'atualiza√ß√£o',\n",
              "  'boletim',\n",
              "  'municipal',\n",
              "  'deste',\n",
              "  'domingo',\n",
              "  '(17/05',\n",
              "  'informa√ß‚Ä¶'],\n",
              " ['\\U0001f9a0\\U0001f9a0',\n",
              "  'boletim',\n",
              "  'coronav√≠rus',\n",
              "  '#covid19',\n",
              "  '|',\n",
              "  'confira',\n",
              "  'atualiza√ß√£o',\n",
              "  'boletim',\n",
              "  'municipal',\n",
              "  'deste',\n",
              "  'domingo',\n",
              "  '(17/05',\n",
              "  'observa√ß√£o',\n",
              "  'fora‚Ä¶'],\n",
              " ['q', 'vale', 'q', 'praia', '#matosinhos', '#covid', 'virgem', 'extra'],\n",
              " ['prioridade',\n",
              "  'profissionais',\n",
              "  'sa√∫de',\n",
              "  'testes',\n",
              "  'covid19',\n",
              "  '#covid',\n",
              "  '#pandemia',\n",
              "  '#sa√∫de‚Ä¶'],\n",
              " ['ac', '/', 'dc', 'antes', 'corona', '/', 'corona', '#quarentena', '#covid'],\n",
              " ['covid19',\n",
              "  '3¬∫',\n",
              "  'caso',\n",
              "  'br√°s',\n",
              "  'alportel',\n",
              "  'aponta',\n",
              "  'nova',\n",
              "  'cadeia',\n",
              "  'cont√°gio',\n",
              "  'ativa',\n",
              "  '#covid19',\n",
              "  '#coronavirus‚Ä¶'],\n",
              " ['liga!',\n",
              "  '#live',\n",
              "  'rel√¢mpago',\n",
              "  'sobre',\n",
              "  '#covid',\n",
              "  'pode',\n",
              "  'ser',\n",
              "  'combatida',\n",
              "  '#radiestesia',\n",
              "  'j√°,',\n",
              "  'j√°!',\n",
              "  'logo',\n",
              "  '17h,‚Ä¶'],\n",
              " ['festa,',\n",
              "  'festa',\n",
              "  'todo',\n",
              "  'mundo',\n",
              "  'diverte,',\n",
              "  'rindo',\n",
              "  'n√≥s!',\n",
              "  '#tbt',\n",
              "  'nada,',\n",
              "  'vou',\n",
              "  'lan√ßar',\n",
              "  'hastag‚Ä¶'],\n",
              " ['üò∑',\n",
              "  'seguran√ßa',\n",
              "  'todos',\n",
              "  'primeiro',\n",
              "  'lugar!',\n",
              "  'isso,',\n",
              "  'precisou',\n",
              "  'sair',\n",
              "  'casa?',\n",
              "  'v√°',\n",
              "  '#m√°scara!',\n",
              "  'üëâ',\n",
              "  'usada',\n",
              "  'corretament‚Ä¶'],\n",
              " ['‚ö†',\n",
              "  'fazemos',\n",
              "  'teste',\n",
              "  'pcr',\n",
              "  'covid19!',\n",
              "  '#corona',\n",
              "  '#virus',\n",
              "  '#coronavirus',\n",
              "  '#saude',\n",
              "  '#covid19',\n",
              "  '#covid19',\n",
              "  '#covid_19',\n",
              "  '#prevencao',\n",
              "  '#sus‚Ä¶'],\n",
              " ['primeira',\n",
              "  'vez,',\n",
              "  'mon√ß√£o',\n",
              "  'casos',\n",
              "  'covid',\n",
              "  'recuperados',\n",
              "  'ativos',\n",
              "  '#covid19',\n",
              "  '#emdestaque',\n",
              "  '#mon√ß√£o'],\n",
              " ['passada',\n",
              "  'ressaca,',\n",
              "  'alguns',\n",
              "  '\"exinfectados\"',\n",
              "  'reclamam',\n",
              "  'extrema',\n",
              "  'fadiga',\n",
              "  'parece',\n",
              "  'ser',\n",
              "  'pr√≥xima',\n",
              "  'fronteira',\n",
              "  'holand‚Ä¶'],\n",
              " ['covid19',\n",
              "  'fran√ßa',\n",
              "  'ultrapassa',\n",
              "  '28',\n",
              "  'mil',\n",
              "  'mortos',\n",
              "  '483',\n",
              "  'novos',\n",
              "  '√≥bitos',\n",
              "  '#covid19',\n",
              "  '#fran√ßa',\n",
              "  '#√≥bitos'],\n",
              " ['lembrando',\n",
              "  'teich',\n",
              "  'ministro',\n",
              "  'indicado',\n",
              "  'amb',\n",
              "  'segundo',\n",
              "  'informa√ß√µes',\n",
              "  'pr√≥pria',\n",
              "  'associa√ß√£o',\n",
              "  'bolsonaro',\n",
              "  'cita‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['covid19',\n",
              "  'it√°lia',\n",
              "  'acentua',\n",
              "  'descida',\n",
              "  '145',\n",
              "  'mortes',\n",
              "  '675',\n",
              "  'casos',\n",
              "  '24',\n",
              "  'horas',\n",
              "  '#covid19',\n",
              "  '#it√°lia',\n",
              "  '#√≥bitos'],\n",
              " ['covid19',\n",
              "  'reino',\n",
              "  'unido',\n",
              "  '170',\n",
              "  'novas',\n",
              "  'mortes,',\n",
              "  'n√∫mero',\n",
              "  'baixo',\n",
              "  'desde',\n",
              "  'mar√ßo',\n",
              "  '#covid19',\n",
              "  '#√≥bitos',\n",
              "  '#reinounido'],\n",
              " ['espanha',\n",
              "  'vai',\n",
              "  'impor',\n",
              "  'uso',\n",
              "  'obrigat√≥rio',\n",
              "  'm√°scara',\n",
              "  'locais',\n",
              "  'p√∫blicos',\n",
              "  '#covid19',\n",
              "  '#espanha',\n",
              "  '#sa√∫de'],\n",
              " ['fc',\n",
              "  'famalicao',\n",
              "  'casos',\n",
              "  'positivos',\n",
              "  'covid',\n",
              "  '#covid19',\n",
              "  '#famalic√£o',\n",
              "  '#fcfamalic√£o'],\n",
              " ['#cloroquina',\n",
              "  'eficaz',\n",
              "  'contra',\n",
              "  'covid',\n",
              "  'perigosa,',\n",
              "  'pode',\n",
              "  'matar',\n",
              "  'pacientes!',\n",
              "  '#hidroxicloroquina',\n",
              "  'efi‚Ä¶'],\n",
              " ['aces',\n",
              "  'nega',\n",
              "  'falta',\n",
              "  'material',\n",
              "  'centro',\n",
              "  'sa√∫de',\n",
              "  'esposende',\n",
              "  '#acesc√°vado',\n",
              "  '#covid19',\n",
              "  '#esposende'],\n",
              " ['sweet',\n",
              "  'dreams',\n",
              "  'assista',\n",
              "  '#albertooliveira',\n",
              "  '#ao',\n",
              "  '#musica',\n",
              "  '#sweetdreams',\n",
              "  '#coronavirus‚Ä¶'],\n",
              " ['#advogado',\n",
              "  'londrina,',\n",
              "  '#igreja,',\n",
              "  '#covid19',\n",
              "  'mpf',\n",
              "  'pede',\n",
              "  'retirada',\n",
              "  'ar',\n",
              "  'v√≠deos',\n",
              "  'pastor',\n",
              "  'anuncia',\n",
              "  'cura',\n",
              "  \"'m√°gica'\",\n",
              "  'cov‚Ä¶'],\n",
              " ['urgente',\n",
              "  'mega',\n",
              "  'carreata',\n",
              "  'bolsonarista',\n",
              "  'rio',\n",
              "  'janeiro',\n",
              "  'manifestantes',\n",
              "  'pedem',\n",
              "  'witzel',\n",
              "  'volta',\n",
              "  'trabalho‚Ä¶'],\n",
              " ['agora',\n",
              "  'avenida',\n",
              "  'paulista,',\n",
              "  'grupo',\n",
              "  'manifestantes',\n",
              "  're√∫nem',\n",
              "  'prox',\n",
              "  'fiesp',\n",
              "  'grupo',\n",
              "  'pede',\n",
              "  'impeachment',\n",
              "  'governador‚Ä¶'],\n",
              " ['live',\n",
              "  'on',\n",
              "  '#periscope',\n",
              "  'explorerinf',\n",
              "  'paranormal',\n",
              "  'pete!',\n",
              "  '#creepy',\n",
              "  '#thesewoodsarrhaunted',\n",
              "  '#covid',\n",
              "  '#ghosts',\n",
              "  '#snakes'],\n",
              " ['üôÑ',\n",
              "  '#covid19',\n",
              "  'causando',\n",
              "  'n',\n",
              "  'planeta',\n",
              "  'n√∫mero',\n",
              "  'd',\n",
              "  'mortandade',\n",
              "  'absurdamente',\n",
              "  'preocupante',\n",
              "  'tempo',\n",
              "  'rev‚Ä¶'],\n",
              " ['neste',\n",
              "  'programa,',\n",
              "  'ivan',\n",
              "  'mizanzuk',\n",
              "  'conversa',\n",
              "  'sonia',\n",
              "  'guajajara',\n",
              "  'sobre',\n",
              "  'impacto',\n",
              "  'novo',\n",
              "  '#coronav√≠rus',\n",
              "  'povos‚Ä¶'],\n",
              " ['funcion√°rios',\n",
              "  'creches',\n",
              "  'barcelos',\n",
              "  'esposende',\n",
              "  'casos',\n",
              "  'positivos',\n",
              "  'covid',\n",
              "  '#acesc√°vado',\n",
              "  '#barcelos',\n",
              "  '#covid19'],\n",
              " ['#ufba',\n",
              "  '#ifba',\n",
              "  '#oceanografia',\n",
              "  '#ufrj',\n",
              "  '#laurodefreitas',\n",
              "  '#brasil',\n",
              "  '#bolsonaro',\n",
              "  '#bahia',\n",
              "  '#salvador',\n",
              "  '#mario',\n",
              "  '#jo√£o',\n",
              "  '#jose',\n",
              "  '#covid',\n",
              "  '#pai‚Ä¶'],\n",
              " ['#pessoal',\n",
              "  'acham',\n",
              "  'dr',\n",
              "  'anthony',\n",
              "  'wong',\n",
              "  'par',\n",
              "  'minist√©rio',\n",
              "  'sa√∫de?',\n",
              "  '#bolsonaro',\n",
              "  '#ministeriodasaude',\n",
              "  '#covid'],\n",
              " ['policial',\n",
              "  'penal',\n",
              "  'problemas',\n",
              "  'sa√∫de',\n",
              "  '(comorbidades',\n",
              "  'infectado',\n",
              "  'dentro',\n",
              "  'papuda',\n",
              "  'enfrenta',\n",
              "  'surto‚Ä¶'],\n",
              " ['üåç',\n",
              "  '#covid',\n",
              "  '#boasnot√≠cias',\n",
              "  'üá´üá∑',\n",
              "  '#fran√ßa',\n",
              "  'registra',\n",
              "  'menos',\n",
              "  'cem',\n",
              "  'mortes',\n",
              "  'covid19',\n",
              "  '24h',\n",
              "  'üáØüáµ',\n",
              "  'com√©rcio',\n",
              "  'reabre',\n",
              "  '#jap√£o‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['pandemia',\n",
              "  'covid19',\n",
              "  'afetou',\n",
              "  'h√°bitos',\n",
              "  'vida?',\n",
              "  'responda',\n",
              "  '#fiqueemcasa',\n",
              "  '#sa√∫de‚Ä¶'],\n",
              " ['triste',\n",
              "  'realidade',\n",
              "  'espalhando',\n",
              "  'todos',\n",
              "  'setores',\n",
              "  'goi√¢nia,',\n",
              "  'goi√°s,',\n",
              "  'ocorrendo',\n",
              "  'todos',\n",
              "  'setores‚Ä¶'],\n",
              " ['covas',\n",
              "  'diz',\n",
              "  'sa√∫de',\n",
              "  'sp',\n",
              "  'perto',\n",
              "  'colapso',\n",
              "  'depende',\n",
              "  'doria',\n",
              "  'implantar',\n",
              "  \"'lockdown'‚Ä¶\"],\n",
              " ['#fifa',\n",
              "  'definir√°',\n",
              "  'pa√≠ssede',\n",
              "  '#mundial',\n",
              "  'futebol',\n",
              "  'feminino',\n",
              "  '25',\n",
              "  'junho',\n",
              "  '#copadomundo',\n",
              "  '#covid'],\n",
              " ['acho',\n",
              "  'dever√≠amos',\n",
              "  'aderir',\n",
              "  'urgente',\n",
              "  'gesto',\n",
              "  'aqui',\n",
              "  '!',\n",
              "  'mostrar',\n",
              "  'n√∫meros',\n",
              "  '!!',\n",
              "  '#vaitomarnocucorona‚Ä¶'],\n",
              " ['direito!!!',\n",
              "  'empresas',\n",
              "  'podem',\n",
              "  'requerer',\n",
              "  'suspens√£o',\n",
              "  'tributos',\n",
              "  'distritais',\n",
              "  'fun√ß√£o',\n",
              "  'pandemia',\n",
              "  'covid19',\n",
              "  '‚Ä¶'],\n",
              " ['enquanto',\n",
              "  'isso,',\n",
              "  'cart√£o',\n",
              "  'corporativo',\n",
              "  'compras',\n",
              "  'emergenciais',\n",
              "  'estados',\n",
              "  'munic√≠pios!!!',\n",
              "  'üò°üò°',\n",
              "  '#vergonha‚Ä¶'],\n",
              " ['covid',\n",
              "  '19',\n",
              "  'ms',\n",
              "  '#covid_19',\n",
              "  '#covid19',\n",
              "  '#covid',\n",
              "  '#covid19cg',\n",
              "  '#campograndems',\n",
              "  '#matogrossodosul',\n",
              "  '#portaljeffersondealmeida‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['#covid19', 'mata', 'segunda', 'crian√ßa', '48', 'horas', 'sp'],\n",
              " ['emocionante',\n",
              "  'texto',\n",
              "  'salvem',\n",
              "  'idosos',\n",
              "  'lutaram',\n",
              "  'tanto,',\n",
              "  'agora',\n",
              "  'sob',\n",
              "  'cuidados',\n",
              "  '#eugenia',\n",
              "  'n‚Ä¶'],\n",
              " ['alerta', 'sobre', 'responsabilidade', 'mortes', 'evit√°veis', '#covid19'],\n",
              " ['empresa',\n",
              "  'alentejana',\n",
              "  'oferece',\n",
              "  '500',\n",
              "  'quilos',\n",
              "  'legumes',\n",
              "  'carenciados',\n",
              "  'famalic√£o',\n",
              "  '#alentejo',\n",
              "  '#covid19',\n",
              "  '#famalic√£o'],\n",
              " ['querem',\n",
              "  'despachar',\n",
              "  'estoque',\n",
              "  'ex√©rcito',\n",
              "  'fabricou',\n",
              "  'larga',\n",
              "  'escala,',\n",
              "  'mando',\n",
              "  'bolsonaro',\n",
              "  'pra',\n",
              "  'livrar',\n",
              "  'crime',\n",
              "  'de‚Ä¶'],\n",
              " ['algu√©m',\n",
              "  'ainda',\n",
              "  'duvida',\n",
              "  'brasil',\n",
              "  'vai',\n",
              "  'protagonizar',\n",
              "  'maiores',\n",
              "  'trag√©dias',\n",
              "  'humanit√°rias',\n",
              "  'hist√≥ria',\n",
              "  'recente?',\n",
              "  've‚Ä¶'],\n",
              " ['overthinking',\n",
              "  'nesses',\n",
              "  'tempos',\n",
              "  'quarentena',\n",
              "  'normal',\n",
              "  'deixemos',\n",
              "  'levar',\n",
              "  'bombas',\n",
              "  'informa√ß√£o',\n",
              "  'constante,',\n",
              "  'pel‚Ä¶'],\n",
              " ['munic√≠pio',\n",
              "  'ind√≠genas',\n",
              "  'pa√≠s',\n",
              "  '219',\n",
              "  'casos',\n",
              "  'covid19',\n",
              "  '#amazonas',\n",
              "  '#covid'],\n",
              " ['ontem',\n",
              "  'convidei',\n",
              "  '@supercaruso',\n",
              "  'participar',\n",
              "  'desse',\n",
              "  'projeto',\n",
              "  'hoje',\n",
              "  '#live',\n",
              "  '1600!',\n",
              "  'no‚Ä¶'],\n",
              " ['partida',\n",
              "  'semifinal',\n",
              "  'jogo',\n",
              "  'bem',\n",
              "  '@evertonri',\n",
              "  'filho',\n",
              "  '@_felipemelo_,',\n",
              "  'davi',\n",
              "  'melo,',\n",
              "  'sensacional!!‚öΩüéÆüî•üíØ‚Ä¶'],\n",
              " ['#china',\n",
              "  '#covid',\n",
              "  'embaixador',\n",
              "  'china',\n",
              "  'israel',\n",
              "  'encontrado',\n",
              "  'morto',\n",
              "  'casa',\n",
              "  '|',\n",
              "  'mundo',\n",
              "  '|',\n",
              "  'g1'],\n",
              " ['exemplo', 'deveria', 'ser', 'seguido', 'muitas', 'pessoas', '#covid'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['lajeado',\n",
              "  'mp',\n",
              "  'conclui',\n",
              "  'acordos',\n",
              "  'brf',\n",
              "  'minuano',\n",
              "  'prote√ß√£o',\n",
              "  'sa√∫de',\n",
              "  'popula√ß√£o',\n",
              "  'local'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho'],\n",
              " ['elogio',\n",
              "  'passando',\n",
              "  'feed',\n",
              "  'üòç',\n",
              "  'dessa',\n",
              "  'vez',\n",
              "  'aluno',\n",
              "  'luiz',\n",
              "  'carlos,',\n",
              "  'super',\n",
              "  'feliz',\n",
              "  'cursosüíö‚Ä¶'],\n",
              " ['@diegomachados01',\n",
              "  '@spsobretrilhos',\n",
              "  '@jdoriajr',\n",
              "  '@brunocovas',\n",
              "  '@metrosp_oficial',\n",
              "  '@jairbolsonaro',\n",
              "  'triste',\n",
              "  'al√¥',\n",
              "  '@prefsp‚Ä¶'],\n",
              " ['principio',\n",
              "  'isonomia',\n",
              "  '\"tratar',\n",
              "  'iguais',\n",
              "  'medida',\n",
              "  'igualdade',\n",
              "  'desiguais',\n",
              "  'medida',\n",
              "  'desigualdade\"‚Ä¶'],\n",
              " ['#governo',\n",
              "  '#federal',\n",
              "  '#diminuir',\n",
              "  '#sal√°rios',\n",
              "  '#deputados,',\n",
              "  '#senadores',\n",
              "  'assessores',\n",
              "  'metade',\n",
              "  '#combater',\n",
              "  '#covid1‚Ä¶'],\n",
              " ['passa',\n",
              "  'vergonha,',\n",
              "  'bolsominios',\n",
              "  't√™m',\n",
              "  'limites',\n",
              "  '#vergonha',\n",
              "  '#impeachmentbolsonaro',\n",
              "  '#jairbolsonaro‚Ä¶'],\n",
              " ['diverg√™ncia,',\n",
              "  'nelson',\n",
              "  'teich',\n",
              "  'deixa',\n",
              "  'cargo',\n",
              "  'ministro',\n",
              "  'sa√∫de',\n",
              "  'brasil',\n",
              "  'di√°rio',\n",
              "  'pandemia,',\n",
              "  '17',\n",
              "  'maio',\n",
              "  '2020',\n",
              "  'ver',\n",
              "  'ma‚Ä¶'],\n",
              " ['\"vai',\n",
              "  'tomar',\n",
              "  'cu',\n",
              "  'corona\"?',\n",
              "  'gado',\n",
              "  'direcione',\n",
              "  'raiva',\n",
              "  'v√≠rus',\n",
              "  'mito!',\n",
              "  '#bolsonaro',\n",
              "  '#brasilien‚Ä¶'],\n",
              " ['#covid19', 'dados', 'oficais', '#mo√ßambique'],\n",
              " ['valeime', 'rafael!!', '#dornacabe√ßa', '#covid', '#cansei'],\n",
              " ['problema',\n",
              "  'meme',\n",
              "  'peti√ß√£o',\n",
              "  '#covas',\n",
              "  '#rod√≠zio',\n",
              "  '#covid',\n",
              "  '#pandemia',\n",
              "  '#advocacia',\n",
              "  '#oab'],\n",
              " ['hipertensos',\n",
              "  'fazem',\n",
              "  'parte',\n",
              "  'grupo',\n",
              "  'vulner√°vel',\n",
              "  'cont√°gio',\n",
              "  'covid19,',\n",
              "  'importante',\n",
              "  'evitem',\n",
              "  'agl‚Ä¶'],\n",
              " ['alimentos,',\n",
              "  'm√°scaras',\n",
              "  'prote√ß√£o',\n",
              "  '√°lcool',\n",
              "  'gel',\n",
              "  'entregues',\n",
              "  'duas',\n",
              "  'mil',\n",
              "  'fam√≠lias',\n",
              "  'ind√≠genas',\n",
              "  'gabriel',\n",
              "  'd‚Ä¶'],\n",
              " ['4',\n",
              "  'planos',\n",
              "  'aula',\n",
              "  'combater',\n",
              "  'desinforma√ß√£o',\n",
              "  'tempos',\n",
              "  'coronav√≠rus',\n",
              "  'via',\n",
              "  '@porvir‚Ä¶'],\n",
              " ['brasil',\n",
              "  'registra',\n",
              "  '14,9',\n",
              "  'mil',\n",
              "  'novos',\n",
              "  '#casos',\n",
              "  '816',\n",
              "  'novas',\n",
              "  '#mortes',\n",
              "  'covid19',\n",
              "  '#balan√ßo',\n",
              "  '#covid'],\n",
              " ['cumprimento',\n",
              "  'decreto',\n",
              "  'gdf,',\n",
              "  'alteramos',\n",
              "  'hor√°rio',\n",
              "  'funcionamento',\n",
              "  'continuamos',\n",
              "  '‚Äúon',\n",
              "  'line‚Äù',\n",
              "  '24',\n",
              "  'horas',\n",
              "  'por‚Ä¶'],\n",
              " ['deputados',\n",
              "  'estaduais',\n",
              "  'impeachment',\n",
              "  'governador',\n",
              "  'camilo',\n",
              "  'santana',\n",
              "  '(',\n",
              "  'pt',\n",
              "  '#foracamilo',\n",
              "  'assine',\n",
              "  'peti√ß√£o!‚Ä¶'],\n",
              " ['empresa?',\n",
              "  'pensou',\n",
              "  'medidas',\n",
              "  'precisa',\n",
              "  'adotar',\n",
              "  'enquanto',\n",
              "  'covid19',\n",
              "  'passa?',\n",
              "  'confira',\n",
              "  'mat√©ria',\n",
              "  'blog',\n",
              "  'para‚Ä¶'],\n",
              " ['#rondon√≥polis', 'registra', 'morte', '#covid19'],\n",
              " ['sobre',\n",
              "  '#covid',\n",
              "  'brasil',\n",
              "  'üò∑',\n",
              "  '\\U0001f9a0',\n",
              "  'üìå',\n",
              "  '#sp',\n",
              "  'continua',\n",
              "  'liderando',\n",
              "  'ranking',\n",
              "  'seguido',\n",
              "  'rj',\n",
              "  'üö´',\n",
              "  '#par√°',\n",
              "  'estende',\n",
              "  '#lockdown',\n",
              "  'p‚Ä¶'],\n",
              " ['2080',\n",
              "  'povo',\n",
              "  'entendeu',\n",
              "  'ainda',\n",
              "  'isolamento',\n",
              "  'social',\n",
              "  '#covid',\n",
              "  '#domingodetremurasdv‚Ä¶'],\n",
              " ['dgs',\n",
              "  'avisado',\n",
              "  'limpar',\n",
              "  'grandes',\n",
              "  'superf√≠cies',\n",
              "  'desinfetante',\n",
              "  'eficaz',\n",
              "  '#covid19',\n",
              "  '#dgs',\n",
              "  '#gra√ßafreitas'],\n",
              " ['@vaseldaniel',\n",
              "  'inimigo',\n",
              "  'inimigo',\n",
              "  'amigo,',\n",
              "  'moro',\n",
              "  'pasta',\n",
              "  'justi√ßa,',\n",
              "  'suspender',\n",
              "  'lavajato,',\n",
              "  'sendo',\n",
              "  'sincero‚Ä¶'],\n",
              " ['@gduvivier',\n",
              "  'fantastico',\n",
              "  'greg',\n",
              "  'news',\n",
              "  'leveza,',\n",
              "  'cultura,',\n",
              "  'arte,',\n",
              "  'vida',\n",
              "  'morte',\n",
              "  '#brasil,',\n",
              "  'tempos',\n",
              "  '#covid,',\n",
              "  'lideranc‚Ä¶'],\n",
              " ['regras',\n",
              "  'festas',\n",
              "  'partid√°rias',\n",
              "  'populares',\n",
              "  't√™m',\n",
              "  '‚Äúvaler',\n",
              "  'todos‚Äù',\n",
              "  '#covid19',\n",
              "  '#pol√≠tica',\n",
              "  '#sa√∫de'],\n",
              " ['vc,',\n",
              "  'cearense,',\n",
              "  '√±',\n",
              "  'ficar',\n",
              "  'casa,',\n",
              "  'todo',\n",
              "  'esfor√ßo',\n",
              "  'v√£o',\n",
              "  '#fiqueemcasa',\n",
              "  '#covid19'],\n",
              " ['vai',\n",
              "  'tomar',\n",
              "  'cu',\n",
              "  'corona',\n",
              "  'deveria',\n",
              "  'ser',\n",
              "  'presidente',\n",
              "  'rep√∫blica',\n",
              "  'financiou',\n",
              "  'pesquisas',\n",
              "  'encontra‚Ä¶'],\n",
              " ['ir√£o',\n",
              "  'regista',\n",
              "  'quase',\n",
              "  '7000',\n",
              "  'mortos',\n",
              "  'devido',\n",
              "  'v√≠rus',\n",
              "  '#covid19',\n",
              "  '#ir√£o',\n",
              "  '#√≥bitos'],\n",
              " ['m√°scaras',\n",
              "  'certificado',\n",
              "  'inv√°lido',\n",
              "  'distribu√≠das',\n",
              "  'pagas',\n",
              "  '#covid19',\n",
              "  '#dgs'],\n",
              " ['medo', 'deve', 'paralisar', 'portugueses', '#covid19', '#dgs', '#sa√∫de'],\n",
              " ['covid19',\n",
              "  'trump',\n",
              "  'parou',\n",
              "  'insistir',\n",
              "  'uso',\n",
              "  'hidroxicloroquina?',\n",
              "  'acredito',\n",
              "  'resposta',\n",
              "  'quest‚Ä¶'],\n",
              " ['reposted',\n",
              "  'from',\n",
              "  '@pcriminalanimal',\n",
              "  'causa',\n",
              "  'pandemia',\n",
              "  '#covid19,',\n",
              "  'n√∫mero',\n",
              "  'casos',\n",
              "  'viol√™ncia',\n",
              "  'dom√©stica',\n",
              "  'fami‚Ä¶'],\n",
              " ['c√£es',\n",
              "  'farejadores',\n",
              "  'come√ßam',\n",
              "  'ser',\n",
              "  'testados',\n",
              "  'detectar',\n",
              "  'pessoas',\n",
              "  'coronav√≠rus',\n",
              "  'cheiro',\n",
              "  '#blogdosilvalima',\n",
              "  '#saude‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'cuidado',\n",
              "  'almo√ßo!',\n",
              "  'pessoas',\n",
              "  'peso',\n",
              "  'acima',\n",
              "  'recomend√°vel',\n",
              "  'devem',\n",
              "  'redobrar',\n",
              "  'cuidados',\n",
              "  'nesse',\n",
              "  'cen√°rio',\n",
              "  'qu‚Ä¶'],\n",
              " ['primo',\n",
              "  'porteiro',\n",
              "  'condom√≠nio',\n",
              "  '04',\n",
              "  'pegou',\n",
              "  'metade,',\n",
              "  'morrido',\n",
              "  'estouro',\n",
              "  'pneu',\n",
              "  'colocaram',\n",
              "  'foi‚Ä¶'],\n",
              " ['lembra,', 'tug√£o', 'vai', 'assim', 'culpa', '#covid', '√≥', '#varandasout?'],\n",
              " ['oficial',\n",
              "  'braga',\n",
              "  'vai',\n",
              "  'seis',\n",
              "  'dias',\n",
              "  'novos',\n",
              "  'casos',\n",
              "  'covid',\n",
              "  '#braga',\n",
              "  '#covid19',\n",
              "  '#dgs'],\n",
              " ['sabe',\n",
              "  'maior',\n",
              "  'medo',\n",
              "  'momento',\n",
              "  '?',\n",
              "  'mortos',\n",
              "  'covid19',\n",
              "  'acordem',\n",
              "  'apocalipse',\n",
              "  'zumbi',\n",
              "  '!',\n",
              "  'vou',\n",
              "  'parar',\n",
              "  'se‚Ä¶'],\n",
              " ['#brasil',\n",
              "  'conseguiu',\n",
              "  'ter',\n",
              "  'hospital',\n",
              "  'superfaturado,',\n",
              "  'dentro',\n",
              "  'est√°dio',\n",
              "  'superfaturado',\n",
              "  'respiradores',\n",
              "  'superfaturados!',\n",
              "  'üëèüèº‚Ä¶'],\n",
              " ['escapa',\n",
              "  'contagiado',\n",
              "  'eagle',\n",
              "  'pass',\n",
              "  'nava',\n",
              "  '#cincomanantiales',\n",
              "  '#covid19'],\n",
              " ['escapa',\n",
              "  'contagiado',\n",
              "  'eagle',\n",
              "  'pass',\n",
              "  'nava',\n",
              "  '#cincomanantiales',\n",
              "  '#covid19'],\n",
              " ['#covid',\n",
              "  '#abrolhosbrasil',\n",
              "  'carlos',\n",
              "  'drumond',\n",
              "  'havia',\n",
              "  'pedra',\n",
              "  'meio',\n",
              "  'caminho',\n",
              "  '@direitonoponto',\n",
              "  'meio',\n",
              "  'caminh‚Ä¶'],\n",
              " ['ofical',\n",
              "  '814',\n",
              "  'pessoas',\n",
              "  'recuperaram',\n",
              "  'covid',\n",
              "  'pa√≠s',\n",
              "  '√∫ltimas',\n",
              "  '24',\n",
              "  'horas',\n",
              "  '#covid19',\n",
              "  '#dgs',\n",
              "  '#emdestaque'],\n",
              " ['bom',\n",
              "  'dia!',\n",
              "  'hoje',\n",
              "  'dia',\n",
              "  'marcado',\n",
              "  'conquistas',\n",
              "  'vit√≥rias',\n",
              "  'gl√≥ria',\n",
              "  'deus',\n",
              "  '#fiqueemcasa',\n",
              "  '#covid19',\n",
              "  '#vamosvencer'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['crise',\n",
              "  'neg√≥cios',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  'prova',\n",
              "  '#automa√ß√£o',\n",
              "  'importante',\n",
              "  '#futurodotrabalho‚Ä¶'],\n",
              " ['atualiza√ß√£o',\n",
              "  '#covid19',\n",
              "  '#brasil',\n",
              "  'atualiza√ß√£o',\n",
              "  '17/05/2020',\n",
              "  '114316',\n",
              "  'utc',\n",
              "  'casos',\n",
              "  '233511',\n",
              "  'casos',\n",
              "  'hoje',\n",
              "  '369',\n",
              "  'mortes',\n",
              "  '15662',\n",
              "  'mo‚Ä¶'],\n",
              " ['üáßüá∑',\n",
              "  'total',\n",
              "  'casos',\n",
              "  'brasil',\n",
              "  'casos',\n",
              "  'confirmadoss',\n",
              "  '233,511',\n",
              "  '√≥bitos',\n",
              "  '15,662',\n",
              "  'recupera√ß√µes',\n",
              "  '89,672',\n",
              "  '#covid,#corona,‚Ä¶'],\n",
              " ['pessoas',\n",
              "  'tipo',\n",
              "  'sangu√≠neo',\n",
              "  'podem',\n",
              "  'ter',\n",
              "  'maiores',\n",
              "  '#chances',\n",
              "  'pegar',\n",
              "  'coronav√≠rus,',\n",
              "  'segundo',\n",
              "  '#pesquisa',\n",
              "  '#covid'],\n",
              " ['pandemia',\n",
              "  '‚Äúroubou‚Äù',\n",
              "  'sustento',\n",
              "  'vendedores',\n",
              "  'farturas',\n",
              "  'feiras',\n",
              "  'romarias',\n",
              "  '#covid19',\n",
              "  '#economia'],\n",
              " ['m√°scaras',\n",
              "  'luvas',\n",
              "  'descart√°veis',\n",
              "  'materiais',\n",
              "  'preven√ß√£o',\n",
              "  'bastante',\n",
              "  'comuns',\n",
              "  'durante',\n",
              "  'pandemia',\n",
              "  'fizermos',\n",
              "  'u‚Ä¶'],\n",
              " ['sa√∫de!',\n",
              "  'paz',\n",
              "  'prosperidade!',\n",
              "  'hoje',\n",
              "  '#orando',\n",
              "  'vez,',\n",
              "  '#infectados/doentes',\n",
              "  '#covid19',\n",
              "  'clamando‚Ä¶'],\n",
              " ['hoje',\n",
              "  '#orando',\n",
              "  'vez,',\n",
              "  '#infectados/doentes',\n",
              "  '#covid19',\n",
              "  'clamando',\n",
              "  'deus',\n",
              "  '#cura!‚Ä¶'],\n",
              " ['tempos',\n",
              "  'pandemia,',\n",
              "  'centro',\n",
              "  'triagem',\n",
              "  'lipor',\n",
              "  'continua',\n",
              "  'laborar!',\n",
              "  'conhe√ßa',\n",
              "  'resultados',\n",
              "  'mar√ßo',\n",
              "  'veja',\n",
              "  'que‚Ä¶'],\n",
              " ['situa√ß√£o',\n",
              "  'clara',\n",
              "  '1',\n",
              "  'sp,',\n",
              "  'rj,',\n",
              "  'pa,',\n",
              "  'ce,',\n",
              "  'radicalmente',\n",
              "  'contra',\n",
              "  '@jairbolsonaro',\n",
              "  ',',\n",
              "  'n√∫meros',\n",
              "  '#covid',\n",
              "  'distorcido‚Ä¶'],\n",
              " ['novas',\n",
              "  'elei√ß√µes',\n",
              "  'vota?',\n",
              "  '(se',\n",
              "  'chapa',\n",
              "  'bolsonaro',\n",
              "  'cassada',\n",
              "  '#globohack',\n",
              "  '#furacao2000',\n",
              "  '#lgbt',\n",
              "  '#covid'],\n",
              " ['fim', 'cloroquina', 'eua', '#covid19'],\n",
              " ['#hospitalodilonbehrens,',\n",
              "  '#bh,',\n",
              "  'vai',\n",
              "  'receber',\n",
              "  'r$',\n",
              "  '339900,77',\n",
              "  'viabilizados',\n",
              "  '@mptmg,',\n",
              "  'recursos',\n",
              "  'utilizados',\n",
              "  'n‚Ä¶'],\n",
              " ['üéÆ‚öΩ√©',\n",
              "  'dia',\n",
              "  'decis√£o‚öΩüéÆ',\n",
              "  'jogo',\n",
              "  'bem',\n",
              "  'chega',\n",
              "  '√∫ltimo',\n",
              "  'dia',\n",
              "  'disputa',\n",
              "  'semifinais',\n",
              "  'final!',\n",
              "  'venha',\n",
              "  'particip‚Ä¶'],\n",
              " ['07h45',\n",
              "  'bom',\n",
              "  'dia',\n",
              "  '#ficaemcasa',\n",
              "  'caraleo',\n",
              "  'preparado',\n",
              "  'gripe',\n",
              "  's√≠nica',\n",
              "  'aparecer',\n",
              "  'bora',\n",
              "  'correr,',\n",
              "  'sedentarismo‚Ä¶'],\n",
              " ['üëâ√±',\n",
              "  'mentir,',\n",
              "  'sabem,',\n",
              "  'fa√ßa',\n",
              "  'pergunta',\n",
              "  'certa',\n",
              "  'escute',\n",
              "  'voz',\n",
              "  'alta',\n",
              "  'resposta,',\n",
              "  '√±',\n",
              "  'tente',\n",
              "  'adivinhar',\n",
              "  '√±',\n",
              "  'vai',\n",
              "  's‚Ä¶'],\n",
              " ['enviou',\n",
              "  'mensagem',\n",
              "  '(email',\n",
              "  'pol√≠tico',\n",
              "  'ajudou',\n",
              "  'eleger',\n",
              "  'pedindo',\n",
              "  'informa√ß√µes',\n",
              "  'cobrando',\n",
              "  'trabalho',\n",
              "  'co‚Ä¶'],\n",
              " ['15000',\n",
              "  'fam√≠lias',\n",
              "  'recorreram',\n",
              "  'pagamento',\n",
              "  'faseado',\n",
              "  'luz',\n",
              "  '#covid19',\n",
              "  '#edp',\n",
              "  '#eletricidade'],\n",
              " ['agricultores',\n",
              "  'pedem',\n",
              "  'apoio',\n",
              "  'forma',\n",
              "  'urgente',\n",
              "  '#agricultura',\n",
              "  '#covid19'],\n",
              " ['15000',\n",
              "  'mortos',\n",
              "  '#covid',\n",
              "  'testes',\n",
              "  'p√≠fios',\n",
              "  '4¬∞',\n",
              "  'lugar',\n",
              "  'mundo',\n",
              "  'n√∫mero',\n",
              "  'casos',\n",
              "  '#forabolsonaro'],\n",
              " ['@jairbolsonaro',\n",
              "  't√°',\n",
              "  'direcionando',\n",
              "  'gado',\n",
              "  'qe',\n",
              "  'fala',\n",
              "  'qe',\n",
              "  '#covid19',\n",
              "  'gripezinha',\n",
              "  'pro',\n",
              "  'curral',\n",
              "  'deveria',\n",
              "  'chegar',\n",
              "  'l√°',\n",
              "  'pra‚Ä¶'],\n",
              " ['d√™',\n",
              "  'prioridade!',\n",
              "  '#valorizesuavida',\n",
              "  '#luteeven√ßa',\n",
              "  '#marksmidia',\n",
              "  '#somostodosiguais',\n",
              "  '#fiqueemcasa',\n",
              "  '#quarentena',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['@minsaude', 'somente', '#covid', '?'],\n",
              " ['brasil',\n",
              "  'galgando',\n",
              "  'posi√ß√µes',\n",
              "  'ranking',\n",
              "  'quer√≠amos',\n",
              "  'estar!!!',\n",
              "  '#forabolsonaro',\n",
              "  '#forabolsonarourgente‚Ä¶'],\n",
              " ['ent√£o,',\n",
              "  'vamos',\n",
              "  'reduzir',\n",
              "  '@assalariado,',\n",
              "  'tirar',\n",
              "  '#direitos',\n",
              "  '#benef√≠cios',\n",
              "  '#trabalhistas,',\n",
              "  'enquanto',\n",
              "  'governo‚Ä¶'],\n",
              " ['governos',\n",
              "  'municipais',\n",
              "  'frente',\n",
              "  'coronav√≠rus',\n",
              "  '#coronavirusbrasil',\n",
              "  '#covid',\n",
              "  '#bolsonarogenocida'],\n",
              " ['crit√©rio',\n",
              "  'uniforme',\n",
              "  'calcular',\n",
              "  '(identificar',\n",
              "  'mortes',\n",
              "  'covid19',\n",
              "  '(varia',\n",
              "  'conforme',\n",
              "  'pa√≠s',\n",
              "  'inte‚Ä¶'],\n",
              " ['üëèüèºüëèüèºüëèüèºüëèüèºüëèüèº',\n",
              "  'bravo',\n",
              "  '#pflege',\n",
              "  '#covid2019',\n",
              "  '#covid',\n",
              "  '#coronapandemie',\n",
              "  '#'],\n",
              " ['vacina',\n",
              "  'anticorpo',\n",
              "  'aprovado',\n",
              "  'sera',\n",
              "  'distribu√≠do',\n",
              "  'alto',\n",
              "  'escala',\n",
              "  'eua',\n",
              "  'daqui',\n",
              "  '5',\n",
              "  'meses',\n",
              "  'eua',\n",
              "  'bras‚Ä¶'],\n",
              " ['domingo,', 'acordo', 'casa,', 'to', 'ressaca,', 'acordei', 'lado', 'u‚Ä¶'],\n",
              " ['@carlos_jb_paz',\n",
              "  'concordar',\n",
              "  'liberais',\n",
              "  'twitter',\n",
              "  'coisa',\n",
              "  'rara',\n",
              "  'aconteceu',\n",
              "  'burocracia',\n",
              "  '#covid',\n",
              "  'o‚Ä¶'],\n",
              " ['\"assembleia',\n",
              "  'mundial',\n",
              "  'sa√∫de',\n",
              "  'oms',\n",
              "  'ocorre',\n",
              "  'meio',\n",
              "  'crise',\n",
              "  '#covid19\"',\n",
              "  '#wha73'],\n",
              " ['quarantine',\n",
              "  'fatigue',\n",
              "  'is',\n",
              "  'real',\n",
              "  '#pandemia',\n",
              "  '#coronavirus',\n",
              "  '#covid'],\n",
              " ['\"#covid19', 'brasil', 'supera', 'espanha', 'it√°lia', 'n√∫mero', 'casos\"'],\n",
              " ['@g1',\n",
              "  'estampa',\n",
              "  'üìå',\n",
              "  '21',\n",
              "  'estados',\n",
              "  '#df',\n",
              "  'prop√µem',\n",
              "  'multar',\n",
              "  'divulga',\n",
              "  '#fakenews',\n",
              "  '#pandemia',\n",
              "  '#covid',\n",
              "  'üò∑',\n",
              "  'regras',\n",
              "  'par‚Ä¶'],\n",
              " ['luz', 'fim', 't√∫nel!?', '#covid', '#covid19brasil', '#covid„Éº19'],\n",
              " ['nada',\n",
              "  'novo',\n",
              "  'terra',\n",
              "  'kimchi',\n",
              "  'üò†',\n",
              "  '#vidanacoreia',\n",
              "  '#coronavirus',\n",
              "  '#covid',\n",
              "  '#coreiadosul'],\n",
              " ['tudo',\n",
              "  'respiradores',\n",
              "  'virem',\n",
              "  'super',\n",
              "  'faturados',\n",
              "  'vergonha!',\n",
              "  '#quarentena',\n",
              "  '#covid',\n",
              "  'debate,',\n",
              "  'governadores',\n",
              "  'p‚Ä¶'],\n",
              " ['#pandemia',\n",
              "  'leva',\n",
              "  '#startups',\n",
              "  'desenvolverem',\n",
              "  'produtos',\n",
              "  'contra',\n",
              "  'covid19',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid'],\n",
              " ['assento',\n",
              "  'preferencial',\n",
              "  'destinado',\n",
              "  'pessoas',\n",
              "  'idosas,',\n",
              "  'gestantes,',\n",
              "  'deficientes',\n",
              "  'pessoas',\n",
              "  'cabe√ßa',\n",
              "  'cachorro‚Ä¶'],\n",
              " ['3',\n",
              "  'di√°rio',\n",
              "  'quarentena',\n",
              "  'vantagem',\n",
              "  'ficar',\n",
              "  'tarde',\n",
              "  'saber',\n",
              "  'tretas',\n",
              "  'pol√≠ticas',\n",
              "  'madruga',\n",
              "  'desvantagem',\n",
              "  'n√£o‚Ä¶'],\n",
              " ['2',\n",
              "  'di√°rio',\n",
              "  'quarentena',\n",
              "  'uso',\n",
              "  'madrugadas',\n",
              "  'estudar,',\n",
              "  'rotina',\n",
              "  'torna',\n",
              "  'rotina',\n",
              "  'pra',\n",
              "  'muitos',\n",
              "  'n√£o‚Ä¶'],\n",
              " ['#covid19', 'india'],\n",
              " ['ai',\n",
              "  '@jairbolsonaro,',\n",
              "  'agr',\n",
              "  'falta',\n",
              "  'vc',\n",
              "  'recusa',\n",
              "  'hist√≥rico',\n",
              "  'atleta',\n",
              "  'cria',\n",
              "  'cura',\n",
              "  'casa',\n",
              "  'hist√≥rico',\n",
              "  'repr‚Ä¶'],\n",
              " ['ny',\n",
              "  'times',\n",
              "  'rememora',\n",
              "  'feitos',\n",
              "  'medicina',\n",
              "  'ci√™ncia,',\n",
              "  'hiv',\n",
              "  'zika',\n",
              "  'v√≠rus,',\n",
              "  'salienta',\n",
              "  'quanto',\n",
              "  'incompat‚Ä¶'],\n",
              " ['mour√£o',\n",
              "  'entra',\n",
              "  'isolamento',\n",
              "  'ap√≥s',\n",
              "  'contato',\n",
              "  'servidor',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid',\n",
              "  '#not√≠cias'],\n",
              " ['pandemia', 'desinforma√ß√£o', '#qanon', '#qanonbr', '#covid'],\n",
              " ['flex√£o',\n",
              "  'madrugada',\n",
              "  'quis',\n",
              "  'fiz',\n",
              "  'decidi',\n",
              "  'realizei',\n",
              "  'desejei',\n",
              "  'nunca',\n",
              "  'desisti',\n",
              "  'conquistei',\n",
              "  'agradeci‚Ä¶'],\n",
              " ['#angola',\n",
              "  'comunidade',\n",
              "  'cient√≠fica',\n",
              "  'consegue',\n",
              "  '#explicar',\n",
              "  'porqu√™',\n",
              "  'agora',\n",
              "  'ainda',\n",
              "  'nenhum',\n",
              "  'paciente',\n",
              "  'de‚Ä¶'],\n",
              " ['not√≠cias',\n",
              "  'corona',\n",
              "  'manaus',\n",
              "  'enchem',\n",
              "  'esperan√ßa',\n",
              "  'leitos',\n",
              "  'vazios',\n",
              "  'v√°rios',\n",
              "  'hospitais,',\n",
              "  'n√∫mero',\n",
              "  'enterro‚Ä¶'],\n",
              " ['precious!',\n",
              "  'üò¢',\n",
              "  '@potus',\n",
              "  '@vp',\n",
              "  '@whitehouse',\n",
              "  '@tuckercarlson',\n",
              "  '@seanhannity',\n",
              "  '@judgejeanine',\n",
              "  '@dbongino',\n",
              "  '@jessebwatters‚Ä¶'],\n",
              " ['üöÄ',\n",
              "  'facilite',\n",
              "  'vendas!',\n",
              "  '#fiqueemcasa',\n",
              "  'receba',\n",
              "  'pedidos',\n",
              "  'web!',\n",
              "  'üì±',\n",
              "  'conhe√ßa',\n",
              "  'agora',\n",
              "  'feira',\n",
              "  'hippie',\n",
              "  'online!!!',\n",
              "  '‚Ä¶'],\n",
              " ['üöÄ',\n",
              "  'facilite',\n",
              "  'vendas!',\n",
              "  '#fiqueemcasa',\n",
              "  'receba',\n",
              "  'pedidos',\n",
              "  'web!',\n",
              "  'üì±',\n",
              "  'conhe√ßa',\n",
              "  'agora',\n",
              "  'feira',\n",
              "  'hippie',\n",
              "  'online!!!',\n",
              "  '‚Ä¶'],\n",
              " ['üöÄ',\n",
              "  'facilite',\n",
              "  'vendas!',\n",
              "  '#fiqueemcasa',\n",
              "  'receba',\n",
              "  'pedidos',\n",
              "  'web!',\n",
              "  'üì±',\n",
              "  'conhe√ßa',\n",
              "  'agora',\n",
              "  'feira',\n",
              "  'hippie',\n",
              "  'online!!!',\n",
              "  '‚Ä¶'],\n",
              " ['üöÄ',\n",
              "  'facilite',\n",
              "  'vendas!',\n",
              "  '#fiqueemcasa',\n",
              "  'receba',\n",
              "  'pedidos',\n",
              "  'web!',\n",
              "  'üì±',\n",
              "  'conhe√ßa',\n",
              "  'agora',\n",
              "  'feira',\n",
              "  'hippie',\n",
              "  'online!!!',\n",
              "  '‚Ä¶'],\n",
              " ['üöÄ',\n",
              "  'facilite',\n",
              "  'vendas!',\n",
              "  '#fiqueemcasa',\n",
              "  'receba',\n",
              "  'pedidos',\n",
              "  'web!',\n",
              "  'üì±',\n",
              "  'conhe√ßa',\n",
              "  'agora',\n",
              "  'feira',\n",
              "  'hippie',\n",
              "  'online!!!',\n",
              "  '‚Ä¶'],\n",
              " ['@gabznscmnt',\n",
              "  'dormir',\n",
              "  'direito',\n",
              "  'hora',\n",
              "  'certa',\n",
              "  'mant√©m',\n",
              "  'imunidade',\n",
              "  'alta',\n",
              "  '#covid'],\n",
              " ['vicepresidente',\n",
              "  'brasil',\n",
              "  'entra',\n",
              "  'isolamento',\n",
              "  'ap√≥s',\n",
              "  'contato',\n",
              "  'servidor',\n",
              "  'coronav√≠rus',\n",
              "  '#brasil',\n",
              "  '#mour√£o‚Ä¶'],\n",
              " ['laborat√≥rio',\n",
              "  'americano',\n",
              "  '#sorrento',\n",
              "  'afirma',\n",
              "  'ter',\n",
              "  'rem√©dio',\n",
              "  '100%',\n",
              "  'eficaz',\n",
              "  'contra',\n",
              "  '#covid19',\n",
              "  'clique',\n",
              "  'ver‚òõ'],\n",
              " ['federa√ß√£o',\n",
              "  'nata√ß√£o',\n",
              "  'solid√°ria',\n",
              "  'movimento',\n",
              "  '‚Äòn√£o',\n",
              "  'deixes',\n",
              "  'portugal',\n",
              "  'afogar‚Äô',\n",
              "  '#covid19',\n",
              "  '#dianadur√£es',\n",
              "  '#jos√©lopes'],\n",
              " ['ortopedista',\n",
              "  'conhecido',\n",
              "  'tubo',\n",
              "  'devido',\n",
              "  '#covid',\n",
              "  'vamos',\n",
              "  'torcer',\n",
              "  'recupere',\n",
              "  'assim',\n",
              "  'outros',\n",
              "  'recuperaram'],\n",
              " ['lives', 'tamo', 'como?!', '#ocorvojubileu', '#covid', '#quarentena'],\n",
              " ['segundo',\n",
              "  '#beneditodaniel',\n",
              "  '#covid19',\n",
              "  'trouxe',\n",
              "  'grandes',\n",
              "  'preju√≠zos',\n",
              "  'li√ß√µes',\n",
              "  'cada',\n",
              "  'pa√≠s',\n",
              "  'crie',\n",
              "  'solu√ß√µes‚Ä¶'],\n",
              " ['\"nenhun',\n",
              "  'pres',\n",
              "  'maior',\n",
              "  'minist√©rio(',\n",
              "  '\"nomea√ß√µes',\n",
              "  't√©cnicas\"',\n",
              "  '#jornalismo',\n",
              "  '#marketing',\n",
              "  'sa√∫de',\n",
              "  'triste',\n",
              "  'al‚Ä¶'],\n",
              " ['üöÄ',\n",
              "  'facilite',\n",
              "  'vendas!',\n",
              "  '#fiqueemcasa',\n",
              "  'receba',\n",
              "  'pedidos',\n",
              "  'web!',\n",
              "  'üì±',\n",
              "  'conhe√ßa',\n",
              "  'agora',\n",
              "  'feira',\n",
              "  'hippie',\n",
              "  'online!!!',\n",
              "  '‚Ä¶'],\n",
              " ['acredito',\n",
              "  'pessoas',\n",
              "  'escutassem',\n",
              "  'poetas',\n",
              "  'topo',\n",
              "  '33',\n",
              "  '(pt',\n",
              "  'mv',\n",
              "  'bill',\n",
              "  'iam',\n",
              "  'parar',\n",
              "  'matar',\n",
              "  'iriam',\n",
              "  'ver',\n",
              "  'n‚Ä¶'],\n",
              " ['sair',\n",
              "  'vacina',\n",
              "  'dezembro',\n",
              "  '(7',\n",
              "  'meses,',\n",
              "  'toma?',\n",
              "  '#coronavirus',\n",
              "  '#covid„Éº19',\n",
              "  '#covid'],\n",
              " ['covarde,',\n",
              "  'assassino,',\n",
              "  'criminoso',\n",
              "  '#impeachmentbolsonaro',\n",
              "  '#covid_19',\n",
              "  '#quarentena',\n",
              "  '#lockdown',\n",
              "  '#conversaafiada',\n",
              "  '#covid‚Ä¶'],\n",
              " ['ainda',\n",
              "  'bem',\n",
              "  '@uolnoticias',\n",
              "  'cometeu',\n",
              "  'erro',\n",
              "  'digita√ß√£o',\n",
              "  'referente',\n",
              "  'mortes',\n",
              "  '#covid',\n",
              "  '#coronavirus'],\n",
              " ['fa√ßa',\n",
              "  'exerc√≠cio',\n",
              "  '‚Äúvergonha',\n",
              "  'alheia‚Äù',\n",
              "  'comigo',\n",
              "  'neste',\n",
              "  'momento',\n",
              "  'c√≠rculo',\n",
              "  'd',\n",
              "  'conviv√™ncia',\n",
              "  'estaria',\n",
              "  'neste',\n",
              "  'ce‚Ä¶'],\n",
              " ['esperando',\n",
              "  'filhinhos',\n",
              "  'vai',\n",
              "  'pegar',\n",
              "  'covid',\n",
              "  'logo,',\n",
              "  'pra',\n",
              "  'imunizar',\n",
              "  'dar',\n",
              "  'historia',\n",
              "  'supera√ß√£o',\n",
              "  'papai‚Ä¶'],\n",
              " ['16/5',\n",
              "  '#covid',\n",
              "  '#paran√°',\n",
              "  '(3/3',\n",
              "  '#fiqueemcasa',\n",
              "  '691(356',\n",
              "  'investig',\n",
              "  '1477',\n",
              "  'recuperados',\n",
              "  '20813(+1017',\n",
              "  'exames',\n",
              "  '18539(+1266‚Ä¶'],\n",
              " ['andrea',\n",
              "  'entra',\n",
              "  'brincar',\n",
              "  'comigo',\n",
              "  'diz',\n",
              "  'respeitando',\n",
              "  'm√°ximo',\n",
              "  'isolamento',\n",
              "  '#covid,',\n",
              "  'est√°‚Ä¶'],\n",
              " ['#bolsonaro',\n",
              "  '#quarentena',\n",
              "  '#brasil',\n",
              "  '#coronavirus',\n",
              "  '#coronavirusbrasil',\n",
              "  '#covid_19',\n",
              "  '#covid',\n",
              "  'bolsonaro‚Ä¶'],\n",
              " ['#covid',\n",
              "  '#brasil',\n",
              "  '\\U0001f9a0',\n",
              "  's√°bado,',\n",
              "  '16',\n",
              "  'maio',\n",
              "  '‚ñ∂Ô∏è',\n",
              "  '233142',\n",
              "  '#casos',\n",
              "  '‚ñ∂Ô∏è',\n",
              "  '15633',\n",
              "  '√≥bitos',\n",
              "  '#rn',\n",
              "  '‚è∫',\n",
              "  '3004',\n",
              "  'cas‚Ä¶'],\n",
              " ['sentimentos',\n",
              "  'familiares',\n",
              "  'mortossem',\n",
              "  'respeito',\n",
              "  'dorsem',\n",
              "  'medir',\n",
              "  'consequencias',\n",
              "  'atos',\n",
              "  'tudo',\n",
              "  'pe‚Ä¶'],\n",
              " ['\"o',\n",
              "  'modelo',\n",
              "  'simula√ß√£o',\n",
              "  'neil',\n",
              "  'ferguson',\n",
              "  '(imperial',\n",
              "  'college',\n",
              "  'pode',\n",
              "  'ser',\n",
              "  'considerado',\n",
              "  'devastante',\n",
              "  \"'erro'\",\n",
              "  'softwar‚Ä¶'],\n",
              " ['pastor',\n",
              "  'clovis',\n",
              "  'entra',\n",
              "  'live,',\n",
              "  'diz',\n",
              "  'favor',\n",
              "  'isolamento',\n",
              "  'total',\n",
              "  'contra',\n",
              "  '#covid',\n",
              "  '\"temos',\n",
              "  'muita',\n",
              "  'vid‚Ä¶'],\n",
              " ['\"se',\n",
              "  'n√∫meros',\n",
              "  'frios',\n",
              "  'tocam',\n",
              "  'gente,',\n",
              "  'espero',\n",
              "  'nomes',\n",
              "  'consigam',\n",
              "  'tocar\"',\n",
              "  'homenagem',\n",
              "  'dr',\n",
              "  '@chicocesarof',\n",
              "  'v√≠timas',\n",
              "  'do‚Ä¶'],\n",
              " ['passamos',\n",
              "  'marca',\n",
              "  '15',\n",
              "  'mil',\n",
              "  '√≥bitos,',\n",
              "  'ocasionados',\n",
              "  'gripezinha',\n",
              "  'ent√£o,',\n",
              "  '10',\n",
              "  'mil',\n",
              "  '#bolsonaro',\n",
              "  'andar',\n",
              "  'j‚Ä¶'],\n",
              " ['geral', 'fazendo', 'agora', '#covid'],\n",
              " ['hoje', 'sufocando', 'mercado', 'pois', 'm√°scara', '#covid', 'saia'],\n",
              " ['partido',\n",
              "  'comunista',\n",
              "  'china',\n",
              "  'iniciou',\n",
              "  'guerra',\n",
              "  'biol√≥gica,',\n",
              "  'devastando',\n",
              "  'todo',\n",
              "  'ocidente',\n",
              "  'choramos',\n",
              "  'mortos,',\n",
              "  'mas‚Ä¶'],\n",
              " ['triste', 'tomar', '#heineken', 'sentir', 'sabor', 'üòï', '#dia27', '#covid'],\n",
              " ['#tbt',\n",
              "  'nada,',\n",
              "  'vou',\n",
              "  'lan√ßar',\n",
              "  'hastag',\n",
              "  '#tudoantesdacovid',\n",
              "  'casamento',\n",
              "  'maravilhoso',\n",
              "  'amigos',\n",
              "  'inf√¢ncia',\n",
              "  '#casamento‚Ä¶'],\n",
              " ['$600',\n",
              "  '20',\n",
              "  'passos',\n",
              "  '#sobreviver',\n",
              "  '#auxilioemerg√™ncia',\n",
              "  'via',\n",
              "  '@youtube',\n",
              "  '#pandemia',\n",
              "  '#covid‚Ä¶'],\n",
              " ['supermercados',\n",
              "  'wuhan',\n",
              "  '2¬™',\n",
              "  'quinzena',\n",
              "  'janeiro,',\n",
              "  'antes',\n",
              "  '#lockdown',\n",
              "  '#covid',\n",
              "  '#covid19',\n",
              "  '#virus'],\n",
              " ['hospital',\n",
              "  'leonardo',\n",
              "  'vinci',\n",
              "  'emocionante!',\n",
              "  '17',\n",
              "  'altas',\n",
              "  '√∫nica',\n",
              "  'enfermaria',\n",
              "  '32',\n",
              "  'leitos',\n",
              "  'dia',\n",
              "  's√≥!',\n",
              "  'atende',\n",
              "  'covid1‚Ä¶'],\n",
              " ['m√°scara',\n",
              "  'esconde',\n",
              "  'boa',\n",
              "  'parte',\n",
              "  'rosto',\n",
              "  'e,',\n",
              "  'todo',\n",
              "  'contato',\n",
              "  'express√µes,',\n",
              "  'agora',\n",
              "  'buscam',\n",
              "  'olhos',\n",
              "  'deveria',\n",
              "  'ser',\n",
              "  'sempre',\n",
              "  'assim,‚Ä¶'],\n",
              " ['@correio',\n",
              "  'amanh√£',\n",
              "  'bras√≠lia',\n",
              "  ',',\n",
              "  'cegueira',\n",
              "  'providencial',\n",
              "  'gov',\n",
              "  'df',\n",
              "  ',',\n",
              "  'mundo',\n",
              "  'vai',\n",
              "  'presenciar',\n",
              "  'ataque',\n",
              "  's‚Ä¶'],\n",
              " ['supondo',\n",
              "  '#benzetacil',\n",
              "  'eficaz',\n",
              "  'contra',\n",
              "  '#covid19,',\n",
              "  'vc',\n",
              "  'al√©rgico,',\n",
              "  'vc',\n",
              "  'faria?',\n",
              "  'iria',\n",
              "  'preferir',\n",
              "  'ficar',\n",
              "  'cas‚Ä¶'],\n",
              " ['artigo',\n",
              "  '|',\n",
              "  'ex√©rcito',\n",
              "  'eua',\n",
              "  'pode',\n",
              "  'ter',\n",
              "  'levado',\n",
              "  'v√≠rus',\n",
              "  'china,',\n",
              "  'pepe',\n",
              "  'escobar'],\n",
              " ['aguento', 'tal', 'covid', '#covid', 'odeio', 'abomino'],\n",
              " ['@blogdonoblat', 'desempenho,', 'p√¥?!!', 't√°', 'tchum', 'pro', '#covid'],\n",
              " ['desculpa',\n",
              "  '@cinthiacribeiro,',\n",
              "  '2',\n",
              "  'meses',\n",
              "  'sair',\n",
              "  'casa',\n",
              "  'vou',\n",
              "  'beber',\n",
              "  'sim!',\n",
              "  '#covid',\n",
              "  '#voubeber',\n",
              "  '#lei‚Ä¶'],\n",
              " ['algu√©m',\n",
              "  'sabe',\n",
              "  'dizer',\n",
              "  'informa√ß√£o',\n",
              "  'ver√≠dica?',\n",
              "  'diz',\n",
              "  'sim',\n",
              "  '#covid'],\n",
              " ['dif√≠cil',\n",
              "  'entender',\n",
              "  'proibi√ß√£o',\n",
              "  'caminhar',\n",
              "  'praias,',\n",
              "  'apesar',\n",
              "  'ser',\n",
              "  'permitido',\n",
              "  'ruas',\n",
              "  'falo',\n",
              "  'simplesmente',\n",
              "  'ca‚Ä¶'],\n",
              " ['v√£o',\n",
              "  'morrer',\n",
              "  '10',\n",
              "  'mil',\n",
              "  'pessoas',\n",
              "  'pr√≥ximos',\n",
              "  '710',\n",
              "  'dias?',\n",
              "  'poss√≠vel',\n",
              "  '233142',\n",
              "  'total',\n",
              "  'infectados',\n",
              "  '89672',\n",
              "  'cu‚Ä¶'],\n",
              " ['tempos', 'negros', 'l√°', 'brasil', '#covid', '#coronavirus'],\n",
              " ['@alexandrebrss',\n",
              "  '@jrguzzofatos',\n",
              "  'ilustra√ß√£o',\n",
              "  'demonstra',\n",
              "  'bem',\n",
              "  'confinamento',\n",
              "  'for√ßado',\n",
              "  'fazendo',\n",
              "  'ca‚Ä¶'],\n",
              " ['premier',\n",
              "  'belga',\n",
              "  'sophie',\n",
              "  'wilm√®s',\n",
              "  'visitou',\n",
              "  'hoje,',\n",
              "  '1¬™',\n",
              "  'vez,',\n",
              "  'desde',\n",
              "  'in√≠cio',\n",
              "  'pandemia,',\n",
              "  'v√°rios',\n",
              "  'hospitais',\n",
              "  'bruxelas‚Ä¶'],\n",
              " ['com√©rcio',\n",
              "  'pior',\n",
              "  'queda',\n",
              "  'mar√ßo',\n",
              "  '17',\n",
              "  'anos',\n",
              "  'veja',\n",
              "  'setores',\n",
              "  'afetados',\n",
              "  '#covid'],\n",
              " ['#covid19',\n",
              "  'governo',\n",
              "  'pretende',\n",
              "  'usar',\n",
              "  'experi√™ncia',\n",
              "  'pi',\n",
              "  'mudar',\n",
              "  'protocolo',\n",
              "  'sobre',\n",
              "  'cloroquina',\n",
              "  'via',\n",
              "  '@revistaoeste'],\n",
              " ['queria',\n",
              "  'compartilhar',\n",
              "  'iniciativa',\n",
              "  '@avischiffmann,',\n",
              "  'adolescente',\n",
              "  'recusa',\n",
              "  'ofertas',\n",
              "  'milion√°rias',\n",
              "  'pra',\n",
              "  'pod‚Ä¶'],\n",
              " ['arbitr√°rio',\n",
              "  'inconstitucional',\n",
              "  'ataque',\n",
              "  'liberdades',\n",
              "  'direitos',\n",
              "  'individuais',\n",
              "  'fundamentais',\n",
              "  'lei',\n",
              "  'seca',\n",
              "  'tocanti‚Ä¶'],\n",
              " ['acabamos',\n",
              "  'atualizar',\n",
              "  'dados',\n",
              "  '#siglitoral',\n",
              "  'ufrgs',\n",
              "  'conta',\n",
              "  'atualiza√ß√£o',\n",
              "  '@sesrs',\n",
              "  'hor√°rio',\n",
              "  'previst‚Ä¶'],\n",
              " ['#elheraldotv', '|', '#covid19almomento'],\n",
              " ['@gerlingeri',\n",
              "  '@brunafcruz',\n",
              "  '@acioli_s',\n",
              "  '@moura_101',\n",
              "  'entretanto',\n",
              "  'negacionistas',\n",
              "  'cidades',\n",
              "  'brasil',\n",
              "  '#covid‚Ä¶'],\n",
              " ['respeito',\n",
              "  'respeita!',\n",
              "  '#bolsonarorainhalouca',\n",
              "  '#bolsonaroassassino',\n",
              "  '#bolsonaroficaquieto',\n",
              "  '#bolsonaro‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'prefeitura',\n",
              "  'alc√¢ntara',\n",
              "  'compra',\n",
              "  'testes',\n",
              "  'r√°pidos',\n",
              "  'rem√©dios',\n",
              "  'combate',\n",
              "  'covid19'],\n",
              " ['justi√ßa',\n",
              "  'federal',\n",
              "  'autoriza',\n",
              "  '#reabertura',\n",
              "  'gradual',\n",
              "  '#lojas',\n",
              "  'bras√≠lia',\n",
              "  '#com√©rcio',\n",
              "  '#covid'],\n",
              " ['desse',\n",
              "  'modelo',\n",
              "  'marque',\n",
              "  'vizinho',\n",
              "  'curioso',\n",
              "  'üòÇüòÇüòÇ',\n",
              "  'vizinhos',\n",
              "  'curiosos',\n",
              "  'üòÇüòÇüòÇüòÇ',\n",
              "  '@bitapaulin',\n",
              "  '#covid‚Ä¶'],\n",
              " ['entretanto', 'negacionistas', 'brasil', '#covid', '#coronavirus'],\n",
              " ['matos',\n",
              "  'collado',\n",
              "  'acabam',\n",
              "  'publicar',\n",
              "  'espanha',\n",
              "  'livro',\n",
              "  'el',\n",
              "  'virus',\n",
              "  'filosof√≠a',\n",
              "  'la',\n",
              "  'filosof√≠a',\n",
              "  'virus',\n",
              "  '‚Äì',\n",
              "  'reflexione‚Ä¶'],\n",
              " ['aplausos',\n",
              "  'pros',\n",
              "  'profissionais',\n",
              "  'sa√∫de',\n",
              "  'üëèüèºüëèüèºüëèüèº',\n",
              "  '12h',\n",
              "  'luva',\n",
              "  'm√°scara',\n",
              "  'engata',\n",
              "  'ziper,',\n",
              "  'd√≥i',\n",
              "  'cabe√ßa,',\n",
              "  'or‚Ä¶'],\n",
              " ['militares',\n",
              "  'gnr',\n",
              "  'guimar√£es',\n",
              "  'doaram',\n",
              "  'alimentos',\n",
              "  'carenciados',\n",
              "  '#covid19',\n",
              "  '#gnr',\n",
              "  '#guimar√£es'],\n",
              " ['204', 'casos', 'confirmados', '#covid19', '#paragominas', 'clique', 'ver‚òõ'],\n",
              " ['virtude',\n",
              "  '#pandemia,',\n",
              "  '#ufba',\n",
              "  'realizar√°',\n",
              "  'congresso',\n",
              "  'modo',\n",
              "  'virtual',\n",
              "  'aqui,',\n",
              "  'programa√ß√£o',\n",
              "  'participa√ß√£o',\n",
              "  'do‚Ä¶'],\n",
              " ['secretaria',\n",
              "  '@saudegovba',\n",
              "  'colocou',\n",
              "  'opera√ß√£o',\n",
              "  'neste',\n",
              "  's√°bado,',\n",
              "  'sistema',\n",
              "  'integra',\n",
              "  'base',\n",
              "  'dados',\n",
              "  'epidemiol√≥gicos',\n",
              "  'e‚Ä¶'],\n",
              " ['dr',\n",
              "  '@nelioaguiar',\n",
              "  'senhor',\n",
              "  'tomou',\n",
              "  'decis√£o',\n",
              "  'correta',\n",
              "  'jesus',\n",
              "  'tomaria',\n",
              "  'exatamente',\n",
              "  'decis√£o',\n",
              "  'lembra',\n",
              "  'expulsou',\n",
              "  'os‚Ä¶'],\n",
              " ['vamos',\n",
              "  'boicotar',\n",
              "  'respeita',\n",
              "  'vida!!!',\n",
              "  '@luciano_hang',\n",
              "  '@maderobrasil',\n",
              "  '@riachuelo',\n",
              "  '#bolsonarorainhalouca‚Ä¶'],\n",
              " ['#covid',\n",
              "  '#edicao18',\n",
              "  'alertei',\n",
              "  'constantemente',\n",
              "  'achatamento',\n",
              "  'curva,',\n",
              "  'isolamento',\n",
              "  'in√≥cuo,',\n",
              "  'ineficaz‚Ä¶'],\n",
              " ['jornal',\n",
              "  'alem√£o',\n",
              "  'den√∫ncia',\n",
              "  'governo',\n",
              "  'chln√™s',\n",
              "  'via',\n",
              "  '@youtube',\n",
              "  '#coronavirus',\n",
              "  '#viruschines',\n",
              "  '#covid19'],\n",
              " ['metade',\n",
              "  'pessoas',\n",
              "  'atendimento',\n",
              "  'fazendo',\n",
              "  'exames',\n",
              "  'profissionais',\n",
              "  'sa√∫de',\n",
              "  'possivelmente',\n",
              "  'infectados',\n",
              "  '#covid‚Ä¶'],\n",
              " ['quero',\n",
              "  'ver',\n",
              "  'corona',\n",
              "  'pegar',\n",
              "  'povo',\n",
              "  'manifesta√ß√£o',\n",
              "  'vou',\n",
              "  'rir',\n",
              "  'pq',\n",
              "  'to',\n",
              "  'aqui',\n",
              "  '#covid',\n",
              "  't√£o',\n",
              "  'com‚Ä¶'],\n",
              " ['ricos',\n",
              "  'direita',\n",
              "  'radical',\n",
              "  'come√ßaram,',\n",
              "  'repente,',\n",
              "  'interessar',\n",
              "  'pobres',\n",
              "  'antes',\n",
              "  'tudo',\n",
              "  'quest√£o',\n",
              "  'meritocracia',\n",
              "  '#covid'],\n",
              " ['‚ö†Ô∏èalerta‚ö†Ô∏è',\n",
              "  '#medicos',\n",
              "  'sendo',\n",
              "  '#pressionados',\n",
              "  'atestar',\n",
              "  'mortes',\n",
              "  'suspeitas',\n",
              "  '#covid',\n",
              "  'exames',\n",
              "  'üáßüá∑#averdadesemp‚Ä¶'],\n",
              " ['senador',\n",
              "  '@josemaranhaopb',\n",
              "  '(mdbpb,',\n",
              "  'refor√ßa',\n",
              "  'necessidade',\n",
              "  'uni√£o',\n",
              "  'todos',\n",
              "  'sa√∫de',\n",
              "  'p√∫blica',\n",
              "  'possa',\n",
              "  'responde‚Ä¶'],\n",
              " ['academia', 'essencial', 'sa√∫de?', '#academias', '#coronavirus', '#covid19'],\n",
              " ['conhce√ßa',\n",
              "  'sistema',\n",
              "  'simula√ß√£o',\n",
              "  'computacional',\n",
              "  'sobre',\n",
              "  'din√¢mica',\n",
              "  'propaga√ß√£o',\n",
              "  '#covid19'],\n",
              " ['casos',\n",
              "  '#covid',\n",
              "  '#guarulhos',\n",
              "  'chegam',\n",
              "  'a1507,',\n",
              "  '165',\n",
              "  'mortes',\n",
              "  'apesar',\n",
              "  'aumento',\n",
              "  'expressivo',\n",
              "  'casos',\n",
              "  '√∫ltima',\n",
              "  'semana‚Ä¶'],\n",
              " ['pa√≠s',\n",
              "  'ingovern√°vel,',\n",
              "  'corrup√ß√£o!',\n",
              "  'pena',\n",
              "  'popula√ß√£o',\n",
              "  'honesta(vide',\n",
              "  '1contra',\n",
              "  'todos',\n",
              "  '#brasil‚Ä¶'],\n",
              " ['agora',\n",
              "  'ganhou',\n",
              "  'for√ßa',\n",
              "  'protestos,',\n",
              "  'pode',\n",
              "  'comer',\n",
              "  'pilha',\n",
              "  'isqueiro',\n",
              "  '@rafaelilha',\n",
              "  '#bolsonarorainhalouca‚Ä¶'],\n",
              " ['cad√™',\n",
              "  'sal√°rios',\n",
              "  'm√©dicos',\n",
              "  'enfermeiros?',\n",
              "  'cad√™',\n",
              "  'dinheiro',\n",
              "  'respiradores',\n",
              "  'comprados',\n",
              "  'empresas',\n",
              "  'fantasmas?‚Ä¶'],\n",
              " ['santista',\n",
              "  '@brunocovas,',\n",
              "  'aborte',\n",
              "  'rodizio',\n",
              "  'desenvolva',\n",
              "  'outra',\n",
              "  'estrat√©gia',\n",
              "  'muita',\n",
              "  'gente',\n",
              "  'precisa',\n",
              "  'ir',\n",
              "  'trabalhar',\n",
              "  'vai',\n",
              "  'u‚Ä¶'],\n",
              " ['#covid',\n",
              "  'mundo',\n",
              "  'dividido',\n",
              "  'tres',\n",
              "  'partes',\n",
              "  'respeita',\n",
              "  'regras',\n",
              "  'quarentena,',\n",
              "  'usa',\n",
              "  'm√°scara',\n",
              "  'coopera',\n",
              "  'outra',\n",
              "  'n‚Ä¶'],\n",
              " ['#calamidade',\n",
              "  '#estadodecalamidade',\n",
              "  '#lisboa',\n",
              "  '#covid',\n",
              "  '#covid19',\n",
              "  '#coronavirus',\n",
              "  '#streetphotography',\n",
              "  '#portugal',\n",
              "  '#paulocaladophoto‚Ä¶'],\n",
              " ['par√°',\n",
              "  'i',\n",
              "  'sesai',\n",
              "  'cumpre',\n",
              "  'recomenda√ß√£o',\n",
              "  'mpf',\n",
              "  'inclui',\n",
              "  'estat√≠stica',\n",
              "  'casos',\n",
              "  '#covid19',\n",
              "  'ind√≠genas',\n",
              "  'alter',\n",
              "  'c‚Ä¶'],\n",
              " ['üéÆ‚öΩagora',\n",
              "  'fase',\n",
              "  'final‚öΩüéÆ',\n",
              "  'jogo',\n",
              "  'bem',\n",
              "  'chegar√°',\n",
              "  'neste',\n",
              "  'domingo',\n",
              "  'partir',\n",
              "  '11h',\n",
              "  'reta',\n",
              "  'final!',\n",
              "  'jogos',\n",
              "  'se‚Ä¶'],\n",
              " ['(multim√≠dia',\n",
              "  '#china',\n",
              "  'completar√°',\n",
              "  'testes',\n",
              "  'cl√≠nicos',\n",
              "  'segunda',\n",
              "  'fase',\n",
              "  'vacinas',\n",
              "  '#covid19',\n",
              "  'julho,',\n",
              "  'diz',\n",
              "  'funcion√°rio‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'estudo',\n",
              "  'indica',\n",
              "  'n√∫mero',\n",
              "  'casos',\n",
              "  'eua',\n",
              "  'poderia',\n",
              "  'ser',\n",
              "  '35',\n",
              "  'vezes',\n",
              "  'maior',\n",
              "  'isolamento'],\n",
              " ['m√°scara',\n",
              "  'simples',\n",
              "  'fazer',\n",
              "  'qualquer',\n",
              "  'd√∫vida',\n",
              "  'chama',\n",
              "  'direct',\n",
              "  '#mascaradetecido',\n",
              "  '#mascara',\n",
              "  '#tecidodealgodao‚Ä¶'],\n",
              " ['g√°s',\n",
              "  'clandestino',\n",
              "  'vendido',\n",
              "  'acima',\n",
              "  'pre√ßo',\n",
              "  'apreendido',\n",
              "  'opera√ß√£o',\n",
              "  '@proconspoficial',\n",
              "  'dope',\n",
              "  '(departamento',\n",
              "  'ope‚Ä¶'],\n",
              " ['‚òùÔ∏è\"eu',\n",
              "  'quero',\n",
              "  'sair',\n",
              "  'governo',\n",
              "  '#bolsonaro\"',\n",
              "  '#comofaz',\n",
              "  '#bolsonarogenocida',\n",
              "  '#covid„Éº19',\n",
              "  '#covidiots',\n",
              "  '#covid„Éº19',\n",
              "  '#covid‚Ä¶'],\n",
              " ['basta',\n",
              "  'palavra',\n",
              "  'deus',\n",
              "  'tudo',\n",
              "  'volta',\n",
              "  'lugar',\n",
              "  'üéºüôåüèæüéºüôåüèæ',\n",
              "  '#covid',\n",
              "  '#sesaia'],\n",
              " ['#fiquememcasa', '#covid', 'acha', 'morte', 'alheia', 'importa', 'quanto?'],\n",
              " ['√©,', '\"quando', '#covid', 'mata,', 'mata', 'dispara\"'],\n",
              " ['gua√≠ra',\n",
              "  'registra',\n",
              "  'quarto',\n",
              "  'caso',\n",
              "  'covid19',\n",
              "  '|',\n",
              "  '#guairasp',\n",
              "  '#coronavirus',\n",
              "  '#covid',\n",
              "  '#saude'],\n",
              " ['sugest√£o',\n",
              "  'acabarmos',\n",
              "  '#covid',\n",
              "  'todos',\n",
              "  'curados,',\n",
              "  'seja,',\n",
              "  'imunizados,',\n",
              "  'assumir',\n",
              "  'servi√ßos',\n",
              "  'essencia‚Ä¶'],\n",
              " ['dia',\n",
              "  'frio',\n",
              "  'd√°',\n",
              "  'pregui√ßa',\n",
              "  'abrir',\n",
              "  'olho!',\n",
              "  'pra',\n",
              "  'dar',\n",
              "  'animada',\n",
              "  'sugest√£o',\n",
              "  'hj',\n",
              "  \"'\",\n",
              "  \"cara'\",\n",
              "  '2005',\n",
              "  'samuel',\n",
              "  'l‚Ä¶'],\n",
              " ['s√°bado',\n",
              "  'vinho',\n",
              "  'chocolate',\n",
              "  'chuva',\n",
              "  'netflix',\n",
              "  'queria',\n",
              "  'chocolate',\n",
              "  'anda,',\n",
              "  'sorri',\n",
              "  'apertar',\n",
              "  'barr‚Ä¶'],\n",
              " ['n√∫mero',\n",
              "  'casos',\n",
              "  'novos',\n",
              "  'covid19',\n",
              "  'registrados',\n",
              "  'amazonas',\n",
              "  '1285,',\n",
              "  'neste',\n",
              "  's√°bado',\n",
              "  '(16,',\n",
              "  'totalizando',\n",
              "  '19677',\n",
              "  'casos‚Ä¶'],\n",
              " ['crime', '???????', '#covid', '#livedodiney', '#bundesliga', '#coronavirus'],\n",
              " ['bora',\n",
              "  'toma',\n",
              "  '@zenetoecristiano',\n",
              "  'after',\n",
              "  '@ludmilla',\n",
              "  '!',\n",
              "  '#ocorvojubileu',\n",
              "  '#live',\n",
              "  '#covid'],\n",
              " ['parab√©ns',\n",
              "  'comunica√ß√£o',\n",
              "  '@policiacivilrn',\n",
              "  'deixar',\n",
              "  'esquecer',\n",
              "  'tema',\n",
              "  'caro',\n",
              "  'sem‚Ä¶'],\n",
              " ['aqui',\n",
              "  'mogi',\n",
              "  'cruzes',\n",
              "  'igreja',\n",
              "  'funcionando',\n",
              "  'mas,',\n",
              "  'vc',\n",
              "  'quer',\n",
              "  'trabalhar',\n",
              "  'gcm',\n",
              "  'fiscaliza√ß√£o',\n",
              "  'vai',\n",
              "  'multar',\n",
              "  'seu‚Ä¶'],\n",
              " ['esperan√ßoso',\n",
              "  '@drtedros,',\n",
              "  'diretorgeral',\n",
              "  '@who,',\n",
              "  'falou',\n",
              "  'sobre',\n",
              "  'realiza√ß√£o',\n",
              "  'jogos',\n",
              "  'ol√≠mpicos',\n",
              "  '@tokyo2020',\n",
              "  'durante',\n",
              "  'r‚Ä¶'],\n",
              " ['distanciamento',\n",
              "  'social',\n",
              "  'indiscriminado',\n",
              "  'ruim',\n",
              "  'sistema',\n",
              "  'imunol√≥gico!',\n",
              "  'quer',\n",
              "  'entender',\n",
              "  'mais?',\n",
              "  'acesse',\n",
              "  'link',\n",
              "  'abaix‚Ä¶'],\n",
              " ['algu√©m',\n",
              "  'covid',\n",
              "  'pra',\n",
              "  'sair',\n",
              "  '(',\n",
              "  'sigilo',\n",
              "  's/aglomera√ß√£o!',\n",
              "  '#orgulholgbtq',\n",
              "  '#covid',\n",
              "  '#sindicatodosdovulgadores'],\n",
              " ['\\U0001f9a0\\U0001f9a0',\n",
              "  'boletim',\n",
              "  'coronav√≠rus',\n",
              "  '#covid19',\n",
              "  '|',\n",
              "  'confira',\n",
              "  'atualiza√ß√£o',\n",
              "  'boletim',\n",
              "  'municipal',\n",
              "  'deste',\n",
              "  's√°bado',\n",
              "  '(16/05'],\n",
              " ['boletim',\n",
              "  'coronav√≠rus',\n",
              "  '#covid19',\n",
              "  '|',\n",
              "  'confira',\n",
              "  'atualiza√ß√£o',\n",
              "  'boletim',\n",
              "  'municipal',\n",
              "  'deste',\n",
              "  's√°bado',\n",
              "  '(16/05',\n",
              "  'informa√ß√µ‚Ä¶'],\n",
              " ['sa√∫de',\n",
              "  'bem',\n",
              "  'essencial',\n",
              "  'liberdade',\n",
              "  'ando',\n",
              "  'aterrado',\n",
              "  'burocratas',\n",
              "  '#covid',\n",
              "  'haver√°',\n",
              "  'no√ß√£o',\n",
              "  'magnitu‚Ä¶'],\n",
              " ['n√∫mero',\n",
              "  'casos',\n",
              "  'coronav√≠rus',\n",
              "  'eua',\n",
              "  'poderia',\n",
              "  'ser',\n",
              "  '35',\n",
              "  'vezes',\n",
              "  'maior',\n",
              "  'medidas',\n",
              "  'isolamento',\n",
              "  'social',\n",
              "  'governo,',\n",
              "  'diz‚Ä¶'],\n",
              " ['#brasil',\n",
              "  'aproxima',\n",
              "  '15',\n",
              "  'mil',\n",
              "  'mortes',\n",
              "  '#covid19',\n",
              "  'acordo',\n",
              "  'dados,',\n",
              "  '√∫ltimas',\n",
              "  '24‚Ä¶'],\n",
              " ['pegar',\n",
              "  '#covid',\n",
              "  'vai',\n",
              "  'querer',\n",
              "  'tratamento',\n",
              "  '#cloroquina?',\n",
              "  'fico',\n",
              "  'pensando',\n",
              "  'sobremeu',\n",
              "  'pai',\n",
              "  'faz',\n",
              "  'tratamento',\n",
              "  'l√∫‚Ä¶'],\n",
              " ['espantem',\n",
              "  'governo',\n",
              "  'americano',\n",
              "  'descobrir',\n",
              "  'comprar',\n",
              "  'patente',\n",
              "  'vacina',\n",
              "  'contra',\n",
              "  'covid19',\n",
              "  'priorizar',\n",
              "  'a‚Ä¶'],\n",
              " ['ap√≥s',\n",
              "  '9',\n",
              "  'dias',\n",
              "  'uti,',\n",
              "  'enfermeiro',\n",
              "  'volta',\n",
              "  'servi√ßo',\n",
              "  'ajudar',\n",
              "  '#covid',\n",
              "  '#sonoticiaboa‚Ä¶'],\n",
              " ['agora',\n",
              "  'd√°',\n",
              "  'pra',\n",
              "  'recusar',\n",
              "  'lanches',\n",
              "  'desculpa',\n",
              "  'corona',\n",
              "  'algu√©m',\n",
              "  'pedir',\n",
              "  '\"me',\n",
              "  'd√°',\n",
              "  'pedacinho\"?‚Ä¶'],\n",
              " ['olga',\n",
              "  'savary,',\n",
              "  'grande,',\n",
              "  'gigante,',\n",
              "  'partiu',\n",
              "  'ontem',\n",
              "  'v√≠tima',\n",
              "  'desse',\n",
              "  'v√≠rus',\n",
              "  'agressivo',\n",
              "  'sorrateiro',\n",
              "  'obrigada',\n",
              "  'tudo,',\n",
              "  'poeta',\n",
              "  '#fiqueemcasa',\n",
              "  '#covid'],\n",
              " ['#assembrati',\n",
              "  'porta',\n",
              "  \"sant'angelo\",\n",
              "  '#scattano',\n",
              "  '#controlli',\n",
              "  '#sanzioni',\n",
              "  '#umbria',\n",
              "  '#terni',\n",
              "  '#covid‚Ä¶'],\n",
              " ['tal',\n",
              "  'cuidar',\n",
              "  'sa√∫de',\n",
              "  'mental?',\n",
              "  'quartafeira,',\n",
              "  'dia',\n",
              "  '20',\n",
              "  'maio,',\n",
              "  '1900',\n",
              "  'hs',\n",
              "  'inscrevase',\n",
              "  'gratuitamente‚Ä¶'],\n",
              " ['inatividade',\n",
              "  'fun√ß√£o',\n",
              "  'covid19',\n",
              "  'riscos',\n",
              "  'sa√∫de',\n",
              "  '#covid19',\n",
              "  '#covid_19',\n",
              "  '#covid',\n",
              "  '#exercicios',\n",
              "  '#saude',\n",
              "  '#inatividade‚Ä¶'],\n",
              " ['üîät√°',\n",
              "  'sabendo?',\n",
              "  'neste',\n",
              "  'domingo,',\n",
              "  '17/05,',\n",
              "  'live',\n",
              "  '@mateusolano',\n",
              "  'falar',\n",
              "  'sobre',\n",
              "  'a√ß√µes',\n",
              "  'enfrentamento',\n",
              "  'coronav‚Ä¶'],\n",
              " ['pulverizar',\n",
              "  'ruas',\n",
              "  'desinfetante',\n",
              "  'perigoso',\n",
              "  'ineficaz,',\n",
              "  'alerta',\n",
              "  'oms',\n",
              "  '#covid19',\n",
              "  '#oms'],\n",
              " ['podcast',\n",
              "  '\"apokalipson',\n",
              "  '06',\n",
              "  'fim',\n",
              "  'mundo',\n",
              "  'todo',\n",
              "  'dia',\n",
              "  'semana\"',\n",
              "  'by',\n",
              "  'apokalipson',\n",
              "  '‚öì',\n",
              "  '#podcast‚Ä¶'],\n",
              " ['poderia',\n",
              "  'acrescentar',\n",
              "  '250',\n",
              "  'inicativas',\n",
              "  'nessa',\n",
              "  '#thread',\n",
              "  'monitor',\n",
              "  'doa√ß√µes',\n",
              "  '@captacaoabcr',\n",
              "  '(associa√ß√£o',\n",
              "  'brasile‚Ä¶'],\n",
              " ['vez',\n",
              "  'falo',\n",
              "  'pq',\n",
              "  '√±',\n",
              "  'vejo',\n",
              "  'alguns',\n",
              "  'notici√°rios',\n",
              "  '√±',\n",
              "  'dou',\n",
              "  'cr√©dito',\n",
              "  '@redeglobo',\n",
              "  '@folha',\n",
              "  'posto',\n",
              "  'im‚Ä¶'],\n",
              " ['(multim√≠dia',\n",
              "  'igual',\n",
              "  'aten√ß√£o',\n",
              "  'prestada',\n",
              "  'casos',\n",
              "  'assintom√°ticos',\n",
              "  '#covid19,',\n",
              "  'diz',\n",
              "  'funcion√°rio',\n",
              "  'chin√™s‚Ä¶'],\n",
              " ['estar',\n",
              "  'insens√≠vel',\n",
              "  'realidade',\n",
              "  'brasil?',\n",
              "  'calamidade',\n",
              "  'sa√∫de,',\n",
              "  '#covid,',\n",
              "  '#governo',\n",
              "  'irrespons√°vel,',\n",
              "  '15',\n",
              "  'mil',\n",
              "  'am‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'breves',\n",
              "  '(na',\n",
              "  'ilha',\n",
              "  'maraj√≥',\n",
              "  'maior',\n",
              "  'taxa',\n",
              "  'letalidade',\n",
              "  'munic√≠pios',\n",
              "  '+',\n",
              "  '100',\n",
              "  'mil',\n",
              "  'habitantes',\n",
              "  'no‚Ä¶'],\n",
              " ['departamento',\n",
              "  'vigil√¢ncia',\n",
              "  'sanit√°ria',\n",
              "  '(devisa',\n",
              "  'campinas',\n",
              "  'apresentou',\n",
              "  'relat√≥rio',\n",
              "  'mostra',\n",
              "  'popula√ß√£o',\n",
              "  'entr‚Ä¶'],\n",
              " ['estrat√©gias',\n",
              "  'dados',\n",
              "  'an√°lise',\n",
              "  'empresas',\n",
              "  'desmoronaram',\n",
              "  '#covid19',\n",
              "  '#vmware',\n",
              "  '#vmw_carbonblack‚Ä¶'],\n",
              " ['espanha',\n",
              "  'vai',\n",
              "  'prolongar',\n",
              "  'estado',\n",
              "  'emerg√™ncia',\n",
              "  'm√™s',\n",
              "  '#covid19',\n",
              "  '#espanha'],\n",
              " ['v√≠deo',\n",
              "  'novo',\n",
              "  'daniel',\n",
              "  'chamado',\n",
              "  'nova',\n",
              "  'reencarna√ß√£o,',\n",
              "  'fica',\n",
              "  'apreensivo',\n",
              "  'retornar',\n",
              "  'l‚Ä¶'],\n",
              " ['trump',\n",
              "  'diz',\n",
              "  'estar',\n",
              "  'avaliar',\n",
              "  'retomar',\n",
              "  'parcialmente',\n",
              "  'contribui√ß√£o',\n",
              "  'oms',\n",
              "  '#covid19',\n",
              "  '#donaldtrump',\n",
              "  '#oms'],\n",
              " ['covid19',\n",
              "  'it√°lia',\n",
              "  '153',\n",
              "  'novas',\n",
              "  'mortes',\n",
              "  '24',\n",
              "  'horas,',\n",
              "  '31763',\n",
              "  'total',\n",
              "  '#covid19',\n",
              "  '#it√°lia'],\n",
              " ['pandemia',\n",
              "  'oportunidade',\n",
              "  'repensar',\n",
              "  'atletismo',\n",
              "  '#atletismo',\n",
              "  '#covid19'],\n",
              " ['tornar',\n",
              "  't√≥quio2020',\n",
              "  'evento',\n",
              "  'global',\n",
              "  'seguro',\n",
              "  '‚Äún√£o',\n",
              "  'f√°cil‚Äù',\n",
              "  '#covid19',\n",
              "  '#t√≥quio'],\n",
              " ['uefa',\n",
              "  'diz',\n",
              "  'entrada',\n",
              "  'competi√ß√µes',\n",
              "  'continua',\n",
              "  'ser',\n",
              "  '‚Äòranking‚Äô',\n",
              "  '#covid19',\n",
              "  '#futebol',\n",
              "  '#uefa'],\n",
              " ['fc',\n",
              "  'porto',\n",
              "  'volta',\n",
              "  'pisar',\n",
              "  'relvado',\n",
              "  'drag√£o,',\n",
              "  'dois',\n",
              "  'meses',\n",
              "  '#covid19',\n",
              "  '#fcporto',\n",
              "  '#futebol'],\n",
              " ['liga',\n",
              "  'vai',\n",
              "  'limitar',\n",
              "  'acesso',\n",
              "  'est√°dio',\n",
              "  '185',\n",
              "  'pessoas',\n",
              "  'dias',\n",
              "  'jogo',\n",
              "  '#covid19',\n",
              "  '#futebol',\n",
              "  '#iliga'],\n",
              " ['covid19',\n",
              "  'jogadores',\n",
              "  '‚Äòstaff‚Äô',\n",
              "  'devem',\n",
              "  'manter',\n",
              "  'isolamento',\n",
              "  'social',\n",
              "  'retoma',\n",
              "  'competi√ß√µes',\n",
              "  '#covid19',\n",
              "  '#futebol'],\n",
              " ['futebolistas,',\n",
              "  'treinadores',\n",
              "  'staff',\n",
              "  'sporting',\n",
              "  'testes',\n",
              "  '‚Äúnegativos‚Äù',\n",
              "  '#covid19',\n",
              "  '#futebol',\n",
              "  '#iliga'],\n",
              " ['grupos',\n",
              "  'ajuda',\n",
              "  'alimentar',\n",
              "  'profissionais',\n",
              "  'cultura',\n",
              "  '#covid19',\n",
              "  '#cultura'],\n",
              " ['supreso?',\n",
              "  'talvez',\n",
              "  'boa',\n",
              "  'ler',\n",
              "  'not√≠cias',\n",
              "  '#covid',\n",
              "  '#madero',\n",
              "  'dono',\n",
              "  'madero',\n",
              "  'diz',\n",
              "  'estar',\n",
              "  'surpreso',\n",
              "  '‚Äúsumi√ßo‚Äù',\n",
              "  'cl‚Ä¶'],\n",
              " ['diminui√ß√£o',\n",
              "  'voos,',\n",
              "  'causa',\n",
              "  '#covid19,',\n",
              "  'local',\n",
              "  'enfrenta',\n",
              "  'problemas',\n",
              "  'receber',\n",
              "  'quantidade',\n",
              "  'bambu',\n",
              "  'ne‚Ä¶'],\n",
              " ['melhor',\n",
              "  'unboxing',\n",
              "  '√∫ltimos',\n",
              "  'tempos!',\n",
              "  '#coronavirus',\n",
              "  '#covid19',\n",
              "  '#covidiots',\n",
              "  '#covid‚Ä¶'],\n",
              " ['#solidariedade',\n",
              "  'fundamental',\n",
              "  'tempos',\n",
              "  'pandemia',\n",
              "  '#hoje,',\n",
              "  '@ordem_publica',\n",
              "  'recebeu,',\n",
              "  'riocentro,',\n",
              "  'doa√ß√µes',\n",
              "  'grupo‚Ä¶'],\n",
              " ['@carlosmoises',\n",
              "  'caminhoneiro',\n",
              "  'veio',\n",
              "  'sp',\n",
              "  '#covid',\n",
              "  'nova',\n",
              "  'trento,',\n",
              "  'hoje',\n",
              "  'detectado',\n",
              "  'cad√™',\n",
              "  'controle',\n",
              "  'e‚Ä¶'],\n",
              " ['dgs',\n",
              "  'garante',\n",
              "  'pa√≠s',\n",
              "  '‚Äúmuito',\n",
              "  'atento‚Äù',\n",
              "  'doen√ßa',\n",
              "  'kawasaki',\n",
              "  '#covid19',\n",
              "  '#dgs',\n",
              "  '#gra√ßafreitas'],\n",
              " ['#espanha',\n",
              "  'registra',\n",
              "  'menor',\n",
              "  'n√∫mero',\n",
              "  'mortes',\n",
              "  '#covid19',\n",
              "  'desde',\n",
              "  'mar√ßo',\n",
              "  'via',\n",
              "  '@portalr7'],\n",
              " ['governo',\n",
              "  'prepara',\n",
              "  'financiamento',\n",
              "  'regi√µes',\n",
              "  'alterar',\n",
              "  'lei',\n",
              "  '#covid19',\n",
              "  '#pol√≠tica',\n",
              "  '#ps'],\n",
              " ['trabalhadores',\n",
              "  'lares',\n",
              "  'creches',\n",
              "  'testados',\n",
              "  'pr√≥ximo',\n",
              "  'dias',\n",
              "  '#covid19',\n",
              "  '#creches',\n",
              "  '#dgs'],\n",
              " ['ministra',\n",
              "  'sa√∫de',\n",
              "  'diz',\n",
              "  'indicadores',\n",
              "  '‚Äúmant√™mse',\n",
              "  'encorajadores‚Äù',\n",
              "  '#covid19',\n",
              "  '#martatemido',\n",
              "  '#sa√∫de'],\n",
              " ['retoma',\n",
              "  'social',\n",
              "  'depende',\n",
              "  'pessoas',\n",
              "  '‚Äúsociedade',\n",
              "  'policial‚Äù',\n",
              "  '#covid19',\n",
              "  '#martatemido'],\n",
              " ['costa',\n",
              "  'antev√™',\n",
              "  'campanha',\n",
              "  'presidencial',\n",
              "  'diferente,',\n",
              "  'distanciamento',\n",
              "  'f√≠sico',\n",
              "  '#ant√≥niocosta',\n",
              "  '#covid19',\n",
              "  '#pol√≠tica'],\n",
              " ['quousque',\n",
              "  'tandem',\n",
              "  'abutere,',\n",
              "  'azzolina,',\n",
              "  'patientia',\n",
              "  'nostra?',\n",
              "  '#covid',\n",
              "  '#scuola',\n",
              "  '#azzolina'],\n",
              " ['editorial',\n",
              "  'lancet',\n",
              "  '\"administra√ß√£o',\n",
              "  'obcecada',\n",
              "  'balas',\n",
              "  'prata',\n",
              "  'vacinas,',\n",
              "  'novas',\n",
              "  'drogas,',\n",
              "  'esperan√ßa',\n",
              "  'v‚Ä¶'],\n",
              " ['algu√©m',\n",
              "  'parou',\n",
              "  'pensar',\n",
              "  'todos',\n",
              "  'morremos',\n",
              "  'pagando',\n",
              "  'pecados',\n",
              "  'inferno,',\n",
              "  '#covid',\n",
              "  '+‚Ä¶'],\n",
              " ['@cirogomes',\n",
              "  'pensou',\n",
              "  'vc',\n",
              "  'cai',\n",
              "  'm√£o',\n",
              "  'm√©dico',\n",
              "  'segue',\n",
              "  'risca',\n",
              "  'cegamente',\n",
              "  'bozo',\n",
              "  'fala????????',\n",
              "  't√™m',\n",
              "  'muit‚Ä¶'],\n",
              " ['@lucianohuck',\n",
              "  '#calaabocalucianohuck',\n",
              "  '@lucianohuck',\n",
              "  'comparsas',\n",
              "  'ajudaram',\n",
              "  'desgoverno',\n",
              "  'agora',\n",
              "  'vem',\n",
              "  'essa‚Ä¶'],\n",
              " ['autoridade',\n",
              "  'mar√≠tima',\n",
              "  'vai',\n",
              "  'estar',\n",
              "  'praias',\n",
              "  '‚Äúcom',\n",
              "  'robusto',\n",
              "  'dispositivo‚Äù',\n",
              "  '#covid19',\n",
              "  '#pol√≠ciamar√≠tima',\n",
              "  '#praias'],\n",
              " ['costa',\n",
              "  'pede',\n",
              "  'portugueses',\n",
              "  'regressem',\n",
              "  'rua',\n",
              "  'cautelas',\n",
              "  '#ant√≥niocosta',\n",
              "  '#covid19',\n",
              "  '#emdestaque'],\n",
              " ['concession√°rios',\n",
              "  'praia',\n",
              "  'avisam',\n",
              "  'muitos',\n",
              "  't√™m',\n",
              "  'condi√ß√µes',\n",
              "  'abrir',\n",
              "  '#covid19',\n",
              "  '#emdestaque',\n",
              "  '#praias'],\n",
              " ['regresso',\n",
              "  'creche',\n",
              "  'bom',\n",
              "  'crian√ßas',\n",
              "  'pais,',\n",
              "  'concordam',\n",
              "  'especialistas',\n",
              "  '#covid19',\n",
              "  '#creches',\n",
              "  '#educa√ß√£o'],\n",
              " ['(multim√≠dia',\n",
              "  'hospitais',\n",
              "  'tempor√°rios',\n",
              "  '#wuhan',\n",
              "  'cr√≠ticos',\n",
              "  'indispens√°veis',\n",
              "  'controle',\n",
              "  '#covid19,',\n",
              "  'dizem',\n",
              "  'especial‚Ä¶'],\n",
              " ['restaurantes',\n",
              "  'reabrem',\n",
              "  'segunda',\n",
              "  '‚Äútodas',\n",
              "  'condi√ß√µes‚Äù',\n",
              "  'seguran√ßa',\n",
              "  '#covid19',\n",
              "  '#emdestaque',\n",
              "  '#restaura√ß√£o'],\n",
              " ['faleceu',\n",
              "  'hoje',\n",
              "  'marido',\n",
              "  'amiga',\n",
              "  'üíî',\n",
              "  'gente,',\n",
              "  'conhecia,',\n",
              "  'imposs√≠vel',\n",
              "  'sentir',\n",
              "  'dor',\n",
              "  'dela!',\n",
              "  'deus',\n",
              "  'cuide',\n",
              "  'do‚Ä¶'],\n",
              " ['dia',\n",
              "  'gari',\n",
              "  'comemorado',\n",
              "  '16',\n",
              "  'maio',\n",
              "  'todo',\n",
              "  'brasil',\n",
              "  'parab√©ns',\n",
              "  'profissionais',\n",
              "  'exercem',\n",
              "  'trabalho',\n",
              "  'e‚Ä¶'],\n",
              " ['perdi',\n",
              "  'toda',\n",
              "  'fama',\n",
              "  'mal',\n",
              "  'm√°scara',\n",
              "  '#covid',\n",
              "  '#coronga',\n",
              "  '#profissionaldetiüíª',\n",
              "  '#lordrenf',\n",
              "  'carapicu√≠ba,',\n",
              "  'brazil'],\n",
              " ['efeitos',\n",
              "  'quarentena',\n",
              "  'chu',\n",
              "  'üëèüëèüëèüëèüëèüëè',\n",
              "  '#puzzle',\n",
              "  '#puzzles',\n",
              "  '#quebracabe√ßa',\n",
              "  '#quarentena',\n",
              "  '#quarentine',\n",
              "  '#covid_19',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['deixe',\n",
              "  'procurar',\n",
              "  'cuidado',\n",
              "  '#m√©dico',\n",
              "  'necess√°rio!',\n",
              "  'where',\n",
              "  'are',\n",
              "  'all',\n",
              "  'the',\n",
              "  'patients?',\n",
              "  'addressing‚Ä¶'],\n",
              " ['precisa',\n",
              "  'explicar?',\n",
              "  '#obrasilnaopodeparar',\n",
              "  '#bolsonarotemrazao',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid',\n",
              "  '#quarentena',\n",
              "  '#brasilnomapadafome‚Ä¶'],\n",
              " ['orgulho',\n",
              "  'pequeno',\n",
              "  'povo',\n",
              "  'medo',\n",
              "  'mostrar!',\n",
              "  'orgulho',\n",
              "  'pernambuco',\n",
              "  'rezam',\n",
              "  'carrilha',\n",
              "  'd‚Ä¶'],\n",
              " ['meio',\n",
              "  'passando',\n",
              "  'resta',\n",
              "  'orar',\n",
              "  'cidade',\n",
              "  '#compartilhem',\n",
              "  '#covid19',\n",
              "  '#ora√ß√£o',\n",
              "  '#chave‚Ä¶'],\n",
              " ['verdade',\n",
              "  'precisa',\n",
              "  'ser',\n",
              "  'complicada',\n",
              "  '#fakenewsmedia',\n",
              "  '#bolsonarogenocida',\n",
              "  '#bolsonaro',\n",
              "  '#impeachmentdebolsonarourgente‚Ä¶'],\n",
              " ['bem',\n",
              "  'vindo',\n",
              "  'brazuela!!!',\n",
              "  '#ficaemcasa',\n",
              "  '#elenao',\n",
              "  '#euavisei',\n",
              "  '#bosonada',\n",
              "  '#governo',\n",
              "  '#brasil‚Ä¶'],\n",
              " ['pasara,',\n",
              "  'en',\n",
              "  'guitiriz,',\n",
              "  'pobo,',\n",
              "  'mertes',\n",
              "  'mercores',\n",
              "  'despois',\n",
              "  'eleccions',\n",
              "  'aparece',\n",
              "  'un',\n",
              "  'votante',\n",
              "  'con',\n",
              "  '#covid19?'],\n",
              " ['marca',\n",
              "  'amiga',\n",
              "  'ta',\n",
              "  'doida',\n",
              "  'pra',\n",
              "  'voltar',\n",
              "  'ex!',\n",
              "  '#ocorvojubileu',\n",
              "  '#covid',\n",
              "  '#quarentena'],\n",
              " ['t√£o',\n",
              "  'dif√≠cil',\n",
              "  'entender',\n",
              "  'limita√ß√£o',\n",
              "  'estudo',\n",
              "  'usa',\n",
              "  '6',\n",
              "  'pacientes',\n",
              "  'grupo',\n",
              "  'tratado',\n",
              "  'hidroxicloroquina‚Ä¶'],\n",
              " ['fiz',\n",
              "  'desenho',\n",
              "  'paisagem',\n",
              "  'janela',\n",
              "  'esperan√ßa',\n",
              "  'queria',\n",
              "  'ver',\n",
              "  'janela',\n",
              "  'pandemia',\n",
              "  'n',\n",
              "  'posso',\n",
              "  'ir',\n",
              "  'p‚Ä¶'],\n",
              " ['amplia√ß√£o',\n",
              "  'dr√°stica',\n",
              "  'uso',\n",
              "  'cloroquina',\n",
              "  'flexibiliza√ß√£o',\n",
              "  'imediata',\n",
              "  'quarentena',\n",
              "  'apenas',\n",
              "  'duas',\n",
              "  'posi√ß√µes',\n",
              "  'presid‚Ä¶'],\n",
              " ['algu√©m',\n",
              "  'explica!!!!',\n",
              "  '#bolsonarorainhalouca',\n",
              "  '#bolsonaroassassino',\n",
              "  '#bolsonaroficaquieto',\n",
              "  '#bolsonaro',\n",
              "  '#brasil‚Ä¶'],\n",
              " ['leveza',\n",
              "  'tempos',\n",
              "  '#pandemia!',\n",
              "  'üôèüçÉ',\n",
              "  'epis√≥dio',\n",
              "  'fort√≠ssimo',\n",
              "  '@gduvivier',\n",
              "  '@hbo_brasil‚Ä¶'],\n",
              " ['hackers',\n",
              "  'invadem',\n",
              "  '#hospital',\n",
              "  'encontram',\n",
              "  '#exame',\n",
              "  '#covid19',\n",
              "  '#bolsonaro',\n",
              "  'ser√°,',\n",
              "  'n√©?!',\n",
              "  'via',\n",
              "  '@tec_mundo'],\n",
              " ['falo', 'qu√™???üòÇüòÇüòÇüòÇ', '#covid', '#humor', '#quarentena'],\n",
              " ['@jim_edwards', '@hblodget', 'india', '#covid'],\n",
              " ['cloroquina',\n",
              "  'derruba',\n",
              "  '#covid19,',\n",
              "  'derrubou',\n",
              "  '2',\n",
              "  'ministros',\n",
              "  'tal',\n",
              "  'agora',\n",
              "  'derrubar',\n",
              "  'presidente?'],\n",
              " ['boa',\n",
              "  'tarde',\n",
              "  'aliados!!!',\n",
              "  'daqui',\n",
              "  'pouco',\n",
              "  'live',\n",
              "  'canal',\n",
              "  'youtube',\n",
              "  'vamos',\n",
              "  'falar',\n",
              "  'sobre',\n",
              "  'guerra',\n",
              "  'narrativas,',\n",
              "  'informa‚Ä¶'],\n",
              " ['casos',\n",
              "  '#covid',\n",
              "  '#guarulhos',\n",
              "  'chegam',\n",
              "  '1426,',\n",
              "  '163',\n",
              "  'mortes',\n",
              "  'fontes',\n",
              "  'seade',\n",
              "  'pmg,',\n",
              "  'dados',\n",
              "  'combinados'],\n",
              " ['@drguiga1',\n",
              "  '@alessandrojferreira',\n",
              "  '@mfrancomed',\n",
              "  '@franciscoguedess',\n",
              "  '@danielcmrocha',\n",
              "  '#novidade',\n",
              "  '#agentefazbemparavoc√™‚Ä¶'],\n",
              " ['#hackathon',\n",
              "  'online',\n",
              "  'gratuito,',\n",
              "  'criado',\n",
              "  'desenvolver',\n",
              "  'reunir',\n",
              "  'solu√ß√µes',\n",
              "  'pro‚Ä¶'],\n",
              " ['saiu',\n",
              "  'hoje',\n",
              "  'estudo',\n",
              "  'randomizado',\n",
              "  'controlado,',\n",
              "  'hidroxicloroquina',\n",
              "  'versus',\n",
              "  'n√£ohidroxicloroquina',\n",
              "  'pacientes',\n",
              "  '#covid‚Ä¶'],\n",
              " ['v√≠deo',\n",
              "  'novo',\n",
              "  'canal',\n",
              "  'vem',\n",
              "  'gente',\n",
              "  '#lockdownpe',\n",
              "  '#covid',\n",
              "  '#forabolsonaro'],\n",
              " ['@benozzatiarthur',\n",
              "  'desatualizado,',\n",
              "  'descobri',\n",
              "  'q',\n",
              "  'vc',\n",
              "  'bolsonarista',\n",
              "  '#forabolsonaro',\n",
              "  '#covid'],\n",
              " ['#coronav√≠rus',\n",
              "  '#covid19',\n",
              "  'tratamento',\n",
              "  'r√°pido',\n",
              "  'barato',\n",
              "  'porque',\n",
              "  'proibido',\n",
              "  'falar',\n",
              "  'nele',\n",
              "  'todas',\n",
              "  'm√≠dias?',\n",
              "  'tratamento‚Ä¶'],\n",
              " ['sendo',\n",
              "  'chamados',\n",
              "  '2',\n",
              "  'enfermeiros',\n",
              "  '44',\n",
              "  't√©cnicos',\n",
              "  'enfermagem,',\n",
              "  'atuar,',\n",
              "  'combate',\n",
              "  'novo',\n",
              "  'coronav√≠rus,',\n",
              "  'causado‚Ä¶'],\n",
              " ['precisamos',\n",
              "  'falar',\n",
              "  'sobre',\n",
              "  'equidade',\n",
              "  'carreira',\n",
              "  'acad√™mica',\n",
              "  '√≥timo',\n",
              "  'levantamento',\n",
              "  '@dadosrevista!',\n",
              "  '#sciencejournal',\n",
              "  '#women‚Ä¶'],\n",
              " ['judici√°rio',\n",
              "  'batendo',\n",
              "  'cabe√ßa',\n",
              "  'pandemia',\n",
              "  '#judici√°rio',\n",
              "  '#justi√ßa',\n",
              "  '#advocacia',\n",
              "  '#covid',\n",
              "  '#pandemia‚Ä¶'],\n",
              " ['sabe',\n",
              "  'n√∫mero',\n",
              "  'mortes',\n",
              "  'di√°ria',\n",
              "  'it√°lia',\n",
              "  'chocou?',\n",
              "  'pois',\n",
              "  'alcan√ßamos',\n",
              "  'virou',\n",
              "  'rotina!',\n",
              "  'sabe',\n",
              "  'q‚Ä¶'],\n",
              " ['#cloroquina',\n",
              "  '#covid',\n",
              "  '#covid_19',\n",
              "  '#coronavirusbrazil',\n",
              "  'prefeiturademacae',\n",
              "  'informemacae',\n",
              "  'portalmacaerj',\n",
              "  'maca√©'],\n",
              " ['mundo',\n",
              "  'pos',\n",
              "  '#covid',\n",
              "  'vai',\n",
              "  'ter',\n",
              "  'viabilizar',\n",
              "  'projeto',\n",
              "  'renda',\n",
              "  'basica',\n",
              "  'universal',\n",
              "  'toda',\n",
              "  'sociedade',\n",
              "  'renda',\n",
              "  'trabalho‚Ä¶'],\n",
              " ['live',\n",
              "  'melhor',\n",
              "  'prote√ß√£o',\n",
              "  '#prematuro',\n",
              "  'tempos',\n",
              "  '#covid19?',\n",
              "  '#prematuridade'],\n",
              " ['üáßüá∑',\n",
              "  'total',\n",
              "  'casos',\n",
              "  'brasil',\n",
              "  'casos',\n",
              "  'confirmadoss',\n",
              "  '220,291',\n",
              "  '√≥bitos',\n",
              "  '14,962',\n",
              "  'recupera√ß√µes',\n",
              "  '84,970',\n",
              "  '#covid,#corona,‚Ä¶'],\n",
              " ['crian√ßa',\n",
              "  'fica',\n",
              "  'apavorada',\n",
              "  '#jn',\n",
              "  '#jornalista',\n",
              "  '#jornal',\n",
              "  '#globo',\n",
              "  '#bebe',\n",
              "  '#medo',\n",
              "  '#covid',\n",
              "  '#nenem',\n",
              "  '#globolixo',\n",
              "  '#bolsonaro‚Ä¶'],\n",
              " ['bundesliga',\n",
              "  'serve',\n",
              "  'term√¥metro',\n",
              "  'volta',\n",
              "  'futebol',\n",
              "  'mundo',\n",
              "  'der',\n",
              "  'certo,',\n",
              "  'veremos',\n",
              "  'cada',\n",
              "  'vez',\n",
              "  'campeonatos‚Ä¶'],\n",
              " ['descobriu',\n",
              "  'trai√ß√£o',\n",
              "  'abandonou',\n",
              "  'relacionamento',\n",
              "  'corno',\n",
              "  'sempre',\n",
              "  '√∫ltimo',\n",
              "  'saber',\n",
              "  '#coronavirus‚Ä¶'],\n",
              " ['#covid', 'quase', 'todos', 'bairros', 'goi√¢nia'],\n",
              " ['nova',\n",
              "  'pesquisa',\n",
              "  'toda',\n",
              "  'cidade',\n",
              "  'paulo',\n",
              "  'dar√°',\n",
              "  'quadro',\n",
              "  'ainda',\n",
              "  '+',\n",
              "  'fidedigno',\n",
              "  'situa√ß√£o',\n",
              "  'pesquisas',\n",
              "  'assim',\n",
              "  'fundame‚Ä¶'],\n",
              " ['conhecimento',\n",
              "  'tudo!!!',\n",
              "  '#universidadepublica',\n",
              "  '#universidade',\n",
              "  '#ciencia',\n",
              "  '#covid',\n",
              "  '#covidbrasil'],\n",
              " ['rede',\n",
              "  'supermercados',\n",
              "  'eua',\n",
              "  'abre',\n",
              "  'hor√°rio',\n",
              "  'especial',\n",
              "  'p/',\n",
              "  'profissionais',\n",
              "  'sa√∫de',\n",
              "  'seguran√ßa',\n",
              "  'e,',\n",
              "  'hora',\n",
              "  'pagarem',\n",
              "  'por‚Ä¶'],\n",
              " ['tempo',\n",
              "  'pandemia,',\n",
              "  'prefeitura',\n",
              "  'manaus',\n",
              "  'oferece',\n",
              "  'vagas',\n",
              "  'cursos',\n",
              "  'profissionalizantes',\n",
              "  'online',\n",
              "  '#covid‚Ä¶'],\n",
              " ['todas',\n",
              "  'limitacoes',\n",
              "  'economicas',\n",
              "  'enfrentando',\n",
              "  'bloqueio',\n",
              "  'genocida',\n",
              "  'eua,',\n",
              "  '#cuba',\n",
              "  'continua',\n",
              "  'dando',\n",
              "  'exemplo',\n",
              "  'posi‚Ä¶'],\n",
              " ['novo',\n",
              "  'coronav√≠rus',\n",
              "  'infetou',\n",
              "  '4549100',\n",
              "  'pessoas',\n",
              "  'todo',\n",
              "  'mundo,',\n",
              "  'menos',\n",
              "  '307321',\n",
              "  'quais',\n",
              "  'morreram,',\n",
              "  'segundo',\n",
              "  'um‚Ä¶'],\n",
              " ['sentes',\n",
              "  'falta?!',\n",
              "  '#coronavirus',\n",
              "  '#covid',\n",
              "  '#covid19',\n",
              "  '#covid„Éº19',\n",
              "  '#thoughtoftheday'],\n",
              " ['favor,',\n",
              "  'algu√©m',\n",
              "  'fala',\n",
              "  'onde',\n",
              "  'desliga',\n",
              "  'bolsonaro?',\n",
              "  '#covid',\n",
              "  '#coronavirus'],\n",
              " ['@caixa',\n",
              "  'amor',\n",
              "  'jesus!',\n",
              "  'jeito',\n",
              "  'vez',\n",
              "  'todas',\n",
              "  'desse',\n",
              "  'aplicativo',\n",
              "  'caixa',\n",
              "  'funcionar',\n",
              "  'quase',\n",
              "  'm‚Ä¶'],\n",
              " ['resumo',\n",
              "  'porqu√™',\n",
              "  'tocado',\n",
              "  'certos',\n",
              "  'assuntos',\n",
              "  '#pol√™mica',\n",
              "  '#pandemia',\n",
              "  '#politica',\n",
              "  '#brasil',\n",
              "  '#covid',\n",
              "  '#etc'],\n",
              " ['aproveite',\n",
              "  'distanciamento',\n",
              "  'social,',\n",
              "  'retomar',\n",
              "  'proximidades',\n",
              "  't√≥xicas',\n",
              "  'elimina',\n",
              "  'logo',\n",
              "  'agora',\n",
              "  'desprende',\n",
              "  '#quarentena',\n",
              "  '#covid'],\n",
              " ['cada',\n",
              "  'dia',\n",
              "  'passa',\n",
              "  'percept√≠vel',\n",
              "  'todos',\n",
              "  'palmenses',\n",
              "  'merc√™',\n",
              "  'desorienta√ß√£o',\n",
              "  'falta',\n",
              "  'di√°logo‚Ä¶'],\n",
              " ['astros',\n",
              "  '#covid',\n",
              "  'saturno',\n",
              "  'dando',\n",
              "  'li√ß√£o',\n",
              "  'nunca',\n",
              "  'esquecermos,',\n",
              "  'pobres',\n",
              "  'arrogantes,‚Ä¶'],\n",
              " ['avi√£o',\n",
              "  'cai',\n",
              "  'cear√°',\n",
              "  'deixa',\n",
              "  '4',\n",
              "  'mortos',\n",
              "  'aeronave',\n",
              "  'transportava',\n",
              "  'piau√≠',\n",
              "  'm√©dico',\n",
              "  'covid',\n",
              "  'avi√£o',\n",
              "  'pequeno',\n",
              "  'po‚Ä¶'],\n",
              " ['@teichnelson,',\n",
              "  'conv√≠vio',\n",
              "  'secretarias',\n",
              "  'estado',\n",
              "  'munic√≠pios',\n",
              "  'devia',\n",
              "  'estar',\n",
              "  'insustent√°vel',\n",
              "  'seguissem',\n",
              "  'a√ß√µ‚Ä¶'],\n",
              " ['telesus',\n",
              "  'criado',\n",
              "  'aproximarmos',\n",
              "  'modo',\n",
              "  'combate',\n",
              "  'coronav√≠rus',\n",
              "  'facilita',\n",
              "  'acesso',\n",
              "  'cons‚Ä¶'],\n",
              " ['*para',\n",
              "  'pensarmos',\n",
              "  'seriamente',\n",
              "  'respeito!!!!!*',\n",
              "  '#covid',\n",
              "  '#coronavirus',\n",
              "  '@jairbolsonaro‚Ä¶'],\n",
              " ['brasil',\n",
              "  '@exercitooficial',\n",
              "  'mata',\n",
              "  'pr√≥prio',\n",
              "  'povo',\n",
              "  'governo',\n",
              "  'miliciano',\n",
              "  'apoiado',\n",
              "  '@exercitooficial',\n",
              "  'des‚Ä¶'],\n",
              " ['cabines',\n",
              "  'desinfec√ß√£o,',\n",
              "  'objetivo',\n",
              "  'evitar',\n",
              "  'dissemina√ß√£o',\n",
              "  'novo',\n",
              "  'coronav√≠rus,',\n",
              "  'autorizada',\n",
              "  'pela‚Ä¶'],\n",
              " ['pedro',\n",
              "  's√°nchez',\n",
              "  '\"temos',\n",
              "  'coidar',\n",
              "  'medidas',\n",
              "  'seguridade,',\n",
              "  'follamos',\n",
              "  'dous',\n",
              "  'metros\"',\n",
              "  '#covid'],\n",
              " ['aqui',\n",
              "  'pensar',\n",
              "  'naquele',\n",
              "  'tempo',\n",
              "  'pessoas',\n",
              "  'sopravam',\n",
              "  'velas',\n",
              "  'cima',\n",
              "  'bolo,',\n",
              "  'cantar',\n",
              "  'parab√©ns',\n",
              "  '#covid'],\n",
              " ['gr√°fico',\n",
              "  'mostra',\n",
              "  'tend√™ncia',\n",
              "  'crescente',\n",
              "  'novos',\n",
              "  'casos',\n",
              "  'brasil',\n",
              "  'decrescente',\n",
              "  'demais',\n",
              "  'pa√≠ses',\n",
              "  'europa‚Ä¶'],\n",
              " ['pa√≠s',\n",
              "  '|',\n",
              "  'regulamentar',\n",
              "  'desporto',\n",
              "  'nacional',\n",
              "  'nada,',\n",
              "  'mil√≠metro',\n",
              "  'quadrado,',\n",
              "  'escapa',\n",
              "  'regras',\n",
              "  'para‚Ä¶'],\n",
              " ['@brumelianebrum',\n",
              "  '@jeanwyllys_real',\n",
              "  'prioridade',\n",
              "  'vida',\n",
              "  'morte',\n",
              "  '#covid'],\n",
              " ['teich,',\n",
              "  'reuni√£o',\n",
              "  'ministerial',\n",
              "  'exames',\n",
              "  'bolsonaro',\n",
              "  'assista',\n",
              "  'fatos',\n",
              "  'semana',\n",
              "  '#brasil‚Ä¶'],\n",
              " ['q',\n",
              "  'acontecer',\n",
              "  'pandemia',\n",
              "  'v√≠rus',\n",
              "  'mundial,',\n",
              "  'pra',\n",
              "  'baixar',\n",
              "  'pre√ßo',\n",
              "  'gasolina',\n",
              "  '#quarentena',\n",
              "  '#pandemia',\n",
              "  '#coronavirus‚Ä¶'],\n",
              " ['pedido',\n",
              "  '@mptmg,',\n",
              "  'vt',\n",
              "  'congonhas',\n",
              "  'determina',\n",
              "  'csn',\n",
              "  'minera√ß√£o',\n",
              "  'adote',\n",
              "  'medidas',\n",
              "  'reduzir',\n",
              "  'risco',\n",
              "  'cont√°gio',\n",
              "  'da‚Ä¶'],\n",
              " ['muita',\n",
              "  'gente',\n",
              "  'internet',\n",
              "  'virou',\n",
              "  'especialista',\n",
              "  '√°rea',\n",
              "  'sa√∫de,',\n",
              "  'nunca',\n",
              "  'ter',\n",
              "  'lido',\n",
              "  'artigo,',\n",
              "  'nunca',\n",
              "  'ter',\n",
              "  'freque‚Ä¶'],\n",
              " ['estudo,',\n",
              "  'pacientes',\n",
              "  'tomavam',\n",
              "  'cloroquina,',\n",
              "  'protegeram',\n",
              "  '#covid_19',\n",
              "  'cloroquina',\n",
              "  'sequer',\n",
              "  'capaz',\n",
              "  'ev‚Ä¶'],\n",
              " ['boa',\n",
              "  'not√≠cia',\n",
              "  'üòÉ!',\n",
              "  'brasil,',\n",
              "  '79479',\n",
              "  'pessoas',\n",
              "  '#curaram',\n",
              "  '#covid19',\n",
              "  'dados',\n",
              "  '14',\n",
              "  'maio',\n",
              "  'minist√©rio',\n",
              "  's‚Ä¶'],\n",
              " ['dia',\n",
              "  'aben√ßoado',\n",
              "  '#jesus',\n",
              "  'dessa',\n",
              "  'pandemia',\n",
              "  'respeito',\n",
              "  'crentes',\n",
              "  'crentes,',\n",
              "  'pra',\n",
              "  'v‚Ä¶'],\n",
              " ['@thammymiranda',\n",
              "  'pronunciou',\n",
              "  'sobre',\n",
              "  'caos',\n",
              "  'passando',\n",
              "  'sa√∫de',\n",
              "  'p√∫blica',\n",
              "  'pa√≠s‚Ä¶'],\n",
              " ['segundo',\n",
              "  'boletim',\n",
              "  'epidemiol√≥gico',\n",
              "  'dire√ß√£ogeral',\n",
              "  'sa√∫de',\n",
              "  '(dgs,',\n",
              "  'comunidade',\n",
              "  'intermunicipal',\n",
              "  'regi√£o',\n",
              "  'coimbra',\n",
              "  'h√°‚Ä¶'],\n",
              " ['#edecasa',\n",
              "  'muit√≠ssimo',\n",
              "  'importante',\n",
              "  'falar',\n",
              "  'sobre',\n",
              "  'profissionais',\n",
              "  'sa√∫de',\n",
              "  'falem',\n",
              "  'tbm',\n",
              "  'seguran√ßas,',\n",
              "  'pessoal',\n",
              "  'li‚Ä¶'],\n",
              " ['avan√ßos',\n",
              "  'ci√™ncia',\n",
              "  'combate',\n",
              "  '#covid',\n",
              "  '\\U0001f9a0üî¨',\n",
              "  'üá∫üá∏',\n",
              "  'calif√≥rnia',\n",
              "  'afirma',\n",
              "  'ter',\n",
              "  'descoberto',\n",
              "  '#anticorpo',\n",
              "  'eficaz',\n",
              "  'contra',\n",
              "  'a‚Ä¶'],\n",
              " ['dia',\n",
              "  '16',\n",
              "  'maio',\n",
              "  '2020,',\n",
              "  '57',\n",
              "  'novos',\n",
              "  'infectados',\n",
              "  'novo',\n",
              "  'coronav√≠rus',\n",
              "  'jap√£o',\n",
              "  '#coronavirus',\n",
              "  '#covid19',\n",
              "  '#pandemia',\n",
              "  '#covid_19japao'],\n",
              " ['enquanto',\n",
              "  'gente',\n",
              "  'furando',\n",
              "  '#quarentena,',\n",
              "  'n√∫mero',\n",
              "  'infectados',\n",
              "  'aumentar√°,',\n",
              "  'n√∫mero',\n",
              "  'interna√ß√µes',\n",
              "  'aumentar√°,',\n",
              "  'o‚Ä¶'],\n",
              " ['@brunnosarttori',\n",
              "  'vai',\n",
              "  'autodeclarar',\n",
              "  'm√©dico',\n",
              "  'receitar',\n",
              "  'cloroquina',\n",
              "  'pra',\n",
              "  '#covid'],\n",
              " ['covid19',\n",
              "  'cinco',\n",
              "  'dias',\n",
              "  'novas',\n",
              "  'infe√ß√µes',\n",
              "  'maia',\n",
              "  '#atualiza√ß√£o',\n",
              "  '#covid',\n",
              "  '#dgs',\n",
              "  '#infe√ß√µes',\n",
              "  '#n√∫meros'],\n",
              " ['üî¥',\n",
              "  'vivo',\n",
              "  '√∫ltimas',\n",
              "  'informa√ß√µes',\n",
              "  'sobre',\n",
              "  'coronav√≠rus',\n",
              "  'chapec√≥',\n",
              "  'neste',\n",
              "  's√°bado',\n",
              "  '(16',\n",
              "  'acesse',\n",
              "  'acompanhe‚Ä¶'],\n",
              " ['bate',\n",
              "  'papo',\n",
              "  'dra',\n",
              "  'tais',\n",
              "  'hon√≥rio',\n",
              "  'sobre',\n",
              "  'gest√£o',\n",
              "  'resolu√ß√£o',\n",
              "  'conflitos',\n",
              "  'durante',\n",
              "  'pandemia',\n",
              "  '#covid',\n",
              "  '#coronavirus'],\n",
              " ['oficial',\n",
              "  'braga',\n",
              "  'infetados',\n",
              "  '120',\n",
              "  'horas',\n",
              "  '#braga',\n",
              "  '#covid19',\n",
              "  '#dgs'],\n",
              " ['bolsonaro',\n",
              "  'defende',\n",
              "  'protocolo',\n",
              "  'diferente',\n",
              "  'covid19,',\n",
              "  'diz',\n",
              "  'braga',\n",
              "  'netto',\n",
              "  '#braganetto',\n",
              "  '#covid'],\n",
              " ['praias',\n",
              "  'p√≥voa',\n",
              "  'varzim',\n",
              "  'abrem',\n",
              "  '01',\n",
              "  'julho',\n",
              "  '#covid19',\n",
              "  '#p√≥voadevarzim',\n",
              "  '#praias'],\n",
              " ['ana',\n",
              "  'carolina',\n",
              "  'precisou',\n",
              "  '1',\n",
              "  'hora',\n",
              "  'live',\n",
              "  'pra',\n",
              "  'dar',\n",
              "  'tap√£o',\n",
              "  '@jairbolsonaro',\n",
              "  '#covid',\n",
              "  '#corona',\n",
              "  '#coronavirus‚Ä¶'],\n",
              " ['quiser',\n",
              "  'outros',\n",
              "  'detalhes',\n",
              "  'sobre',\n",
              "  'diz',\n",
              "  'projeto',\n",
              "  '#ldo2021,',\n",
              "  'clique',\n",
              "  'aqui'],\n",
              " ['#r√∫ssia',\n",
              "  'alerta',\n",
              "  'desinforma√ß√£o',\n",
              "  'durante',\n",
              "  '#pandemia',\n",
              "  '#covid19',\n",
              "  '#epidemia',\n",
              "  '#oms',\n",
              "  '#saludmundial'],\n",
              " ['#midiasocial',\n",
              "  '#quarentena',\n",
              "  '#pandemia',\n",
              "  '#covid',\n",
              "  '#gera√ß√µes',\n",
              "  'baby',\n",
              "  'boomers',\n",
              "  'gera√ß√£o',\n",
              "  'z',\n",
              "  'con‚Ä¶'],\n",
              " ['sobre',\n",
              "  'rem√©dio,',\n",
              "  'todos',\n",
              "  'contra',\n",
              "  'usam',\n",
              "  'contra',\n",
              "  'favor',\n",
              "  '#cloroquina',\n",
              "  '#covid',\n",
              "  '#fiqueemcasa',\n",
              "  '#emcasa'],\n",
              " ['vou',\n",
              "  'fazer',\n",
              "  'parte',\n",
              "  'üí°',\n",
              "  '________',\n",
              "  '________',\n",
              "  '#life',\n",
              "  '#words',\n",
              "  '#today',\n",
              "  '#quotes',\n",
              "  '#mood',\n",
              "  '#covid',\n",
              "  '#quarantine‚Ä¶'],\n",
              " ['trump',\n",
              "  '\"est√°',\n",
              "  'considerando\"',\n",
              "  'vacina',\n",
              "  'contra',\n",
              "  '#coronav√≠rus',\n",
              "  'dispon√≠vel',\n",
              "  'gratuitamente',\n",
              "  '#oms',\n",
              "  '#epidemia',\n",
              "  '#covid‚Ä¶'],\n",
              " ['üÜï',\n",
              "  '‚òÖfumigadora',\n",
              "  'astarsa',\n",
              "  'aa33‚òÖ',\n",
              "  '‚òé',\n",
              "  '+54',\n",
              "  '11',\n",
              "  '52635610',\n",
              "  'int',\n",
              "  '206',\n",
              "  'üì≤+54',\n",
              "  '9',\n",
              "  '3512023508',\n",
              "  'consultas@corvialcomar',\n",
              "  '#corvial‚Ä¶'],\n",
              " ['pa√≠s',\n",
              "  '√≥bitos',\n",
              "  'casos',\n",
              "  '1',\n",
              "  'üá∫üá∏',\n",
              "  '88237',\n",
              "  '1473415',\n",
              "  '2üá¨üáß',\n",
              "  '34078',\n",
              "  '238004',\n",
              "  '3',\n",
              "  'üáÆüáπ',\n",
              "  '31610‚Ä¶'],\n",
              " ['ningu√©m',\n",
              "  'desconfia',\n",
              "  'pegou',\n",
              "  '#covid19,',\n",
              "  'trataram',\n",
              "  '#cloroquina,',\n",
              "  'recuperou,',\n",
              "  'falsificou',\n",
              "  'exames',\n",
              "  'quer‚Ä¶'],\n",
              " ['@xicograziano',\n",
              "  'coisa',\n",
              "  'proibi√ß√£o',\n",
              "  'cloroquina',\n",
              "  'narrativa',\n",
              "  'criada',\n",
              "  'governo',\n",
              "  'proibi√ß√£o',\n",
              "  'uso',\n",
              "  'o‚Ä¶'],\n",
              " ['#health',\n",
              "  '#professionals',\n",
              "  '#covid',\n",
              "  '#pandemic',\n",
              "  '#pandemia',\n",
              "  'her√≥is',\n",
              "  'precisam',\n",
              "  'ajuda‚Ä¶'],\n",
              " ['#espanha,',\n",
              "  'falecido',\n",
              "  'caiu',\n",
              "  '102',\n",
              "  '√∫ltimas',\n",
              "  '24',\n",
              "  'horas',\n",
              "  'total',\n",
              "  '27563',\n",
              "  '#salud',\n",
              "  '#profecionalesdelasalud‚Ä¶'],\n",
              " ['famalic√£o',\n",
              "  'empresas',\n",
              "  'doam',\n",
              "  '3500',\n",
              "  'euros',\n",
              "  'tal√µes',\n",
              "  'alimentares',\n",
              "  'solid√°rios',\n",
              "  'minimercados',\n",
              "  '#com√©rcio',\n",
              "  '#covid19',\n",
              "  '#economia'],\n",
              " ['#ignorebolsonaro',\n",
              "  'presidente',\n",
              "  'no√ß√£o',\n",
              "  'confira',\n",
              "  'n√∫meros',\n",
              "  'pesquise',\n",
              "  'sobre',\n",
              "  'fala',\n",
              "  'parem',\n",
              "  'fazer',\n",
              "  'politicag‚Ä¶'],\n",
              " ['dois',\n",
              "  'meses',\n",
              "  'ap√≥s',\n",
              "  '1¬™',\n",
              "  'morte',\n",
              "  '#covid19,',\n",
              "  '#brasil',\n",
              "  'cen√°rio',\n",
              "  'pesadelos',\n",
              "  'via',\n",
              "  '@folha'],\n",
              " ['existe',\n",
              "  'podrid√£o',\n",
              "  'tr√°s',\n",
              "  'disso',\n",
              "  'tudo',\n",
              "  'povo',\n",
              "  'acordasse',\n",
              "  'veria#covƒ±d'],\n",
              " ['farmac√™utica',\n",
              "  'sobe',\n",
              "  '240%',\n",
              "  'ap√≥s',\n",
              "  'dizer',\n",
              "  'ter',\n",
              "  'poss√≠vel',\n",
              "  '‚Äúcura‚Äù',\n",
              "  'covid19',\n",
              "  '|',\n",
              "  'exame',\n",
              "  '#covid__19',\n",
              "  '#covid',\n",
              "  '#cura'],\n",
              " ['cader',\n",
              "  'rem√©dios',\n",
              "  'prefeitos',\n",
              "  'governadores',\n",
              "  'receberam',\n",
              "  'governo',\n",
              "  'federal',\n",
              "  '#foramaia',\n",
              "  '#foraalcolumbre',\n",
              "  '#forastf‚Ä¶'],\n",
              " ['morcegos',\n",
              "  'brasil',\n",
              "  't√™m',\n",
              "  'coronav√≠rus',\n",
              "  'diferente',\n",
              "  'surgiu',\n",
              "  'china',\n",
              "  'via',\n",
              "  '@uolnoticias',\n",
              "  '@uol',\n",
              "  '#covid19'],\n",
              " ['caixa',\n",
              "  'disponibilizar√°',\n",
              "  'r$',\n",
              "  '246',\n",
              "  'milh√µes',\n",
              "  'aux√≠lio',\n",
              "  'emergencial',\n",
              "  '405163',\n",
              "  'pessoas',\n",
              "  'neste',\n",
              "  's√°bado',\n",
              "  '#covid‚Ä¶'],\n",
              " ['‚öΩüéÆjogo',\n",
              "  'bemüéÆ‚öΩ',\n",
              "  '‚†Ä',\n",
              "  'seguimos',\n",
              "  'quartas',\n",
              "  'finais',\n",
              "  'jogo',\n",
              "  'bem!',\n",
              "  'fique',\n",
              "  'ligado',\n",
              "  'partir',\n",
              "  '11h',\n",
              "  'participe',\n",
              "  'fa√ßa‚Ä¶'],\n",
              " ['ficarmos',\n",
              "  'atentos',\n",
              "  'n√∫meros',\n",
              "  'medonhos',\n",
              "  'utilizados',\n",
              "  'm√≠dia',\n",
              "  'politicagem',\n",
              "  'continuar',\n",
              "  'medidas',\n",
              "  'preventivas',\n",
              "  'de‚Ä¶'],\n",
              " ['ap√≥s',\n",
              "  'afrouxamento',\n",
              "  'geral',\n",
              "  'pandemia,',\n",
              "  'devemos',\n",
              "  'continuar',\n",
              "  'pensando',\n",
              "  'pr√≥ximo',\n",
              "  'lutar',\n",
              "  'contra',\n",
              "  'roubalheiras,',\n",
              "  'su‚Ä¶'],\n",
              " ['finalmente',\n",
              "  'florian√≥polis',\n",
              "  'sob',\n",
              "  'controle',\n",
              "  'infec√ß√£o',\n",
              "  '#covid19',\n",
              "  'gra√ßas',\n",
              "  'confinamento',\n",
              "  'imposto',\n",
              "  'prefeit‚Ä¶'],\n",
              " ['nesse',\n",
              "  'momento',\n",
              "  'deveria',\n",
              "  'existir',\n",
              "  'esquerda,',\n",
              "  'direita',\n",
              "  'sim',\n",
              "  'todos',\n",
              "  'juntos',\n",
              "  'vida!',\n",
              "  '14‚Ä¶'],\n",
              " ['ministro',\n",
              "  'sa√∫de',\n",
              "  'ideal,',\n",
              "  'cabe√ßa',\n",
              "  'bolsonaro,',\n",
              "  'deve',\n",
              "  'ser',\n",
              "  'felizmente',\n",
              "  'morreu',\n",
              "  'bertioga,',\n",
              "  '1979',\n",
              "  'josef',\n",
              "  'me‚Ä¶'],\n",
              " ['viva',\n",
              "  'transplante',\n",
              "  'combatendo',\n",
              "  'not√≠cias',\n",
              "  'falsas',\n",
              "  'sobre',\n",
              "  'covid',\n",
              "  '#covid19',\n",
              "  '#covid'],\n",
              " ['@govsc',\n",
              "  'quantos',\n",
              "  'casos',\n",
              "  'novos',\n",
              "  '#covid',\n",
              "  'registrados',\n",
              "  'sc',\n",
              "  'dia',\n",
              "  '14',\n",
              "  'dia',\n",
              "  '15/05',\n",
              "  'encontrei',\n",
              "  'lugar',\n",
              "  'nenhum‚Ä¶'],\n",
              " ['milhares',\n",
              "  'creches',\n",
              "  'preparadas',\n",
              "  'reabrir',\n",
              "  'sob',\n",
              "  'condi√ß√µes',\n",
              "  'at√≠picas,',\n",
              "  'especialistas',\n",
              "  'educadores',\n",
              "  'inf√¢nci‚Ä¶'],\n",
              " ['liberar',\n",
              "  '#hidroxicloroquina',\n",
              "  '#sus',\n",
              "  'estados=',\n",
              "  'acabar√°',\n",
              "  'mamata',\n",
              "  'cm',\n",
              "  'grana',\n",
              "  'gov',\n",
              "  'federal',\n",
              "  'medicamento',\n",
              "  'ba‚Ä¶'],\n",
              " ['directora',\n",
              "  'nacional',\n",
              "  'sa√∫de',\n",
              "  'p√∫blica',\n",
              "  'indicou',\n",
              "  'doente,',\n",
              "  '33',\n",
              "  'anos',\n",
              "  'idade,',\n",
              "  'diagnosticada',\n",
              "  '#covid19',\n",
              "  'cid‚Ä¶'],\n",
              " ['directora',\n",
              "  'nacional',\n",
              "  'sa√∫de',\n",
              "  'p√∫blica',\n",
              "  'indicou',\n",
              "  'doente,',\n",
              "  '33',\n",
              "  'anos',\n",
              "  'idade,',\n",
              "  'diagnosticada',\n",
              "  '#covid19',\n",
              "  'cid‚Ä¶'],\n",
              " ['assembleia',\n",
              "  'mundial',\n",
              "  'sa√∫de',\n",
              "  'oms',\n",
              "  'ocorre',\n",
              "  'meio',\n",
              "  'crise',\n",
              "  '#covid19',\n",
              "  '#wha73'],\n",
              " ['it√°lia',\n",
              "  'vai',\n",
              "  'abrir',\n",
              "  'fronteiras',\n",
              "  'uni√£o',\n",
              "  'europeia,',\n",
              "  'necessidade',\n",
              "  'quarentena,',\n",
              "  'partir',\n",
              "  '3',\n",
              "  'junho,',\n",
              "  'segundo‚Ä¶'],\n",
              " ['quantos',\n",
              "  'funcion√°rios',\n",
              "  'supermercado,',\n",
              "  'farm√°cia,',\n",
              "  'restaurante,',\n",
              "  'motoboys',\n",
              "  'afins',\n",
              "  'morreram',\n",
              "  '#covid?'],\n",
              " ['@lucianohuck',\n",
              "  'imaginou',\n",
              "  'salvando',\n",
              "  'todo',\n",
              "  'mundo',\n",
              "  'seria,',\n",
              "  'super',\n",
              "  'her√≥i,',\n",
              "  'imperador',\n",
              "  'mundo,',\n",
              "  'basta',\n",
              "  'voc√™‚Ä¶'],\n",
              " ['@teichnelson',\n",
              "  'saia!',\n",
              "  '#fiqueemcasacomaciencia',\n",
              "  '#fiquememcasa',\n",
              "  '#covid'],\n",
              " ['piritiba',\n",
              "  '√¥nibus',\n",
              "  '40',\n",
              "  'pessoas',\n",
              "  'vindas',\n",
              "  'outra',\n",
              "  'cidade',\n",
              "  'barrado',\n",
              "  'blitz',\n",
              "  'sa√∫de',\n",
              "  'porto',\n",
              "  'feliz',\n",
              "  'confira!‚Ä¶'],\n",
              " ['@wilsonwitzel',\n",
              "  'her√≥i',\n",
              "  'q',\n",
              "  'vai',\n",
              "  'cadeia',\n",
              "  'mario',\n",
              "  'peixoto',\n",
              "  'olha,',\n",
              "  '@policiafederal',\n",
              "  'iniciou',\n",
              "  'a√ß√µes',\n",
              "  'rj',\n",
              "  'et‚Ä¶'],\n",
              " ['quase',\n",
              "  '6h',\n",
              "  'manh√£',\n",
              "  'nada',\n",
              "  'sono',\n",
              "  'troco',\n",
              "  'dia',\n",
              "  'noite',\n",
              "  'entrevistas',\n",
              "  'notici√°rios',\n",
              "  'descubro',\n",
              "  'q',\n",
              "  '√∫nica‚Ä¶'],\n",
              " ['not√≠cia', 'senhores', 'üòç', '#coronavitus', '#covid19', '#covid'],\n",
              " ['#covid19',\n",
              "  't√¥',\n",
              "  'fora!',\n",
              "  '#m√°scaradetecido,',\n",
              "  '#robertsjeans',\n",
              "  'tem!',\n",
              "  'pe√ßa',\n",
              "  'imagem',\n",
              "  'original',\n",
              "  'via',\n",
              "  '#whatsappüì≤',\n",
              "  '11',\n",
              "  '22924461',\n",
              "  'rob‚Ä¶'],\n",
              " ['#tipoftheday',\n",
              "  'in',\n",
              "  '#covid19',\n",
              "  'caros',\n",
              "  'amigos',\n",
              "  '#profissionaisdesa√∫de',\n",
              "  'bem',\n",
              "  'vindos',\n",
              "  '#webmeeting',\n",
              "  'refer√™ncia',\n",
              "  'sobre',\n",
              "  'a‚Ä¶'],\n",
              " ['diagnosticados',\n",
              "  'nesta',\n",
              "  'sextafeira',\n",
              "  '(15',\n",
              "  'novos',\n",
              "  'infectados',\n",
              "  '#covid19',\n",
              "  '#mo√ßambique,',\n",
              "  '\"temos',\n",
              "  'quatro',\n",
              "  'indiv√≠duo‚Ä¶'],\n",
              " ['jap√£o',\n",
              "  'autoriza',\n",
              "  'antiviral',\n",
              "  '#tratamento',\n",
              "  '#covid19',\n",
              "  'promete',\n",
              "  '#vacina',\n",
              "  'via',\n",
              "  '@yahoobr'],\n",
              " ['gente',\n",
              "  'achando',\n",
              "  'grande',\n",
              "  'mancha',\n",
              "  'oleo',\n",
              "  'litoral',\n",
              "  'ne',\n",
              "  'grande',\n",
              "  'dor',\n",
              "  'cabe√ßa',\n",
              "  '2020',\n",
              "  '#tolinhos',\n",
              "  '#covid'],\n",
              " ['#covid19',\n",
              "  '#s√£ovicente',\n",
              "  'confira',\n",
              "  '#casos',\n",
              "  '#bairro',\n",
              "  'nesta',\n",
              "  '#sexta,',\n",
              "  '15',\n",
              "  'via',\n",
              "  '@costanortemais'],\n",
              " ['bom',\n",
              "  'dia',\n",
              "  'fa√ßam',\n",
              "  'teste',\n",
              "  'hahahahahahahahahahahahahahaha',\n",
              "  '#quarentena',\n",
              "  '#covid',\n",
              "  '#radio',\n",
              "  '#agentenaodesiste',\n",
              "  '#sucupirasat'],\n",
              " ['impress√£o', 'fotos', 'volante', 'heteros', 'top', 'diminuiram', '#covid'],\n",
              " ['@folha',\n",
              "  'pena',\n",
              "  'melhores',\n",
              "  'programas',\n",
              "  'informa√ß√£o,',\n",
              "  'dedicados',\n",
              "  '#covid19'],\n",
              " ['@mamuteobeso',\n",
              "  '@brehenrique_',\n",
              "  '@william_castro',\n",
              "  'censura',\n",
              "  'cnn',\n",
              "  'cortar',\n",
              "  'microfone',\n",
              "  'ministro',\n",
              "  'cnn',\n",
              "  'prestando',\n",
              "  'um‚Ä¶'],\n",
              " ['#portadaprocesodigital',\n",
              "  's√°bado',\n",
              "  '16052020',\n",
              "  '#tapasdeld√≠a',\n",
              "  '#honduras',\n",
              "  '#covid19',\n",
              "  '#tusaludestaentusmanos'],\n",
              " ['rindo,',\n",
              "  'desespero',\n",
              "  'm√°scara',\n",
              "  '#ministrodasa√∫de',\n",
              "  '#bolsonarogenocida',\n",
              "  '#bolsonaroenlouqueceu',\n",
              "  '#rindodedesespero‚Ä¶'],\n",
              " ['@melimoficial',\n",
              "  '#livemelim',\n",
              "  '#euquero',\n",
              "  '#ifeatvoce',\n",
              "  '#letsdance',\n",
              "  '#musicismagic',\n",
              "  '#vegpress',\n",
              "  '#confins',\n",
              "  '#angradosreis‚Ä¶'],\n",
              " ['quatro',\n",
              "  'pessoas',\n",
              "  'morreram',\n",
              "  'ap√≥s',\n",
              "  'avi√£o',\n",
              "  'pequeno',\n",
              "  'porte,',\n",
              "  'levava',\n",
              "  'paciente',\n",
              "  'coronav√≠rus',\n",
              "  'teresina,',\n",
              "  'pi‚Ä¶'],\n",
              " ['#m√°scarapersonalizada#m√°scaraprote√ß√£o',\n",
              "  '#bts',\n",
              "  '#covid19',\n",
              "  'lugalma',\n",
              "  'acess√≥rios'],\n",
              " ['enquanto',\n",
              "  'quarentena',\n",
              "  'devido',\n",
              "  '#pandemia',\n",
              "  'causado',\n",
              "  '#covid19,',\n",
              "  'pal√°cio',\n",
              "  'planalto',\n",
              "  'segue',\n",
              "  '#pandemonio',\n",
              "  'ca‚Ä¶'],\n",
              " ['#m√°scaraprote√ß√£o',\n",
              "  '#m√°scarapersonalizada',\n",
              "  '#nowunited',\n",
              "  '#covid19',\n",
              "  'lugalma',\n",
              "  'acess√≥rios'],\n",
              " ['#m√°scarapersonalizada',\n",
              "  '#m√°scaradeprote√ß√£o',\n",
              "  '#covid19',\n",
              "  'lugalma',\n",
              "  'acess√≥rios'],\n",
              " ['#mascaradeprote√ßao',\n",
              "  '#m√°scarapersonalizada',\n",
              "  '#covid19',\n",
              "  'lugalma',\n",
              "  'acess√≥rios'],\n",
              " ['@ninafreitas',\n",
              "  'mandar',\n",
              "  'equipe',\n",
              "  'surpresa',\n",
              "  'todos',\n",
              "  'dias',\n",
              "  'pro',\n",
              "  'augusto',\n",
              "  'franco,',\n",
              "  'bater√°',\n",
              "  'recorde',\n",
              "  'mundial',\n",
              "  'infectado‚Ä¶'],\n",
              " ['al√©m',\n",
              "  'importar',\n",
              "  'popula√ß√£o',\n",
              "  'pobre,',\n",
              "  '@pauloguedesmf',\n",
              "  'mostra',\n",
              "  'nesta',\n",
              "  'entrevista',\n",
              "  'nunca',\n",
              "  'encheu',\n",
              "  'laj‚Ä¶'],\n",
              " ['@afpespanol',\n",
              "  '@lulaoficial',\n",
              "  '@paulacramon',\n",
              "  'mito',\n",
              "  'bolsonaro',\n",
              "  'vem',\n",
              "  'demonstrando',\n",
              "  'ser',\n",
              "  'exemplo',\n",
              "  'tr√°gico',\n",
              "  'brasil,',\n",
              "  'assim‚Ä¶'],\n",
              " ['deve',\n",
              "  'ser',\n",
              "  'novo',\n",
              "  'ministro?',\n",
              "  '#auxilioemergencial',\n",
              "  '#auxilioemergecial',\n",
              "  '#covid',\n",
              "  '#covid1948',\n",
              "  '#covid19',\n",
              "  '#covid„Éº19',\n",
              "  '#coronavirus'],\n",
              " ['tuuuuudo',\n",
              "  'f',\n",
              "  'k',\n",
              "  'numeros',\n",
              "  'fakes',\n",
              "  'morte',\n",
              "  '#coronahoax',\n",
              "  '#covid19',\n",
              "  'sigla',\n",
              "  'certificate',\n",
              "  'of',\n",
              "  'vaccine',\n",
              "  'identity‚Ä¶'],\n",
              " ['sobre',\n",
              "  'd√≥lar',\n",
              "  'subindo,',\n",
              "  'bolsa',\n",
              "  'caindo,',\n",
              "  'fuga',\n",
              "  'capital',\n",
              "  'estrangeiro',\n",
              "  'falta',\n",
              "  'perspectiva',\n",
              "  'recupera√ß√£o',\n",
              "  'eco‚Ä¶'],\n",
              " ['@lulaoficial',\n",
              "  'governo',\n",
              "  'matou',\n",
              "  'covid',\n",
              "  'poder√°',\n",
              "  'matar',\n",
              "  'aqui',\n",
              "  'brasil',\n",
              "  'governo',\n",
              "  'v√≠rus',\n",
              "  'mortal',\n",
              "  'pt',\n",
              "  'nun‚Ä¶'],\n",
              " ['üí∞',\n",
              "  'pagamento',\n",
              "  '2¬™',\n",
              "  'parcela',\n",
              "  'aux√≠lio',\n",
              "  'emergencial',\n",
              "  'veja!',\n",
              "  'confira',\n",
              "  'detalhes',\n",
              "  'arrastando',\n",
              "  'cima',\n",
              "  'stories',\n",
              "  'di‚Ä¶'],\n",
              " ['pr√≥xima', 'semana', 'inicia', 'descenso', 'casos', '#covid19', '#amlo'],\n",
              " ['jeito,',\n",
              "  '@wilsonwitzel',\n",
              "  'curado',\n",
              "  '#covid',\n",
              "  'falou',\n",
              "  'pra',\n",
              "  'ningu√©m',\n",
              "  'menos',\n",
              "  'cheio',\n",
              "  'disposi√ß√£o,',\n",
              "  'po‚Ä¶'],\n",
              " ['vamos',\n",
              "  'ter',\n",
              "  'outro',\n",
              "  'governador',\n",
              "  'preso',\n",
              "  '@riodejaneiro?',\n",
              "  'aguardando',\n",
              "  'cenas',\n",
              "  'pr√≥ximos',\n",
              "  'cap√≠tulos',\n",
              "  'carioca‚Ä¶'],\n",
              " ['membros',\n",
              "  'stf',\n",
              "  'tempo',\n",
              "  'tendo',\n",
              "  'posi√ß√£o',\n",
              "  'contr√°rio',\n",
              "  'desejos',\n",
              "  'povo',\n",
              "  'povo',\n",
              "  'queremos',\n",
              "  'moti‚Ä¶'],\n",
              " ['tributa√ß√£o',\n",
              "  'ricos',\n",
              "  'equilibrar',\n",
              "  'contas',\n",
              "  'p√≥spandemia',\n",
              "  '#tributo',\n",
              "  '#imposto',\n",
              "  '#economia‚Ä¶'],\n",
              " ['sabe',\n",
              "  'diz',\n",
              "  'manh√™',\n",
              "  'to',\n",
              "  'achando',\n",
              "  'coiso',\n",
              "  'diz',\n",
              "  'menino,',\n",
              "  'a√≠',\n",
              "  'achar',\n",
              "  'pqp,',\n",
              "  'mainha,',\n",
              "  't‚Ä¶'],\n",
              " ['mortes',\n",
              "  's√≠ndromes',\n",
              "  'respirat√≥rias',\n",
              "  '2020',\n",
              "  'superam',\n",
              "  'm√©dia',\n",
              "  '√∫ltimos',\n",
              "  '10',\n",
              "  'anos,',\n",
              "  'apontam',\n",
              "  'dados',\n",
              "  'fiocruz',\n",
              "  '|',\n",
              "  'coronav√≠ru‚Ä¶'],\n",
              " ['petrobras', 'preju√≠zo', 'r$', '48,5', 'bi', '1¬∞', 'trimestre', '#covid'],\n",
              " ['prefeito',\n",
              "  'bel√©m,',\n",
              "  'zenaldo',\n",
              "  'coutinho,',\n",
              "  'anunciou',\n",
              "  'in√≠cio',\n",
              "  'tarde',\n",
              "  'desta',\n",
              "  'sextafeira,',\n",
              "  '15,',\n",
              "  'bel√©m',\n",
              "  'ir√°',\n",
              "  'prorrogar',\n",
              "  'a‚Ä¶'],\n",
              " ['gl√≥ria',\n",
              "  'deus!!!',\n",
              "  'nenhuma',\n",
              "  'morte',\n",
              "  '#covid„Éº19,',\n",
              "  '√∫ltimas',\n",
              "  '24',\n",
              "  'horas',\n",
              "  'maranh√£o!!!',\n",
              "  'compartilhe',\n",
              "  'verdade!!!',\n",
              "  '#covid‚Ä¶'],\n",
              " ['sindicato',\n",
              "  'aciona',\n",
              "  'mp',\n",
              "  'investigar',\n",
              "  'suposta',\n",
              "  'press√£o',\n",
              "  'm√©dicos',\n",
              "  'atestarem',\n",
              "  '√≥bitos',\n",
              "  '#covid19'],\n",
              " ['parece',\n",
              "  'bolsominios',\n",
              "  'continuam',\n",
              "  'defendendo',\n",
              "  'vagabundo',\n",
              "  'jair',\n",
              "  'bolsonaro',\n",
              "  '#impeachmentbolsonaro',\n",
              "  '#covid_19',\n",
              "  '#covid‚Ä¶'],\n",
              " ['mulher',\n",
              "  'fan√°tica',\n",
              "  'religiosa,',\n",
              "  'irrespons√°vel',\n",
              "  'ponto',\n",
              "  'defender',\n",
              "  'indefens√°vel',\n",
              "  '#impeachmentbolsonaro‚Ä¶'],\n",
              " ['tr√™s',\n",
              "  'coisas',\n",
              "  'aprendi',\n",
              "  'hoje',\n",
              "  '1',\n",
              "  'segundo',\n",
              "  'ministro',\n",
              "  'educa√ß√£o',\n",
              "  '#cnn',\n",
              "  'pode',\n",
              "  'perguntar',\n",
              "  '‚Äúcombinado‚Äù',\n",
              "  '2‚Ä¶'],\n",
              " ['marta',\n",
              "  'pergunta',\n",
              "  'ser',\n",
              "  'assistente',\n",
              "  'social',\n",
              "  'durante',\n",
              "  'pandemia',\n",
              "  '#covid',\n",
              "  'geane',\n",
              "  'diz',\n",
              "  'ser',\n",
              "  '\"persistente',\n",
              "  'soc‚Ä¶'],\n",
              " ['imagine',\n",
              "  '\"isto\"',\n",
              "  'presidente!',\n",
              "  'üíÄüëé‚ö∞Ô∏èüï≥Ô∏è#china',\n",
              "  '#chinavirus',\n",
              "  '#chinawuhan',\n",
              "  '#wuhanvirus',\n",
              "  '#covid',\n",
              "  '#covid19',\n",
              "  '#corona',\n",
              "  '#coronavirus‚Ä¶'],\n",
              " ['arte',\n",
              "  'disse',\n",
              "  'fazendo',\n",
              "  'maus',\n",
              "  'demora',\n",
              "  'v',\n",
              "  'compartilhem',\n",
              "  'favor!',\n",
              "  '#politica',\n",
              "  '#bolsonaro‚Ä¶'],\n",
              " ['camila',\n",
              "  'pergunta',\n",
              "  'maior',\n",
              "  'dificuldade',\n",
              "  'orienta√ß√£o',\n",
              "  'idosos',\n",
              "  'sobre',\n",
              "  '#covid',\n",
              "  'geane',\n",
              "  'diz',\n",
              "  'que,',\n",
              "  'onde',\n",
              "  'atua,',\n",
              "  'os‚Ä¶'],\n",
              " ['mulherada',\n",
              "  'fiquem',\n",
              "  'esperta,',\n",
              "  'homem',\n",
              "  'tipo',\n",
              "  '#covid',\n",
              "  ',',\n",
              "  'al√©m',\n",
              "  'ti',\n",
              "  't√™m',\n",
              "  '+',\n",
              "  '5',\n",
              "  'casos',\n",
              "  'confirmados',\n",
              "  '+',\n",
              "  '2',\n",
              "  '\"amigas',\n",
              "  'suspeitas\"',\n",
              "  'üôÑüò¨\\U0001f92büòÇ'],\n",
              " ['palabras',\n",
              "  'clave',\n",
              "  'manejar',\n",
              "  'la',\n",
              "  'pandemia',\n",
              "  'testtraceisolate',\n",
              "  '#covid19',\n",
              "  '#sarscov2'],\n",
              " ['anadelma',\n",
              "  'pergunta',\n",
              "  'sobre',\n",
              "  '#covid',\n",
              "  'geane',\n",
              "  'diz',\n",
              "  'todos',\n",
              "  'servi√ßos',\n",
              "  'assist√™ncia',\n",
              "  'social',\n",
              "  'funcionando,',\n",
              "  'com‚Ä¶'],\n",
              " ['defesa',\n",
              "  'civil',\n",
              "  'sg',\n",
              "  'informa',\n",
              "  'atualiza√ß√£o',\n",
              "  'dados',\n",
              "  'nacionais',\n",
              "  'üáßüá∑',\n",
              "  '15/05/20',\n",
              "  '19h',\n",
              "  '#covid',\n",
              "  '#coronavirus'],\n",
              " ['braga',\n",
              "  'neto,',\n",
              "  'mando',\n",
              "  '@jairbolsonaro,',\n",
              "  'dourando',\n",
              "  'n√∫mero',\n",
              "  'mortes',\n",
              "  'gr√°fico',\n",
              "  'log',\n",
              "  'comparado',\n",
              "  'brasil',\n",
              "  'b√©lgica‚Ä¶'],\n",
              " ['momento',\n",
              "  'bra',\n",
              "  '0',\n",
              "  'x',\n",
              "  'cor',\n",
              "  '14817',\n",
              "  'presidente',\n",
              "  'esfor√ßando',\n",
              "  '#bolsonaro',\n",
              "  '#brasil',\n",
              "  '#covid'],\n",
              " ['dias',\n",
              "  'fazer',\n",
              "  'compras',\n",
              "  'dias',\n",
              "  'luta,',\n",
              "  'dias',\n",
              "  'beber',\n",
              "  'dias',\n",
              "  'gl√≥ria!',\n",
              "  '#quarentena',\n",
              "  '#covid19',\n",
              "  '#covid'],\n",
              " ['cara',\n",
              "  'inclui',\n",
              "  'academias',\n",
              "  'gin√°stica,',\n",
              "  'sal√µes',\n",
              "  'beleza',\n",
              "  'barbearias',\n",
              "  'servi√ßos',\n",
              "  'essenciais',\n",
              "  'durante',\n",
              "  'pandemia',\n",
              "  'do‚Ä¶'],\n",
              " ['michele',\n",
              "  'pergunta',\n",
              "  'sobre',\n",
              "  'trabalho',\n",
              "  'idosos',\n",
              "  'durante',\n",
              "  'pandemia',\n",
              "  '#covid',\n",
              "  'geane',\n",
              "  'responde',\n",
              "  'acompanhamento‚Ä¶'],\n",
              " ['distantes,',\n",
              "  'sido',\n",
              "  'incr√≠vel!!',\n",
              "  'digitalizar',\n",
              "  'aproximar',\n",
              "  '#orgulhoempertencer',\n",
              "  '#timegrande',\n",
              "  '#jur√≠dico‚Ä¶'],\n",
              " ['rindo',\n",
              "  'pra',\n",
              "  'chorar',\n",
              "  'üòÇüò≠',\n",
              "  'moro',\n",
              "  'aconselhando',\n",
              "  '#teich',\n",
              "  '#cloroquina',\n",
              "  '#coronavirus',\n",
              "  '#covidiotas‚Ä¶'],\n",
              " ['geane',\n",
              "  'diz',\n",
              "  'que,',\n",
              "  'idoso',\n",
              "  'mora',\n",
              "  'sozinho,',\n",
              "  'antes',\n",
              "  '#covid,',\n",
              "  'orienta√ß√£o',\n",
              "  'ter',\n",
              "  'rede',\n",
              "  'prote√ß√£o',\n",
              "  'conta‚Ä¶'],\n",
              " ['enquanto',\n",
              "  'gente',\n",
              "  'assiste',\n",
              "  'dan√ßa',\n",
              "  'cadeiras',\n",
              "  'governo,',\n",
              "  'pov√£o',\n",
              "  'continua',\n",
              "  'pagando',\n",
              "  'conta',\n",
              "  '#covid',\n",
              "  'aumentando‚Ä¶'],\n",
              " ['presidente',\n",
              "  'conselho',\n",
              "  'sa√∫de',\n",
              "  'roraima',\n",
              "  'afirmou',\n",
              "  'hospital',\n",
              "  'ventiladores',\n",
              "  'renovar',\n",
              "  'ar',\n",
              "  'hospi‚Ä¶'],\n",
              " ['pergunto',\n",
              "  'geane',\n",
              "  'sobre',\n",
              "  'orienta√ß√µes',\n",
              "  'idosos',\n",
              "  'durante',\n",
              "  'pandemia',\n",
              "  '#covid',\n",
              "  'diz',\n",
              "  'comunidades',\n",
              "  'id‚Ä¶'],\n",
              " ['@fasalles',\n",
              "  '@edgaarcia',\n",
              "  'esquerdistas',\n",
              "  'podem',\n",
              "  'usar',\n",
              "  'maconha',\n",
              "  'globo',\n",
              "  'disse',\n",
              "  'eficiente',\n",
              "  'combate',\n",
              "  '#covid',\n",
              "  'po‚Ä¶'],\n",
              " ['reuni√£o',\n",
              "  'semanal',\n",
              "  'projeto',\n",
              "  'gradua√ß√£o',\n",
              "  'engenharia',\n",
              "  'qu√≠mica',\n",
              "  '!',\n",
              "  '#jitsi',\n",
              "  '#reuniao',\n",
              "  '#fiqueemcasa',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['coisa',\n",
              "  'surreal',\n",
              "  'tentar',\n",
              "  'argumentar',\n",
              "  'contra',\n",
              "  'isolamento',\n",
              "  'cuidados',\n",
              "  're',\n",
              "  '#covid',\n",
              "  'comparando',\n",
              "  'mortes',\n",
              "  'de‚Ä¶'],\n",
              " ['colocar',\n",
              "  'militar',\n",
              "  'justificar',\n",
              "  'mortes',\n",
              "  '#covid19',\n",
              "  'comparandoas',\n",
              "  'n√∫mero',\n",
              "  'mortes',\n",
              "  'conta',\n",
              "  'outra‚Ä¶'],\n",
              " ['vai',\n",
              "  'gerar',\n",
              "  'fome,',\n",
              "  'pobreza',\n",
              "  'tudo',\n",
              "  '@govbr',\n",
              "  '#forabolsonarourgente',\n",
              "  'economia',\n",
              "  't√°',\n",
              "  'afundada',\n",
              "  'pa√≠s‚Ä¶'],\n",
              " ['skate',\n",
              "  'park',\n",
              "  'tempos',\n",
              "  'pandemia',\n",
              "  'licita√ß√£o?',\n",
              "  'modalidade?',\n",
              "  '@tcuoficial',\n",
              "  'entendimento',\n",
              "  'consolidado‚Ä¶'],\n",
              " ['üÜï',\n",
              "  '‚òÖfumigadora',\n",
              "  'astarsa',\n",
              "  'aa33‚òÖ',\n",
              "  '‚òé',\n",
              "  '+54',\n",
              "  '11',\n",
              "  '52635610',\n",
              "  'int',\n",
              "  '206',\n",
              "  'üì≤+54',\n",
              "  '9',\n",
              "  '3512023508',\n",
              "  'consultas@corvialcomar',\n",
              "  '#corvial‚Ä¶'],\n",
              " ['uso',\n",
              "  '#hidroxicloroquina',\n",
              "  'tratamento',\n",
              "  '#covid_19',\n",
              "  'estudo',\n",
              "  'washington',\n",
              "  'university',\n",
              "  'mostra',\n",
              "  'brasil',\n",
              "  'podem',\n",
              "  'mor‚Ä¶'],\n",
              " ['vamos',\n",
              "  'desesperardeus',\n",
              "  'controle',\n",
              "  'tudotenhamos',\n",
              "  'f√©',\n",
              "  '#coronavirus',\n",
              "  '#covid19',\n",
              "  '#esperanca‚Ä¶'],\n",
              " ['covid19',\n",
              "  'm√°rcio',\n",
              "  'ara√∫jo',\n",
              "  'recebe',\n",
              "  'alta',\n",
              "  'ap√≥s',\n",
              "  'quatro',\n",
              "  'dias',\n",
              "  'uti',\n",
              "  '#covid',\n",
              "  '#esportes'],\n",
              " ['parab√©ns',\n",
              "  'exministro',\n",
              "  '@teichnelson',\n",
              "  'ter',\n",
              "  'escolhido',\n",
              "  'princ√≠pios',\n",
              "  'detrimento',\n",
              "  'corja',\n",
              "  'quer',\n",
              "  'comprometer',\n",
              "  'todos‚Ä¶'],\n",
              " ['hoje',\n",
              "  'vivemos',\n",
              "  'caos',\n",
              "  'estrutura',\n",
              "  'sa√∫de?',\n",
              "  'hoje?',\n",
              "  'hoje',\n",
              "  'n√£o!',\n",
              "  'faz',\n",
              "  'algum',\n",
              "  'tempo',\n",
              "  'sa√∫de',\n",
              "  'renegada',\n",
              "  'a‚Ä¶'],\n",
              " ['amanh√£',\n",
              "  'hein',\n",
              "  'vai',\n",
              "  'perder',\n",
              "  '#covid',\n",
              "  '#dianacionaldecombateahomofobia',\n",
              "  '#coronavirus',\n",
              "  '#amor',\n",
              "  '#webserielgbt‚Ä¶'],\n",
              " ['vivo',\n",
              "  '#conectadocomramalha',\n",
              "  'hoje,',\n",
              "  'convidada',\n",
              "  'geane',\n",
              "  'souza,',\n",
              "  '√©‚Ä¶'],\n",
              " ['nesta',\n",
              "  'sextafeira',\n",
              "  '(15,',\n",
              "  'boletim',\n",
              "  'epidemiol√≥gico',\n",
              "  'registra',\n",
              "  '√≥bito',\n",
              "  'homem,',\n",
              "  'v√≠tima',\n",
              "  'covid19',\n",
              "  '26',\n",
              "  'an‚Ä¶'],\n",
              " ['acabou',\n",
              "  'acontecer',\n",
              "  'natal',\n",
              "  'homem',\n",
              "  'quer',\n",
              "  'bruno',\n",
              "  'nogueira',\n",
              "  'passou',\n",
              "  'duas',\n",
              "  'vezes',\n",
              "  'rua',\n",
              "  '#lisboa‚Ä¶'],\n",
              " ['assist√™ncia',\n",
              "  '#enfermagem',\n",
              "  'uti',\n",
              "  'pacientes',\n",
              "  '#covid19',\n",
              "  'tema',\n",
              "  'palestra',\n",
              "  'ministrada',\n",
              "  'noite',\n",
              "  'hoje',\n",
              "  'pel‚Ä¶'],\n",
              " ['mostrem',\n",
              "  'pa√≠s',\n",
              "  'descente,',\n",
              "  '2',\n",
              "  'meses',\n",
              "  'estado',\n",
              "  'emergencia,',\n",
              "  'devido',\n",
              "  'pandemia',\n",
              "  '#covid,',\n",
              "  'perde',\n",
              "  'minist‚Ä¶'],\n",
              " ['n√∫meros',\n",
              "  'casos',\n",
              "  'confirmados',\n",
              "  'covid19',\n",
              "  'cana√£',\n",
              "  'caraj√°s',\n",
              "  'aumentando',\n",
              "  'cada',\n",
              "  'dia',\n",
              "  '#voceinformado‚Ä¶'],\n",
              " ['hospital',\n",
              "  'campanha',\n",
              "  'pronto',\n",
              "  'aqui',\n",
              "  'boa',\n",
              "  'vista',\n",
              "  'por√©m',\n",
              "  'm√£o',\n",
              "  'obra!',\n",
              "  'm√©dicos',\n",
              "  'um‚Ä¶'],\n",
              " ['contagem', 'confirma', 'duas', 'mortes', '#covid19', '#coronav√≠rusmg'],\n",
              " ['contagem', 'confirma', 'duas', 'mortes', '#covid19', '#coronav√≠rusmg'],\n",
              " ['2',\n",
              "  'mil',\n",
              "  'sergipanos',\n",
              "  'contaminados',\n",
              "  'coronav√≠rus,',\n",
              "  'empres√°rios',\n",
              "  'mostram',\n",
              "  'desd√©m',\n",
              "  'vida',\n",
              "  'trabalhadore‚Ä¶'],\n",
              " ['filho',\n",
              "  'ambuzando',\n",
              "  'pai',\n",
              "  'enquanto',\n",
              "  'espera',\n",
              "  'ventilador',\n",
              "  'todo',\n",
              "  'dia',\n",
              "  'choro',\n",
              "  'pouquinho',\n",
              "  '#covid'],\n",
              " ['acabamos',\n",
              "  'atualizar',\n",
              "  'dados',\n",
              "  '#siglitoral',\n",
              "  'ufrgs',\n",
              "  'hoje',\n",
              "  'maior',\n",
              "  'alta',\n",
              "  'novos',\n",
              "  'casos',\n",
              "  'registrados',\n",
              "  'rs',\n",
              "  '60‚Ä¶'],\n",
              " ['preocupados',\n",
              "  '#covid',\n",
              "  'manos',\n",
              "  'fazer',\n",
              "  'penteados',\n",
              "  'pra',\n",
              "  'estrear',\n",
              "  'casa',\n",
              "  'üò£üò£üò£',\n",
              "  't√°',\n",
              "  'bom',\n",
              "  'tamb√©m,',\n",
              "  't‚Ä¶'],\n",
              " ['sobre',\n",
              "  'pol√≠tica,',\n",
              "  'falando',\n",
              "  'vidas',\n",
              "  'antes',\n",
              "  'tudo',\n",
              "  'pense',\n",
              "  '14',\n",
              "  'mil',\n",
              "  'pessoas',\n",
              "  'vieram',\n",
              "  '√≥bito',\n",
              "  's‚Ä¶'],\n",
              " ['@srlm',\n",
              "  'silvio,',\n",
              "  'viu',\n",
              "  'uk',\n",
              "  '#fakenews',\n",
              "  'relaciona',\n",
              "  '5g',\n",
              "  '#covid',\n",
              "  '(!!!!',\n",
              "  'levando',\n",
              "  'pessoas',\n",
              "  'atacar',\n",
              "  'equipamen‚Ä¶'],\n",
              " ['@lucianohuck',\n",
              "  '#ditadoria',\n",
              "  'sobre',\n",
              "  '#covid',\n",
              "  'carnaval',\n",
              "  'cr√°pula,',\n",
              "  'sr',\n",
              "  '@lucianohuck‚Ä¶'],\n",
              " ['objetivo',\n",
              "  'salvar',\n",
              "  'vidas!',\n",
              "  'chega',\n",
              "  'politizar',\n",
              "  'v√≠rus',\n",
              "  '‚Ä¢',\n",
              "  '@biakicis',\n",
              "  '‚Ä¢',\n",
              "  '#cloroquina',\n",
              "  '#hospitaisprivados‚Ä¶'],\n",
              " ['ministro',\n",
              "  'sa√∫de',\n",
              "  'pediu',\n",
              "  'demiss√£o',\n",
              "  '#covid',\n",
              "  '@miltonneves',\n",
              "  '@leojaime',\n",
              "  '@danilogentili'],\n",
              " ['braga',\n",
              "  'dst',\n",
              "  'contratou',\n",
              "  '158',\n",
              "  'trabalhdores',\n",
              "  'durante',\n",
              "  'pandemia',\n",
              "  '#braga',\n",
              "  '#covid19',\n",
              "  '#dst'],\n",
              " ['marcos',\n",
              "  'pontes',\n",
              "  'visita',\n",
              "  'linha',\n",
              "  'montagem',\n",
              "  'ventiladores',\n",
              "  'pulmonares',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid'],\n",
              " ['sensa√ß√µes',\n",
              "  'paga',\n",
              "  'pode',\n",
              "  'sentir',\n",
              "  't√°',\n",
              "  'afim',\n",
              "  'pagar',\n",
              "  'pra',\n",
              "  'v√™?',\n",
              "  'ent√£o',\n",
              "  'agende',\n",
              "  'hor√°rio!',\n",
              "  'sinta',\n",
              "  'prazer',\n",
              "  'nessa',\n",
              "  'qua‚Ä¶'],\n",
              " ['plano',\n",
              "  'fuga?',\n",
              "  'melhor',\n",
              "  't√°',\n",
              "  'tendo',\n",
              "  'pra',\n",
              "  'entra',\n",
              "  'ali',\n",
              "  '#coronavirusplantao',\n",
              "  '#coronavirus',\n",
              "  '#coronaviruspandemic‚Ä¶'],\n",
              " ['\"quando',\n",
              "  'cabe√ßa',\n",
              "  'pensa,',\n",
              "  'corpo',\n",
              "  'padece\"',\n",
              "  '(ditado',\n",
              "  'av√≥',\n",
              "  '#coronavirusplantao',\n",
              "  '#covidiots',\n",
              "  '#coronavirus‚Ä¶'],\n",
              " ['brasil‚è¨',\n",
              "  '#fiqueemcasa',\n",
              "  '#ficaemcasa',\n",
              "  '#covid„Éº19',\n",
              "  '#coronavirusnobrasil',\n",
              "  '#coronavirus',\n",
              "  '#covid__19',\n",
              "  '#covid',\n",
              "  '#covid19',\n",
              "  '#brasil',\n",
              "  'b‚Ä¶'],\n",
              " ['relat√≥rio',\n",
              "  'semestral',\n",
              "  'sobre',\n",
              "  'regi√£o',\n",
              "  'am√©rica',\n",
              "  'latina',\n",
              "  'caribe',\n",
              "  'economia',\n",
              "  'tempos',\n",
              "  '#covid19',\n",
              "  '#economia‚Ä¶'],\n",
              " ['ter√ßafeira,',\n",
              "  '12/05,',\n",
              "  'riogale√£o',\n",
              "  'cargo',\n",
              "  'recebeu',\n",
              "  '1¬∫',\n",
              "  '6',\n",
              "  'voos',\n",
              "  'transportando',\n",
              "  'respiradores',\n",
              "  'equipamentos',\n",
              "  'm√©dicos',\n",
              "  'q‚Ä¶'],\n",
              " ['hj',\n",
              "  'not√≠cia',\n",
              "  'amigo',\n",
              "  '@edvaldonogueira',\n",
              "  'testou',\n",
              "  'positivo',\n",
              "  'p/',\n",
              "  '#covid',\n",
              "  'conhecer',\n",
              "  'garra',\n",
              "  'comprometimen‚Ä¶'],\n",
              " ['solidariedade',\n",
              "  'familiares,',\n",
              "  'amigas',\n",
              "  'amigos',\n",
              "  'rodolfo,',\n",
              "  'adufes',\n",
              "  'reitera',\n",
              "  'posi√ß√£o',\n",
              "  'afirmativa',\n",
              "  'prote√ß√£o',\n",
              "  'i‚Ä¶'],\n",
              " ['munic√≠pio',\n",
              "  'confirmou',\n",
              "  '√≥bito',\n",
              "  'paciente',\n",
              "  '68',\n",
              "  'anos,',\n",
              "  'moradora',\n",
              "  'bairro',\n",
              "  'retiro,',\n",
              "  'internada',\n",
              "  'hac',\n",
              "  'de‚Ä¶'],\n",
              " ['#covid',\n",
              "  '\\U0001f9a0',\n",
              "  '#brasil',\n",
              "  'sexta,',\n",
              "  '15',\n",
              "  'maio',\n",
              "  '2020',\n",
              "  '‚§µÔ∏è',\n",
              "  '‚ñ∂Ô∏è218223',\n",
              "  'casos',\n",
              "  '‚ñ∂Ô∏è14817',\n",
              "  '√≥bitos',\n",
              "  '#rn',\n",
              "  'üò∑',\n",
              "  '‚è∫',\n",
              "  '2786',\n",
              "  '#casos',\n",
              "  '‚è∫‚Ä¶'],\n",
              " ['aulas',\n",
              "  'online',\n",
              "  'seguem',\n",
              "  'firme',\n",
              "  'duas',\n",
              "  'novas',\n",
              "  'alunas',\n",
              "  'encararam',\n",
              "  'desafio',\n",
              "  'plena',\n",
              "  'pandemia!',\n",
              "  'assim',\n",
              "  'seguimos',\n",
              "  'vencendo',\n",
              "  'nossa‚Ä¶'],\n",
              " ['infelizmente',\n",
              "  'carro√ßa',\n",
              "  'brasil',\n",
              "  'burro',\n",
              "  'dianteira!!!',\n",
              "  '#bolsonarorainhalouca',\n",
              "  '#bolsonaroassassino‚Ä¶'],\n",
              " ['t√©nis', 'prolonga', 'suspens√£o', '31', 'julho', '#covid19', '#t√©nis'],\n",
              " ['sporting',\n",
              "  'prolonga',\n",
              "  '‚Äòlayoff‚Äô',\n",
              "  '30',\n",
              "  'dias',\n",
              "  '#covid19',\n",
              "  '#futebol',\n",
              "  '#iliga'],\n",
              " ['pandemia',\n",
              "  'vai',\n",
              "  '‚Äúrecentrar',\n",
              "  'posi√ß√£o',\n",
              "  'adepto‚Äù',\n",
              "  'futebol',\n",
              "  '#covid19',\n",
              "  '#futebol'],\n",
              " ['@cesargomes23',\n",
              "  '@gugachacra',\n",
              "  'vai',\n",
              "  'pra',\n",
              "  'rua!',\n",
              "  'sabe',\n",
              "  'vc',\n",
              "  'pega',\n",
              "  '#covid',\n",
              "  'a√≠',\n",
              "  'ficar',\n",
              "  '100%',\n",
              "  'morto',\n",
              "  'calado,',\n",
              "  'ningu√©m',\n",
              "  'a‚Ä¶'],\n",
              " ['83',\n",
              "  'mortes',\n",
              "  'dia',\n",
              "  'hoje',\n",
              "  '(15/05/2020',\n",
              "  'estado',\n",
              "  'pernambuco',\n",
              "  'üò≠',\n",
              "  'ainda',\n",
              "  'dizem',\n",
              "  'lockdow',\n",
              "  'necess√°ri‚Ä¶'],\n",
              " ['dia',\n",
              "  '30/03/2020',\n",
              "  'it√°lia',\n",
              "  '100000',\n",
              "  'casos',\n",
              "  'covid',\n",
              "  'br',\n",
              "  'debochava',\n",
              "  'apenas',\n",
              "  '4,500',\n",
              "  'casos',\n",
              "  'amanh√£',\n",
              "  'dia',\n",
              "  '16/05/2020',\n",
              "  'o‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'brasil',\n",
              "  'bate',\n",
              "  'recorde',\n",
              "  'registra',\n",
              "  '15,3',\n",
              "  'mil',\n",
              "  'casos',\n",
              "  'dia',\n",
              "  'outras',\n",
              "  '824',\n",
              "  'mortes',\n",
              "  'inclu√≠das‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'brasil',\n",
              "  'bate',\n",
              "  'recorde',\n",
              "  'registra',\n",
              "  '15,3',\n",
              "  'mil',\n",
              "  'casos',\n",
              "  'dia',\n",
              "  'outras',\n",
              "  '824',\n",
              "  'mortes',\n",
              "  'inclu√≠das‚Ä¶'],\n",
              " ['governo',\n",
              "  'prop√µe',\n",
              "  'prolongamento',\n",
              "  '01',\n",
              "  'setembro',\n",
              "  'empr√©stimos',\n",
              "  'rendas',\n",
              "  '#covid19',\n",
              "  '#economia',\n",
              "  '#habita√ß√£o'],\n",
              " ['feiras',\n",
              "  'mercados',\n",
              "  'reabrem',\n",
              "  'segundafeira',\n",
              "  'plano',\n",
              "  'conting√™ncia',\n",
              "  '#covid19',\n",
              "  '#economia',\n",
              "  '#feiras'],\n",
              " ['dr',\n",
              "  'rey',\n",
              "  'minist√©rio',\n",
              "  'sa√∫de?',\n",
              "  'menos',\n",
              "  'engra√ßado',\n",
              "  'certamente',\n",
              "  'iria',\n",
              "  'usar',\n",
              "  'terno',\n",
              "  'aberto,',\n",
              "  'camisa',\n",
              "  'co‚Ä¶'],\n",
              " ['caminha',\n",
              "  'vai',\n",
              "  'ter',\n",
              "  'equipas',\n",
              "  'aconselhamento',\n",
              "  'cada',\n",
              "  'praia',\n",
              "  '#caminha',\n",
              "  '#covid19',\n",
              "  '#praia'],\n",
              " ['telesus',\n",
              "  'criado',\n",
              "  'aproximar',\n",
              "  'minist√©rio',\n",
              "  'sa√∫de',\n",
              "  'modo',\n",
              "  'combate',\n",
              "  'coronav√≠rus',\n",
              "  'faci‚Ä¶'],\n",
              " ['gente',\n",
              "  'moro',\n",
              "  'perdeu',\n",
              "  'tempo!',\n",
              "  '#nelsonteich',\n",
              "  '#covid',\n",
              "  '#moro',\n",
              "  '#estoufechadocombolsonaro'],\n",
              " ['pois',\n",
              "  'china',\n",
              "  'criou',\n",
              "  'doen√ßa',\n",
              "  'poder',\n",
              "  'vender',\n",
              "  'vacinas',\n",
              "  'podemos',\n",
              "  'deixar',\n",
              "  'guerreiro',\n",
              "  'brasileiro,',\n",
              "  'negr‚Ä¶'],\n",
              " ['aten√ß√£o,',\n",
              "  'veja',\n",
              "  'pagamento',\n",
              "  '2¬™',\n",
              "  'parcela',\n",
              "  'aux√≠lio',\n",
              "  'emergencial',\n",
              "  '#coronavirus',\n",
              "  '#covid_19',\n",
              "  '#covid‚Ä¶'],\n",
              " ['amanh√£',\n",
              "  'estado',\n",
              "  'pernambuco',\n",
              "  'estar√°',\n",
              "  'lockdown',\n",
              "  'queremos',\n",
              "  'pedir',\n",
              "  'todos',\n",
              "  'respeitem',\n",
              "  'orienta√ß√µes,',\n",
              "  'conforme',\n",
              "  'i‚Ä¶'],\n",
              " ['falta',\n",
              "  'representatividade',\n",
              "  'poder',\n",
              "  'd√°',\n",
              "  'nisso',\n",
              "  'completo',\n",
              "  'desconhecimento',\n",
              "  'realidade',\n",
              "  'pa√≠s',\n",
              "  '(ou',\n",
              "  'm√°',\n",
              "  'f√©',\n",
              "  'mesmo,',\n",
              "  'pe‚Ä¶'],\n",
              " ['gente',\n",
              "  'sexta',\n",
              "  'casa!!',\n",
              "  '#40tena',\n",
              "  '#coronga',\n",
              "  '#covid',\n",
              "  '#sextou',\n",
              "  '#rebola',\n",
              "  '#instabola',\n",
              "  '#bolarebola',\n",
              "  '#tremetreme‚Ä¶'],\n",
              " ['cloroquina',\n",
              "  'jesuis',\n",
              "  'tiririca',\n",
              "  'ministro',\n",
              "  'sa√∫de',\n",
              "  'salva√ß√£o',\n",
              "  'pior',\n",
              "  't√°',\n",
              "  'fica!',\n",
              "  '#brasil',\n",
              "  '#teich',\n",
              "  '#mandetta‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'vagas',\n",
              "  'emprego',\n",
              "  'hospital',\n",
              "  'regional',\n",
              "  'guarapuava/pr',\n",
              "  '|',\n",
              "  'jnot√≠cias'],\n",
              " ['insista',\n",
              "  'm√©dico',\n",
              "  'prescrever',\n",
              "  'medicamentos,',\n",
              "  'sabe',\n",
              "  'melhor',\n",
              "  'tome',\n",
              "  '#cloroquina',\n",
              "  'c‚Ä¶'],\n",
              " ['partir',\n",
              "  '19',\n",
              "  'maio,',\n",
              "  'macap√°',\n",
              "  'entrar√°',\n",
              "  'isolamento',\n",
              "  'social',\n",
              "  'r√≠gido',\n",
              "  'combater',\n",
              "  'cont√°gio',\n",
              "  'corona',\n",
              "  'v√≠rus‚Ä¶'],\n",
              " ['‚Äúbrasil',\n",
              "  '14817',\n",
              "  'mortes',\n",
              "  '218223',\n",
              "  'casos',\n",
              "  'confirmados',\n",
              "  'novo',\n",
              "  'coronav√≠rus,',\n",
              "  'diz',\n",
              "  'minist√©rio‚Äù',\n",
              "  '#coronavirus',\n",
              "  '#covid‚Ä¶'],\n",
              " ['@xicograziano',\n",
              "  'onde',\n",
              "  'est√°?',\n",
              "  'acaba',\n",
              "  'pandemia',\n",
              "  'gastan√ßa',\n",
              "  'dinheiro',\n",
              "  'federal',\n",
              "  'licita√ß√£o,',\n",
              "  'economia',\n",
              "  'volta‚Ä¶'],\n",
              " ['disse',\n",
              "  '@luizbacci',\n",
              "  '\"',\n",
              "  'favor',\n",
              "  'isolamento',\n",
              "  'social',\n",
              "  'condi√ß√µes\"',\n",
              "  'adianta',\n",
              "  'querer',\n",
              "  'travar',\n",
              "  'qu‚Ä¶'],\n",
              " ['acho',\n",
              "  'trump',\n",
              "  'method',\n",
              "  'similar',\n",
              "  'm√©todo',\n",
              "  'bolsonaro',\n",
              "  '#forabolsonaro',\n",
              "  '#ci√™ncia',\n",
              "  '#m√©todocientifico',\n",
              "  '#covid'],\n",
              " ['ainda',\n",
              "  'esperan√ßa!',\n",
              "  'recife',\n",
              "  'come√ßa',\n",
              "  'reagir',\n",
              "  'contra',\n",
              "  'governador',\n",
              "  'paulo',\n",
              "  'c√¢mara',\n",
              "  'pernambuco',\n",
              "  'come√ßa',\n",
              "  'reagir',\n",
              "  'sob‚Ä¶'],\n",
              " ['fique',\n",
              "  'casa',\n",
              "  'promo√ß√£o',\n",
              "  'artes',\n",
              "  'divulga√ß√£o',\n",
              "  'produtos#bbb20',\n",
              "  '#redebbb',\n",
              "  '#perguntacorona',\n",
              "  '#globo',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['8/365',\n",
              "  '(sem',\n",
              "  'legenda',\n",
              "  '#illustration',\n",
              "  '#drawing',\n",
              "  '#bolsonaro',\n",
              "  '#covid',\n",
              "  '#digitalart'],\n",
              " ['filmes',\n",
              "  'gospel',\n",
              "  'beb√™',\n",
              "  'outubro',\n",
              "  'link',\n",
              "  'ap√≥s',\n",
              "  'ir',\n",
              "  'parar',\n",
              "  'hospital',\n",
              "  's√©rios',\n",
              "  'problemas',\n",
              "  's‚Ä¶'],\n",
              " ['ministro',\n",
              "  'educa√ß√£o',\n",
              "  'explicando',\n",
              "  'meritocracia',\n",
              "  '‚Äú',\n",
              "  '@proenemoficial',\n",
              "  'resolver',\n",
              "  'problema',\n",
              "  'social,',\n",
              "  'escolh‚Ä¶'],\n",
              " ['sindicato',\n",
              "  'm√©dicos',\n",
              "  '#cear√°',\n",
              "  'denuncia',\n",
              "  'press√£o',\n",
              "  'atestar',\n",
              "  '#covid',\n",
              "  '√≥bitos'],\n",
              " ['casos',\n",
              "  '#covid',\n",
              "  '#guarulhos',\n",
              "  'chegam',\n",
              "  '1426,',\n",
              "  '160',\n",
              "  'mortes',\n",
              "  'fonte',\n",
              "  'seade,',\n",
              "  '15/05',\n",
              "  '1400'],\n",
              " ['caos,',\n",
              "  'resumindo',\n",
              "  'mitologia',\n",
              "  'grega',\n",
              "  'origem',\n",
              "  'palavra',\n",
              "  'come√ßo',\n",
              "  'fim',\n",
              "  'tudo',\n",
              "  'separa√ß√£o,',\n",
              "  'abismo',\n",
              "  'que‚Ä¶'],\n",
              " ['presidente',\n",
              "  'chin√™ses,',\n",
              "  'xi',\n",
              "  'jinping,',\n",
              "  'sabe',\n",
              "  'quanto',\n",
              "  'perigoso',\n",
              "  'conter',\n",
              "  'covid19,',\n",
              "  'respons√°vel',\n",
              "  'milh‚Ä¶'],\n",
              " ['not√≠cias',\n",
              "  'dia!',\n",
              "  '#lockdown',\n",
              "  'prorrogado',\n",
              "  'par√°!',\n",
              "  'an√∫ncio',\n",
              "  'feito',\n",
              "  'governador',\n",
              "  '@helderbarbalho',\n",
              "  '#noticias‚Ä¶'],\n",
              " ['objetivo',\n",
              "  'controlar',\n",
              "  'pandemia,',\n",
              "  'liberado,',\n",
              "  'minist√©rio',\n",
              "  'sa√∫de,',\n",
              "  'telemedicinaüë©üî¨üë®üî¨üë©üíªüë®üíª',\n",
              "  '‚†Ä',\n",
              "  'üë®üíª',\n",
              "  'mark‚Ä¶'],\n",
              " ['nojo',\n",
              "  'dessa',\n",
              "  '#damares',\n",
              "  '#foraguedes',\n",
              "  '#impeachmentdobolsonarourgente',\n",
              "  '#forabraganetto',\n",
              "  '#foraosmarterra‚Ä¶'],\n",
              " ['usar',\n",
              "  'm√°scaras',\n",
              "  'ajuda',\n",
              "  'estimular',\n",
              "  'contato',\n",
              "  'olho',\n",
              "  'olho,',\n",
              "  'pode',\n",
              "  'ser',\n",
              "  'bom',\n",
              "  'rela√ß√µes',\n",
              "  'humanas',\n",
              "  'pois',\n",
              "  'olhar‚Ä¶'],\n",
              " ['dia',\n",
              "  'ministro',\n",
              "  'sa√∫de',\n",
              "  'alertar',\n",
              "  'efeitos',\n",
              "  'colaterais,',\n",
              "  'presidente',\n",
              "  'quer',\n",
              "  'rem√©dio',\n",
              "  'usado',\n",
              "  'paci‚Ä¶'],\n",
              " ['assistindo',\n",
              "  'trecho',\n",
              "  'titanic',\n",
              "  'tv',\n",
              "  'fez',\n",
              "  'lembrar',\n",
              "  'sensa√ß√£o',\n",
              "  'ler',\n",
              "  'not√≠cias',\n",
              "  'brasil!',\n",
              "  '#tenso‚Ä¶'],\n",
              " ['maldito',\n",
              "  'ta',\n",
              "  'fazendo',\n",
              "  '#terrorismo',\n",
              "  '#osmarterraterrorista',\n",
              "  '#covid',\n",
              "  '#forabolsonaro',\n",
              "  '#impeachmentbolsonarourgente'],\n",
              " ['bolsonaro',\n",
              "  'manda',\n",
              "  'general',\n",
              "  'assinar',\n",
              "  'decreto',\n",
              "  'libera√ß√£o',\n",
              "  'cloroquina',\n",
              "  '#jairbolsonaro',\n",
              "  '#bolsonaro',\n",
              "  '#cloroquina',\n",
              "  '#stf‚Ä¶'],\n",
              " ['jap√£o',\n",
              "  'inicia',\n",
              "  'fornecimento',\n",
              "  'antiviral',\n",
              "  'tratar',\n",
              "  'pacientes',\n",
              "  '#covid19',\n",
              "  '#doenca',\n",
              "  '#saude',\n",
              "  '#coronavirus'],\n",
              " ['aguento',\n",
              "  'discutir',\n",
              "  'sobre',\n",
              "  '#desgoverno',\n",
              "  'sobre',\n",
              "  '#covid',\n",
              "  'tentar',\n",
              "  'colocar',\n",
              "  'pouco',\n",
              "  'humanidade',\n",
              "  'cora‚Ä¶'],\n",
              " ['respiradores',\n",
              "  'montes',\n",
              "  'jogados',\n",
              "  'canto',\n",
              "  'desse',\n",
              "  'brasilz√£o',\n",
              "  'futuro',\n",
              "  'distantesim',\n",
              "  'certeza?',\n",
              "  '#covid',\n",
              "  'üáßüá∑'],\n",
              " ['dia',\n",
              "  'seguinte',\n",
              "  'rio',\n",
              "  'bate',\n",
              "  'novo',\n",
              "  'recorde',\n",
              "  'mortes',\n",
              "  '#covid',\n",
              "  ',',\n",
              "  'governador',\n",
              "  '@wilsonwitzel',\n",
              "  'comanda',\n",
              "  'mega‚Ä¶'],\n",
              " ['futuro', 'prossimo', '#covid', '#delazione', '@kevinjames', '#short'],\n",
              " ['campina',\n",
              "  'grande',\n",
              "  '101',\n",
              "  'novos',\n",
              "  'casos',\n",
              "  'positivos',\n",
              "  'pra',\n",
              "  'covid19',\n",
              "  'dia!',\n",
              "  'cidade',\n",
              "  'saiu',\n",
              "  '160',\n",
              "  'casos',\n",
              "  '261',\n",
              "  'result‚Ä¶'],\n",
              " ['vamos',\n",
              "  'falar',\n",
              "  'sobre',\n",
              "  '#recupera√ß√£ojudicial',\n",
              "  'raz√£o',\n",
              "  '#covid19?',\n",
              "  'acessar',\n",
              "  'artigos,',\n",
              "  'acessem',\n",
              "  'sit‚Ä¶'],\n",
              " ['fique',\n",
              "  'casa',\n",
              "  'promo√ß√£o',\n",
              "  'artes',\n",
              "  'divulga√ß√£o',\n",
              "  'produtos#bbb20',\n",
              "  '#redebbb',\n",
              "  '#perguntacorona',\n",
              "  '#globo',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['recurso',\n",
              "  'conta!!',\n",
              "  'parab√©ns',\n",
              "  'bancada',\n",
              "  'federal',\n",
              "  'amap√°',\n",
              "  'trabalhado',\n",
              "  'incansavelmente',\n",
              "  'conseguir',\n",
              "  'recursos',\n",
              "  'p‚Ä¶'],\n",
              " ['confira',\n",
              "  'n√∫meros',\n",
              "  'pandemia',\n",
              "  'covid19',\n",
              "  'brasil',\n",
              "  'mundo',\n",
              "  'hoje',\n",
              "  '(15/05',\n",
              "  'boletim',\n",
              "  'cognys',\n",
              "  'desta',\n",
              "  'semana',\n",
              "  '‚†Ä‚Ä¶'],\n",
              " ['fossemos',\n",
              "  'prever',\n",
              "  'situa√ß√£o',\n",
              "  'casos',\n",
              "  '#covid',\n",
              "  '#novaigua√ßu',\n",
              "  'seria?'],\n",
              " ['pa√≠s',\n",
              "  'mortes',\n",
              "  'pandemia',\n",
              "  '#covid19,',\n",
              "  'eua',\n",
              "  'reabrir√£o',\n",
              "  'economia',\n",
              "  'trump',\n",
              "  '‚Äúest√°',\n",
              "  'tentando',\n",
              "  'for√ßar',\n",
              "  'economi‚Ä¶'],\n",
              " ['#mec',\n",
              "  'prorroga',\n",
              "  'autoriza√ß√£o',\n",
              "  'cursos',\n",
              "  'dist√¢ncia',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid'],\n",
              " ['#covid19',\n",
              "  '|',\n",
              "  'acompanhe',\n",
              "  'evolu√ß√£o',\n",
              "  'doen√ßa',\n",
              "  'munic√≠pio',\n",
              "  '#sigacariacica',\n",
              "  '#fiqueemcasa',\n",
              "  '#fiqueemcasaparasalvarvidas‚Ä¶'],\n",
              " ['primeira',\n",
              "  'mentira',\n",
              "  'toda',\n",
              "  'verdade',\n",
              "  'vira',\n",
              "  'd√∫vida',\n",
              "  '#coronavirus',\n",
              "  '#covid__19',\n",
              "  '#covid',\n",
              "  '#goiania',\n",
              "  '#brasil',\n",
              "  '#kuwait',\n",
              "  '#lebanon',\n",
              "  '#curfew',\n",
              "  '#you'],\n",
              " ['passe',\n",
              "  'm√°gica',\n",
              "  'torna',\n",
              "  'melhor',\n",
              "  'm√©dico',\n",
              "  'mundo,',\n",
              "  'equilibrado,',\n",
              "  'coerente',\n",
              "  's√©rio,',\n",
              "  'mostra',\n",
              "  'q',\n",
              "  'raiva',\n",
              "  's√≥‚Ä¶'],\n",
              " ['ministro',\n",
              "  'paulo',\n",
              "  'guedes',\n",
              "  'acha',\n",
              "  'tirando',\n",
              "  'impostos',\n",
              "  'sobre',\n",
              "  'empres√°rio',\n",
              "  'trabalhadores',\n",
              "  'receber√£o',\n",
              "  'maior',\n",
              "  'sal√°rio',\n",
              "  'no‚Ä¶'],\n",
              " ['povo',\n",
              "  't√°',\n",
              "  'debochando',\n",
              "  'artigo',\n",
              "  'chin√™s',\n",
              "  'sobre',\n",
              "  'cloroquina',\n",
              "  'sabe',\n",
              "  'ventiladores,as',\n",
              "  'm√°scaras,luvas',\n",
              "  'outros',\n",
              "  'u‚Ä¶'],\n",
              " ['#rnp', 'combate', '#covid', 'percam', '@tvbrasil'],\n",
              " ['psicologia',\n",
              "  'reversa,',\n",
              "  'super',\n",
              "  'funciona!!!',\n",
              "  '√≥tima',\n",
              "  'ideia',\n",
              "  '@bolsonarosp',\n",
              "  '@jairbolsonaro',\n",
              "  '#covid‚Ä¶'],\n",
              " ['@recifeordinario',\n",
              "  'ficar',\n",
              "  'casa',\n",
              "  '√∫nica',\n",
              "  'forma',\n",
              "  'eficaz',\n",
              "  'proteger',\n",
              "  'proteger',\n",
              "  'outros',\n",
              "  '#covid',\n",
              "  'quantas',\n",
              "  'pessoa‚Ä¶'],\n",
              " ['@profpaulamarisa',\n",
              "  'pior',\n",
              "  'cego',\n",
              "  'ver,',\n",
              "  'gostaria',\n",
              "  'saber',\n",
              "  'quanto',\n",
              "  'cada',\n",
              "  'adorador',\n",
              "  '@jairbolsonaro',\n",
              "  'ganha',\n",
              "  'p‚Ä¶'],\n",
              " ['pacientes',\n",
              "  'q',\n",
              "  'quadro',\n",
              "  'doen√ßa',\n",
              "  'grave,',\n",
              "  'acho',\n",
              "  'q',\n",
              "  'governo',\n",
              "  'l√°',\n",
              "  'tbm',\n",
              "  'deve',\n",
              "  'ser',\n",
              "  'louco',\n",
              "  'n√©,',\n",
              "  'ah!',\n",
              "  'piau√≠',\n",
              "  'tbm',\n",
              "  'est√£‚Ä¶'],\n",
              " ['deus',\n",
              "  'miseric√≥rdia',\n",
              "  'n√≥s,',\n",
              "  'pq',\n",
              "  'depender',\n",
              "  '\"certa',\n",
              "  'pessoa\"',\n",
              "  'todos',\n",
              "  'mortos',\n",
              "  '!',\n",
              "  '#covid1948',\n",
              "  '#covid',\n",
              "  '#coronavirus'],\n",
              " ['15/5',\n",
              "  '#covid',\n",
              "  '#paran√°',\n",
              "  '(3/3',\n",
              "  '#fiqueemcasa',\n",
              "  '1047(+250',\n",
              "  'investig',\n",
              "  '1477(+28',\n",
              "  'recuperados',\n",
              "  '19796(+852',\n",
              "  'exames',\n",
              "  '17273(+55‚Ä¶'],\n",
              " ['conquista',\n",
              "  'lidera',\n",
              "  'vilas',\n",
              "  'cachoeira',\n",
              "  'nazar√©',\n",
              "  '¬¥o√°sis¬¥',\n",
              "  'pandemia',\n",
              "  'ilh√©us'],\n",
              " ['fique',\n",
              "  'casa',\n",
              "  'promo√ß√£o',\n",
              "  'artes',\n",
              "  'divulga√ß√£o',\n",
              "  'produtos#bbb20',\n",
              "  '#redebbb',\n",
              "  '#perguntacorona',\n",
              "  '#globo',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['gostaria',\n",
              "  'acreditar,',\n",
              "  'infelizmente',\n",
              "  '#megarodizio',\n",
              "  '@prefsp',\n",
              "  'fazendo',\n",
              "  'efeito',\n",
              "  'desej√°vel',\n",
              "  'deve',\n",
              "  'ser‚Ä¶'],\n",
              " ['#covid',\n",
              "  'm√©dica',\n",
              "  'medicina',\n",
              "  'interna',\n",
              "  'centro',\n",
              "  'hospital',\n",
              "  't√¢mega',\n",
              "  'sousa,',\n",
              "  'rita',\n",
              "  'neto,',\n",
              "  'partilha',\n",
              "  'imagens',\n",
              "  'urg√™ncia',\n",
              "  'c‚Ä¶'],\n",
              " ['vamos', 'ajudar!', '#covid', '#manaus', '#catadores', '@tjamazonas'],\n",
              " ['gente',\n",
              "  'salta',\n",
              "  'olhos,',\n",
              "  'rep√≥rter',\n",
              "  'corta',\n",
              "  'entrevistado',\n",
              "  'hora',\n",
              "  'q',\n",
              "  'vai',\n",
              "  'citar',\n",
              "  'nome',\n",
              "  '#cloroquina',\n",
              "  'rem√©dio',\n",
              "  'q‚Ä¶'],\n",
              " ['doutores',\n",
              "  'samba',\n",
              "  'banda',\n",
              "  'm√©dicos',\n",
              "  'faz',\n",
              "  'parte',\n",
              "  'hist√≥ria',\n",
              "  'acad√™mica',\n",
              "  'unife‚Ä¶'],\n",
              " ['siga',\n",
              "  'recomenda√ß√µes',\n",
              "  'prevenir',\n",
              "  'propaga√ß√£o',\n",
              "  'novo',\n",
              "  'coronav√≠rus',\n",
              "  '#coronavirus',\n",
              "  '#coronav√≠rus',\n",
              "  '#coronavirusbrazil‚Ä¶'],\n",
              " ['atualiza√ß√£o',\n",
              "  '1505',\n",
              "  'painel',\n",
              "  '#covid19',\n",
              "  '#covid',\n",
              "  '#coronav√≠rus',\n",
              "  '#powerbi',\n",
              "  '#teres√≥polis'],\n",
              " ['confesso',\n",
              "  'ser',\n",
              "  'desligado',\n",
              "  'momento',\n",
              "  'pandemia',\n",
              "  'dois',\n",
              "  'rec√©m',\n",
              "  'nascidos',\n",
              "  'casa',\n",
              "  '(por',\n",
              "  'fofinhos',\n",
              "  'se‚Ä¶'],\n",
              " ['tragote',\n",
              "  'verdades',\n",
              "  '#covid',\n",
              "  '#bolsonaro',\n",
              "  '#pt',\n",
              "  '#midia',\n",
              "  '#globolixo'],\n",
              " ['live',\n",
              "  'hoje',\n",
              "  '18h',\n",
              "  '&gt',\n",
              "  '‚Äúmoradia',\n",
              "  'estudantil',\n",
              "  '#unicamp',\n",
              "  '#covid19‚Äù',\n",
              "  'unicamp',\n",
              "  'confirma',\n",
              "  'primeiro',\n",
              "  'caso',\n",
              "  'covid19‚Ä¶'],\n",
              " ['combate',\n",
              "  '#covid19',\n",
              "  'continua!',\n",
              "  'roraima',\n",
              "  'instaladas',\n",
              "  '15',\n",
              "  'esta√ß√µes',\n",
              "  'lavagem',\n",
              "  'm√£os',\n",
              "  '23',\n",
              "  'caixas',\n",
              "  'abastec‚Ä¶'],\n",
              " ['estudo',\n",
              "  'mostra',\n",
              "  'combina√ß√£o',\n",
              "  'hidroxicloroquinazinco',\n",
              "  'eficaz',\n",
              "  'contra',\n",
              "  'covid19',\n",
              "  '#coronav√≠rus',\n",
              "  '#covid'],\n",
              " ['cadeia',\n",
              "  'sempre',\n",
              "  'lugar',\n",
              "  'pra',\n",
              "  'm√£os',\n",
              "  'um!!!',\n",
              "  '#bolsonarorainhalouca',\n",
              "  '#bolsonaroassassino',\n",
              "  '#bolsonaroficaquieto',\n",
              "  '#bolsonaro‚Ä¶'],\n",
              " ['aten√ß√£o',\n",
              "  'tuita√ßo!',\n",
              "  'üåäüåäüåä',\n",
              "  '#enem2020',\n",
              "  '#enem',\n",
              "  '#educa√ß√£o',\n",
              "  '#adiaenem',\n",
              "  '#forabolsonaro',\n",
              "  '#foraweintraub‚Ä¶'],\n",
              " ['rumo',\n",
              "  'caos',\n",
              "  'via',\n",
              "  '@guiasobrevivent',\n",
              "  '#prepara√ß√£o',\n",
              "  '#sobrevivencialismo',\n",
              "  '#xequemate',\n",
              "  '#teich',\n",
              "  '#covid',\n",
              "  '#guiadosobrevivente'],\n",
              " ['terras',\n",
              "  'bouro',\n",
              "  'assegura',\n",
              "  'transporte',\n",
              "  'alunos',\n",
              "  '11¬∫',\n",
              "  '12¬∫',\n",
              "  'anos',\n",
              "  '#covid19',\n",
              "  '#educa√ß√£o',\n",
              "  '#terrasdebouro'],\n",
              " ['dia',\n",
              "  '12/3',\n",
              "  'dia',\n",
              "  '14/5,',\n",
              "  'recebidas',\n",
              "  '#funedmg',\n",
              "  '17222',\n",
              "  'amostras',\n",
              "  'casos',\n",
              "  'notificados',\n",
              "  's√≠ndromes',\n",
              "  'respirat√≥r‚Ä¶'],\n",
              " ['(multim√≠dia',\n",
              "  '#china',\n",
              "  'apoia',\n",
              "  'firmemente',\n",
              "  'luta',\n",
              "  '#r√∫ssia',\n",
              "  'contra',\n",
              "  '#covid19,',\n",
              "  'diz',\n",
              "  'portavoz'],\n",
              " ['13',\n",
              "  'mil',\n",
              "  'afetados',\n",
              "  '98',\n",
              "  'perderam',\n",
              "  'vida',\n",
              "  'segundo',\n",
              "  '\\u2066@cofen_oficial\\u2069',\n",
              "  'enfermeiros,',\n",
              "  't√©cnicos,',\n",
              "  'auxiliares',\n",
              "  'outros',\n",
              "  'profissi‚Ä¶'],\n",
              " ['ficam',\n",
              "  'rindo,',\n",
              "  'mas,',\n",
              "  'assim',\n",
              "  'g√™meos',\n",
              "  'batizados',\n",
              "  '#covid',\n",
              "  '#corona,',\n",
              "  'breve',\n",
              "  'v√°rias',\n",
              "  'c‚Ä¶'],\n",
              " ['fique',\n",
              "  'casa',\n",
              "  'promo√ß√£o',\n",
              "  'artes',\n",
              "  'divulga√ß√£o',\n",
              "  'produtos#bbb20',\n",
              "  '#redebbb',\n",
              "  '#perguntacorona',\n",
              "  '#globo',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['dist√¢ncia',\n",
              "  'ideal',\n",
              "  'fazer',\n",
              "  'atividade',\n",
              "  'f√≠sica',\n",
              "  'ar',\n",
              "  'livre',\n",
              "  'nessa',\n",
              "  '#quarentena',\n",
              "  '#covid19',\n",
              "  '?',\n",
              "  'infogr√°fico',\n",
              "  'simula‚Ä¶'],\n",
              " ['#matogrosso',\n",
              "  '#indea',\n",
              "  'fechado',\n",
              "  'ap√≥s',\n",
              "  'servidor',\n",
              "  'testar',\n",
              "  'positivo',\n",
              "  '#covid19'],\n",
              " ['fraco',\n",
              "  'fragil',\n",
              "  'estupido',\n",
              "  '#eugostodevoce',\n",
              "  '#inmaturo',\n",
              "  '#jao',\n",
              "  '#lobos',\n",
              "  '#brasil',\n",
              "  '#sp',\n",
              "  '#saopaulo',\n",
              "  '#cover',\n",
              "  '#pop',\n",
              "  '#instagay‚Ä¶'],\n",
              " ['cinco',\n",
              "  'jornalistas',\n",
              "  'infectados',\n",
              "  '#covid',\n",
              "  'dois',\n",
              "  'rio,',\n",
              "  'paulo,',\n",
              "  'cear√°',\n",
              "  'maranh√£o‚Ä¶'],\n",
              " ['#l√≠deres',\n",
              "  'paran√°',\n",
              "  'a√ß√£o',\n",
              "  's√©rie',\n",
              "  'lives',\n",
              "  'conceito',\n",
              "  'informar',\n",
              "  'conectar',\n",
              "  'l√≠deres',\n",
              "  'reflex√µes',\n",
              "  'sobre',\n",
              "  'o‚Ä¶'],\n",
              " ['‚òëchapec√≥',\n",
              "  'divulga',\n",
              "  'partir',\n",
              "  'hoje',\n",
              "  'n√∫meros',\n",
              "  'casos',\n",
              "  'confirmados',\n",
              "  'bairros,',\n",
              "  'loteamentos',\n",
              "  'distritos,',\n",
              "  'onde',\n",
              "  'houve‚Ä¶'],\n",
              " ['#covid19',\n",
              "  'deve',\n",
              "  'ser',\n",
              "  'tratada',\n",
              "  'doen√ßa',\n",
              "  'tromb√≥tica,',\n",
              "  'afirma',\n",
              "  'm√©dica',\n",
              "  'brasileira'],\n",
              " ['mundo',\n",
              "  'p√≥s',\n",
              "  '#covid19,',\n",
              "  'vai',\n",
              "  'ser?',\n",
              "  'confira',\n",
              "  'texto',\n",
              "  'blog',\n",
              "  'deixe',\n",
              "  'coment√°rio',\n",
              "  'aqui',\n",
              "  '=]‚Ä¶'],\n",
              " ['pesquisadores',\n",
              "  '#israel',\n",
              "  'criaram',\n",
              "  'aparelho',\n",
              "  'semelhante',\n",
              "  'baf√¥metro',\n",
              "  'capaz',\n",
              "  'detectar',\n",
              "  'presen√ßa',\n",
              "  '#covid19',\n",
              "  'na‚Ä¶'],\n",
              " ['hoje',\n",
              "  'gente',\n",
              "  'quer',\n",
              "  'desejar',\n",
              "  '√≥timo',\n",
              "  'final',\n",
              "  'semana',\n",
              "  'fam√≠lia',\n",
              "  '‚ù§',\n",
              "  'viva',\n",
              "  'fam√≠lia',\n",
              "  'üòò',\n",
              "  'üëâ',\n",
              "  '15',\n",
              "  'maio',\n",
              "  'dia‚Ä¶'],\n",
              " ['fique',\n",
              "  'casa',\n",
              "  'promo√ß√£o',\n",
              "  'artes',\n",
              "  'divulga√ß√£o',\n",
              "  'produtos#bbb20',\n",
              "  '#redebbb',\n",
              "  '#perguntacorona',\n",
              "  '#globo',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['boletim',\n",
              "  'turismo',\n",
              "  '|',\n",
              "  'covid19',\n",
              "  'mar√ßo',\n",
              "  '2020',\n",
              "  'brasil',\n",
              "  'retra√ß√£o',\n",
              "  '30%',\n",
              "  '√≠ndice',\n",
              "  'atividades',\n",
              "  'tur√≠sticas',\n",
              "  'n‚Ä¶'],\n",
              " ['\\U0001f9a0\\U0001f9a0',\n",
              "  'boletim',\n",
              "  'coronav√≠rus',\n",
              "  '#covid19',\n",
              "  '|',\n",
              "  'confira',\n",
              "  'atualiza√ß√£o',\n",
              "  'boletim',\n",
              "  'municipal',\n",
              "  'desta',\n",
              "  'sexta',\n",
              "  '(15/05'],\n",
              " ['boletim',\n",
              "  'coronav√≠rus',\n",
              "  '#covid19',\n",
              "  '|',\n",
              "  'confira',\n",
              "  'atualiza√ß√£o',\n",
              "  'boletim',\n",
              "  'municipal',\n",
              "  'desta',\n",
              "  'sextafeira',\n",
              "  '(15/05',\n",
              "  'info‚Ä¶'],\n",
              " ['paciente',\n",
              "  'casos',\n",
              "  'suspeitos',\n",
              "  'notificados',\n",
              "  'vigil√¢ncia',\n",
              "  'epidemiol√≥gica',\n",
              "  '#coronavirusitabira',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['for√ßatarefa',\n",
              "  'higieniza√ß√£o',\n",
              "  'locais',\n",
              "  'p√∫blico',\n",
              "  '#covid19',\n",
              "  '|',\n",
              "  'a√ß√µes',\n",
              "  'higieniza√ß√£o',\n",
              "  'unidades',\n",
              "  'hospitalares,',\n",
              "  'ter‚Ä¶'],\n",
              " ['cen√°rio',\n",
              "  'povo',\n",
              "  'brasileiro',\n",
              "  'milhares',\n",
              "  'mortos',\n",
              "  'hospitais',\n",
              "  'lotados',\n",
              "  'dificuldade',\n",
              "  'p/',\n",
              "  'sacar',\n",
              "  '$600',\n",
              "  'empresas',\n",
              "  'quebran‚Ä¶'],\n",
              " ['@drguiga1',\n",
              "  '@alessandrojferreira',\n",
              "  '@mfrancomed',\n",
              "  '@franciscoguedess',\n",
              "  '@danielcmrocha',\n",
              "  '#novidade',\n",
              "  '#agentefazbemparavoc√™‚Ä¶'],\n",
              " ['alguns',\n",
              "  'servi√ßos',\n",
              "  'prazos',\n",
              "  'atendimento',\n",
              "  'prorrogados',\n",
              "  'ans',\n",
              "  'significa',\n",
              "  'suspens√£o',\n",
              "  'todas‚Ä¶'],\n",
              " ['parques',\n",
              "  'campismo',\n",
              "  'podem',\n",
              "  'reabrir',\n",
              "  'segundafeira',\n",
              "  'dois',\n",
              "  'ter√ßos',\n",
              "  'lota√ß√£o',\n",
              "  '#covid19',\n",
              "  '#economia',\n",
              "  '#turismo'],\n",
              " ['uso',\n",
              "  'm√°scara',\n",
              "  'passa',\n",
              "  'ser',\n",
              "  'obrigat√≥rio',\n",
              "  'partir',\n",
              "  '10',\n",
              "  'anos',\n",
              "  '#covid19',\n",
              "  '#m√°scaras',\n",
              "  '#sa√∫de'],\n",
              " ['v√£o',\n",
              "  'deixar',\n",
              "  'brasil',\n",
              "  'morrer',\n",
              "  'm√£os',\n",
              "  'cidad√£o',\n",
              "  'possui',\n",
              "  'cargo',\n",
              "  'alto',\n",
              "  'democracia?',\n",
              "  'senhores‚Ä¶'],\n",
              " ['#acmneto',\n",
              "  '#covid',\n",
              "  '#deus',\n",
              "  '#salvador',\n",
              "  '#ufba',\n",
              "  '#uneb',\n",
              "  '#marinhadobrasil',\n",
              "  '@geografia',\n",
              "  '#historia',\n",
              "  '#universidade',\n",
              "  '#universitarios‚Ä¶'],\n",
              " ['prestou',\n",
              "  'esclarecimentos',\n",
              "  'comiss√£o',\n",
              "  'parlamentares',\n",
              "  'acompanha',\n",
              "  'medidas',\n",
              "  'governo',\n",
              "  'durante',\n",
              "  'per√≠odo',\n",
              "  'ca‚Ä¶'],\n",
              " ['sextou!!',\n",
              "  'bora',\n",
              "  'pro',\n",
              "  'show',\n",
              "  'drive',\n",
              "  'in!',\n",
              "  '#futerock',\n",
              "  '#blogfuterock',\n",
              "  '#quarentena',\n",
              "  '#covid19',\n",
              "  '#covid„Éº19',\n",
              "  '#covid',\n",
              "  '#covid_19‚Ä¶'],\n",
              " ['@teichnelson',\n",
              "  'obrigada',\n",
              "  'tudo,',\n",
              "  'culpa',\n",
              "  'sua,',\n",
              "  '2018!',\n",
              "  '#fiqueemcasa',\n",
              "  '#covid'],\n",
              " ['@tuliogadelha',\n",
              "  '@rodrigomaia',\n",
              "  'presidente',\n",
              "  'quer',\n",
              "  'ter',\n",
              "  'discurso',\n",
              "  'eleitoral',\n",
              "  'independente',\n",
              "  'fazer',\n",
              "  'bem',\n",
              "  'quer',\n",
              "  'cloroquin‚Ä¶'],\n",
              " ['5', 'v√≠timas', '#covid', 'complexo', 'alem√£o'],\n",
              " ['ano',\n",
              "  '2025',\n",
              "  'brasil,',\n",
              "  'pa√≠s',\n",
              "  'ainda',\n",
              "  'quarentena',\n",
              "  'apesar',\n",
              "  'nunca',\n",
              "  't√™la',\n",
              "  'feito',\n",
              "  'fato',\n",
              "  '#coronavirusnobrasil‚Ä¶'],\n",
              " ['fique',\n",
              "  'casa',\n",
              "  'promo√ß√£o',\n",
              "  'artes',\n",
              "  'divulga√ß√£o',\n",
              "  'produtos#bbb20',\n",
              "  '#redebbb',\n",
              "  '#perguntacorona',\n",
              "  '#globo',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['multadas',\n",
              "  '60',\n",
              "  'pessoas',\n",
              "  'usarem',\n",
              "  'm√°scara',\n",
              "  'transportes',\n",
              "  'p√∫blicos',\n",
              "  '#covid19',\n",
              "  '#m√°scaras'],\n",
              " ['(multim√≠dia',\n",
              "  '#wuhan',\n",
              "  'far√°',\n",
              "  'testes',\n",
              "  'cidade',\n",
              "  'inteira',\n",
              "  'detectar',\n",
              "  'casos',\n",
              "  'assintom√°ticos',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['estrat√©gias',\n",
              "  'dados',\n",
              "  'an√°lise',\n",
              "  'empresas',\n",
              "  'desmoronaram',\n",
              "  '#covid19',\n",
              "  '#vmware',\n",
              "  '#vmw_carbonblack‚Ä¶'],\n",
              " ['estrat√©gias',\n",
              "  'dados',\n",
              "  'an√°lise',\n",
              "  'empresas',\n",
              "  'desmoronaram',\n",
              "  '#covid19',\n",
              "  '#vmware',\n",
              "  '#vmw_carbonblack‚Ä¶'],\n",
              " ['utilidade',\n",
              "  'p√∫blica!',\n",
              "  'calend√°rio',\n",
              "  'pagamento',\n",
              "  '2',\n",
              "  'parcela',\n",
              "  '#auxilioemergecial',\n",
              "  'segue',\n",
              "  'liga',\n",
              "  'ai‚Ä¶'],\n",
              " ['#ferrari',\n",
              "  'instituto',\n",
              "  'italiano',\n",
              "  'tecnologia',\n",
              "  'produzem',\n",
              "  'novo',\n",
              "  'respirador',\n",
              "  'pacientes',\n",
              "  'covid19',\n",
              "  '#colunista',\n",
              "  '#covid'],\n",
              " ['dizem?',\n",
              "  '#covid19',\n",
              "  '#coronavirusplantao',\n",
              "  '#covid',\n",
              "  '#plandemic',\n",
              "  '#pandemia',\n",
              "  '#conspiracytheory',\n",
              "  '#socorro'],\n",
              " ['braga',\n",
              "  '62',\n",
              "  'mortos,',\n",
              "  '1332',\n",
              "  'infetados',\n",
              "  '699',\n",
              "  'recuperados',\n",
              "  '#braga',\n",
              "  '#covid19',\n",
              "  '#emdestaque'],\n",
              " ['costa',\n",
              "  'admite',\n",
              "  'levantar',\n",
              "  'limite',\n",
              "  'lota√ß√£o',\n",
              "  'restaurantes',\n",
              "  'partir',\n",
              "  'junho',\n",
              "  '#ant√≥niocosta',\n",
              "  '#covid19',\n",
              "  '#economia'],\n",
              " ['seguran√ßa',\n",
              "  'social',\n",
              "  'pagou',\n",
              "  '284',\n",
              "  'milh√µes',\n",
              "  'empresas',\n",
              "  '‚Äòlayoff‚Äô',\n",
              "  '#covid19',\n",
              "  '#economia',\n",
              "  '#seguran√ßasocial'],\n",
              " ['@allantercalivre',\n",
              "  'totalmente',\n",
              "  'despropositada',\n",
              "  'coletiva',\n",
              "  'imprensa',\n",
              "  'ministro',\n",
              "  'ministro',\n",
              "  'pediu',\n",
              "  'demiss√£o‚Ä¶'],\n",
              " ['florian√≥polis',\n",
              "  'nesta',\n",
              "  'sextafeira',\n",
              "  '(15',\n",
              "  '#covid',\n",
              "  '#covid19',\n",
              "  '#pandemia',\n",
              "  '#coronav√≠rus',\n",
              "  '#floripa',\n",
              "  '#sc',\n",
              "  '#santacatarina',\n",
              "  '#centro‚Ä¶'],\n",
              " ['(multim√≠dia',\n",
              "  '#china',\n",
              "  'completar√°',\n",
              "  'testes',\n",
              "  'cl√≠nicos',\n",
              "  'segunda',\n",
              "  'fase',\n",
              "  'vacinas',\n",
              "  '#covid19',\n",
              "  'julho,',\n",
              "  'diz',\n",
              "  'funcion√°rio‚Ä¶'],\n",
              " ['restaurantes',\n",
              "  'lojas',\n",
              "  '400',\n",
              "  'metros',\n",
              "  'quadrados',\n",
              "  'reabrem',\n",
              "  'dia',\n",
              "  '18',\n",
              "  '#com√©rcio',\n",
              "  '#covid19',\n",
              "  '#economia'],\n",
              " ['@psdboficial',\n",
              "  '@eduardoleite_',\n",
              "  'totalmente',\n",
              "  'despropositada',\n",
              "  'coletiva',\n",
              "  'imprensa',\n",
              "  'ministro',\n",
              "  'ministro',\n",
              "  'ped‚Ä¶'],\n",
              " ['governo',\n",
              "  'prop√µe',\n",
              "  'prolongamento',\n",
              "  '01',\n",
              "  'setembro',\n",
              "  'empr√©stimos',\n",
              "  'rendas',\n",
              "  '#covid19',\n",
              "  '#economia',\n",
              "  '#rendas'],\n",
              " ['@radiobandnewsfm',\n",
              "  'totalmente',\n",
              "  'despropositada',\n",
              "  'coletiva',\n",
              "  'imprensa',\n",
              "  'ministro',\n",
              "  'ministro',\n",
              "  'pediu',\n",
              "  'demiss√£o‚Ä¶'],\n",
              " ['@biakicis',\n",
              "  'totalmente',\n",
              "  'despropositada',\n",
              "  'coletiva',\n",
              "  'imprensa',\n",
              "  'ministro',\n",
              "  'ministro',\n",
              "  'pediu',\n",
              "  'demiss√£o',\n",
              "  'cai',\n",
              "  'fo‚Ä¶'],\n",
              " ['@andreiasadi',\n",
              "  'totalmente',\n",
              "  'despropositada',\n",
              "  'coletiva',\n",
              "  'imprensa',\n",
              "  'ministro',\n",
              "  'ministro',\n",
              "  'pediu',\n",
              "  'demiss√£o',\n",
              "  'cai‚Ä¶'],\n",
              " ['@gianeguerra',\n",
              "  '@gauchazh',\n",
              "  'totalmente',\n",
              "  'despropositada',\n",
              "  'coletiva',\n",
              "  'imprensa',\n",
              "  'ministro',\n",
              "  'ministro',\n",
              "  'pediu',\n",
              "  'de‚Ä¶'],\n",
              " ['costa',\n",
              "  'afirma',\n",
              "  'resultados',\n",
              "  'permitem',\n",
              "  'dar',\n",
              "  'novo',\n",
              "  'passo',\n",
              "  'reabertura',\n",
              "  'atividades',\n",
              "  '#ant√≥niocosta',\n",
              "  '#covid19',\n",
              "  '#pol√≠tica'],\n",
              " ['@bandnews',\n",
              "  'totalmente',\n",
              "  'despropositada',\n",
              "  'coletiva',\n",
              "  'imprensa',\n",
              "  'ministro',\n",
              "  'ministro',\n",
              "  'pediu',\n",
              "  'demiss√£o',\n",
              "  'cai',\n",
              "  'fo‚Ä¶'],\n",
              " ['totalmente',\n",
              "  'despropositada',\n",
              "  'coletiva',\n",
              "  'imprensa',\n",
              "  'ministro',\n",
              "  'ministro',\n",
              "  'pediu',\n",
              "  'demiss√£o',\n",
              "  'cai',\n",
              "  'fora!',\n",
              "  'vai',\n",
              "  'da‚Ä¶'],\n",
              " ['@jornaldarecord',\n",
              "  'assustador',\n",
              "  'n√∫mero',\n",
              "  'mortes',\n",
              "  '#covid',\n",
              "  'estado',\n",
              "  '#saopaulo',\n",
              "  '@governosp',\n",
              "  '@jdoriajr',\n",
              "  'isolament‚Ä¶'],\n",
              " ['situa√ß√£o',\n",
              "  'calamidade',\n",
              "  'prorrogada',\n",
              "  'final',\n",
              "  'maio',\n",
              "  '#ant√≥niocosta',\n",
              "  '#covid19',\n",
              "  '#pol√≠tica'],\n",
              " ['üí™vem',\n",
              "  'somar',\n",
              "  'for√ßas!',\n",
              "  'pnuma',\n",
              "  'apoia',\n",
              "  '\"alian√ßa',\n",
              "  'povos',\n",
              "  'ind√≠genas',\n",
              "  'popula√ß√µes',\n",
              "  'tradicionais',\n",
              "  'organiza√ß√µes',\n",
              "  'parceira‚Ä¶'],\n",
              " ['fique',\n",
              "  'casa',\n",
              "  'promo√ß√£o',\n",
              "  'artes',\n",
              "  'divulga√ß√£o',\n",
              "  'produtos#bbb20',\n",
              "  '#redebbb',\n",
              "  '#perguntacorona',\n",
              "  '#globo',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['pcp',\n",
              "  'apoia',\n",
              "  '‚Äúa',\n",
              "  'justa',\n",
              "  'luta‚Äù',\n",
              "  'feirantes',\n",
              "  'viana',\n",
              "  'castelo',\n",
              "  '#covid19',\n",
              "  '#feiras',\n",
              "  '#vianadocastelo'],\n",
              " ['primeiro',\n",
              "  'v√≠deo',\n",
              "  'canal,',\n",
              "  'compartilhem',\n",
              "  '#cloroquina',\n",
              "  '#hidroxicloroquina',\n",
              "  '#covid19',\n",
              "  '#covid',\n",
              "  '#ciencia',\n",
              "  '#universocortical'],\n",
              " ['conci√™ncia',\n",
              "  'realidade',\n",
              "  'periferia',\n",
              "  'imposs√≠vel',\n",
              "  '#covid',\n",
              "  '#trabalhar',\n",
              "  '#periferia',\n",
              "  '#jornalistas',\n",
              "  '#sim√£o',\n",
              "  '#trendtopics‚Ä¶'],\n",
              " ['clique',\n",
              "  'link',\n",
              "  'veja',\n",
              "  'ponto',\n",
              "  'arrecada√ß√£o',\n",
              "  'pr√≥ximo',\n",
              "  '#covid19',\n",
              "  '#covid‚Ä¶'],\n",
              " ['#forabolsonarourgente',\n",
              "  '#forabolÂçêonaro',\n",
              "  '#forabolsonaro',\n",
              "  '#impeachmentdobolsonarourgente',\n",
              "  '#impeachmentdebolsonaro‚Ä¶'],\n",
              " ['chega',\n",
              "  'tirem',\n",
              "  'urgente',\n",
              "  'genocida',\n",
              "  'a√≠',\n",
              "  'pro',\n",
              "  'povo',\n",
              "  'pra',\n",
              "  'economia',\n",
              "  'trar√°',\n",
              "  'psicopata',\n",
              "  'quer',\n",
              "  've‚Ä¶'],\n",
              " ['@lottenberg',\n",
              "  'excelente',\n",
              "  'posicionamento!',\n",
              "  '@cnnbrasil',\n",
              "  'vis√£o',\n",
              "  'cnn',\n",
              "  'concordo',\n",
              "  'ter',\n",
              "  'discuss√µes',\n",
              "  't√©cnicas‚Ä¶'],\n",
              " ['@eumanosilva',\n",
              "  'presidente',\n",
              "  'quer',\n",
              "  'ter',\n",
              "  'discurso',\n",
              "  'eleitoral',\n",
              "  'independente',\n",
              "  'fazer',\n",
              "  'bem',\n",
              "  'quer',\n",
              "  'cloroquina',\n",
              "  'pra',\n",
              "  'casos',\n",
              "  'le‚Ä¶'],\n",
              " ['@brunogagliasso',\n",
              "  'presidente',\n",
              "  'quer',\n",
              "  'ter',\n",
              "  'discurso',\n",
              "  'eleitoral',\n",
              "  'independente',\n",
              "  'fazer',\n",
              "  'bem',\n",
              "  'quer',\n",
              "  'cloroquina',\n",
              "  'pra',\n",
              "  'casos‚Ä¶'],\n",
              " ['t√¥',\n",
              "  'mesa',\n",
              "  '4',\n",
              "  'cadeiras,',\n",
              "  'aqui',\n",
              "  '3',\n",
              "  'enganados',\n",
              "  '#ministrodasaude',\n",
              "  '#covid',\n",
              "  '#forabolsonarourgente‚Ä¶'],\n",
              " ['cego',\n",
              "  'planalto',\n",
              "  'brasil',\n",
              "  '2020,',\n",
              "  '#coronavirus',\n",
              "  '#covid',\n",
              "  '#teich',\n",
              "  '#forabolÂçêonaro'],\n",
              " ['@revistacrusoe',\n",
              "  'lockdown',\n",
              "  'salvou',\n",
              "  'vidas',\n",
              "  'europa',\n",
              "  'assista',\n",
              "  '#lockdown',\n",
              "  '#covid'],\n",
              " ['agora,', 't√°', 'rindo?', '#daciolo', '#covid', '#urgente'],\n",
              " ['parab√©ns',\n",
              "  '@spleituras',\n",
              "  '#bibliotecas',\n",
              "  '#aprendizagem',\n",
              "  '#planejamento',\n",
              "  '#bibliotec√°rios',\n",
              "  '#covid'],\n",
              " ['segundo',\n",
              "  'pesquisadores',\n",
              "  'canadenses,',\n",
              "  '#maconha',\n",
              "  'pode',\n",
              "  'ajudar',\n",
              "  'tratamento',\n",
              "  'contra',\n",
              "  '#coronavirus',\n",
              "  '#covid'],\n",
              " ['inscri√ß√µes',\n",
              "  '#mestrado',\n",
              "  '#doutorado',\n",
              "  'programa',\n",
              "  'pesquisa',\n",
              "  'cl√≠nica',\n",
              "  'doen√ßas',\n",
              "  'infecciosas',\n",
              "  '@inifiocruz‚Ä¶'],\n",
              " ['altice',\n",
              "  'forum',\n",
              "  'braga',\n",
              "  'reabre',\n",
              "  'segundafeira',\n",
              "  'reagendou',\n",
              "  'espet√°culos',\n",
              "  '#alticeforum',\n",
              "  '#braga',\n",
              "  '#covid19'],\n",
              " ['fique',\n",
              "  'casa',\n",
              "  'promo√ß√£o',\n",
              "  'artes',\n",
              "  'divulga√ß√£o',\n",
              "  'produtos#bbb20',\n",
              "  '#redebbb',\n",
              "  '#perguntacorona',\n",
              "  '#globo',\n",
              "  '#covid19‚Ä¶'],\n",
              " ['@lhmandetta',\n",
              "  'monte',\n",
              "  'gente',\n",
              "  'tomando',\n",
              "  'cloroquina',\n",
              "  'morrendo',\n",
              "  'casa,',\n",
              "  'problemas',\n",
              "  'card√≠acos',\n",
              "  'decorrente',\n",
              "  'uso‚Ä¶'],\n",
              " ['criminoso',\n",
              "  'vai',\n",
              "  'cair',\n",
              "  '#impeachmentbolsonaro',\n",
              "  '#jairbolsonaro',\n",
              "  '#covid',\n",
              "  '#covid_19',\n",
              "  '#cloroquina',\n",
              "  '#sueciaüá∏üá™',\n",
              "  '#argentina‚Ä¶'],\n",
              " ['@miltonneves',\n",
              "  '@joelpinheiro85',\n",
              "  'presidente',\n",
              "  'quer',\n",
              "  'ter',\n",
              "  'discurso',\n",
              "  'eleitoral',\n",
              "  'independente',\n",
              "  'fazer',\n",
              "  'bem',\n",
              "  'quer',\n",
              "  'cloroqu‚Ä¶'],\n",
              " ['@xicograziano',\n",
              "  '@joelpinheiro85',\n",
              "  'presidente',\n",
              "  'quer',\n",
              "  'ter',\n",
              "  'discurso',\n",
              "  'eleitoral',\n",
              "  'independente',\n",
              "  'fazer',\n",
              "  'bem',\n",
              "  'quer',\n",
              "  'cloroq‚Ä¶'],\n",
              " ['@brasil247',\n",
              "  'presidente',\n",
              "  'quer',\n",
              "  'ter',\n",
              "  'discurso',\n",
              "  'eleitoral',\n",
              "  'independente',\n",
              "  'fazer',\n",
              "  'bem',\n",
              "  'quer',\n",
              "  'cloroquina',\n",
              "  'pra',\n",
              "  'casos',\n",
              "  'leve‚Ä¶'],\n",
              " ['@bernardomf',\n",
              "  'presidente',\n",
              "  'quer',\n",
              "  'ter',\n",
              "  'discurso',\n",
              "  'eleitoral',\n",
              "  'independente',\n",
              "  'fazer',\n",
              "  'bem',\n",
              "  'quer',\n",
              "  'cloroquina',\n",
              "  'pra',\n",
              "  'casos',\n",
              "  'lev‚Ä¶'],\n",
              " ['@bragal0ures',\n",
              "  '@lhmandetta',\n",
              "  'extremistas',\n",
              "  'direita',\n",
              "  'assinar',\n",
              "  'termo',\n",
              "  'aceita√ß√£o',\n",
              "  'servi√ßos',\n",
              "  'm√©dicos‚Ä¶'],\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYGiRPQCk-11",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b5f56d42-f105-4b3a-b939-f67e621e59e9"
      },
      "source": [
        "phrases = Phrases(sent, min_count=30, progress_per=100000)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 17:49:34: collecting all words and their counts\n",
            "INFO - 17:49:34: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
            "INFO - 17:49:36: PROGRESS: at sentence #100000, processed 1012683 words and 652674 word types\n",
            "INFO - 17:49:36: collected 674495 word types from a corpus of 1048210 words (unigram + bigrams) and 103364 sentences\n",
            "INFO - 17:49:36: using 674495 counts as vocab in Phrases<0 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a28rb0mltnwB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c67938d3-7e53-4cbc-b2f7-24b0b737c955"
      },
      "source": [
        "#Construindo modelo baseado em Bigram, para a detec√ß√£o de palavras (√∫nicas) que s√£o formadas por outras duas.\n",
        "bigram = Phraser(phrases)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 17:49:37: source_vocab length 674495\n",
            "INFO - 17:49:42: Phraser built with 861 phrasegrams\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtiPEzyvmVfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = bigram[sent]"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3_capprlL2K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd7ecadb-f506-4d73-de77-0b6feb90a3a8"
      },
      "source": [
        "#Percorrendo os dados e fazendo uma contagem para verificar as palavras mais frequentes da base.\n",
        "word_freq = defaultdict(int)\n",
        "for sent in sentences:\n",
        "    for i in sent:\n",
        "        word_freq[i] += 1\n",
        "len(word_freq)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "117576"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NilpgoImlzjj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "547e44f6-3999-4063-b4ae-40d374094a13"
      },
      "source": [
        "#Exibindo as 10 palavras mais frequentes da base de dados.\n",
        "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['coronav√≠rus',\n",
              " 'covid19',\n",
              " 'lockdown',\n",
              " 'coronavirus',\n",
              " 'brasil',\n",
              " 'pra',\n",
              " 'casos',\n",
              " 'sobre',\n",
              " 'mortes',\n",
              " 'contra']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8E9qBS87Uiq",
        "colab_type": "text"
      },
      "source": [
        "# Criando o Modelo Word2VEC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoYBoaSIl4ZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importando biblioteca e m√≥dulo do Gensim, para a implementa√ß√£o do Word2VEC.\n",
        "import multiprocessing\n",
        "\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fq89FR4oq2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fun√ß√£o que conta o n√∫mero de cores da m√°quina.\n",
        "cores = multiprocessing.cpu_count()"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkS_Ofefok0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Instanciando modelo Word2VEC a partir dos mesmos par√¢metros estabelecidos pelo artigo.\n",
        "w2v_model = Word2Vec(min_count=3,\n",
        "                     window=4,\n",
        "                     size=300,\n",
        "                     sample=0.8, \n",
        "                     alpha=0.03, \n",
        "                     min_alpha=0.0007, \n",
        "                     negative=20,\n",
        "                     workers=multiprocessing.cpu_count()-1)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPcSopbConnQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "ae221d61-b535-49c9-c06a-408707f2453c"
      },
      "source": [
        "#Construindo vocabul√°rio a partir das senten√ßas.\n",
        "w2v_model.build_vocab(sentences, progress_per=100000)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 17:49:46: collecting all words and their counts\n",
            "INFO - 17:49:46: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "INFO - 17:49:49: PROGRESS: at sentence #100000, processed 953320 words, keeping 114711 word types\n",
            "INFO - 17:49:49: collected 117576 word types from a corpus of 987411 raw words and 103364 sentences\n",
            "INFO - 17:49:49: Loading a fresh vocabulary\n",
            "INFO - 17:49:49: effective_min_count=3 retains 30785 unique words (26% of original 117576, drops 86791)\n",
            "INFO - 17:49:49: effective_min_count=3 leaves 885593 word corpus (89% of original 987411, drops 101818)\n",
            "INFO - 17:49:49: deleting the raw counts dictionary of 117576 items\n",
            "INFO - 17:49:49: sample=0.8 downsamples 0 most-common words\n",
            "INFO - 17:49:49: downsampling leaves estimated 885593 word corpus (100.0% of prior 885593)\n",
            "INFO - 17:49:50: estimated required memory for 30785 words and 300 dimensions: 89276500 bytes\n",
            "INFO - 17:49:50: resetting layer weights\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USvaq5m3VnPJ",
        "colab_type": "text"
      },
      "source": [
        "# Treinando o Modelo Word2VEC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elb-e0LpoulX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "df6dac13-567a-41ca-a230-6de500e83fac"
      },
      "source": [
        "#Treiando modelo Word2VEC.\n",
        "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 17:49:56: training model with 1 workers on 30785 vocabulary and 300 features, using sg=0 hs=0 sample=0.8 negative=20 window=4\n",
            "INFO - 17:49:57: EPOCH 1 - PROGRESS: at 7.77% examples, 69408 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:49:58: EPOCH 1 - PROGRESS: at 16.89% examples, 72792 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:49:59: EPOCH 1 - PROGRESS: at 26.08% examples, 73610 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 17:50:00: EPOCH 1 - PROGRESS: at 35.24% examples, 74112 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:01: EPOCH 1 - PROGRESS: at 44.23% examples, 74435 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:02: EPOCH 1 - PROGRESS: at 53.26% examples, 74461 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:03: EPOCH 1 - PROGRESS: at 62.33% examples, 74592 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:04: EPOCH 1 - PROGRESS: at 71.62% examples, 74611 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:05: EPOCH 1 - PROGRESS: at 79.88% examples, 73397 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:06: EPOCH 1 - PROGRESS: at 89.27% examples, 73330 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:07: EPOCH 1 - PROGRESS: at 98.33% examples, 73675 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:08: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:50:08: EPOCH - 1 : training on 987411 raw words (885593 effective words) took 12.0s, 73882 effective words/s\n",
            "INFO - 17:50:09: EPOCH 2 - PROGRESS: at 7.77% examples, 69546 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:10: EPOCH 2 - PROGRESS: at 16.89% examples, 71879 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:11: EPOCH 2 - PROGRESS: at 26.08% examples, 72577 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 17:50:12: EPOCH 2 - PROGRESS: at 35.24% examples, 73397 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:13: EPOCH 2 - PROGRESS: at 44.23% examples, 73648 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:14: EPOCH 2 - PROGRESS: at 53.26% examples, 74070 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:15: EPOCH 2 - PROGRESS: at 62.33% examples, 74348 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:16: EPOCH 2 - PROGRESS: at 71.62% examples, 74567 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:17: EPOCH 2 - PROGRESS: at 80.91% examples, 74704 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:18: EPOCH 2 - PROGRESS: at 90.32% examples, 74686 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:19: EPOCH 2 - PROGRESS: at 99.27% examples, 75077 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:19: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:50:19: EPOCH - 2 : training on 987411 raw words (885593 effective words) took 11.8s, 75190 effective words/s\n",
            "INFO - 17:50:20: EPOCH 3 - PROGRESS: at 7.77% examples, 69926 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:22: EPOCH 3 - PROGRESS: at 16.89% examples, 71760 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:23: EPOCH 3 - PROGRESS: at 26.08% examples, 72996 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:24: EPOCH 3 - PROGRESS: at 35.24% examples, 73223 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:25: EPOCH 3 - PROGRESS: at 44.23% examples, 73730 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:26: EPOCH 3 - PROGRESS: at 53.26% examples, 73683 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 17:50:27: EPOCH 3 - PROGRESS: at 62.33% examples, 73569 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:28: EPOCH 3 - PROGRESS: at 71.62% examples, 73342 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 17:50:29: EPOCH 3 - PROGRESS: at 79.88% examples, 72908 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 17:50:30: EPOCH 3 - PROGRESS: at 89.27% examples, 72994 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:31: EPOCH 3 - PROGRESS: at 98.33% examples, 73216 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:32: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:50:32: EPOCH - 3 : training on 987411 raw words (885593 effective words) took 12.1s, 73429 effective words/s\n",
            "INFO - 17:50:33: EPOCH 4 - PROGRESS: at 7.77% examples, 67660 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:34: EPOCH 4 - PROGRESS: at 16.89% examples, 70749 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:35: EPOCH 4 - PROGRESS: at 25.05% examples, 71014 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:36: EPOCH 4 - PROGRESS: at 34.17% examples, 71235 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:37: EPOCH 4 - PROGRESS: at 43.25% examples, 71791 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:38: EPOCH 4 - PROGRESS: at 52.26% examples, 72119 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:39: EPOCH 4 - PROGRESS: at 60.26% examples, 72039 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 17:50:40: EPOCH 4 - PROGRESS: at 69.53% examples, 72026 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:41: EPOCH 4 - PROGRESS: at 78.88% examples, 72082 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:42: EPOCH 4 - PROGRESS: at 88.22% examples, 72212 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:43: EPOCH 4 - PROGRESS: at 97.37% examples, 72287 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:44: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:50:44: EPOCH - 4 : training on 987411 raw words (885593 effective words) took 12.2s, 72680 effective words/s\n",
            "INFO - 17:50:45: EPOCH 5 - PROGRESS: at 7.77% examples, 66405 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 17:50:46: EPOCH 5 - PROGRESS: at 16.89% examples, 69656 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:47: EPOCH 5 - PROGRESS: at 26.08% examples, 70737 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 17:50:48: EPOCH 5 - PROGRESS: at 35.24% examples, 71505 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:49: EPOCH 5 - PROGRESS: at 44.23% examples, 70622 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:50: EPOCH 5 - PROGRESS: at 53.26% examples, 71203 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:51: EPOCH 5 - PROGRESS: at 62.33% examples, 71951 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:53: EPOCH 5 - PROGRESS: at 71.62% examples, 72137 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 17:50:54: EPOCH 5 - PROGRESS: at 80.91% examples, 72360 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:55: EPOCH 5 - PROGRESS: at 90.32% examples, 72569 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:56: EPOCH 5 - PROGRESS: at 99.27% examples, 73101 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:56: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:50:56: EPOCH - 5 : training on 987411 raw words (885593 effective words) took 12.1s, 73227 effective words/s\n",
            "INFO - 17:50:57: EPOCH 6 - PROGRESS: at 8.80% examples, 71370 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:58: EPOCH 6 - PROGRESS: at 17.90% examples, 73647 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:50:59: EPOCH 6 - PROGRESS: at 27.07% examples, 74452 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:00: EPOCH 6 - PROGRESS: at 36.27% examples, 74205 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:01: EPOCH 6 - PROGRESS: at 45.23% examples, 74400 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:02: EPOCH 6 - PROGRESS: at 54.26% examples, 74564 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:03: EPOCH 6 - PROGRESS: at 63.40% examples, 74756 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:04: EPOCH 6 - PROGRESS: at 72.65% examples, 74908 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:06: EPOCH 6 - PROGRESS: at 81.94% examples, 74957 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:07: EPOCH 6 - PROGRESS: at 91.36% examples, 74964 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:08: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:51:08: EPOCH - 6 : training on 987411 raw words (885593 effective words) took 11.7s, 75426 effective words/s\n",
            "INFO - 17:51:09: EPOCH 7 - PROGRESS: at 8.80% examples, 71259 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:10: EPOCH 7 - PROGRESS: at 17.90% examples, 73570 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:11: EPOCH 7 - PROGRESS: at 27.07% examples, 73896 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:12: EPOCH 7 - PROGRESS: at 36.27% examples, 74640 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:13: EPOCH 7 - PROGRESS: at 45.23% examples, 74744 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:14: EPOCH 7 - PROGRESS: at 54.26% examples, 74920 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:15: EPOCH 7 - PROGRESS: at 63.40% examples, 75224 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:16: EPOCH 7 - PROGRESS: at 72.65% examples, 75189 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:17: EPOCH 7 - PROGRESS: at 81.94% examples, 75257 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:18: EPOCH 7 - PROGRESS: at 91.36% examples, 75360 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:19: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:51:19: EPOCH - 7 : training on 987411 raw words (885593 effective words) took 11.7s, 75877 effective words/s\n",
            "INFO - 17:51:20: EPOCH 8 - PROGRESS: at 7.77% examples, 69728 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:21: EPOCH 8 - PROGRESS: at 16.89% examples, 72017 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:22: EPOCH 8 - PROGRESS: at 26.08% examples, 73099 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:24: EPOCH 8 - PROGRESS: at 35.24% examples, 73274 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:25: EPOCH 8 - PROGRESS: at 44.23% examples, 73455 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:26: EPOCH 8 - PROGRESS: at 53.26% examples, 73933 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:27: EPOCH 8 - PROGRESS: at 62.33% examples, 74091 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:28: EPOCH 8 - PROGRESS: at 71.62% examples, 74252 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:29: EPOCH 8 - PROGRESS: at 80.91% examples, 74400 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:30: EPOCH 8 - PROGRESS: at 90.32% examples, 74562 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:31: EPOCH 8 - PROGRESS: at 99.27% examples, 75077 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:31: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:51:31: EPOCH - 8 : training on 987411 raw words (885593 effective words) took 11.8s, 75200 effective words/s\n",
            "INFO - 17:51:32: EPOCH 9 - PROGRESS: at 7.77% examples, 68565 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:33: EPOCH 9 - PROGRESS: at 15.88% examples, 67315 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:34: EPOCH 9 - PROGRESS: at 25.05% examples, 69886 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:35: EPOCH 9 - PROGRESS: at 34.17% examples, 71039 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:36: EPOCH 9 - PROGRESS: at 43.25% examples, 71575 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:38: EPOCH 9 - PROGRESS: at 52.26% examples, 71942 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:39: EPOCH 9 - PROGRESS: at 61.29% examples, 72100 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:40: EPOCH 9 - PROGRESS: at 70.56% examples, 72296 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:41: EPOCH 9 - PROGRESS: at 79.88% examples, 72423 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:42: EPOCH 9 - PROGRESS: at 89.27% examples, 72609 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:43: EPOCH 9 - PROGRESS: at 98.33% examples, 72810 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:51:43: EPOCH - 9 : training on 987411 raw words (885593 effective words) took 12.1s, 73078 effective words/s\n",
            "INFO - 17:51:44: EPOCH 10 - PROGRESS: at 7.77% examples, 69111 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:45: EPOCH 10 - PROGRESS: at 16.89% examples, 71803 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:46: EPOCH 10 - PROGRESS: at 26.08% examples, 72324 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:47: EPOCH 10 - PROGRESS: at 35.24% examples, 72819 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:49: EPOCH 10 - PROGRESS: at 44.23% examples, 72917 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 17:51:50: EPOCH 10 - PROGRESS: at 53.26% examples, 73192 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:51: EPOCH 10 - PROGRESS: at 62.33% examples, 73375 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:52: EPOCH 10 - PROGRESS: at 71.62% examples, 73502 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:53: EPOCH 10 - PROGRESS: at 80.91% examples, 73451 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:54: EPOCH 10 - PROGRESS: at 90.32% examples, 73458 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:55: EPOCH 10 - PROGRESS: at 99.27% examples, 73858 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:51:55: EPOCH - 10 : training on 987411 raw words (885593 effective words) took 12.0s, 73961 effective words/s\n",
            "INFO - 17:51:56: EPOCH 11 - PROGRESS: at 7.77% examples, 68839 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:57: EPOCH 11 - PROGRESS: at 16.89% examples, 71134 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:58: EPOCH 11 - PROGRESS: at 26.08% examples, 71971 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:51:59: EPOCH 11 - PROGRESS: at 35.24% examples, 72697 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:01: EPOCH 11 - PROGRESS: at 44.23% examples, 72944 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:02: EPOCH 11 - PROGRESS: at 53.26% examples, 73261 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:03: EPOCH 11 - PROGRESS: at 62.33% examples, 73564 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:04: EPOCH 11 - PROGRESS: at 71.62% examples, 73562 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:05: EPOCH 11 - PROGRESS: at 80.91% examples, 73647 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:06: EPOCH 11 - PROGRESS: at 90.32% examples, 73728 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:07: EPOCH 11 - PROGRESS: at 99.27% examples, 74088 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:07: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:52:07: EPOCH - 11 : training on 987411 raw words (885593 effective words) took 11.9s, 74184 effective words/s\n",
            "INFO - 17:52:08: EPOCH 12 - PROGRESS: at 7.77% examples, 68933 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:09: EPOCH 12 - PROGRESS: at 16.89% examples, 71957 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:10: EPOCH 12 - PROGRESS: at 26.08% examples, 71937 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 17:52:11: EPOCH 12 - PROGRESS: at 35.24% examples, 73084 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:12: EPOCH 12 - PROGRESS: at 44.23% examples, 73580 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:14: EPOCH 12 - PROGRESS: at 53.26% examples, 74019 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:15: EPOCH 12 - PROGRESS: at 62.33% examples, 72854 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:16: EPOCH 12 - PROGRESS: at 71.62% examples, 72921 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:17: EPOCH 12 - PROGRESS: at 80.91% examples, 72880 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:18: EPOCH 12 - PROGRESS: at 89.27% examples, 72820 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:19: EPOCH 12 - PROGRESS: at 98.33% examples, 73022 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:19: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:52:19: EPOCH - 12 : training on 987411 raw words (885593 effective words) took 12.1s, 73271 effective words/s\n",
            "INFO - 17:52:20: EPOCH 13 - PROGRESS: at 7.77% examples, 67803 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:21: EPOCH 13 - PROGRESS: at 16.89% examples, 70225 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:22: EPOCH 13 - PROGRESS: at 26.08% examples, 71644 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:24: EPOCH 13 - PROGRESS: at 35.24% examples, 72237 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:25: EPOCH 13 - PROGRESS: at 44.23% examples, 72497 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:26: EPOCH 13 - PROGRESS: at 53.26% examples, 72795 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 17:52:27: EPOCH 13 - PROGRESS: at 62.33% examples, 73098 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:28: EPOCH 13 - PROGRESS: at 71.62% examples, 73246 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:29: EPOCH 13 - PROGRESS: at 80.91% examples, 73433 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:30: EPOCH 13 - PROGRESS: at 90.32% examples, 73671 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:31: EPOCH 13 - PROGRESS: at 99.27% examples, 74160 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:31: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:52:31: EPOCH - 13 : training on 987411 raw words (885593 effective words) took 11.9s, 74239 effective words/s\n",
            "INFO - 17:52:32: EPOCH 14 - PROGRESS: at 7.77% examples, 69077 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 17:52:33: EPOCH 14 - PROGRESS: at 16.89% examples, 72809 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:34: EPOCH 14 - PROGRESS: at 26.08% examples, 73331 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:35: EPOCH 14 - PROGRESS: at 35.24% examples, 73739 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:36: EPOCH 14 - PROGRESS: at 44.23% examples, 73936 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:38: EPOCH 14 - PROGRESS: at 53.26% examples, 73989 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:39: EPOCH 14 - PROGRESS: at 62.33% examples, 74157 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:40: EPOCH 14 - PROGRESS: at 71.62% examples, 74260 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:41: EPOCH 14 - PROGRESS: at 80.91% examples, 74296 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:42: EPOCH 14 - PROGRESS: at 90.32% examples, 74520 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:43: EPOCH 14 - PROGRESS: at 100.00% examples, 75303 words/s, in_qsize 0, out_qsize 1\n",
            "INFO - 17:52:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:52:43: EPOCH - 14 : training on 987411 raw words (885593 effective words) took 11.8s, 75279 effective words/s\n",
            "INFO - 17:52:44: EPOCH 15 - PROGRESS: at 8.80% examples, 72334 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:45: EPOCH 15 - PROGRESS: at 17.90% examples, 74732 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:46: EPOCH 15 - PROGRESS: at 27.07% examples, 75652 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:47: EPOCH 15 - PROGRESS: at 36.27% examples, 75937 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:48: EPOCH 15 - PROGRESS: at 45.23% examples, 76423 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:49: EPOCH 15 - PROGRESS: at 54.26% examples, 76666 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:50: EPOCH 15 - PROGRESS: at 63.40% examples, 76735 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:51: EPOCH 15 - PROGRESS: at 72.65% examples, 76806 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:52: EPOCH 15 - PROGRESS: at 81.94% examples, 76877 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:53: EPOCH 15 - PROGRESS: at 91.36% examples, 76837 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:54: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:52:54: EPOCH - 15 : training on 987411 raw words (885593 effective words) took 11.5s, 77256 effective words/s\n",
            "INFO - 17:52:55: EPOCH 16 - PROGRESS: at 8.80% examples, 72577 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:57: EPOCH 16 - PROGRESS: at 16.89% examples, 70093 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:58: EPOCH 16 - PROGRESS: at 26.08% examples, 72790 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:52:59: EPOCH 16 - PROGRESS: at 35.24% examples, 73820 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:00: EPOCH 16 - PROGRESS: at 44.23% examples, 74293 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:01: EPOCH 16 - PROGRESS: at 53.26% examples, 74874 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:02: EPOCH 16 - PROGRESS: at 62.33% examples, 75217 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:03: EPOCH 16 - PROGRESS: at 71.62% examples, 75411 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:04: EPOCH 16 - PROGRESS: at 80.91% examples, 75633 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:05: EPOCH 16 - PROGRESS: at 90.32% examples, 75791 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:06: EPOCH 16 - PROGRESS: at 99.27% examples, 76173 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:06: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:53:06: EPOCH - 16 : training on 987411 raw words (885593 effective words) took 11.6s, 76288 effective words/s\n",
            "INFO - 17:53:07: EPOCH 17 - PROGRESS: at 8.80% examples, 72219 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:08: EPOCH 17 - PROGRESS: at 17.90% examples, 73834 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:09: EPOCH 17 - PROGRESS: at 27.07% examples, 74570 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:10: EPOCH 17 - PROGRESS: at 36.27% examples, 75227 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:11: EPOCH 17 - PROGRESS: at 45.23% examples, 75814 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:12: EPOCH 17 - PROGRESS: at 54.26% examples, 76062 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:13: EPOCH 17 - PROGRESS: at 63.40% examples, 76304 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:14: EPOCH 17 - PROGRESS: at 72.65% examples, 76319 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:15: EPOCH 17 - PROGRESS: at 81.94% examples, 76553 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:17: EPOCH 17 - PROGRESS: at 91.36% examples, 76647 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:17: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:53:17: EPOCH - 17 : training on 987411 raw words (885593 effective words) took 11.5s, 77279 effective words/s\n",
            "INFO - 17:53:19: EPOCH 18 - PROGRESS: at 8.80% examples, 72806 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:20: EPOCH 18 - PROGRESS: at 17.90% examples, 75266 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:21: EPOCH 18 - PROGRESS: at 27.07% examples, 75817 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:22: EPOCH 18 - PROGRESS: at 36.27% examples, 76319 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:23: EPOCH 18 - PROGRESS: at 45.23% examples, 76210 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:24: EPOCH 18 - PROGRESS: at 54.26% examples, 76236 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:25: EPOCH 18 - PROGRESS: at 63.40% examples, 76156 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:26: EPOCH 18 - PROGRESS: at 72.65% examples, 76180 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:27: EPOCH 18 - PROGRESS: at 81.94% examples, 76248 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:28: EPOCH 18 - PROGRESS: at 91.36% examples, 76355 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:53:29: EPOCH - 18 : training on 987411 raw words (885593 effective words) took 11.5s, 76906 effective words/s\n",
            "INFO - 17:53:30: EPOCH 19 - PROGRESS: at 8.80% examples, 75501 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:31: EPOCH 19 - PROGRESS: at 17.90% examples, 76436 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:32: EPOCH 19 - PROGRESS: at 27.07% examples, 76541 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:33: EPOCH 19 - PROGRESS: at 36.27% examples, 76849 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:34: EPOCH 19 - PROGRESS: at 45.23% examples, 76670 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:35: EPOCH 19 - PROGRESS: at 54.26% examples, 76659 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:36: EPOCH 19 - PROGRESS: at 63.40% examples, 76537 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:37: EPOCH 19 - PROGRESS: at 72.65% examples, 76539 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:39: EPOCH 19 - PROGRESS: at 80.91% examples, 75563 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:40: EPOCH 19 - PROGRESS: at 90.32% examples, 75814 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:41: EPOCH 19 - PROGRESS: at 99.27% examples, 76260 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:41: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:53:41: EPOCH - 19 : training on 987411 raw words (885593 effective words) took 11.6s, 76370 effective words/s\n",
            "INFO - 17:53:42: EPOCH 20 - PROGRESS: at 8.80% examples, 72431 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:43: EPOCH 20 - PROGRESS: at 17.90% examples, 75219 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:44: EPOCH 20 - PROGRESS: at 27.07% examples, 76075 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:45: EPOCH 20 - PROGRESS: at 36.27% examples, 76515 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:46: EPOCH 20 - PROGRESS: at 45.23% examples, 76803 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:47: EPOCH 20 - PROGRESS: at 54.26% examples, 76789 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:48: EPOCH 20 - PROGRESS: at 63.40% examples, 76945 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:49: EPOCH 20 - PROGRESS: at 72.65% examples, 76988 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:50: EPOCH 20 - PROGRESS: at 81.94% examples, 76962 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:51: EPOCH 20 - PROGRESS: at 91.36% examples, 77033 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:52: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:53:52: EPOCH - 20 : training on 987411 raw words (885593 effective words) took 11.4s, 77591 effective words/s\n",
            "INFO - 17:53:53: EPOCH 21 - PROGRESS: at 8.80% examples, 71836 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:54: EPOCH 21 - PROGRESS: at 17.90% examples, 73720 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:55: EPOCH 21 - PROGRESS: at 27.07% examples, 74799 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:56: EPOCH 21 - PROGRESS: at 36.27% examples, 75632 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:57: EPOCH 21 - PROGRESS: at 45.23% examples, 75945 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:58: EPOCH 21 - PROGRESS: at 54.26% examples, 76345 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:53:59: EPOCH 21 - PROGRESS: at 63.40% examples, 76605 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:01: EPOCH 21 - PROGRESS: at 72.65% examples, 76577 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:02: EPOCH 21 - PROGRESS: at 81.94% examples, 76790 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:03: EPOCH 21 - PROGRESS: at 91.36% examples, 76813 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:04: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:54:04: EPOCH - 21 : training on 987411 raw words (885593 effective words) took 11.5s, 77334 effective words/s\n",
            "INFO - 17:54:05: EPOCH 22 - PROGRESS: at 8.80% examples, 73697 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:06: EPOCH 22 - PROGRESS: at 17.90% examples, 75285 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:07: EPOCH 22 - PROGRESS: at 27.07% examples, 75895 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:08: EPOCH 22 - PROGRESS: at 36.27% examples, 76368 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:09: EPOCH 22 - PROGRESS: at 45.23% examples, 76576 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:10: EPOCH 22 - PROGRESS: at 54.26% examples, 76864 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:11: EPOCH 22 - PROGRESS: at 63.40% examples, 77108 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:12: EPOCH 22 - PROGRESS: at 72.65% examples, 77290 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:13: EPOCH 22 - PROGRESS: at 81.94% examples, 77473 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:14: EPOCH 22 - PROGRESS: at 91.36% examples, 77582 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:15: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:54:15: EPOCH - 22 : training on 987411 raw words (885593 effective words) took 11.3s, 78198 effective words/s\n",
            "INFO - 17:54:16: EPOCH 23 - PROGRESS: at 8.80% examples, 72906 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:17: EPOCH 23 - PROGRESS: at 17.90% examples, 75335 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:18: EPOCH 23 - PROGRESS: at 27.07% examples, 76225 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:19: EPOCH 23 - PROGRESS: at 36.27% examples, 76452 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:20: EPOCH 23 - PROGRESS: at 44.23% examples, 74467 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:21: EPOCH 23 - PROGRESS: at 53.26% examples, 74971 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:22: EPOCH 23 - PROGRESS: at 62.33% examples, 75318 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:23: EPOCH 23 - PROGRESS: at 71.62% examples, 75606 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:24: EPOCH 23 - PROGRESS: at 80.91% examples, 75611 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 17:54:25: EPOCH 23 - PROGRESS: at 90.32% examples, 75772 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:26: EPOCH 23 - PROGRESS: at 100.00% examples, 76536 words/s, in_qsize 0, out_qsize 1\n",
            "INFO - 17:54:26: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:54:26: EPOCH - 23 : training on 987411 raw words (885593 effective words) took 11.6s, 76516 effective words/s\n",
            "INFO - 17:54:28: EPOCH 24 - PROGRESS: at 8.80% examples, 72910 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:29: EPOCH 24 - PROGRESS: at 17.90% examples, 75045 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:30: EPOCH 24 - PROGRESS: at 27.07% examples, 76056 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:31: EPOCH 24 - PROGRESS: at 36.27% examples, 76773 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:32: EPOCH 24 - PROGRESS: at 45.23% examples, 77217 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:33: EPOCH 24 - PROGRESS: at 54.26% examples, 77280 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:34: EPOCH 24 - PROGRESS: at 63.40% examples, 77364 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:35: EPOCH 24 - PROGRESS: at 72.65% examples, 77112 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:36: EPOCH 24 - PROGRESS: at 81.94% examples, 77153 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:37: EPOCH 24 - PROGRESS: at 91.36% examples, 77214 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:38: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:54:38: EPOCH - 24 : training on 987411 raw words (885593 effective words) took 11.4s, 77677 effective words/s\n",
            "INFO - 17:54:39: EPOCH 25 - PROGRESS: at 8.80% examples, 72103 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:40: EPOCH 25 - PROGRESS: at 17.90% examples, 74171 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:41: EPOCH 25 - PROGRESS: at 27.07% examples, 75504 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:42: EPOCH 25 - PROGRESS: at 36.27% examples, 76132 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:43: EPOCH 25 - PROGRESS: at 45.23% examples, 76375 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:44: EPOCH 25 - PROGRESS: at 54.26% examples, 76430 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:45: EPOCH 25 - PROGRESS: at 63.40% examples, 76577 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:46: EPOCH 25 - PROGRESS: at 72.65% examples, 76561 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:47: EPOCH 25 - PROGRESS: at 81.94% examples, 76624 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:48: EPOCH 25 - PROGRESS: at 91.36% examples, 76681 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 17:54:49: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:54:49: EPOCH - 25 : training on 987411 raw words (885593 effective words) took 11.5s, 77319 effective words/s\n",
            "INFO - 17:54:50: EPOCH 26 - PROGRESS: at 8.80% examples, 72801 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:51: EPOCH 26 - PROGRESS: at 17.90% examples, 75546 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:53: EPOCH 26 - PROGRESS: at 27.07% examples, 76046 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:54: EPOCH 26 - PROGRESS: at 36.27% examples, 75650 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:55: EPOCH 26 - PROGRESS: at 45.23% examples, 75766 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:56: EPOCH 26 - PROGRESS: at 54.26% examples, 75832 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 17:54:57: EPOCH 26 - PROGRESS: at 63.40% examples, 75783 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:58: EPOCH 26 - PROGRESS: at 72.65% examples, 75764 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:54:59: EPOCH 26 - PROGRESS: at 81.94% examples, 75798 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:00: EPOCH 26 - PROGRESS: at 91.36% examples, 75852 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 17:55:01: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:55:01: EPOCH - 26 : training on 987411 raw words (885593 effective words) took 11.6s, 76329 effective words/s\n",
            "INFO - 17:55:02: EPOCH 27 - PROGRESS: at 6.76% examples, 57611 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:03: EPOCH 27 - PROGRESS: at 15.88% examples, 65861 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:04: EPOCH 27 - PROGRESS: at 25.05% examples, 69086 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:05: EPOCH 27 - PROGRESS: at 34.17% examples, 70761 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:06: EPOCH 27 - PROGRESS: at 43.25% examples, 71702 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:07: EPOCH 27 - PROGRESS: at 52.26% examples, 72128 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:08: EPOCH 27 - PROGRESS: at 61.29% examples, 72576 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:10: EPOCH 27 - PROGRESS: at 70.56% examples, 73057 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:11: EPOCH 27 - PROGRESS: at 79.88% examples, 73376 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:12: EPOCH 27 - PROGRESS: at 89.27% examples, 73747 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:13: EPOCH 27 - PROGRESS: at 98.33% examples, 74208 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:13: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:55:13: EPOCH - 27 : training on 987411 raw words (885593 effective words) took 11.9s, 74507 effective words/s\n",
            "INFO - 17:55:14: EPOCH 28 - PROGRESS: at 8.80% examples, 72618 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:15: EPOCH 28 - PROGRESS: at 17.90% examples, 74760 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:16: EPOCH 28 - PROGRESS: at 27.07% examples, 75561 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:17: EPOCH 28 - PROGRESS: at 36.27% examples, 75841 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:18: EPOCH 28 - PROGRESS: at 45.23% examples, 76064 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:19: EPOCH 28 - PROGRESS: at 54.26% examples, 75991 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:20: EPOCH 28 - PROGRESS: at 63.40% examples, 75979 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:21: EPOCH 28 - PROGRESS: at 72.65% examples, 75868 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:22: EPOCH 28 - PROGRESS: at 81.94% examples, 75938 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:23: EPOCH 28 - PROGRESS: at 91.36% examples, 75862 words/s, in_qsize 2, out_qsize 0\n",
            "INFO - 17:55:24: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:55:24: EPOCH - 28 : training on 987411 raw words (885593 effective words) took 11.6s, 76380 effective words/s\n",
            "INFO - 17:55:26: EPOCH 29 - PROGRESS: at 8.80% examples, 71521 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:27: EPOCH 29 - PROGRESS: at 17.90% examples, 73135 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:28: EPOCH 29 - PROGRESS: at 27.07% examples, 73851 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:29: EPOCH 29 - PROGRESS: at 36.27% examples, 73732 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:30: EPOCH 29 - PROGRESS: at 45.23% examples, 74026 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:31: EPOCH 29 - PROGRESS: at 54.26% examples, 74423 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:32: EPOCH 29 - PROGRESS: at 63.40% examples, 74777 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:33: EPOCH 29 - PROGRESS: at 72.65% examples, 74855 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:34: EPOCH 29 - PROGRESS: at 81.94% examples, 74899 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:35: EPOCH 29 - PROGRESS: at 91.36% examples, 75047 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:36: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:55:36: EPOCH - 29 : training on 987411 raw words (885593 effective words) took 11.7s, 75600 effective words/s\n",
            "INFO - 17:55:37: EPOCH 30 - PROGRESS: at 8.80% examples, 71410 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:38: EPOCH 30 - PROGRESS: at 17.90% examples, 72608 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:39: EPOCH 30 - PROGRESS: at 27.07% examples, 73714 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:41: EPOCH 30 - PROGRESS: at 36.27% examples, 74189 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:42: EPOCH 30 - PROGRESS: at 45.23% examples, 74470 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:43: EPOCH 30 - PROGRESS: at 53.26% examples, 73322 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:44: EPOCH 30 - PROGRESS: at 62.33% examples, 73908 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:45: EPOCH 30 - PROGRESS: at 71.62% examples, 74149 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:46: EPOCH 30 - PROGRESS: at 80.91% examples, 74609 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:47: EPOCH 30 - PROGRESS: at 90.32% examples, 75003 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 17:55:48: EPOCH 30 - PROGRESS: at 100.00% examples, 75695 words/s, in_qsize 0, out_qsize 1\n",
            "INFO - 17:55:48: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:55:48: EPOCH - 30 : training on 987411 raw words (885593 effective words) took 11.7s, 75675 effective words/s\n",
            "INFO - 17:55:48: training on a 29622330 raw words (26567790 effective words) took 352.2s, 75430 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26567790, 29622330)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4aa0DVvow3R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49e34d4a-193d-4f63-edb5-1f666f8b9886"
      },
      "source": [
        "#Tornando o modelo mais eficiente em quest√µes de uso de mem√≥ria.\n",
        "w2v_model.init_sims(replace=True)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 17:55:48: precomputing L2-norms of word weight vectors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMEQVcaV6K-t",
        "colab_type": "text"
      },
      "source": [
        "**A partir do Word2VEC podemos verificar a similaridade de outras palavras para determinados termos.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG8WLQdaqJpZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "9cdd87c8-1589-4552-fe83-b91801547a30"
      },
      "source": [
        "w2v_model.wv.most_similar([\"vacina\"])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('vacina_contra', 0.6103950142860413),\n",
              " ('vacina_chinesa', 0.575373649597168),\n",
              " ('tomar_vacina', 0.5506119728088379),\n",
              " ('\"vacina', 0.55013108253479),\n",
              " ('vacinas', 0.5209200382232666),\n",
              " ('doses_vacina', 0.5143899917602539),\n",
              " ('cura_pro', 0.49834805727005005),\n",
              " ('testes_vacina', 0.46528884768486023),\n",
              " ('#vacina', 0.46326375007629395),\n",
              " ('vacina_oxford', 0.4472700357437134)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzHB_w9O67oU",
        "colab_type": "text"
      },
      "source": [
        "**Podemos determinar filtros para uma verifica√ß√£o de similaridade.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsZeL1qQ62sP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "96727fd2-898c-4691-b2a0-7a4d7bcd5a29"
      },
      "source": [
        "w2v_model.wv.most_similar([\"recuperados\"])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('curados', 0.6723613739013672),\n",
              " ('pacientes_recuperados', 0.6644158959388733),\n",
              " ('pessoas_recuperadas', 0.5978997349739075),\n",
              " ('pessoas_curadas', 0.5825570821762085),\n",
              " ('casos_ativos', 0.5789518356323242),\n",
              " ('v√≠timas_fatais', 0.5399223566055298),\n",
              " ('confirma√ß√µes', 0.5339558124542236),\n",
              " ('recuperados‚Ä¶', 0.5291306376457214),\n",
              " ('mortes_confirmadas', 0.5233118534088135),\n",
              " ('recuperados,', 0.5071163773536682)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rduVJL697A28",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "a0467c13-84d8-4c6b-cf72-fc69ad3bad65"
      },
      "source": [
        "w2v_model.wv.most_similar([\"mortes\"])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('mortes_causadas', 0.7534787654876709),\n",
              " ('novas_mortes', 0.7022619247436523),\n",
              " ('mortes_confirmadas', 0.6499084830284119),\n",
              " ('mortes,', 0.6382780075073242),\n",
              " ('mortos', 0.6382266283035278),\n",
              " ('vidas_perdidas', 0.6365260481834412),\n",
              " ('√≥bitos', 0.6325196027755737),\n",
              " ('1300_mortes', 0.6275931000709534),\n",
              " ('mortes_di√°rias', 0.6254568099975586),\n",
              " ('pessoas_recuperadas', 0.6249717473983765)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GnO8u4J6fnY",
        "colab_type": "text"
      },
      "source": [
        "**Podemos compararar a taxa de similaridade para termos espec√≠ficos.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSZ3e0qeqR0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "d6c2baed-9768-41fb-f641-c7f00b2608b3"
      },
      "source": [
        "w2v_model.wv.similarity(\"coronavirus\", 'mortes')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.38481155"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNOuLotAqZuy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "dce5668c-c2e8-41b0-fe04-ae98e872a391"
      },
      "source": [
        "w2v_model.wv.similarity(\"coronavirus\", 'casos')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.40403104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrv67Or1qc0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "aac81207-30b8-488c-fcc2-87a1d8abbc46"
      },
      "source": [
        "w2v_model.wv.similarity(\"pandemia\", 'coronavirus')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.111920424"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OzMkt6cm_zX",
        "colab_type": "text"
      },
      "source": [
        "**Dado uma lista, qual palavra n√£o se encaixa no contexto ?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KGwOtgOm7Iz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "257f44e8-0d81-4518-e7c3-f0f8def42916"
      },
      "source": [
        "w2v_model.wv.doesnt_match([\"pandemia\", \"vacina\", \"futebol\"])"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'futebol'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPGIwf79m_Td",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "9f0a0001-0528-4802-f718-28784c065d80"
      },
      "source": [
        "w2v_model.wv.doesnt_match([\"mortes\", \"alegria\", \"casos\"])"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'alegria'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg6Us2Tp9NwJ",
        "colab_type": "text"
      },
      "source": [
        "# Aplicando Modelo N√£o Supervisionado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r9qksJG9-Wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importando algoritmo KMeans da biblioteca Sklearn.\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnjRhOa0XRzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Carregando modelo Word2VEC.\n",
        "word_vectors = w2v_model.wv\n",
        "#Criando inst√¢ncia do algoritmo K-Means e passando como entrada os vetores originados pelo Word2VEC.\n",
        "model = KMeans(n_clusters=2, init='k-means++', max_iter=1000, n_init=50).fit(X=word_vectors.vectors)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj7oNOz4xZVl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "4cc05b36-1361-49f5-ea42-69f6a60b10a1"
      },
      "source": [
        "word_vectors.similar_by_vector(model.cluster_centers_[0], topn=10, restrict_vocab=None)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ùêÇùê®ùê´ùê®ùêßùêöùêØùê¢ÃÅùê´ùêÆùê¨', 0.8969775438308716),\n",
              " ('@rizickyusuphl', 0.8798004388809204),\n",
              " ('@danielmarvin01', 0.8796795606613159),\n",
              " ('#f√©emdeus‚Ä¶', 0.8795099258422852),\n",
              " ('@gainarisfanss', 0.8782029151916504),\n",
              " ('@tweetsdesflps', 0.8736926317214966),\n",
              " ('crn9_#projetonutrisdv‚Ä¶', 0.8723886609077454),\n",
              " ('@kephas_joe', 0.8673235177993774),\n",
              " ('#@a‚Ä¶', 0.865475058555603),\n",
              " ('@heirmainem', 0.8643310070037842)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFWaDlYYxtoT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "4ed3037e-1eb3-46dc-c0de-b44ae1d6619e"
      },
      "source": [
        "word_vectors.similar_by_vector(model.cluster_centers_[1], topn=10, restrict_vocab=None)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('üáßüá™belgiumüáßüá™', 0.8052440881729126),\n",
              " ('üá™üá∏spainüá™üá∏', 0.7937214374542236),\n",
              " ('üá®üá≥chinaüá®üá≥', 0.7917062044143677),\n",
              " ('üá∑üá∫russiaüá∑üá∫', 0.7911747694015503),\n",
              " ('üáµüá∞pakistanüáµüá∞', 0.7902183532714844),\n",
              " ('üáµüá±polandüáµüá±', 0.7901195287704468),\n",
              " ('üáÆüáπitalyüáÆüáπ', 0.7869265079498291),\n",
              " ('üá®üá¶canadaüá®üá¶', 0.786351203918457),\n",
              " ('144%', 0.7807823419570923),\n",
              " ('üá´üá∑franceüá´üá∑', 0.7795273065567017)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL-MDRTTx0G6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#word_vectors.similar_by_vector(model.cluster_centers_[2], topn=10, restrict_vocab=None)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIpDjbcQxa0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "positive_cluster_center = model.cluster_centers_[0]\n",
        "negative_cluster_center = model.cluster_centers_[1]\n",
        "#neutral_cluster_center = model.cluster_centers_[2]"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqR8eQhEXbCm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "66525f26-1f8e-472e-c4ae-b4c8ef79b51b"
      },
      "source": [
        "#Verificando os vetores que foram entradas para o algoritmo, criados pelo modelo Word2VEC.\n",
        "word_vectors.vectors"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.07247983,  0.09380963, -0.06688488, ..., -0.03902691,\n",
              "        -0.048719  ,  0.03785762],\n",
              "       [-0.07692402,  0.1365095 , -0.08250232, ..., -0.03696414,\n",
              "        -0.02828272,  0.03831188],\n",
              "       [ 0.00591224,  0.06191151, -0.04618785, ..., -0.02679166,\n",
              "        -0.11386555, -0.01721167],\n",
              "       ...,\n",
              "       [-0.00844941,  0.03773918, -0.05117185, ..., -0.00842633,\n",
              "        -0.16460082,  0.04072035],\n",
              "       [ 0.03110459, -0.01783972,  0.00416496, ...,  0.04767651,\n",
              "        -0.02908188, -0.117335  ],\n",
              "       [ 0.01073382, -0.05020504,  0.00884969, ..., -0.06653279,\n",
              "        -0.04862808,  0.01243616]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KqEfIOPXKbb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "90a98312-f9cf-4c6a-f84c-ed35fc04e7e8"
      },
      "source": [
        "model.cluster_centers_"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.49804088e-02,  1.24381315e-02, -1.18124327e-02,\n",
              "        -3.74690210e-03,  1.14237787e-02, -6.32320810e-03,\n",
              "        -2.95741428e-02,  4.58739698e-04, -2.30015777e-02,\n",
              "        -1.14693614e-02,  1.01594124e-02,  7.99133535e-03,\n",
              "         6.67918660e-03, -1.14769135e-02, -1.14016337e-02,\n",
              "         4.29918850e-03, -8.06625746e-03, -2.15933286e-02,\n",
              "        -8.11564364e-03,  2.60968655e-02, -3.95966647e-03,\n",
              "        -1.69766825e-02,  1.76073238e-02, -1.86691545e-02,\n",
              "         2.03257501e-02,  3.75981741e-02, -1.08377514e-02,\n",
              "         1.79280806e-03,  4.11629677e-02, -3.70318405e-02,\n",
              "        -3.80904265e-02,  1.98014583e-02, -2.55570095e-02,\n",
              "         6.02965336e-03, -4.55115512e-02, -4.19063866e-03,\n",
              "        -1.88215841e-02,  1.55554842e-02,  6.14742562e-03,\n",
              "         1.56976078e-02,  7.18734786e-03, -1.76417939e-02,\n",
              "        -3.34281940e-05, -5.18056843e-03, -8.27098824e-03,\n",
              "         1.71032250e-02,  2.24395990e-02,  2.30482742e-02,\n",
              "        -1.17594488e-02, -1.59287658e-02,  9.35545098e-03,\n",
              "        -3.55297886e-03,  1.25476057e-02, -1.41717121e-02,\n",
              "        -4.99577355e-03,  1.89217478e-02, -2.54738797e-02,\n",
              "         1.03654657e-02, -2.02454273e-02, -1.87454242e-02,\n",
              "        -1.41753284e-02, -4.28863466e-02, -1.35741318e-02,\n",
              "         4.12096921e-03,  1.78221613e-04, -1.61565957e-03,\n",
              "        -1.26254437e-02,  3.30846058e-04, -6.06151624e-03,\n",
              "         6.61646016e-04,  2.30632648e-02,  9.78817232e-03,\n",
              "         9.96273663e-03, -1.46271288e-02, -6.54621497e-02,\n",
              "         8.20461754e-03,  7.41773425e-03, -5.08853281e-03,\n",
              "        -5.77975856e-03,  4.37162369e-02, -2.07513049e-02,\n",
              "         3.72805484e-02,  2.85689416e-03,  5.78823872e-03,\n",
              "         2.79714148e-02,  9.84619651e-03,  2.90709501e-03,\n",
              "        -1.36425439e-03, -6.02526590e-03, -1.75293051e-02,\n",
              "        -6.73357211e-03, -2.13097185e-02, -1.98194236e-02,\n",
              "        -3.38001102e-02, -7.26480922e-03, -1.87129155e-02,\n",
              "        -4.01158668e-02,  4.17358801e-03,  2.94990093e-03,\n",
              "        -4.03023586e-02,  3.49299945e-02,  3.29822749e-02,\n",
              "        -3.21036242e-02, -4.57938127e-02,  1.01822969e-02,\n",
              "        -1.38446456e-02, -7.43913837e-03,  8.91202129e-04,\n",
              "         2.27341838e-02,  3.42176110e-02,  1.38156558e-03,\n",
              "        -5.96195459e-03, -4.33878787e-03,  2.04531848e-02,\n",
              "         1.35413241e-02, -1.19115459e-02, -1.93997286e-02,\n",
              "        -8.37579835e-03, -1.30949272e-02,  2.25444436e-02,\n",
              "         1.39666107e-02,  1.48530724e-03,  2.07991004e-02,\n",
              "         1.01853516e-02,  3.04375421e-02,  2.15531606e-02,\n",
              "         3.21568698e-02,  2.66437829e-02, -3.05921379e-02,\n",
              "         1.17392093e-03,  5.83226420e-03,  8.41912068e-03,\n",
              "         2.10563689e-02, -4.87582758e-03,  7.71136489e-04,\n",
              "        -1.48558421e-02,  6.60071615e-04, -2.89970059e-02,\n",
              "        -4.95389570e-03,  1.87271684e-02, -3.08763571e-02,\n",
              "         1.78855192e-02, -8.07480607e-03, -3.46981958e-02,\n",
              "         4.40889969e-03,  1.22298896e-02,  2.08875276e-02,\n",
              "        -6.36069896e-03, -7.81936105e-03,  2.87338942e-02,\n",
              "        -2.20132172e-02,  1.23713948e-02, -2.43478455e-02,\n",
              "        -3.84653509e-02,  2.23065354e-02, -6.32387586e-03,\n",
              "         5.52837737e-05, -1.01485197e-02, -2.34123450e-02,\n",
              "        -2.06794357e-03,  1.62488688e-02, -2.45709508e-03,\n",
              "         3.16888629e-03,  2.10897066e-02, -6.35993388e-03,\n",
              "        -2.05898285e-02, -1.80559158e-02,  1.11686317e-02,\n",
              "         1.88802984e-02, -8.21895339e-03,  2.35296208e-02,\n",
              "         1.61346793e-02,  2.67579909e-02, -2.53710505e-02,\n",
              "         7.71172205e-03, -1.13185057e-02,  1.23949861e-02,\n",
              "        -2.52383444e-02,  1.30419750e-02, -2.39377134e-02,\n",
              "        -9.79876798e-03, -3.35652009e-02, -1.25113390e-02,\n",
              "         1.09083168e-02,  3.58517654e-03, -1.79536641e-02,\n",
              "        -8.25913344e-03, -6.84554130e-03,  2.47668903e-02,\n",
              "         1.46040730e-02,  1.08622471e-02,  5.78582520e-03,\n",
              "        -6.58333022e-03, -2.12533846e-02,  1.13692246e-02,\n",
              "        -6.31120522e-03, -1.32258702e-02,  2.48899180e-02,\n",
              "         2.28438992e-02,  4.82782908e-03,  4.19365317e-02,\n",
              "         9.91651881e-03,  3.63885565e-03,  2.73156911e-05,\n",
              "        -9.14615113e-03,  2.16138121e-02,  1.73606584e-03,\n",
              "        -3.11917253e-03,  1.74665693e-02,  1.63723398e-02,\n",
              "         1.36658549e-02,  2.85407305e-02, -2.49222890e-02,\n",
              "        -3.75376567e-02,  4.07429179e-04, -1.57344416e-02,\n",
              "         2.53318548e-02, -1.29969418e-03, -3.03681958e-02,\n",
              "         2.68979575e-02, -1.62643678e-02,  2.80185323e-03,\n",
              "         7.49757979e-03, -1.71346068e-02, -4.20416072e-02,\n",
              "        -2.51759053e-03,  3.00880559e-02,  1.91135909e-02,\n",
              "         8.69814213e-03,  1.57219097e-02, -2.46771658e-03,\n",
              "         1.48142744e-02,  1.85033381e-02, -1.10413153e-02,\n",
              "         2.94920057e-02,  5.24393003e-03,  1.97495706e-02,\n",
              "        -2.11165920e-02, -1.23210819e-02,  7.23843137e-03,\n",
              "         6.13480667e-03, -2.85457186e-02,  1.31878583e-02,\n",
              "        -3.23784538e-03, -3.16896364e-02,  1.31720537e-03,\n",
              "        -2.09056437e-02,  1.20195057e-02, -2.29619257e-03,\n",
              "        -5.81328757e-03, -7.79643049e-03, -5.48337549e-02,\n",
              "         1.60253793e-02,  2.06631143e-02, -1.35658178e-02,\n",
              "         2.51234621e-02, -3.04496335e-03,  1.26718562e-02,\n",
              "         3.67182083e-02, -6.86396752e-03, -1.60882324e-02,\n",
              "         8.54435749e-03,  3.17678899e-02, -4.62466702e-02,\n",
              "        -1.76664479e-02, -3.18148881e-02, -1.66915474e-03,\n",
              "        -1.27127832e-02,  6.83351001e-03,  8.23444873e-03,\n",
              "        -8.73657223e-03, -2.04882156e-02,  1.95387676e-02,\n",
              "         1.17953727e-02,  3.46332695e-03, -1.05049992e-02,\n",
              "         3.84589583e-02,  2.14877315e-02, -4.05483842e-02,\n",
              "        -1.20013049e-02, -2.49255188e-02, -1.89833238e-03,\n",
              "        -1.55571280e-02,  3.72873023e-02, -3.41633968e-02,\n",
              "         1.07533140e-02, -2.18155086e-02,  3.33294980e-02,\n",
              "         2.40794234e-02, -2.35053990e-03, -1.76645312e-02,\n",
              "        -1.82731450e-02, -1.41584724e-02,  1.47756645e-02,\n",
              "        -1.67598929e-02,  1.07678701e-04,  2.77698087e-03,\n",
              "         8.07332620e-03, -3.75009328e-02,  5.81653975e-03],\n",
              "       [ 1.66158937e-02,  1.61472848e-03, -1.44147584e-02,\n",
              "         8.91493633e-03, -1.41782751e-02, -8.85832822e-04,\n",
              "        -1.29802395e-02,  2.08872389e-02, -1.32350391e-02,\n",
              "        -7.49663357e-03, -3.63940978e-03,  1.01121310e-02,\n",
              "        -2.34112367e-02,  1.70065872e-02, -1.79833658e-02,\n",
              "         8.64656270e-03, -3.49468812e-02, -8.10790062e-03,\n",
              "         2.14428362e-02,  4.46843877e-02,  8.42109229e-03,\n",
              "        -1.83454193e-02, -3.51112597e-02, -6.06272463e-03,\n",
              "        -1.66463964e-02,  2.86952760e-02, -2.96385735e-02,\n",
              "         1.78385731e-02,  2.78179422e-02, -2.26209983e-02,\n",
              "        -2.34577656e-02,  1.04108360e-03, -3.75853404e-02,\n",
              "        -9.00221057e-03, -3.33296917e-02,  2.95010079e-02,\n",
              "        -4.98876050e-02, -1.75733902e-02,  1.28892278e-02,\n",
              "         9.68439970e-03,  4.97492915e-03, -3.00390329e-02,\n",
              "         5.48635004e-03, -2.38208808e-02,  3.43549699e-02,\n",
              "         5.53141255e-03,  2.10573897e-04,  1.48904482e-02,\n",
              "        -1.67224016e-02, -4.11006948e-03,  2.29135118e-02,\n",
              "        -1.38024390e-02, -1.98964979e-02, -6.62395172e-03,\n",
              "        -1.03762718e-02,  8.84534232e-03, -1.90327279e-02,\n",
              "         5.45972679e-03,  1.47542395e-02, -3.75823975e-02,\n",
              "        -3.41758505e-02, -3.53579558e-02, -3.58039290e-02,\n",
              "         9.86059010e-03,  1.55015662e-02, -3.48958327e-03,\n",
              "        -9.64744575e-03, -2.79480102e-03, -2.24567181e-03,\n",
              "        -1.69580504e-02, -1.06729781e-02, -2.54596248e-02,\n",
              "         2.13523358e-02, -8.97789840e-03, -1.82628985e-02,\n",
              "         1.17164226e-02, -4.23025340e-03,  2.41818856e-02,\n",
              "        -2.01986153e-02,  2.02824995e-02, -4.10288796e-02,\n",
              "         6.23825006e-03, -1.66753423e-03, -2.59386264e-02,\n",
              "         1.96269453e-02, -1.21016474e-03,  1.66124906e-02,\n",
              "        -2.01282036e-02, -2.59103738e-02, -3.87486592e-02,\n",
              "         1.41544743e-02, -1.79139879e-02, -8.79064575e-03,\n",
              "        -5.36878221e-03, -1.49363605e-03,  6.90280832e-03,\n",
              "        -1.68797337e-02,  1.45014506e-02,  1.24969203e-02,\n",
              "        -1.56837292e-02,  2.24288739e-02,  3.07949018e-02,\n",
              "        -5.27721643e-03, -4.18696143e-02,  1.87042132e-02,\n",
              "        -2.22564321e-02,  4.21418156e-03,  1.23175252e-02,\n",
              "         1.75086539e-02,  1.05294148e-02, -6.17899175e-04,\n",
              "        -1.26254866e-02, -1.58814788e-02, -1.05495080e-02,\n",
              "         4.02135914e-03,  7.54566956e-03, -7.67756905e-03,\n",
              "         1.79711170e-02, -4.69316281e-02,  2.91690230e-05,\n",
              "         2.88056489e-03,  1.04004573e-02, -1.72502846e-02,\n",
              "        -5.03615662e-03,  4.24163714e-02,  6.17518649e-03,\n",
              "         3.57786007e-03, -2.36249547e-02,  1.96559150e-02,\n",
              "        -2.25228816e-02, -5.52389771e-04, -1.22288475e-03,\n",
              "         2.53844466e-02,  1.58500229e-03,  6.65554835e-04,\n",
              "         4.72349767e-03, -1.08079584e-02, -1.92291737e-02,\n",
              "         1.06281880e-03,  1.54955443e-02, -1.39466776e-02,\n",
              "         2.41436008e-02, -1.47722047e-02, -3.35284695e-03,\n",
              "         1.46936555e-03, -1.12109017e-02, -2.32289732e-03,\n",
              "        -3.99813242e-03,  6.59311051e-03,  1.41225820e-02,\n",
              "        -2.63290443e-02,  1.42622888e-02, -4.61460464e-03,\n",
              "        -2.48242933e-02,  2.53924243e-02,  4.21254616e-03,\n",
              "         9.53770056e-03,  3.48377740e-03, -1.83161832e-02,\n",
              "         9.55681375e-04,  2.00150814e-02, -7.60549447e-03,\n",
              "        -1.00880023e-02,  1.32305669e-02, -1.06603969e-02,\n",
              "        -9.82674211e-03, -8.20795447e-03,  1.43765407e-02,\n",
              "         2.83279251e-02,  2.75147799e-02,  2.22175680e-02,\n",
              "        -4.94034775e-03,  2.55755819e-02, -1.51786683e-02,\n",
              "        -7.31235044e-03, -7.05200108e-03,  1.67150702e-02,\n",
              "        -1.43707776e-02, -1.23153729e-02, -2.05713827e-02,\n",
              "        -1.41639998e-02,  4.78308462e-03, -2.79701725e-02,\n",
              "        -1.47386249e-02,  2.81775966e-02, -1.44500192e-03,\n",
              "         2.95513822e-03, -1.07313152e-02,  2.17446573e-02,\n",
              "         2.51006149e-02, -2.19707713e-02, -3.53425834e-03,\n",
              "         3.87781784e-02, -2.14632358e-02, -9.75661166e-03,\n",
              "        -5.34766400e-03,  7.87763484e-03,  5.30357845e-03,\n",
              "         3.59551329e-03,  1.52595881e-02, -6.11695834e-03,\n",
              "         9.41868406e-03,  1.61942896e-02, -1.76214892e-02,\n",
              "        -1.62788443e-02,  3.56901959e-02,  1.04259886e-02,\n",
              "         2.11651362e-02,  1.99177098e-02,  2.16702130e-02,\n",
              "        -6.95510488e-03,  1.16533060e-02,  1.45803075e-02,\n",
              "        -4.49390523e-03, -5.42008644e-03, -8.91620759e-03,\n",
              "         2.67497562e-02, -1.93297789e-02, -1.67105626e-02,\n",
              "        -4.55899443e-03, -1.16001731e-02, -2.42379829e-02,\n",
              "         6.22271048e-03, -9.11803171e-03, -2.08914056e-02,\n",
              "         9.71732847e-03,  3.33637744e-02,  3.84397991e-03,\n",
              "        -1.07200388e-02,  4.80639236e-03,  1.29704652e-02,\n",
              "         3.38839507e-03, -6.98487274e-03, -1.25766676e-02,\n",
              "         4.56110016e-03,  4.84647555e-03, -3.39396950e-03,\n",
              "        -2.31314041e-02,  1.78281702e-02, -2.33988743e-02,\n",
              "         7.97091797e-03,  1.29957860e-02,  1.40995020e-02,\n",
              "        -2.74399426e-02, -6.17570616e-03,  5.56724239e-03,\n",
              "        -8.14780220e-03, -5.16546424e-04,  3.61106247e-02,\n",
              "         2.02556401e-02, -2.33381465e-02,  4.41639684e-03,\n",
              "         2.85356026e-02,  2.58563478e-02, -1.73382293e-02,\n",
              "         2.16572881e-02,  6.03606971e-03,  3.16359289e-03,\n",
              "         3.00255716e-02, -6.41177595e-03, -6.66582352e-03,\n",
              "        -4.62882314e-03,  4.54205927e-03, -1.18977204e-02,\n",
              "        -7.52229849e-03, -5.03249466e-04,  1.80018344e-03,\n",
              "        -4.84387111e-03,  1.64591670e-02,  1.79528035e-02,\n",
              "        -4.74200584e-04, -1.15226321e-02,  3.00618745e-02,\n",
              "         1.86913181e-04, -9.71126137e-05, -1.64154004e-02,\n",
              "        -1.75753012e-02,  1.16529260e-02, -1.49236172e-02,\n",
              "        -2.10684724e-02, -4.49243784e-02,  2.19747238e-03,\n",
              "        -1.52341621e-02,  9.76890326e-03,  8.31902679e-03,\n",
              "        -1.35217868e-02, -3.10991034e-02,  1.51436953e-02,\n",
              "         1.09652672e-02,  1.53429611e-02,  1.10950135e-02,\n",
              "        -9.44829639e-03,  1.93579169e-03,  8.28963518e-03,\n",
              "        -5.64605929e-04, -1.86790200e-03,  3.98330064e-03,\n",
              "         1.93040017e-02, -4.47487757e-02, -3.11478768e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRQpEqHj_BEc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0162a98b-ae7a-41fb-c624-e196664db815"
      },
      "source": [
        "len(model.labels_)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30785"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScCYPYk0XnoI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "01b01b7c-3dee-4795-db82-ff986177732c"
      },
      "source": [
        "#Verificando os labels originados pelo modelo.\n",
        "model.labels_"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 1, 0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqLT1tBQXrkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Criando DataFrame com as classifica√ß√µes para os tweets.\n",
        "df_kmeans = pd.DataFrame(data=model.labels_, columns=['text'])"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzwCr24tXyWZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "1614eb96-d853-4119-c145-9db6bf960c76"
      },
      "source": [
        "#Visualizando o novo DataFrame criado.\n",
        "df_kmeans"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30780</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30781</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30782</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30783</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30784</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30785 rows √ó 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       text\n",
              "0         0\n",
              "1         0\n",
              "2         1\n",
              "3         1\n",
              "4         1\n",
              "...     ...\n",
              "30780     0\n",
              "30781     0\n",
              "30782     0\n",
              "30783     1\n",
              "30784     0\n",
              "\n",
              "[30785 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9nS7aCbZuJ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "285466e5-1f38-48cf-ec91-a938832faa1c"
      },
      "source": [
        "#Distruibui√ß√£o das senten√ßas nos clusters pelo algoritmo K-Means.\n",
        "df_kmeans['text'].value_counts()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    17314\n",
              "1    13471\n",
              "Name: text, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pPCQMzx63bX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "989e3e1f-c3bb-42bf-c675-51add526e57b"
      },
      "source": [
        "#Porcentagem que representa a distribui√ß√£o das senten√ßas nos clusters pelo algoritmo K-Means.\n",
        "df_kmeans['text'].value_counts(normalize=True)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 17:56:16: NumExpr defaulting to 2 threads.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.562417\n",
              "1    0.437583\n",
              "Name: text, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkmCimHTaxyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "065b8322-b768-4029-e2da-813b448fc46c"
      },
      "source": [
        "#Verificando os clusters √∫nicos.\n",
        "df_kmeans['text'].unique()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSMHnyZg6rgd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c9b33af9-70b7-4a49-97a8-4b4a11c3f924"
      },
      "source": [
        "#Criando Vocabul√°rio em formato de Dicion√°rio para o sentimento das palavras.\n",
        "words = pd.DataFrame(word_vectors.vocab.keys())\n",
        "#Nomeando a coluna do DataFrame.\n",
        "words.columns = ['words']\n",
        "#Atribuindo as palavras a classe positiva ou negativa, de acordo com a clusteriza√ß√£o.\n",
        "words['vectors'] = words.words.apply(lambda x: word_vectors.wv[f'{x}'])\n",
        "words['cluster'] = words.vectors.apply(lambda x: model.predict([np.array(x)]))\n",
        "words.cluster = words.cluster.apply(lambda x: x[0])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXCf-GaVvYCd",
        "colab_type": "text"
      },
      "source": [
        "*Explica√ß√£o para Fun√ß√£o Lambda que atribui um sentimento em potencial para as palavras.*\n",
        "\n",
        "**Para atribuir uma pontua√ß√£o de sentimento para cada palavra foi realizada uma multiplica√ß√£o pelo qu√£o pr√≥ximos eles estavam de seu cluster (para denotar o qu√£o potencialmente positivos / negativos os termos s√£o). Como a pontua√ß√£o que o algoritmo K-means produz √© a dist√¢ncia de ambos os clusters, para ponder√°-los corretamente, foi feita a multiplica√ß√£o pelo inverso da pontua√ß√£o de proximidade (divis√£o da pontua√ß√£o de sentimento pela pontua√ß√£o de proximidade).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exlvF0Qd6ulu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Para o cluster 0 atribuiu-se o sentimento como positivo e para o outro cluster atribuiu-se o sentimento negativo.\n",
        "words['cluster_value'] = [1 if i==0 else -1 for i in words.cluster]\n",
        "words['closeness_score'] = words.apply(lambda x: 1/(model.transform([x.vectors]).min()), axis=1)\n",
        "words['sentiment_coeff'] = words.closeness_score * words.cluster_value"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HamQZYMm6v56",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "12fa2363-224f-40e8-db5a-4e290db8d9c5"
      },
      "source": [
        "words.head(5)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>vectors</th>\n",
              "      <th>cluster</th>\n",
              "      <th>cluster_value</th>\n",
              "      <th>closeness_score</th>\n",
              "      <th>sentiment_coeff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tudo</td>\n",
              "      <td>[-0.082223766, -0.06573236, -0.011766441, -0.0...</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1.019969</td>\n",
              "      <td>-1.019969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mudou</td>\n",
              "      <td>[-0.010562198, 0.013092855, -0.06566104, -0.06...</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1.007841</td>\n",
              "      <td>-1.007841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>forma</td>\n",
              "      <td>[0.039309442, 0.019204998, 0.047211986, -0.112...</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.982408</td>\n",
              "      <td>-0.982408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>trabalhar,</td>\n",
              "      <td>[0.041999727, -0.08049979, -0.049231, -0.07167...</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1.002712</td>\n",
              "      <td>-1.002712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nada</td>\n",
              "      <td>[-0.017216848, -0.035219144, 0.09126132, 0.034...</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1.018203</td>\n",
              "      <td>-1.018203</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        words  ... sentiment_coeff\n",
              "0        tudo  ...       -1.019969\n",
              "1       mudou  ...       -1.007841\n",
              "2       forma  ...       -0.982408\n",
              "3  trabalhar,  ...       -1.002712\n",
              "4        nada  ...       -1.018203\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXIc3OkQv9tv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "1529f138-6f30-423c-92ed-f994f4524f1b"
      },
      "source": [
        "words.tail(5)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>vectors</th>\n",
              "      <th>cluster</th>\n",
              "      <th>cluster_value</th>\n",
              "      <th>closeness_score</th>\n",
              "      <th>sentiment_coeff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30780</th>\n",
              "      <td>@bresciia</td>\n",
              "      <td>[0.023966901, 0.12090902, 0.020043233, 0.00681...</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1.078989</td>\n",
              "      <td>-1.078989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30781</th>\n",
              "      <td>@theluks21</td>\n",
              "      <td>[0.11509398, 0.04878816, -0.033598218, 0.04876...</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1.164135</td>\n",
              "      <td>-1.164135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30782</th>\n",
              "      <td>@kozixmana</td>\n",
              "      <td>[0.031104594, -0.017839719, 0.0041649593, 0.00...</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1.115375</td>\n",
              "      <td>-1.115375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30783</th>\n",
              "      <td>@victorkazoo</td>\n",
              "      <td>[-0.082417674, -0.03384743, -0.058688905, -0.0...</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1.083299</td>\n",
              "      <td>-1.083299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30784</th>\n",
              "      <td>#renunciaperes</td>\n",
              "      <td>[0.01073382, -0.050205044, 0.008849689, 0.0268...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.148505</td>\n",
              "      <td>1.148505</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                words  ... sentiment_coeff\n",
              "30780       @bresciia  ...       -1.078989\n",
              "30781      @theluks21  ...       -1.164135\n",
              "30782      @kozixmana  ...       -1.115375\n",
              "30783    @victorkazoo  ...       -1.083299\n",
              "30784  #renunciaperes  ...        1.148505\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj1gMCxnwDP0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e223b090-a20c-43cd-d4fc-99394d688c73"
      },
      "source": [
        "words.shape"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30785, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3uHRA4m6xbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words[['words', 'sentiment_coeff']].to_csv('dicionario_sentimentos.csv', index=False)"
      ],
      "execution_count": 91,
      "outputs": []
    }
  ]
}